{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b09b98",
   "metadata": {},
   "source": [
    "Tutorial on U-NET: https://www.youtube.com/watch?v=IHq1t7NxS8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65f5c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d52f0f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n",
    "    ):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)   \n",
    "    \n",
    "def test():\n",
    "    x = torch.randn((3, 1, 161, 161))\n",
    "    model = UNET(in_channels=1, out_channels=1)\n",
    "    preds = model(x)\n",
    "    assert preds.shape == x.shape\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13589bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d4656bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamVidDataSet(Dataset):\n",
    "    def __init__(self, imgs_path, labels_path, transform=None):\n",
    "        self.imgs_path = imgs_path\n",
    "        self.labels_path = labels_path #mask\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.imgs = os.listdir(self.imgs_path)\n",
    "        self.labels = list(map(lambda x: x[:-4] + '_L.png', self.imgs)) #see train_labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.imgs_path, self.imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        \n",
    "        label_loc = os.path.join(self.labels_path, self.labels[idx])\n",
    "        label = Image.open(label_loc).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "        \n",
    "        image_tensor = T.Compose([T.ToTensor()])(image) \n",
    "        label_tensor = T.Compose([T.PILToTensor()])(label)\n",
    "        \n",
    "        return image_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c657c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d01eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = T.Compose([T.Resize(input_size, T.InterpolationMode.BICUBIC)])\n",
    "train_data = CamVidDataSet(\n",
    "        imgs_path=\"./CamVid/train/\",\n",
    "        labels_path=\"./CamVid/train_labels/\",\n",
    "        transform=transformation,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87a7e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "    train_dir,\n",
    "    train_labeldir,\n",
    "    val_dir,\n",
    "    val_labeldir,\n",
    "    batch_size,\n",
    "    train_transform,\n",
    "    val_transform,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "):\n",
    "    train_data = CamVidDataSet(\n",
    "        imgs_path=train_dir,\n",
    "        labels_path=train_labeldir,\n",
    "        transform=train_transform,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_data = CamVidDataSet(\n",
    "        imgs_path=val_dir,\n",
    "        labels_path=val_labeldir,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b58bf2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (128, 128)\n",
    "transformation = T.Compose([T.Resize(input_size, T.InterpolationMode.BICUBIC)])\n",
    "\n",
    "data_loader, data_loader_test = get_loaders(\n",
    "        train_dir=\"./CamVid/train/\",\n",
    "        train_labeldir=\"./CamVid/train_labels/\",\n",
    "        val_dir=\"./CamVid/val/\",\n",
    "        val_labeldir=\"./CamVid/val_labels/\",\n",
    "        batch_size=3,\n",
    "        train_transform=transformation,\n",
    "        val_transform=transformation,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f05f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_size = (128, 128)\n",
    "#transformation = transforms.Compose([T.Resize(input_size, T.InterpolationMode.BICUBIC)])\n",
    "#camvid_train = CamVidDataSet(\"./CamVid/train/\", \"./CamVid/train_labels/\", transform=transformation)\n",
    "#camvid_test = CamVidDataSet(\"./CamVid/val/\", \"./CamVid/val_labels/\", transform=transformation)\n",
    "\n",
    "# define training and validation data loaders\n",
    "#data_loader = torch.utils.data.DataLoader(\n",
    "#    camvid_train, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "#data_loader_test = torch.utils.data.DataLoader(\n",
    "#    camvid_test, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b82ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = UNET(in_channels=3, out_channels=3)\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e310b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "803ef711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(data_loader, model, optimizer, loss_fn, scaler):\n",
    "    for batch_idx, (data, targets) in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        targets = targets.float().to(device)\n",
    "        \n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            print(predictions)\n",
    "            print(predictions.shape)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update tqdm loop\n",
    "        #loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aec93e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2443,  0.4067,  0.8369,  ...,  0.5034, -0.4668, -0.6250],\n",
      "          [ 0.4539,  0.0213, -0.2108,  ..., -0.6089, -0.7017, -0.2235],\n",
      "          [-0.0787, -0.3960,  0.8530,  ...,  0.1588, -0.5825,  0.0978],\n",
      "          ...,\n",
      "          [-0.0436, -0.0547,  0.4263,  ..., -0.1217, -0.3823,  0.5098],\n",
      "          [-0.2230,  0.2607, -0.0968,  ...,  0.1407, -0.2086,  0.5693],\n",
      "          [-0.4233, -0.2372, -0.2905,  ...,  0.0609, -0.0867,  0.5571]],\n",
      "\n",
      "         [[-0.1826,  0.9595,  0.7344,  ...,  1.1367,  1.9434,  1.0723],\n",
      "          [ 0.6626,  0.0330,  0.0114,  ...,  0.6675,  1.1035,  0.0062],\n",
      "          [-0.3052, -0.3740,  0.1152,  ..., -0.5967,  1.2021,  0.2462],\n",
      "          ...,\n",
      "          [ 0.4229, -0.3169,  0.1106,  ..., -0.0079,  0.3704,  0.2727],\n",
      "          [ 0.3635, -0.6216,  0.0223,  ...,  0.0647,  0.2815,  0.2578],\n",
      "          [ 0.5293,  0.1503,  0.3633,  ...,  0.5518,  0.6025,  0.5771]],\n",
      "\n",
      "         [[-0.4070, -0.8076, -0.6611,  ..., -1.6611, -1.7100,  0.0323],\n",
      "          [-0.6299,  0.0986,  0.2817,  ..., -0.2922, -1.1055, -0.6025],\n",
      "          [-0.8750, -1.0137, -1.0264,  ..., -2.5840, -2.2148, -1.0088],\n",
      "          ...,\n",
      "          [ 0.0139, -0.5874, -0.6289,  ..., -0.0451,  0.0927, -0.1052],\n",
      "          [ 0.3169, -0.7725, -0.5908,  ..., -0.3574, -0.0961, -0.1283],\n",
      "          [-0.0359, -0.3867, -0.3374,  ..., -0.2377,  0.0250, -0.1129]]],\n",
      "\n",
      "\n",
      "        [[[-0.1779, -0.1534,  0.2059,  ...,  0.0034,  0.0867,  0.3503],\n",
      "          [-0.0363,  0.0087, -0.0183,  ..., -0.2566, -0.0785,  0.3921],\n",
      "          [ 0.1521, -0.6587, -0.6372,  ...,  0.3105,  0.3816,  0.5820],\n",
      "          ...,\n",
      "          [ 0.0419,  0.2025,  0.2705,  ..., -0.0249, -0.3933,  0.2010],\n",
      "          [ 0.1952,  0.1948,  0.1798,  ...,  0.1571, -0.1727,  0.5015],\n",
      "          [ 0.2412,  0.0742,  0.1160,  ...,  0.0699, -0.1512,  0.2708]],\n",
      "\n",
      "         [[ 0.5137,  0.9219,  0.6279,  ...,  0.5688,  0.4163,  0.4741],\n",
      "          [ 0.2046, -0.2109,  0.2363,  ..., -0.3765,  0.3831,  0.1210],\n",
      "          [ 0.0146, -0.1362,  0.4841,  ...,  0.1040,  0.1343,  0.1189],\n",
      "          ...,\n",
      "          [ 0.5322,  0.0138,  0.2335,  ...,  0.1301,  0.5005,  0.5464],\n",
      "          [ 0.2173, -0.2539,  0.3740,  ...,  0.1458,  0.7690,  0.4451],\n",
      "          [ 0.1672,  0.2644,  0.2334,  ...,  0.4861,  0.6831,  0.4534]],\n",
      "\n",
      "         [[-0.1648, -0.3259, -0.8359,  ..., -0.0823, -0.2627, -0.4963],\n",
      "          [-0.2834,  0.8291, -0.7373,  ...,  0.0718, -0.3989, -0.0701],\n",
      "          [-0.3213,  0.0125,  0.0331,  ..., -0.9443, -0.3611, -0.8027],\n",
      "          ...,\n",
      "          [ 0.0352, -0.1021, -0.6914,  ..., -0.3267, -0.3000, -0.5078],\n",
      "          [-0.0966, -0.4065, -0.6221,  ..., -0.5137, -0.2137, -0.4758],\n",
      "          [ 0.0511,  0.0306, -0.1020,  ..., -0.1266,  0.2522,  0.0056]]],\n",
      "\n",
      "\n",
      "        [[[-0.0913,  0.1249,  0.2981,  ...,  0.3298, -0.4163, -0.5425],\n",
      "          [ 0.5190,  0.0800, -0.6230,  ..., -0.9697, -0.9155, -0.1742],\n",
      "          [-0.3708, -0.4045,  0.3977,  ...,  0.1039, -0.9727, -0.0152],\n",
      "          ...,\n",
      "          [ 0.1888,  0.1202,  0.0937,  ..., -0.0282, -0.6313,  0.4133],\n",
      "          [ 0.0881,  0.0458, -0.0886,  ...,  0.2297, -0.1707,  0.3806],\n",
      "          [ 0.2786, -0.0580, -0.0544,  ...,  0.2286, -0.7905,  0.5659]],\n",
      "\n",
      "         [[ 0.1335,  0.5132,  0.5684,  ...,  0.9966,  2.1504,  0.8999],\n",
      "          [-0.0992,  0.4827,  1.0391,  ...,  0.0988,  0.6348,  0.1009],\n",
      "          [-0.3103, -1.2178,  1.0537,  ..., -0.6416,  1.3662,  0.2646],\n",
      "          ...,\n",
      "          [ 0.5889,  0.0402,  0.1155,  ..., -0.0070,  0.4006,  0.0473],\n",
      "          [ 0.4072, -0.2122,  0.4963,  ...,  0.1643,  0.4197, -0.0916],\n",
      "          [ 0.2881,  0.3677,  0.4700,  ...,  0.7778,  1.3096,  0.6602]],\n",
      "\n",
      "         [[-0.5420, -0.2250, -0.5635,  ..., -1.7334, -2.0469, -0.1459],\n",
      "          [-0.4829, -0.6943,  0.0923,  ..., -0.3193, -1.3096, -0.5762],\n",
      "          [ 0.0167, -0.2163, -1.4365,  ..., -1.9766, -2.0840, -1.1533],\n",
      "          ...,\n",
      "          [ 0.1538, -0.0450, -0.2212,  ..., -0.0090, -0.0165, -0.1754],\n",
      "          [ 0.1868, -0.0572,  0.0691,  ..., -0.0612, -0.0728, -0.2681],\n",
      "          [-0.2310, -0.1752, -0.2974,  ..., -0.5684, -0.0511, -0.1738]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 7.9834e-02,  6.7017e-02,  2.2363e-01,  ..., -5.3192e-02,\n",
      "           -8.0566e-02, -1.0999e-01],\n",
      "          [ 1.2195e-01,  3.8477e-01,  2.4280e-01,  ..., -2.2937e-01,\n",
      "           -4.4159e-02,  4.4727e-01],\n",
      "          [-3.6835e-02,  2.8369e-01,  3.9355e-01,  ...,  3.6816e-01,\n",
      "           -3.5181e-01,  2.3804e-03],\n",
      "          ...,\n",
      "          [-4.6234e-02,  1.5027e-01,  3.3325e-01,  ..., -1.0852e-01,\n",
      "           -4.1089e-01,  3.7378e-01],\n",
      "          [ 1.6675e-01,  1.8677e-01,  7.2693e-02,  ...,  2.1948e-01,\n",
      "           -5.0507e-02,  6.0205e-01],\n",
      "          [ 2.7148e-01,  8.0261e-02,  1.5637e-01,  ...,  4.9927e-02,\n",
      "           -1.2488e-01,  3.6841e-01]],\n",
      "\n",
      "         [[ 2.7002e-01,  5.3027e-01,  1.5076e-02,  ...,  8.9062e-01,\n",
      "            9.9902e-01,  8.5840e-01],\n",
      "          [ 7.1167e-02, -1.6235e-01,  8.6792e-02,  ...,  2.4768e-01,\n",
      "            4.3237e-01, -2.6025e-01],\n",
      "          [ 4.5215e-01,  9.0942e-03,  1.5076e-02,  ..., -3.8623e-01,\n",
      "            3.3838e-01,  2.4817e-01],\n",
      "          ...,\n",
      "          [ 4.9780e-01,  9.1919e-02,  1.2915e-01,  ...,  2.2144e-01,\n",
      "            4.2871e-01,  5.2246e-01],\n",
      "          [ 2.8931e-01, -2.6270e-01,  3.1836e-01,  ...,  2.4646e-01,\n",
      "            5.4980e-01,  3.6035e-01],\n",
      "          [ 1.5381e-01,  2.4731e-01,  3.1348e-01,  ...,  4.7632e-01,\n",
      "            6.1621e-01,  4.9365e-01]],\n",
      "\n",
      "         [[-8.0261e-02, -2.6074e-01, -2.5342e-01,  ..., -3.1055e-01,\n",
      "           -1.0474e-01, -1.6345e-01],\n",
      "          [-1.4880e-01,  1.6943e-01, -1.8091e-01,  ..., -6.4209e-02,\n",
      "           -2.5488e-01, -1.9470e-01],\n",
      "          [ 6.0303e-02, -3.3740e-01, -4.2188e-01,  ..., -9.9707e-01,\n",
      "           -6.2500e-01, -6.5234e-01],\n",
      "          ...,\n",
      "          [ 1.6479e-01, -6.8604e-02, -5.5371e-01,  ..., -1.9727e-01,\n",
      "           -2.0422e-01, -3.1006e-01],\n",
      "          [-2.7771e-02, -4.3726e-01, -4.1260e-01,  ..., -5.3027e-01,\n",
      "           -1.0883e-01, -3.7476e-01],\n",
      "          [-1.6113e-02,  2.1912e-02, -1.5894e-01,  ..., -7.0801e-02,\n",
      "            2.3657e-01, -2.8076e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3098e-01,  1.1963e-02,  6.0059e-01,  ...,  3.2129e-01,\n",
      "           -6.9824e-01, -5.0342e-01],\n",
      "          [ 4.8999e-01,  2.7979e-01,  4.4019e-01,  ..., -1.5039e-01,\n",
      "           -5.6885e-01,  3.0762e-01],\n",
      "          [-1.5491e-01,  8.6060e-02,  6.2305e-01,  ...,  3.2153e-01,\n",
      "           -3.2324e-01,  1.6211e-01],\n",
      "          ...,\n",
      "          [ 1.7407e-01, -1.5271e-01,  7.2705e-01,  ..., -1.8787e-01,\n",
      "           -4.3042e-01,  4.3359e-01],\n",
      "          [-1.9257e-02, -5.3174e-01,  1.5576e-01,  ...,  2.5220e-01,\n",
      "           -1.7908e-01,  5.4102e-01],\n",
      "          [ 2.5049e-01, -1.1401e-01, -4.3732e-02,  ...,  7.3608e-02,\n",
      "           -3.7262e-02,  4.6143e-01]],\n",
      "\n",
      "         [[ 2.3254e-02,  5.9082e-01,  8.2568e-01,  ...,  1.3594e+00,\n",
      "            1.7285e+00,  7.5195e-01],\n",
      "          [ 6.4648e-01,  7.2876e-02, -3.7964e-02,  ...,  7.7026e-02,\n",
      "            9.3115e-01, -1.5125e-01],\n",
      "          [-3.9673e-03,  1.3330e-01,  6.2354e-01,  ..., -6.7432e-01,\n",
      "            1.2402e+00, -1.6357e-01],\n",
      "          ...,\n",
      "          [ 5.4297e-01, -1.8774e-01,  1.2915e-01,  ...,  1.2512e-01,\n",
      "            5.1660e-01,  2.2021e-01],\n",
      "          [ 6.5771e-01,  7.6514e-01,  5.8887e-01,  ...,  2.2266e-01,\n",
      "            5.5762e-01,  3.0420e-01],\n",
      "          [ 6.7090e-01,  4.6289e-01,  4.0356e-01,  ...,  4.6948e-01,\n",
      "            5.2051e-01,  5.2930e-01]],\n",
      "\n",
      "         [[-2.8052e-01, -2.1118e-01, -4.6826e-01,  ..., -1.2236e+00,\n",
      "           -7.4414e-01,  1.6113e-01],\n",
      "          [-1.7737e-01,  1.9849e-01, -3.4698e-02,  ..., -1.4783e-01,\n",
      "           -6.2207e-01, -2.6221e-01],\n",
      "          [-2.0203e-01, -4.8560e-01, -7.5781e-01,  ..., -1.6719e+00,\n",
      "           -1.4912e+00, -4.6460e-01],\n",
      "          ...,\n",
      "          [-1.2018e-01, -1.7261e-01, -5.5957e-01,  ..., -8.0383e-02,\n",
      "           -1.7822e-02, -1.1383e-01],\n",
      "          [ 2.4170e-01,  3.9795e-02, -2.5732e-01,  ..., -5.3906e-01,\n",
      "           -2.1899e-01, -2.3157e-01],\n",
      "          [ 3.2593e-02,  3.1104e-01, -2.1558e-01,  ..., -1.9897e-01,\n",
      "            6.4453e-02, -6.7505e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2024e-02,  9.7534e-02, -4.6997e-03,  ...,  4.7607e-01,\n",
      "           -1.3440e-01, -4.3457e-01],\n",
      "          [-1.9263e-01,  2.8906e-01,  4.4238e-01,  ..., -1.6729e+00,\n",
      "           -7.8320e-01,  5.7764e-01],\n",
      "          [ 2.2900e-01, -3.6108e-01,  1.7419e-01,  ...,  5.3925e-02,\n",
      "           -9.1211e-01,  3.1616e-01],\n",
      "          ...,\n",
      "          [-1.8005e-03,  3.3740e-01,  2.0911e-01,  ..., -3.3295e-02,\n",
      "           -5.5664e-01,  3.0420e-01],\n",
      "          [ 1.5674e-01,  5.1239e-02, -3.9398e-02,  ...,  3.8037e-01,\n",
      "           -1.7419e-01,  4.5996e-01],\n",
      "          [ 2.4304e-01, -1.3733e-01, -3.0884e-01,  ...,  4.1962e-02,\n",
      "           -8.1104e-01,  5.9229e-01]],\n",
      "\n",
      "         [[ 3.1299e-01,  2.6172e-01,  3.8037e-01,  ...,  1.5322e+00,\n",
      "            2.0039e+00,  7.6807e-01],\n",
      "          [ 1.8970e-01, -1.7627e-01, -3.0786e-01,  ..., -5.4492e-01,\n",
      "            1.3115e+00, -1.0576e+00],\n",
      "          [ 4.4995e-01,  5.1953e-01,  4.8853e-01,  ..., -4.5166e-01,\n",
      "            1.0781e+00,  1.2097e-01],\n",
      "          ...,\n",
      "          [ 6.2109e-01, -1.7358e-01, -3.6621e-04,  ...,  4.5227e-02,\n",
      "            3.1787e-01,  8.3191e-02],\n",
      "          [ 3.3203e-01, -4.3579e-02,  3.9160e-01,  ...,  1.3403e-01,\n",
      "            3.4595e-01,  1.8408e-01],\n",
      "          [ 2.6709e-01,  3.1079e-01,  4.2700e-01,  ...,  7.9297e-01,\n",
      "            1.1016e+00,  6.0498e-01]],\n",
      "\n",
      "         [[-2.0898e-01, -4.2285e-01, -5.0781e-01,  ..., -1.1318e+00,\n",
      "           -2.1328e+00, -1.4270e-01],\n",
      "          [-1.1499e-01,  4.0186e-01, -4.4824e-01,  ..., -4.5923e-01,\n",
      "           -8.2227e-01, -1.3794e-01],\n",
      "          [-1.6943e-01, -1.3599e-01, -3.1616e-01,  ..., -1.7959e+00,\n",
      "           -1.7148e+00, -1.3096e+00],\n",
      "          ...,\n",
      "          [ 2.2510e-01,  1.2891e-01,  1.2939e-01,  ..., -4.2938e-02,\n",
      "           -1.0876e-01,  6.9946e-02],\n",
      "          [ 1.0669e-01,  6.2256e-02,  7.1655e-02,  ..., -3.0298e-01,\n",
      "           -4.6539e-02, -2.9321e-01],\n",
      "          [-1.5417e-01, -6.7383e-02, -3.9819e-01,  ..., -4.7266e-01,\n",
      "           -1.4062e-01, -8.4961e-02]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 9.1370e-02, -3.2990e-02,  2.1765e-01,  ...,  5.0342e-01,\n",
      "           -3.8257e-01, -4.3652e-01],\n",
      "          [ 1.7017e-01,  4.0039e-01,  4.7656e-01,  ..., -7.5244e-01,\n",
      "           -9.0527e-01, -1.1584e-01],\n",
      "          [ 1.8982e-01,  2.0251e-01,  5.2637e-01,  ...,  6.4941e-01,\n",
      "           -6.6553e-01, -3.6407e-02],\n",
      "          ...,\n",
      "          [-9.1431e-02,  6.9946e-02,  2.8931e-01,  ..., -2.2595e-01,\n",
      "           -3.0713e-01,  4.3750e-01],\n",
      "          [ 9.7168e-02,  1.3013e-01,  1.8738e-02,  ...,  2.7417e-01,\n",
      "           -5.2338e-02,  5.6445e-01],\n",
      "          [ 2.8296e-01,  1.5515e-01,  1.6565e-01,  ...,  9.4849e-02,\n",
      "           -7.8979e-02,  4.7754e-01]],\n",
      "\n",
      "         [[ 3.8257e-01,  4.1943e-01,  9.6497e-02,  ...,  1.4639e+00,\n",
      "            2.2070e+00,  1.1133e+00],\n",
      "          [ 1.4380e-01, -7.8979e-02, -7.5439e-02,  ...,  1.5320e-02,\n",
      "            7.2363e-01,  8.7158e-02],\n",
      "          [ 1.8665e-01,  9.5215e-02,  1.3855e-02,  ..., -9.2285e-01,\n",
      "            1.1426e+00,  2.4963e-01],\n",
      "          ...,\n",
      "          [ 6.6504e-01,  2.4719e-01,  2.4915e-01,  ...,  1.7639e-01,\n",
      "            4.6631e-01,  4.3115e-01],\n",
      "          [ 3.4326e-01, -2.2461e-01,  7.7209e-02,  ...,  1.1401e-01,\n",
      "            3.1396e-01,  3.1421e-01],\n",
      "          [ 2.2644e-01,  3.4863e-01,  2.5879e-01,  ...,  6.2451e-01,\n",
      "            6.3037e-01,  5.4883e-01]],\n",
      "\n",
      "         [[-1.6040e-01, -2.2437e-01, -4.1187e-01,  ..., -1.9170e+00,\n",
      "           -1.9580e+00, -1.4355e-01],\n",
      "          [-5.6366e-02,  7.4341e-02, -1.1847e-01,  ..., -2.7734e-01,\n",
      "           -1.1689e+00, -6.4844e-01],\n",
      "          [ 1.1145e-01, -1.5540e-01, -4.1675e-01,  ..., -2.2188e+00,\n",
      "           -2.2480e+00, -1.2168e+00],\n",
      "          ...,\n",
      "          [ 2.8906e-01,  4.0039e-02, -4.6680e-01,  ..., -6.6345e-02,\n",
      "           -1.8848e-01, -1.4880e-01],\n",
      "          [ 1.1011e-01, -3.2324e-01, -1.7932e-01,  ..., -4.6436e-01,\n",
      "           -9.4543e-02, -1.2976e-01],\n",
      "          [ 1.0132e-02,  4.2358e-02, -2.3865e-01,  ..., -1.0522e-01,\n",
      "            1.6138e-01, -5.7617e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.1406e-01,  1.0962e-01, -1.0315e-01,  ...,  5.1221e-01,\n",
      "           -4.4531e-01, -3.4912e-01],\n",
      "          [-5.9479e-02, -2.0459e-01, -5.6396e-01,  ..., -7.3584e-01,\n",
      "           -8.5742e-01,  8.9355e-02],\n",
      "          [ 4.2877e-03,  1.2646e-01, -4.8730e-01,  ...,  4.3384e-01,\n",
      "           -5.2686e-01,  7.1411e-02],\n",
      "          ...,\n",
      "          [ 1.4197e-01,  1.7651e-01,  2.3560e-01,  ..., -1.5479e-01,\n",
      "           -3.3594e-01,  4.3701e-01],\n",
      "          [ 1.5881e-01,  1.4612e-01, -8.5815e-02,  ...,  2.5610e-01,\n",
      "           -1.3806e-01,  5.3809e-01],\n",
      "          [ 3.3032e-01,  1.0071e-01, -5.1605e-02,  ...,  6.0547e-02,\n",
      "           -5.9052e-02,  4.3188e-01]],\n",
      "\n",
      "         [[ 5.5273e-01,  9.7266e-01,  7.5928e-01,  ...,  1.5625e+00,\n",
      "            1.8281e+00,  9.9609e-01],\n",
      "          [ 9.3018e-01, -2.1216e-01,  3.4082e-01,  ...,  3.5278e-01,\n",
      "            7.8125e-01, -1.9348e-02],\n",
      "          [-5.6763e-02,  2.1411e-01,  9.0576e-01,  ..., -8.0127e-01,\n",
      "            1.2900e+00,  4.0918e-01],\n",
      "          ...,\n",
      "          [ 6.4209e-01,  1.1292e-02,  1.3782e-01,  ...,  2.2620e-01,\n",
      "            4.8413e-01,  1.6577e-01],\n",
      "          [ 4.1772e-01, -2.3584e-01,  4.3799e-01,  ...,  1.1835e-01,\n",
      "            6.1133e-01,  2.9883e-01],\n",
      "          [ 2.2412e-01,  3.2910e-01,  4.3359e-01,  ...,  6.5674e-01,\n",
      "            6.3818e-01,  5.3076e-01]],\n",
      "\n",
      "         [[-3.5571e-01, -5.9863e-01, -7.4121e-01,  ..., -1.5645e+00,\n",
      "           -1.4404e+00,  4.2603e-02],\n",
      "          [-2.8662e-01,  7.5806e-02,  5.5420e-02,  ..., -1.8872e-01,\n",
      "           -6.1914e-01, -3.2642e-01],\n",
      "          [-3.4149e-02, -4.1553e-01, -4.6631e-01,  ..., -2.0020e+00,\n",
      "           -1.8604e+00, -9.9707e-01],\n",
      "          ...,\n",
      "          [ 1.2610e-01, -1.1597e-03, -2.8223e-01,  ..., -6.0883e-02,\n",
      "           -3.4790e-02, -1.4844e-01],\n",
      "          [ 1.4575e-01, -1.0327e-01,  1.6357e-02,  ..., -4.0894e-01,\n",
      "           -1.1377e-01, -1.8506e-01],\n",
      "          [-1.7065e-01, -4.9500e-02, -1.7822e-01,  ..., -1.7078e-01,\n",
      "            1.1401e-01, -7.6904e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2402e-01, -1.7120e-02,  1.9324e-01,  ...,  1.1047e-01,\n",
      "           -3.5864e-01, -2.3914e-01],\n",
      "          [ 3.0090e-02,  2.5488e-01,  1.7444e-01,  ..., -1.4043e+00,\n",
      "           -8.5254e-01,  6.8018e-01],\n",
      "          [ 3.0713e-01,  5.2979e-01,  3.0200e-01,  ..., -6.5820e-01,\n",
      "           -6.0645e-01,  1.6101e-01],\n",
      "          ...,\n",
      "          [ 1.7969e-01,  2.1851e-01,  2.2229e-01,  ..., -1.3196e-01,\n",
      "           -3.5278e-01,  3.9355e-01],\n",
      "          [ 1.4233e-01,  8.4106e-02, -1.0156e-01,  ...,  2.0276e-01,\n",
      "           -1.6553e-01,  4.7412e-01],\n",
      "          [ 2.2705e-01,  2.8885e-02, -1.8408e-01,  ..., -5.9845e-02,\n",
      "           -2.7930e-01,  5.6836e-01]],\n",
      "\n",
      "         [[ 3.9062e-01,  5.0244e-01,  2.3767e-01,  ...,  1.7793e+00,\n",
      "            2.5410e+00,  5.0195e-01],\n",
      "          [ 4.6460e-01, -1.0767e-01, -1.8335e-01,  ...,  3.3594e-01,\n",
      "            7.1729e-01,  4.7089e-02],\n",
      "          [ 1.9348e-01,  3.8635e-02,  1.5942e-01,  ..., -1.2061e+00,\n",
      "            5.9766e-01,  7.2949e-01],\n",
      "          ...,\n",
      "          [ 6.2646e-01,  8.5632e-02,  1.3354e-01,  ...,  2.7954e-02,\n",
      "            4.6948e-01,  1.4880e-01],\n",
      "          [ 3.6304e-01, -1.5210e-01,  5.3320e-01,  ...,  3.7994e-02,\n",
      "            5.6250e-01,  2.1216e-01],\n",
      "          [ 2.2009e-01,  3.2227e-01,  4.4067e-01,  ...,  6.7432e-01,\n",
      "            7.9395e-01,  6.1035e-01]],\n",
      "\n",
      "         [[-3.5718e-01, -3.5913e-01, -4.4263e-01,  ..., -1.6484e+00,\n",
      "           -2.2266e+00, -2.1326e-01],\n",
      "          [-8.8562e-02,  2.2827e-01, -1.3147e-01,  ..., -1.0425e-01,\n",
      "           -5.9766e-01, -3.6841e-01],\n",
      "          [-2.7100e-01, -4.2700e-01, -3.2104e-01,  ..., -1.7109e+00,\n",
      "           -2.1172e+00, -2.0488e+00],\n",
      "          ...,\n",
      "          [ 1.0413e-01, -8.1177e-03, -1.6260e-01,  ...,  7.1411e-02,\n",
      "           -5.2063e-02,  4.4067e-02],\n",
      "          [ 1.1902e-01, -9.6069e-02,  7.8247e-02,  ..., -3.1152e-01,\n",
      "           -4.4586e-02, -4.7729e-02],\n",
      "          [-2.2229e-01, -1.9543e-01, -1.9983e-01,  ..., -2.9932e-01,\n",
      "            6.0425e-02, -1.1603e-01]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 8.1055e-02, -1.2976e-01,  2.9907e-01,  ...,  1.2744e-01,\n",
      "            1.1377e-01,  2.1228e-01],\n",
      "          [ 1.3782e-01,  3.4692e-01,  2.7856e-01,  ..., -7.7734e-01,\n",
      "           -4.9854e-01,  3.4863e-01],\n",
      "          [ 3.9978e-03,  2.8369e-01,  2.7515e-01,  ...,  4.0698e-01,\n",
      "            8.3862e-02,  7.0361e-01],\n",
      "          ...,\n",
      "          [-1.1597e-02,  3.0869e-02,  2.3657e-01,  ..., -1.6455e-01,\n",
      "           -4.4556e-01,  3.7915e-01],\n",
      "          [ 2.2559e-01,  1.4661e-01,  2.2125e-02,  ...,  2.6123e-01,\n",
      "           -1.2024e-02,  6.5527e-01],\n",
      "          [ 3.2422e-01,  7.3853e-02,  1.4246e-01,  ...,  4.6997e-02,\n",
      "           -6.8237e-02,  3.5156e-01]],\n",
      "\n",
      "         [[ 3.7598e-01,  6.7041e-01,  1.1902e-01,  ...,  8.7451e-01,\n",
      "            4.2114e-01,  6.0205e-01],\n",
      "          [ 1.2903e-01, -2.6489e-01,  2.3560e-02,  ...,  1.6162e-01,\n",
      "            4.5135e-02, -1.2927e-01],\n",
      "          [ 3.2959e-01, -8.2153e-02,  9.1736e-02,  ..., -1.1316e-01,\n",
      "           -6.0181e-02,  2.1765e-01],\n",
      "          ...,\n",
      "          [ 4.9658e-01, -3.7231e-03,  1.2878e-01,  ...,  2.6562e-01,\n",
      "            4.0112e-01,  2.9663e-01],\n",
      "          [ 2.7100e-01, -3.0981e-01,  3.5645e-01,  ...,  1.7578e-01,\n",
      "            6.5771e-01,  2.9980e-01],\n",
      "          [ 8.5815e-02,  2.6367e-01,  2.9932e-01,  ...,  4.9536e-01,\n",
      "            5.3418e-01,  5.1367e-01]],\n",
      "\n",
      "         [[-7.1350e-02, -1.6260e-01, -2.6562e-01,  ..., -2.9541e-01,\n",
      "            6.3843e-02, -3.2129e-01],\n",
      "          [-1.1865e-01,  6.1157e-02, -1.8494e-02,  ...,  3.8770e-01,\n",
      "            2.6074e-01,  7.8125e-02],\n",
      "          [-4.3335e-03, -4.2773e-01, -2.7539e-01,  ..., -4.5044e-01,\n",
      "           -2.3096e-01, -2.1191e-01],\n",
      "          ...,\n",
      "          [ 1.6870e-01, -6.3721e-02, -6.5625e-01,  ..., -1.5576e-01,\n",
      "           -8.4717e-02, -1.9019e-01],\n",
      "          [-1.6968e-02, -3.9844e-01, -4.3799e-01,  ..., -4.4531e-01,\n",
      "           -4.2450e-02, -3.9111e-01],\n",
      "          [-3.4851e-02,  7.5195e-02, -2.2144e-01,  ..., -5.8258e-02,\n",
      "            1.8970e-01, -5.0232e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0527e-01,  5.9277e-01, -3.4668e-01,  ..., -1.8848e-01,\n",
      "            2.3047e-01,  5.3320e-01],\n",
      "          [ 8.4766e-01,  3.3447e-01,  8.6060e-02,  ..., -2.9492e-01,\n",
      "           -1.3806e-01,  4.8584e-01],\n",
      "          [ 4.4922e-01, -2.6685e-01,  6.1523e-01,  ..., -6.3843e-02,\n",
      "            7.0801e-02,  6.0156e-01],\n",
      "          ...,\n",
      "          [ 6.8726e-02,  1.0974e-01, -1.8262e-01,  ..., -1.1328e-01,\n",
      "           -4.3311e-01,  5.1562e-01],\n",
      "          [ 7.8491e-02,  1.9031e-01, -1.0938e-01,  ...,  1.8628e-01,\n",
      "           -1.3489e-01,  6.1670e-01],\n",
      "          [ 2.1289e-01,  1.2024e-01, -8.3862e-02,  ...,  6.0760e-02,\n",
      "           -1.8616e-03,  4.8877e-01]],\n",
      "\n",
      "         [[-5.2637e-01,  7.0996e-01,  2.4004e+00,  ...,  5.4541e-01,\n",
      "            2.8882e-01,  2.4939e-01],\n",
      "          [ 5.4980e-01,  6.7871e-01,  9.3506e-01,  ..., -2.9480e-02,\n",
      "            4.8047e-01, -1.0266e-01],\n",
      "          [-6.4404e-01,  3.6011e-01,  6.3135e-01,  ...,  3.4790e-03,\n",
      "            4.3311e-01, -4.9561e-02],\n",
      "          ...,\n",
      "          [ 4.1040e-01,  2.3694e-01,  5.1367e-01,  ...,  1.9653e-01,\n",
      "            3.9990e-01,  1.0956e-01],\n",
      "          [ 2.3865e-01, -2.4707e-01,  2.6660e-01,  ...,  1.5405e-01,\n",
      "            4.2285e-01,  2.2266e-01],\n",
      "          [ 2.9126e-01,  1.7432e-01,  2.4072e-01,  ...,  6.3867e-01,\n",
      "            6.3086e-01,  5.7617e-01]],\n",
      "\n",
      "         [[-3.4424e-01, -1.1108e-01, -9.3652e-01,  ..., -3.1128e-03,\n",
      "           -3.4937e-01, -3.8281e-01],\n",
      "          [-7.1582e-01,  4.5435e-01, -1.8372e-02,  ..., -6.5308e-02,\n",
      "            7.4219e-02, -1.3184e-01],\n",
      "          [-6.3184e-01, -5.8301e-01, -1.5703e+00,  ..., -5.1709e-01,\n",
      "           -1.8530e-01, -8.7695e-01],\n",
      "          ...,\n",
      "          [ 1.2939e-01,  1.0876e-01,  4.1382e-02,  ..., -1.2146e-02,\n",
      "            9.9609e-02, -6.0089e-02],\n",
      "          [ 1.5234e-01, -1.3611e-01,  1.5173e-01,  ..., -4.5215e-01,\n",
      "           -1.3989e-01, -1.5710e-01],\n",
      "          [-7.4585e-02, -1.5063e-01, -1.3611e-01,  ..., -1.3965e-01,\n",
      "           -4.9438e-03, -9.6252e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0654e-01,  7.1045e-01,  9.2041e-01,  ...,  4.6753e-01,\n",
      "           -3.9624e-01, -3.8892e-01],\n",
      "          [ 2.1069e-01,  3.7329e-01,  7.7100e-01,  ..., -8.4033e-01,\n",
      "           -8.7891e-01, -1.6455e-01],\n",
      "          [-2.2693e-01,  4.0381e-01,  1.2598e+00,  ...,  6.5283e-01,\n",
      "           -8.1543e-01, -7.7026e-02],\n",
      "          ...,\n",
      "          [ 8.5266e-02,  1.3794e-01,  3.2471e-02,  ..., -2.7496e-02,\n",
      "           -6.9873e-01,  2.5806e-01],\n",
      "          [ 1.4929e-01, -2.8595e-02,  2.3877e-01,  ...,  5.1855e-01,\n",
      "           -2.0142e-01,  3.9478e-01],\n",
      "          [ 3.5718e-01,  8.5632e-02,  4.1443e-02,  ...,  1.2708e-01,\n",
      "           -1.0068e+00,  6.2598e-01]],\n",
      "\n",
      "         [[-4.2627e-01, -1.1646e-01,  2.4622e-01,  ...,  1.3867e+00,\n",
      "            2.0859e+00,  9.6191e-01],\n",
      "          [ 1.1865e-01,  3.7402e-01,  6.0303e-01,  ..., -8.7402e-02,\n",
      "            6.7383e-01,  1.9299e-01],\n",
      "          [-3.5132e-01,  5.1660e-01,  2.9590e-01,  ..., -8.1006e-01,\n",
      "            1.3174e+00,  3.9453e-01],\n",
      "          ...,\n",
      "          [ 6.0449e-01, -1.9531e-03,  4.6313e-01,  ...,  2.7881e-01,\n",
      "            5.9912e-01,  3.7994e-02],\n",
      "          [ 3.8721e-01, -1.9385e-01,  5.7764e-01,  ...,  2.4731e-01,\n",
      "            1.1841e-01, -7.4585e-02],\n",
      "          [ 2.6953e-01,  3.1055e-01,  1.8579e-01,  ...,  7.9883e-01,\n",
      "            1.2803e+00,  6.2988e-01]],\n",
      "\n",
      "         [[-4.6387e-03, -3.3887e-01, -1.0830e+00,  ..., -1.8398e+00,\n",
      "           -1.8623e+00, -1.0217e-01],\n",
      "          [-3.2568e-01, -4.4873e-01, -3.4351e-01,  ..., -3.6743e-01,\n",
      "           -1.1973e+00, -5.9082e-01],\n",
      "          [-3.2007e-01, -1.5957e+00, -2.3125e+00,  ..., -2.2148e+00,\n",
      "           -2.3535e+00, -1.2607e+00],\n",
      "          ...,\n",
      "          [ 2.5122e-01, -1.5308e-01, -2.7271e-01,  ...,  5.3345e-02,\n",
      "           -1.1316e-01,  1.8921e-02],\n",
      "          [ 7.8857e-02, -3.8159e-01, -1.5564e-01,  ..., -2.2290e-01,\n",
      "           -9.5886e-02, -2.6562e-01],\n",
      "          [-1.2024e-01,  1.5210e-01, -3.1543e-01,  ..., -5.3027e-01,\n",
      "           -4.7638e-02, -1.6528e-01]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 4.2407e-01,  4.1187e-01,  1.8176e-01,  ...,  3.7964e-02,\n",
      "           -1.7944e-01,  7.6843e-02],\n",
      "          [ 1.0791e+00, -6.9214e-02, -7.0361e-01,  ..., -5.7812e-01,\n",
      "           -3.4961e-01, -4.4220e-02],\n",
      "          [ 7.5879e-01, -1.3062e-01,  5.5859e-01,  ...,  3.7811e-02,\n",
      "           -5.3906e-01, -1.2903e-01],\n",
      "          ...,\n",
      "          [-4.5502e-02,  6.2866e-02,  9.2102e-02,  ..., -1.9592e-01,\n",
      "            1.3672e-01, -1.0266e-01],\n",
      "          [ 1.3525e-01, -1.5991e-02, -7.1106e-03,  ..., -2.1313e-01,\n",
      "           -2.8839e-02,  5.3223e-01],\n",
      "          [ 6.7688e-02, -1.7529e-01, -1.0840e-01,  ...,  2.1252e-01,\n",
      "           -7.5928e-01,  5.9033e-01]],\n",
      "\n",
      "         [[-9.1992e-01,  2.1033e-01,  1.1279e+00,  ...,  1.8184e+00,\n",
      "            1.3809e+00,  9.4531e-01],\n",
      "          [ 2.1094e-01,  6.4258e-01,  1.1377e+00,  ...,  2.9492e-01,\n",
      "            2.6172e-01,  3.8794e-01],\n",
      "          [-6.1523e-01, -5.4492e-01,  6.5332e-01,  ..., -2.9980e-01,\n",
      "            5.6104e-01, -6.1230e-01],\n",
      "          ...,\n",
      "          [ 2.9541e-01,  1.3452e-01,  1.8201e-01,  ...,  1.0358e-01,\n",
      "            7.5977e-01, -1.0706e-01],\n",
      "          [ 3.0103e-01, -1.4099e-01,  3.5181e-01,  ...,  2.3682e-01,\n",
      "            6.1719e-01,  1.7017e-01],\n",
      "          [ 2.2241e-01,  3.6401e-01,  4.7388e-01,  ..., -5.6396e-02,\n",
      "            1.4502e+00,  5.8740e-01]],\n",
      "\n",
      "         [[-3.8013e-01, -1.1310e-01, -9.7754e-01,  ..., -9.3652e-01,\n",
      "           -8.0566e-01, -4.9463e-01],\n",
      "          [-9.6680e-01, -8.8477e-01,  2.7905e-01,  ..., -7.5293e-01,\n",
      "           -6.9238e-01,  2.0947e-01],\n",
      "          [-1.3213e+00, -1.0947e+00, -2.5781e+00,  ..., -1.4307e+00,\n",
      "           -1.8887e+00, -6.1230e-01],\n",
      "          ...,\n",
      "          [ 1.4209e-01, -1.3794e-02, -1.5625e-01,  ...,  1.1890e-01,\n",
      "           -2.5122e-01, -7.9297e-01],\n",
      "          [ 6.9580e-02, -7.3669e-02, -1.9165e-02,  ..., -9.4971e-02,\n",
      "            1.0522e-01, -3.3203e-01],\n",
      "          [-1.8604e-01, -1.3611e-01, -1.8909e-01,  ..., -8.2812e-01,\n",
      "            2.4658e-02, -2.9785e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0142e-01, -3.3813e-01, -2.4866e-01,  ...,  2.1655e-01,\n",
      "            1.4417e-01,  2.9468e-01],\n",
      "          [ 3.3203e-01, -2.4792e-01, -5.2197e-01,  ..., -3.1421e-01,\n",
      "           -2.8540e-01,  3.8770e-01],\n",
      "          [ 5.1611e-01,  1.6089e-01, -7.3730e-01,  ...,  9.0698e-02,\n",
      "           -2.7832e-01,  3.7036e-01],\n",
      "          ...,\n",
      "          [-7.0312e-02,  1.5430e-01,  1.6125e-01,  ..., -8.2520e-02,\n",
      "           -3.4180e-01,  3.9355e-01],\n",
      "          [ 1.8433e-01,  2.8473e-02, -4.6417e-02,  ...,  2.9150e-01,\n",
      "           -9.4116e-02,  5.4541e-01],\n",
      "          [ 1.5808e-01,  8.0566e-02,  5.3284e-02,  ...,  6.2866e-02,\n",
      "            2.4460e-02,  3.4155e-01]],\n",
      "\n",
      "         [[-3.4448e-01,  1.1553e+00,  1.5273e+00,  ...,  2.6904e-01,\n",
      "            4.7510e-01,  3.8843e-01],\n",
      "          [ 6.3965e-01,  1.6394e-01,  3.5278e-01,  ..., -5.1758e-02,\n",
      "            1.4636e-01, -2.2290e-01],\n",
      "          [-1.0869e+00, -1.0361e+00,  6.1462e-02,  ..., -1.5259e-02,\n",
      "            5.8545e-01,  9.1614e-02],\n",
      "          ...,\n",
      "          [ 4.4482e-01,  5.5847e-02,  1.3599e-01,  ...,  2.8662e-01,\n",
      "            5.0000e-01,  1.8018e-01],\n",
      "          [ 3.9624e-01, -1.6382e-01,  3.8062e-01,  ...,  7.2876e-02,\n",
      "            4.6313e-01,  3.3203e-01],\n",
      "          [ 2.3962e-01,  2.8125e-01,  3.8379e-01,  ...,  5.1221e-01,\n",
      "            5.0586e-01,  4.8608e-01]],\n",
      "\n",
      "         [[-3.8428e-01, -2.2217e-02, -5.5078e-01,  ..., -2.0386e-01,\n",
      "           -2.0093e-01, -2.6855e-01],\n",
      "          [-7.4121e-01,  3.6377e-02,  1.1340e-01,  ...,  3.1396e-01,\n",
      "           -3.6060e-01, -7.7759e-02],\n",
      "          [-9.4824e-01, -9.2578e-01, -9.9512e-01,  ..., -3.9087e-01,\n",
      "           -3.7402e-01, -2.8638e-01],\n",
      "          ...,\n",
      "          [ 1.0962e-01, -1.8311e-03, -3.3447e-02,  ..., -7.7332e-02,\n",
      "           -2.0386e-02, -1.7773e-01],\n",
      "          [ 1.1523e-01, -7.2815e-02,  1.1462e-01,  ..., -4.8804e-01,\n",
      "           -5.4626e-02, -2.3438e-01],\n",
      "          [-2.1338e-01, -8.5266e-02, -2.1313e-01,  ..., -9.1370e-02,\n",
      "            1.1755e-01, -4.7455e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8960e-02,  1.0413e-01,  1.0901e-01,  ...,  3.9282e-01,\n",
      "           -2.2937e-01, -7.1680e-01],\n",
      "          [ 8.7769e-02,  2.8198e-01, -2.1423e-02,  ..., -9.5703e-01,\n",
      "           -5.9180e-01, -2.9346e-01],\n",
      "          [ 9.9854e-02,  2.2559e-01,  2.3291e-01,  ..., -6.1981e-02,\n",
      "           -3.3203e-01,  9.1187e-02],\n",
      "          ...,\n",
      "          [-5.2032e-02,  1.4429e-01,  3.6719e-01,  ..., -1.0156e-01,\n",
      "           -2.9468e-01,  3.1714e-01],\n",
      "          [ 1.7444e-01,  1.0156e-01, -3.1036e-02,  ...,  2.1667e-01,\n",
      "           -8.4717e-02,  5.4248e-01],\n",
      "          [ 2.3022e-01,  8.8074e-02,  1.1597e-01,  ...,  6.1646e-02,\n",
      "           -7.1411e-02,  3.3716e-01]],\n",
      "\n",
      "         [[ 3.5474e-01,  4.6851e-01,  3.4253e-01,  ...,  1.4033e+00,\n",
      "            2.0781e+00,  1.3857e+00],\n",
      "          [ 3.6084e-01, -1.1108e-01, -2.6306e-02,  ...,  5.9961e-01,\n",
      "            1.4121e+00,  4.1199e-02],\n",
      "          [ 2.3462e-01, -4.1626e-02,  3.5083e-01,  ..., -5.7129e-01,\n",
      "            1.3320e+00,  1.4062e-01],\n",
      "          ...,\n",
      "          [ 4.4238e-01, -5.7617e-02,  9.5459e-02,  ...,  1.5747e-01,\n",
      "            3.5645e-01,  3.3398e-01],\n",
      "          [ 2.8076e-01, -1.9336e-01,  3.2495e-01,  ...,  1.1194e-01,\n",
      "            5.4395e-01,  2.9834e-01],\n",
      "          [ 1.3904e-01,  3.3057e-01,  3.9478e-01,  ...,  4.5850e-01,\n",
      "            3.9136e-01,  4.6313e-01]],\n",
      "\n",
      "         [[-2.0654e-01, -3.2153e-01, -2.4219e-01,  ..., -1.8154e+00,\n",
      "           -1.7910e+00, -1.6064e-01],\n",
      "          [-5.4626e-02,  8.8257e-02, -7.5317e-02,  ..., -2.5854e-01,\n",
      "           -9.5410e-01, -4.2627e-01],\n",
      "          [-2.8369e-01, -5.5371e-01, -2.3047e-01,  ..., -2.3555e+00,\n",
      "           -2.2871e+00, -1.3613e+00],\n",
      "          ...,\n",
      "          [ 1.5161e-01, -7.8979e-02, -3.7378e-01,  ..., -1.6406e-01,\n",
      "           -5.8563e-02, -1.5979e-01],\n",
      "          [ 5.4321e-02, -1.7737e-01, -8.3374e-02,  ..., -4.1870e-01,\n",
      "           -2.7344e-02, -3.2031e-01],\n",
      "          [-9.0454e-02, -3.5278e-02, -2.2595e-01,  ..., -8.0811e-02,\n",
      "            2.2388e-01, -1.3000e-02]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 4.7266e-01,  2.2424e-01,  1.9434e-01,  ...,  5.1611e-01,\n",
      "           -4.8145e-01, -6.2793e-01],\n",
      "          [ 1.1797e+00, -2.4182e-01, -5.1465e-01,  ..., -4.4409e-01,\n",
      "           -7.2852e-01, -1.2805e-01],\n",
      "          [ 4.2114e-01, -2.3572e-01,  3.6206e-01,  ...,  1.7554e-01,\n",
      "           -6.2207e-01,  1.5283e-01],\n",
      "          ...,\n",
      "          [ 2.6709e-01,  5.6543e-01,  4.4250e-02,  ..., -5.5084e-02,\n",
      "           -6.0059e-01,  2.8540e-01],\n",
      "          [-7.7881e-02, -1.5479e-01, -2.7954e-02,  ...,  3.9453e-01,\n",
      "           -1.9482e-01,  4.0527e-01],\n",
      "          [ 1.9272e-02,  1.4050e-01, -6.9678e-01,  ...,  3.8025e-02,\n",
      "           -8.0713e-01,  5.6201e-01]],\n",
      "\n",
      "         [[-8.0664e-01,  4.5947e-01,  1.2393e+00,  ...,  1.1064e+00,\n",
      "            1.9092e+00,  1.1484e+00],\n",
      "          [ 2.8662e-01,  5.3857e-01,  8.1641e-01,  ...,  4.1138e-01,\n",
      "            1.0879e+00, -1.7969e-01],\n",
      "          [-6.2646e-01, -2.8589e-01,  3.8037e-01,  ..., -6.8506e-01,\n",
      "            1.2520e+00,  2.3694e-01],\n",
      "          ...,\n",
      "          [ 3.5425e-01,  2.5732e-01,  1.9873e-01,  ...,  1.8066e-01,\n",
      "            5.1172e-01,  2.8381e-02],\n",
      "          [ 8.6084e-01,  6.2695e-01,  2.5439e-01,  ...,  2.8760e-01,\n",
      "            2.1265e-01,  7.6294e-02],\n",
      "          [ 8.1201e-01,  1.3794e-01,  2.2815e-01,  ...,  6.9287e-01,\n",
      "            1.0547e+00,  6.3867e-01]],\n",
      "\n",
      "         [[-4.3530e-01, -1.5845e-01, -7.2461e-01,  ..., -1.6436e+00,\n",
      "           -1.6387e+00, -3.4180e-03],\n",
      "          [-1.0469e+00, -3.3594e-01,  1.1682e-01,  ..., -1.7529e-01,\n",
      "           -1.0029e+00, -6.4844e-01],\n",
      "          [-9.8438e-01, -1.2051e+00, -2.0449e+00,  ..., -2.4414e+00,\n",
      "           -2.0215e+00, -1.0479e+00],\n",
      "          ...,\n",
      "          [-2.3877e-01, -2.6245e-01, -5.4297e-01,  ...,  1.0852e-01,\n",
      "           -1.4172e-01,  1.5112e-01],\n",
      "          [ 3.6377e-02, -2.3865e-01, -4.7534e-01,  ..., -2.1094e-01,\n",
      "           -1.1646e-01, -2.1814e-01],\n",
      "          [ 6.7993e-02, -2.4670e-01, -8.0566e-01,  ..., -4.8145e-01,\n",
      "           -1.8103e-01, -1.1743e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4197e-01, -8.8623e-02,  3.1128e-01,  ...,  4.8633e-01,\n",
      "           -3.8574e-01, -2.0654e-01],\n",
      "          [ 2.5439e-01,  3.9331e-01,  9.9243e-02,  ...,  1.1145e-01,\n",
      "           -6.0303e-01, -3.7793e-01],\n",
      "          [ 8.1177e-02,  6.8750e-01,  8.8013e-02,  ...,  2.8320e-01,\n",
      "           -6.2061e-01,  4.4434e-01],\n",
      "          ...,\n",
      "          [-6.7627e-02,  7.2754e-02,  1.9373e-01,  ..., -1.0107e-01,\n",
      "           -3.7207e-01,  4.1675e-01],\n",
      "          [ 1.9592e-01,  5.1392e-02, -8.3740e-02,  ...,  2.9419e-01,\n",
      "           -1.1200e-02,  6.6455e-01],\n",
      "          [ 3.2812e-01,  8.7158e-02,  1.8408e-01,  ...,  2.5101e-02,\n",
      "           -5.4779e-02,  3.6450e-01]],\n",
      "\n",
      "         [[ 5.2930e-01,  6.2793e-01,  2.8027e-01,  ...,  1.5205e+00,\n",
      "            1.7070e+00,  5.0293e-01],\n",
      "          [ 8.0505e-02, -5.4736e-01,  1.5137e-02,  ..., -1.7944e-02,\n",
      "            1.8994e-01,  2.2217e-02],\n",
      "          [ 1.9312e-01,  4.5715e-02,  5.5634e-02,  ...,  3.4424e-02,\n",
      "            5.6299e-01,  2.1838e-01],\n",
      "          ...,\n",
      "          [ 3.5083e-01, -3.3325e-02,  3.9160e-01,  ...,  1.1554e-01,\n",
      "            5.1562e-01,  2.4426e-01],\n",
      "          [ 2.7393e-01, -2.8711e-01,  4.2212e-01,  ...,  2.4841e-02,\n",
      "            4.2358e-01,  2.8760e-01],\n",
      "          [ 1.8408e-01,  2.8809e-01,  2.8271e-01,  ...,  4.9243e-01,\n",
      "            4.0601e-01,  5.4150e-01]],\n",
      "\n",
      "         [[-5.2765e-02, -1.2866e-01, -3.0615e-01,  ..., -7.6953e-01,\n",
      "           -9.6973e-01,  1.2366e-01],\n",
      "          [-1.3562e-01, -3.2617e-01, -5.8624e-02,  ..., -1.6577e-01,\n",
      "           -1.7126e-01, -5.5273e-01],\n",
      "          [-1.1005e-01, -4.5361e-01, -4.4849e-01,  ..., -1.2148e+00,\n",
      "           -9.9316e-01, -8.2227e-01],\n",
      "          ...,\n",
      "          [ 8.3130e-02, -9.9609e-02, -5.5859e-01,  ..., -1.7700e-01,\n",
      "           -6.3477e-03, -2.2632e-01],\n",
      "          [-5.4474e-02, -3.6328e-01, -2.4011e-01,  ..., -5.2539e-01,\n",
      "           -1.4160e-02, -3.5327e-01],\n",
      "          [-1.7151e-02,  6.2012e-02, -1.3977e-01,  ..., -9.7900e-02,\n",
      "            1.1157e-01, -1.0480e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6611e-01,  5.3955e-01,  5.4199e-01,  ...,  6.2402e-01,\n",
      "           -2.3792e-01, -3.2031e-01],\n",
      "          [ 1.4551e-01,  2.5732e-01,  7.5073e-02,  ...,  4.8126e-02,\n",
      "           -6.4893e-01, -1.3696e-01],\n",
      "          [ 2.1082e-01,  2.5391e-01,  5.4230e-02,  ...,  2.5909e-02,\n",
      "           -1.4636e-01,  2.8473e-02],\n",
      "          ...,\n",
      "          [-2.0599e-02,  4.0649e-02,  3.3081e-01,  ..., -1.0620e-01,\n",
      "           -3.8599e-01,  3.7964e-01],\n",
      "          [ 1.5759e-01,  1.5381e-01,  8.3374e-02,  ...,  2.7222e-01,\n",
      "           -1.3092e-02,  5.9961e-01],\n",
      "          [ 2.7612e-01,  3.4332e-02,  1.7261e-01,  ...,  6.4453e-02,\n",
      "           -6.5308e-02,  3.8354e-01]],\n",
      "\n",
      "         [[ 1.0504e-01,  2.8394e-01,  3.3594e-01,  ...,  4.0283e-01,\n",
      "            1.1846e+00,  9.5312e-01],\n",
      "          [ 3.7158e-01, -1.1865e-01,  6.4160e-01,  ..., -5.5957e-01,\n",
      "            8.1250e-01,  7.7637e-02],\n",
      "          [ 5.0391e-01,  4.7070e-01,  8.1201e-01,  ..., -7.0190e-03,\n",
      "            1.7256e+00,  2.8125e-01],\n",
      "          ...,\n",
      "          [ 3.8501e-01, -3.8574e-02,  2.1155e-01,  ...,  2.0557e-01,\n",
      "            4.5361e-01,  3.3203e-01],\n",
      "          [ 2.9663e-01, -3.2153e-01,  3.4424e-01,  ...,  9.7717e-02,\n",
      "            5.4590e-01,  2.9883e-01],\n",
      "          [ 1.3440e-01,  1.5918e-01,  2.1851e-01,  ...,  4.8853e-01,\n",
      "            4.3799e-01,  5.3027e-01]],\n",
      "\n",
      "         [[-4.4775e-01, -9.8242e-01, -1.1318e+00,  ..., -7.8418e-01,\n",
      "           -8.8867e-01, -2.5977e-01],\n",
      "          [-2.2595e-01, -4.8364e-01, -3.5474e-01,  ..., -5.8789e-01,\n",
      "            4.3945e-02,  7.1045e-02],\n",
      "          [-5.4004e-01, -9.0137e-01, -9.2285e-01,  ..., -1.1279e+00,\n",
      "           -7.7734e-01, -6.8665e-02],\n",
      "          ...,\n",
      "          [ 8.3130e-02, -1.0864e-01, -6.1133e-01,  ..., -1.9592e-01,\n",
      "            6.1035e-05, -1.8652e-01],\n",
      "          [-4.8584e-02, -3.2446e-01, -4.4873e-01,  ..., -4.5898e-01,\n",
      "           -2.0203e-02, -2.8711e-01],\n",
      "          [-1.1719e-02,  1.2463e-01, -1.2170e-01,  ..., -1.1597e-01,\n",
      "            1.7334e-01, -7.5806e-02]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 4.7559e-01,  9.2041e-02,  2.0068e-01,  ...,  5.1074e-01,\n",
      "           -5.1123e-01, -6.4160e-01],\n",
      "          [ 1.1768e+00, -3.2812e-01, -5.1025e-01,  ..., -8.5303e-01,\n",
      "           -6.6406e-01, -5.3741e-02],\n",
      "          [ 4.7681e-01, -2.8540e-01,  3.7744e-01,  ..., -2.5244e-01,\n",
      "           -6.3867e-01,  4.8218e-01],\n",
      "          ...,\n",
      "          [ 1.0498e-01,  1.5161e-01,  2.6099e-01,  ..., -4.8798e-02,\n",
      "           -4.6777e-01,  2.7710e-01],\n",
      "          [ 4.8828e-02,  1.9556e-01,  6.3904e-02,  ...,  3.8013e-01,\n",
      "           -1.3477e-01,  4.0356e-01],\n",
      "          [-1.1505e-02, -2.0996e-01, -1.9641e-01,  ..., -1.1646e-01,\n",
      "           -6.0693e-01,  5.6494e-01]],\n",
      "\n",
      "         [[-7.9834e-01,  4.5679e-01,  1.1953e+00,  ...,  1.1709e+00,\n",
      "            2.0801e+00,  1.0615e+00],\n",
      "          [ 2.6660e-01,  5.4199e-01,  9.6924e-01,  ...,  3.4277e-01,\n",
      "            1.0254e+00, -3.0811e-01],\n",
      "          [-6.4990e-01, -4.5264e-01,  6.6260e-01,  ..., -4.4189e-01,\n",
      "            8.4766e-01, -1.8311e-01],\n",
      "          ...,\n",
      "          [ 5.0977e-01,  1.7969e-01,  2.5684e-01,  ...,  1.6431e-01,\n",
      "            3.8403e-01,  1.0779e-01],\n",
      "          [ 1.8018e-01, -2.6807e-01,  2.7881e-01,  ...,  1.4453e-01,\n",
      "            3.8306e-01,  1.4307e-01],\n",
      "          [ 2.6221e-01,  2.7197e-01,  5.2637e-01,  ...,  7.2803e-01,\n",
      "            1.0029e+00,  5.7275e-01]],\n",
      "\n",
      "         [[-3.6914e-01, -7.5745e-02, -7.4414e-01,  ..., -1.6074e+00,\n",
      "           -1.6758e+00,  1.3184e-01],\n",
      "          [-1.0283e+00, -4.4653e-01,  2.3315e-01,  ..., -1.5540e-01,\n",
      "           -1.1416e+00, -4.5459e-01],\n",
      "          [-9.2578e-01, -1.2959e+00, -2.1797e+00,  ..., -2.1543e+00,\n",
      "           -2.4141e+00, -1.1006e+00],\n",
      "          ...,\n",
      "          [ 7.3242e-04, -1.4319e-01, -2.4170e-02,  ..., -9.3384e-03,\n",
      "           -1.4026e-01,  1.6504e-01],\n",
      "          [ 9.0210e-02, -1.4648e-01, -2.6978e-02,  ..., -2.6489e-01,\n",
      "           -1.2390e-02, -1.9775e-01],\n",
      "          [-1.3818e-01, -2.1875e-01, -1.1621e-01,  ..., -3.6279e-01,\n",
      "           -7.8308e-02, -1.1798e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2373e-01,  2.1741e-01, -8.4961e-02,  ...,  7.8735e-02,\n",
      "           -5.4657e-02,  3.1396e-01],\n",
      "          [ 7.8760e-01,  2.2385e-02, -3.0615e-01,  ...,  2.4854e-01,\n",
      "           -2.3450e-01,  2.6611e-01],\n",
      "          [ 3.7500e-01, -1.4270e-01,  3.8013e-01,  ...,  2.2815e-01,\n",
      "           -3.2056e-01,  6.1963e-01],\n",
      "          ...,\n",
      "          [-1.9714e-02,  1.6260e-01,  2.1814e-01,  ..., -1.5881e-01,\n",
      "           -3.8770e-01,  4.5972e-01],\n",
      "          [ 1.6052e-01,  4.4525e-02, -9.8755e-02,  ...,  2.6172e-01,\n",
      "           -9.2896e-02,  5.8789e-01],\n",
      "          [ 2.3621e-01,  1.0083e-01,  5.1178e-02,  ...,  4.3243e-02,\n",
      "           -4.7821e-02,  4.4629e-01]],\n",
      "\n",
      "         [[-5.9277e-01,  4.2041e-01,  1.5850e+00,  ...,  5.8301e-01,\n",
      "            5.6689e-01,  4.6533e-01],\n",
      "          [ 3.7842e-01, -1.0925e-02,  5.9863e-01,  ..., -3.7720e-02,\n",
      "            6.5857e-02,  2.2009e-01],\n",
      "          [-3.1641e-01, -9.3945e-01,  4.1187e-01,  ...,  2.4780e-01,\n",
      "            4.9512e-01, -1.7883e-02],\n",
      "          ...,\n",
      "          [ 5.6348e-01, -5.2002e-02, -1.0217e-01,  ...,  1.8237e-01,\n",
      "            4.7510e-01,  1.5369e-01],\n",
      "          [ 3.5376e-01, -2.4146e-01,  4.0259e-01,  ...,  1.4575e-01,\n",
      "            3.9307e-01,  2.6855e-01],\n",
      "          [ 1.6309e-01,  3.5693e-01,  4.3433e-01,  ...,  4.5825e-01,\n",
      "            5.2344e-01,  5.6543e-01]],\n",
      "\n",
      "         [[-2.9590e-01,  3.8086e-02, -7.0117e-01,  ..., -4.1284e-01,\n",
      "           -3.2202e-01, -4.3384e-01],\n",
      "          [-7.9590e-01,  2.4597e-02,  4.9097e-01,  ..., -1.1273e-01,\n",
      "           -1.3135e-01, -7.2693e-02],\n",
      "          [-9.0527e-01, -1.0146e+00, -1.7158e+00,  ..., -7.8809e-01,\n",
      "           -1.0620e-01, -5.8008e-01],\n",
      "          ...,\n",
      "          [ 1.9482e-01, -4.7424e-02, -3.1348e-01,  ..., -1.8433e-02,\n",
      "            6.3477e-03, -1.0504e-01],\n",
      "          [ 1.4807e-01, -1.6235e-01, -3.4271e-02,  ..., -4.7412e-01,\n",
      "           -1.7993e-01, -1.3477e-01],\n",
      "          [-1.4062e-01, -1.9958e-02, -1.9604e-01,  ..., -1.6052e-01,\n",
      "            7.3242e-02, -1.1267e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1331e-02,  2.8229e-02,  1.2048e-01,  ...,  2.9761e-01,\n",
      "            1.2329e-01,  3.9502e-01],\n",
      "          [ 8.1024e-03,  1.9446e-01,  5.2393e-01,  ..., -2.8516e-01,\n",
      "           -4.7394e-02,  1.2000e-01],\n",
      "          [ 3.1714e-01,  2.5317e-01,  3.8110e-01,  ..., -2.1912e-02,\n",
      "            2.6520e-02,  5.2734e-01],\n",
      "          ...,\n",
      "          [-5.4352e-02,  4.5837e-02,  3.7012e-01,  ..., -1.8396e-01,\n",
      "           -3.6426e-01,  3.5303e-01],\n",
      "          [ 1.5796e-01,  1.2476e-01,  1.1084e-01,  ...,  2.5000e-01,\n",
      "           -6.5308e-02,  5.8154e-01],\n",
      "          [ 2.6123e-01,  1.0254e-01,  1.8860e-01,  ...,  3.1769e-02,\n",
      "           -1.0168e-01,  3.3032e-01]],\n",
      "\n",
      "         [[ 3.2520e-01,  4.0723e-01,  1.8347e-01,  ...,  3.2666e-01,\n",
      "            5.4492e-01,  6.4014e-01],\n",
      "          [ 4.9585e-01,  1.7822e-02, -1.9556e-01,  ...,  2.0630e-01,\n",
      "            2.6318e-01,  1.4966e-01],\n",
      "          [ 4.0723e-01,  8.5144e-02,  2.1252e-01,  ...,  1.8213e-01,\n",
      "           -9.7778e-02,  2.7771e-02],\n",
      "          ...,\n",
      "          [ 4.6973e-01,  1.7944e-02,  2.0728e-01,  ...,  2.8467e-01,\n",
      "            4.2236e-01,  3.6768e-01],\n",
      "          [ 2.5537e-01, -2.5562e-01,  2.2559e-01,  ...,  1.4880e-01,\n",
      "            5.8496e-01,  3.6938e-01],\n",
      "          [ 1.7639e-01,  1.9775e-01,  2.9053e-01,  ...,  5.2539e-01,\n",
      "            5.1465e-01,  5.3174e-01]],\n",
      "\n",
      "         [[-1.5820e-01, -4.1455e-01, -4.4775e-01,  ..., -4.2358e-01,\n",
      "           -2.9248e-01, -1.7725e-01],\n",
      "          [ 5.2246e-02,  2.1875e-01, -3.0908e-01,  ..., -8.9722e-03,\n",
      "           -4.6924e-01, -3.2910e-01],\n",
      "          [-1.7603e-01, -1.1499e-01, -2.7783e-01,  ..., -4.0552e-01,\n",
      "           -3.7012e-01, -4.3628e-01],\n",
      "          ...,\n",
      "          [ 1.7358e-01, -4.1748e-02, -5.4297e-01,  ..., -6.2866e-02,\n",
      "           -9.1980e-02, -1.6333e-01],\n",
      "          [ 1.2024e-02, -4.0137e-01, -3.7598e-01,  ..., -4.4019e-01,\n",
      "           -9.2468e-02, -2.9053e-01],\n",
      "          [ 2.9541e-02,  7.1777e-02, -1.4099e-01,  ..., -4.7607e-02,\n",
      "            2.0410e-01, -2.9785e-02]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-3.6230e-01, -4.1968e-01, -3.7256e-01,  ..., -1.5833e-01,\n",
      "           -1.4636e-01, -1.1755e-01],\n",
      "          [-2.6392e-01, -3.3911e-01, -1.7224e-01,  ...,  2.3547e-01,\n",
      "            6.2134e-02, -9.6191e-02],\n",
      "          [-2.7197e-01, -2.7588e-01, -8.2886e-02,  ...,  4.5776e-01,\n",
      "            1.8384e-01,  4.9194e-02],\n",
      "          ...,\n",
      "          [-8.5205e-02, -1.2317e-01, -8.8013e-02,  ..., -4.2816e-02,\n",
      "           -1.6296e-01, -1.1365e-01],\n",
      "          [-1.8359e-01, -1.7126e-01, -7.8247e-02,  ..., -8.3862e-02,\n",
      "           -1.4209e-01, -8.5815e-02],\n",
      "          [-1.2769e-01, -1.1243e-01, -9.6436e-02,  ..., -6.2988e-02,\n",
      "           -7.8125e-02, -4.9133e-03]],\n",
      "\n",
      "         [[-1.9482e-01, -3.2764e-01, -3.2129e-01,  ...,  8.9355e-01,\n",
      "            6.4844e-01,  3.7939e-01],\n",
      "          [-4.4653e-01, -8.4766e-01, -6.7188e-01,  ...,  1.1338e+00,\n",
      "            1.0918e+00,  6.7578e-01],\n",
      "          [-3.6865e-01, -5.9180e-01, -6.3770e-01,  ...,  1.1094e+00,\n",
      "            1.5010e+00,  1.1016e+00],\n",
      "          ...,\n",
      "          [ 1.6699e-01,  1.4258e-01,  5.8154e-01,  ...,  2.4072e-01,\n",
      "            1.5686e-01,  1.6333e-01],\n",
      "          [-6.5796e-02, -1.6846e-02,  1.9690e-01,  ...,  1.0565e-01,\n",
      "           -1.1511e-01,  9.4910e-02],\n",
      "          [ 8.6060e-02,  8.4351e-02,  2.5488e-01,  ...,  2.1631e-01,\n",
      "            6.1188e-02,  2.0190e-01]],\n",
      "\n",
      "         [[ 2.8979e-01,  9.6924e-02,  5.9082e-02,  ...,  1.6394e-01,\n",
      "            1.6846e-01,  6.1035e-01],\n",
      "          [-7.3242e-02, -3.1030e-01, -2.6807e-01,  ...,  1.0913e-01,\n",
      "           -8.4229e-02,  5.9668e-01],\n",
      "          [ 1.4832e-01,  1.7761e-02, -2.4231e-02,  ..., -3.6011e-01,\n",
      "            1.1841e-02,  5.9912e-01],\n",
      "          ...,\n",
      "          [ 5.6104e-01,  5.7080e-01,  6.8359e-01,  ...,  7.1924e-01,\n",
      "            3.7573e-01,  5.0342e-01],\n",
      "          [ 4.2920e-01,  3.7598e-01,  5.5225e-01,  ...,  4.6631e-01,\n",
      "            3.0005e-01,  4.9023e-01],\n",
      "          [ 6.8115e-01,  6.5674e-01,  7.4707e-01,  ...,  7.6172e-01,\n",
      "            6.1328e-01,  7.4072e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3862e-01, -3.7476e-01, -3.6523e-01,  ..., -2.0581e-01,\n",
      "           -2.0862e-01, -1.1926e-01],\n",
      "          [-2.1448e-01, -3.0005e-01, -1.9836e-01,  ...,  2.6587e-01,\n",
      "            8.5632e-02, -9.4604e-02],\n",
      "          [-2.1252e-01, -2.4841e-01, -1.4575e-01,  ...,  6.3623e-01,\n",
      "            2.5366e-01,  3.2532e-02],\n",
      "          ...,\n",
      "          [-1.2659e-01, -1.8005e-01, -1.4331e-01,  ...,  3.6804e-02,\n",
      "           -8.5571e-02, -2.6215e-02],\n",
      "          [-2.1863e-01, -2.5269e-01, -1.3391e-01,  ..., -8.3984e-02,\n",
      "           -1.1072e-01, -8.3618e-02],\n",
      "          [-1.2646e-01, -1.3965e-01, -1.1328e-01,  ..., -5.1056e-02,\n",
      "           -6.9824e-02,  5.6458e-03]],\n",
      "\n",
      "         [[-3.0933e-01, -4.2212e-01, -3.4131e-01,  ...,  1.0332e+00,\n",
      "            7.5391e-01,  3.5962e-01],\n",
      "          [-6.1719e-01, -9.3457e-01, -6.7773e-01,  ...,  1.3330e+00,\n",
      "            1.2988e+00,  6.9434e-01],\n",
      "          [-7.3145e-01, -8.3008e-01, -7.3340e-01,  ...,  1.2910e+00,\n",
      "            1.6562e+00,  1.1406e+00],\n",
      "          ...,\n",
      "          [ 1.4709e-02, -1.2939e-01,  2.2766e-01,  ...,  1.1536e-01,\n",
      "            5.8838e-02,  1.0150e-01],\n",
      "          [-1.8506e-01, -1.9604e-01,  1.0681e-02,  ...,  7.0618e-02,\n",
      "           -1.4868e-01,  5.6885e-02],\n",
      "          [-6.8359e-03, -3.4668e-02,  1.2793e-01,  ...,  1.6418e-01,\n",
      "            2.3560e-02,  1.6992e-01]],\n",
      "\n",
      "         [[ 1.5051e-01, -5.4932e-04,  8.2764e-02,  ...,  1.7969e-01,\n",
      "            1.7700e-01,  5.9082e-01],\n",
      "          [-2.5635e-01, -4.9658e-01, -3.3521e-01,  ..., -4.7119e-02,\n",
      "           -1.1987e-01,  5.6689e-01],\n",
      "          [-2.1875e-01, -2.5537e-01, -1.9629e-01,  ..., -8.2178e-01,\n",
      "           -2.9932e-01,  4.6289e-01],\n",
      "          ...,\n",
      "          [ 4.2383e-01,  4.1089e-01,  4.4678e-01,  ...,  5.7910e-01,\n",
      "            3.3740e-01,  4.9854e-01],\n",
      "          [ 3.2300e-01,  2.6001e-01,  4.0308e-01,  ...,  3.8843e-01,\n",
      "            2.3657e-01,  4.5264e-01],\n",
      "          [ 5.9082e-01,  5.7031e-01,  6.2793e-01,  ...,  6.8652e-01,\n",
      "            5.5566e-01,  7.1143e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2935e-01, -3.5425e-01, -3.4204e-01,  ..., -3.3740e-01,\n",
      "           -3.4155e-01, -2.5049e-01],\n",
      "          [-1.9043e-01, -2.1960e-01, -6.7139e-02,  ..., -2.2424e-01,\n",
      "           -1.3757e-01, -2.0020e-01],\n",
      "          [-1.9556e-01, -2.1252e-01, -1.7102e-01,  ...,  4.0771e-02,\n",
      "            2.8473e-02, -5.9418e-02],\n",
      "          ...,\n",
      "          [-1.0718e-01, -1.4917e-01, -8.5449e-02,  ..., -3.9825e-02,\n",
      "           -1.6138e-01, -1.1389e-01],\n",
      "          [-1.8347e-01, -1.8091e-01, -6.3110e-02,  ..., -9.3140e-02,\n",
      "           -1.5161e-01, -9.2773e-02],\n",
      "          [-1.1877e-01, -1.1499e-01, -9.0210e-02,  ..., -6.8848e-02,\n",
      "           -7.2998e-02, -4.3640e-03]],\n",
      "\n",
      "         [[-2.3218e-01, -3.6548e-01, -2.2217e-01,  ..., -1.5430e-01,\n",
      "           -2.8687e-01,  5.1270e-03],\n",
      "          [-4.7632e-01, -6.9824e-01, -4.2114e-01,  ..., -6.8066e-01,\n",
      "           -6.7090e-01, -3.2544e-01],\n",
      "          [-3.5669e-01, -2.4219e-01, -8.3374e-02,  ..., -3.8184e-01,\n",
      "           -5.8496e-01, -1.3562e-01],\n",
      "          ...,\n",
      "          [ 6.8420e-02,  1.8433e-02,  4.3896e-01,  ...,  2.3022e-01,\n",
      "            1.4722e-01,  1.5601e-01],\n",
      "          [-9.9365e-02, -6.3354e-02,  1.7188e-01,  ...,  8.9600e-02,\n",
      "           -1.3599e-01,  8.2520e-02],\n",
      "          [ 6.7993e-02,  6.3232e-02,  2.2058e-01,  ...,  1.9971e-01,\n",
      "            4.0283e-02,  1.9409e-01]],\n",
      "\n",
      "         [[ 2.0044e-01,  9.6069e-02,  1.1682e-01,  ...,  1.5491e-01,\n",
      "            1.1523e-01,  4.0259e-01],\n",
      "          [-9.4116e-02, -2.2681e-01, -1.6528e-01,  ..., -2.1460e-01,\n",
      "           -2.6660e-01,  2.7588e-01],\n",
      "          [ 1.7041e-01,  1.9824e-01,  3.8623e-01,  ...,  8.9111e-02,\n",
      "           -2.0447e-02,  3.9209e-01],\n",
      "          ...,\n",
      "          [ 4.6973e-01,  5.2246e-01,  6.1572e-01,  ...,  7.0996e-01,\n",
      "            3.7378e-01,  5.0244e-01],\n",
      "          [ 3.9966e-01,  3.3911e-01,  5.4297e-01,  ...,  4.4727e-01,\n",
      "            2.8198e-01,  4.8438e-01],\n",
      "          [ 6.5918e-01,  6.3818e-01,  7.1924e-01,  ...,  7.4072e-01,\n",
      "            6.0303e-01,  7.3682e-01]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[-3.9368e-02,  1.0406e-02,  1.0376e-02,  ..., -2.3682e-01,\n",
      "           -2.2852e-01, -1.5186e-01],\n",
      "          [ 8.3679e-02,  1.8262e-01,  1.9141e-01,  ...,  1.8005e-03,\n",
      "           -1.9214e-01, -2.1045e-01],\n",
      "          [ 2.7390e-02,  1.4502e-01,  1.5039e-01,  ...,  1.7896e-01,\n",
      "           -3.8818e-02, -2.0923e-01],\n",
      "          ...,\n",
      "          [ 7.1960e-02,  1.4001e-01,  1.9604e-01,  ...,  1.5686e-01,\n",
      "            1.8042e-01,  7.9834e-02],\n",
      "          [ 4.4739e-02,  1.4417e-01,  1.6992e-01,  ...,  1.5186e-01,\n",
      "            1.7419e-01,  8.7402e-02],\n",
      "          [ 1.2756e-02,  9.1431e-02,  1.2231e-01,  ...,  8.9600e-02,\n",
      "            1.0425e-01,  2.8748e-02]],\n",
      "\n",
      "         [[ 3.9893e-01,  2.8003e-01,  2.6221e-01,  ...,  1.4199e+00,\n",
      "            1.2285e+00,  9.7217e-01],\n",
      "          [ 2.1387e-01, -3.1494e-02, -1.4526e-02,  ...,  2.0645e+00,\n",
      "            1.6348e+00,  1.1387e+00],\n",
      "          [ 2.2681e-01, -1.2512e-02, -2.8442e-02,  ...,  2.5508e+00,\n",
      "            2.1797e+00,  1.3398e+00],\n",
      "          ...,\n",
      "          [ 1.8152e-01, -5.6763e-02, -5.4932e-02,  ...,  3.3569e-03,\n",
      "           -2.1362e-02,  2.6831e-01],\n",
      "          [ 1.7224e-01, -8.0566e-02, -9.8511e-02,  ..., -3.9062e-02,\n",
      "           -6.3965e-02,  2.3828e-01],\n",
      "          [ 3.4839e-01,  1.6772e-01,  1.4709e-01,  ...,  2.1545e-01,\n",
      "            2.1680e-01,  4.1724e-01]],\n",
      "\n",
      "         [[ 8.4570e-01,  7.4609e-01,  7.1582e-01,  ...,  1.1582e+00,\n",
      "            1.1172e+00,  1.1025e+00],\n",
      "          [ 7.1484e-01,  5.6836e-01,  5.5371e-01,  ...,  1.2432e+00,\n",
      "            1.1514e+00,  1.1406e+00],\n",
      "          [ 7.5781e-01,  5.9082e-01,  5.3516e-01,  ...,  1.2852e+00,\n",
      "            1.3154e+00,  1.1826e+00],\n",
      "          ...,\n",
      "          [ 5.1270e-01,  2.1021e-01,  5.3833e-02,  ...,  4.6362e-01,\n",
      "            4.6655e-01,  7.2070e-01],\n",
      "          [ 5.6738e-01,  2.7808e-01,  1.4722e-01,  ...,  4.5972e-01,\n",
      "            4.6753e-01,  7.1680e-01],\n",
      "          [ 7.9980e-01,  6.2305e-01,  5.4492e-01,  ...,  7.2949e-01,\n",
      "            7.4414e-01,  8.9551e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2329e-02,  3.1799e-02,  2.5681e-02,  ..., -1.7578e-02,\n",
      "           -8.7891e-03, -1.3550e-02],\n",
      "          [ 1.5625e-01,  2.3438e-01,  2.0361e-01,  ...,  1.2268e-01,\n",
      "            2.0288e-01,  6.7810e-02],\n",
      "          [ 6.9763e-02,  1.7163e-01,  1.2549e-01,  ...,  5.3314e-02,\n",
      "            9.0942e-02,  6.0120e-02],\n",
      "          ...,\n",
      "          [ 8.4473e-02,  1.3989e-01,  2.1216e-01,  ...,  1.6699e-01,\n",
      "            2.0703e-01,  1.0193e-01],\n",
      "          [ 5.0476e-02,  1.4807e-01,  1.7554e-01,  ...,  1.6064e-01,\n",
      "            1.7773e-01,  1.0425e-01],\n",
      "          [ 1.8372e-02,  9.6069e-02,  1.3110e-01,  ...,  9.4727e-02,\n",
      "            1.1450e-01,  4.2297e-02]],\n",
      "\n",
      "         [[ 3.8647e-01,  3.1934e-01,  3.4448e-01,  ...,  4.2236e-01,\n",
      "            3.0249e-01,  4.5630e-01],\n",
      "          [ 2.0557e-01,  1.8494e-02,  1.6431e-01,  ...,  1.7603e-01,\n",
      "            1.2939e-02,  2.3804e-01],\n",
      "          [ 2.4255e-01,  1.0144e-01,  2.1997e-01,  ...,  2.0374e-01,\n",
      "           -3.2959e-03,  2.4438e-01],\n",
      "          ...,\n",
      "          [ 1.6443e-01, -6.2500e-02, -4.4434e-02,  ..., -5.0537e-02,\n",
      "           -7.2876e-02,  2.1655e-01],\n",
      "          [ 1.6309e-01, -9.2773e-02, -9.2285e-02,  ..., -8.6426e-02,\n",
      "           -9.6436e-02,  2.1399e-01],\n",
      "          [ 3.3691e-01,  1.5698e-01,  1.3599e-01,  ...,  1.8115e-01,\n",
      "            1.8555e-01,  3.9819e-01]],\n",
      "\n",
      "         [[ 8.4961e-01,  7.9199e-01,  7.7734e-01,  ...,  7.6953e-01,\n",
      "            7.2754e-01,  8.2324e-01],\n",
      "          [ 7.1973e-01,  6.3184e-01,  6.5918e-01,  ...,  5.8789e-01,\n",
      "            5.0586e-01,  6.9531e-01],\n",
      "          [ 7.9590e-01,  7.0215e-01,  7.2070e-01,  ...,  5.6738e-01,\n",
      "            4.4067e-01,  6.4355e-01],\n",
      "          ...,\n",
      "          [ 4.4897e-01,  1.1914e-01, -3.6438e-02,  ...,  9.9487e-02,\n",
      "            1.6382e-01,  5.5566e-01],\n",
      "          [ 5.2539e-01,  2.1387e-01,  8.2886e-02,  ...,  2.3340e-01,\n",
      "            2.8442e-01,  6.0352e-01],\n",
      "          [ 7.7441e-01,  5.9082e-01,  5.0391e-01,  ...,  6.2207e-01,\n",
      "            6.4062e-01,  8.3984e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7676e-01, -1.4893e-01, -1.9775e-02,  ...,  3.5400e-02,\n",
      "            3.2166e-02,  3.5095e-03],\n",
      "          [-3.0884e-02,  4.2676e-01,  6.8457e-01,  ...,  1.9556e-01,\n",
      "            2.1094e-01,  7.9834e-02],\n",
      "          [ 2.5415e-01,  7.9443e-01,  1.2568e+00,  ...,  1.8994e-01,\n",
      "            1.7029e-01,  8.5144e-02],\n",
      "          ...,\n",
      "          [ 9.8999e-02,  2.0728e-01,  2.4902e-01,  ...,  1.6284e-01,\n",
      "            1.7944e-01,  7.5806e-02],\n",
      "          [ 5.8228e-02,  1.8213e-01,  1.9067e-01,  ...,  1.6321e-01,\n",
      "            1.7480e-01,  8.8318e-02],\n",
      "          [ 1.9348e-02,  9.5459e-02,  1.0748e-01,  ...,  8.8623e-02,\n",
      "            1.0126e-01,  2.7832e-02]],\n",
      "\n",
      "         [[ 1.4141e+00,  2.0625e+00,  2.6035e+00,  ...,  2.8125e-01,\n",
      "            2.6855e-01,  4.5312e-01],\n",
      "          [ 1.8418e+00,  3.1602e+00,  4.0391e+00,  ..., -6.0425e-03,\n",
      "           -2.6123e-02,  2.6660e-01],\n",
      "          [ 2.1699e+00,  3.7969e+00,  4.7969e+00,  ..., -1.1108e-02,\n",
      "            8.9722e-03,  2.8564e-01],\n",
      "          ...,\n",
      "          [ 2.1228e-01, -1.1719e-02,  3.0518e-03,  ...,  1.5381e-02,\n",
      "           -6.6528e-03,  2.7808e-01],\n",
      "          [ 2.1301e-01, -2.8442e-02, -2.8076e-02,  ..., -3.1616e-02,\n",
      "           -4.8462e-02,  2.4402e-01],\n",
      "          [ 3.9575e-01,  2.3718e-01,  2.4158e-01,  ...,  2.2791e-01,\n",
      "            2.2607e-01,  4.2163e-01]],\n",
      "\n",
      "         [[ 1.1768e+00,  1.1777e+00,  1.2168e+00,  ...,  7.6270e-01,\n",
      "            7.6953e-01,  8.6133e-01],\n",
      "          [ 1.0742e+00,  1.1826e+00,  1.2207e+00,  ...,  6.0840e-01,\n",
      "            6.0059e-01,  7.9395e-01],\n",
      "          [ 9.9805e-01,  1.1299e+00,  1.1094e+00,  ...,  6.3574e-01,\n",
      "            6.5918e-01,  8.1543e-01],\n",
      "          ...,\n",
      "          [ 7.7344e-01,  6.7188e-01,  6.8359e-01,  ...,  5.6641e-01,\n",
      "            5.5176e-01,  7.6270e-01],\n",
      "          [ 7.7539e-01,  6.4355e-01,  6.4062e-01,  ...,  5.3906e-01,\n",
      "            5.3125e-01,  7.5098e-01],\n",
      "          [ 9.2383e-01,  8.2910e-01,  8.4375e-01,  ...,  7.7539e-01,\n",
      "            7.8027e-01,  9.1309e-01]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[0.2642, 0.2788, 0.2556,  ..., 0.1727, 0.1831, 0.2534],\n",
      "          [0.3037, 0.3083, 0.3020,  ..., 0.1854, 0.1584, 0.2194],\n",
      "          [0.2969, 0.3083, 0.2837,  ..., 0.2126, 0.1604, 0.2046],\n",
      "          ...,\n",
      "          [0.2305, 0.2131, 0.2249,  ..., 0.1996, 0.2327, 0.2479],\n",
      "          [0.2279, 0.2207, 0.2252,  ..., 0.2078, 0.2294, 0.2544],\n",
      "          [0.2527, 0.2559, 0.2622,  ..., 0.2471, 0.2637, 0.2834]],\n",
      "\n",
      "         [[0.4272, 0.3701, 0.3701,  ..., 0.8086, 0.6572, 0.5928],\n",
      "          [0.3245, 0.2180, 0.2239,  ..., 0.9941, 0.7041, 0.5923],\n",
      "          [0.3242, 0.2292, 0.2188,  ..., 1.2119, 0.9004, 0.6826],\n",
      "          ...,\n",
      "          [0.3037, 0.2109, 0.2161,  ..., 0.2534, 0.2080, 0.3264],\n",
      "          [0.2944, 0.1626, 0.1807,  ..., 0.1986, 0.1794, 0.3062],\n",
      "          [0.3877, 0.2793, 0.2717,  ..., 0.2734, 0.2754, 0.3999]],\n",
      "\n",
      "         [[1.1094, 1.0107, 0.9634,  ..., 1.0400, 1.0088, 1.0918],\n",
      "          [1.0527, 0.9448, 0.8740,  ..., 0.9312, 0.8804, 1.0088],\n",
      "          [1.0830, 0.9907, 0.9316,  ..., 0.9741, 0.9268, 1.0312],\n",
      "          ...,\n",
      "          [0.8369, 0.5938, 0.5132,  ..., 0.4810, 0.5552, 0.7949],\n",
      "          [0.8833, 0.6533, 0.6094,  ..., 0.5586, 0.6348, 0.8301],\n",
      "          [1.0322, 0.8794, 0.8433,  ..., 0.8276, 0.8564, 1.0039]]],\n",
      "\n",
      "\n",
      "        [[[0.2026, 0.1860, 0.2964,  ..., 0.2264, 0.2050, 0.2395],\n",
      "          [0.2473, 0.6831, 1.0059,  ..., 0.1996, 0.1892, 0.2097],\n",
      "          [0.3718, 1.0156, 1.4746,  ..., 0.1768, 0.1569, 0.2317],\n",
      "          ...,\n",
      "          [0.2417, 0.2368, 0.2490,  ..., 0.2378, 0.2590, 0.2725],\n",
      "          [0.2384, 0.2351, 0.2433,  ..., 0.2325, 0.2487, 0.2727],\n",
      "          [0.2595, 0.2681, 0.2749,  ..., 0.2668, 0.2822, 0.2942]],\n",
      "\n",
      "         [[1.0303, 1.3760, 1.7900,  ..., 0.6001, 0.6309, 0.6592],\n",
      "          [1.3047, 2.3164, 3.1016,  ..., 0.5762, 0.5586, 0.6172],\n",
      "          [1.5801, 2.9531, 3.9473,  ..., 0.6992, 0.5586, 0.5615],\n",
      "          ...,\n",
      "          [0.3123, 0.1938, 0.1892,  ..., 0.2030, 0.1866, 0.3428],\n",
      "          [0.3015, 0.1664, 0.1742,  ..., 0.1692, 0.1738, 0.3230],\n",
      "          [0.3916, 0.2927, 0.2825,  ..., 0.2959, 0.2910, 0.4080]],\n",
      "\n",
      "         [[1.1396, 0.9976, 1.0176,  ..., 0.9878, 1.0146, 1.1064],\n",
      "          [0.9614, 0.9644, 1.0225,  ..., 0.8608, 0.8384, 1.0020],\n",
      "          [0.9307, 1.0039, 1.0283,  ..., 0.9238, 0.8608, 0.9858],\n",
      "          ...,\n",
      "          [0.9233, 0.7275, 0.6880,  ..., 0.7363, 0.7529, 0.9185],\n",
      "          [0.9438, 0.7495, 0.7266,  ..., 0.7495, 0.7817, 0.9268],\n",
      "          [1.0645, 0.9380, 0.9141,  ..., 0.9390, 0.9478, 1.0566]]],\n",
      "\n",
      "\n",
      "        [[[0.2074, 0.1923, 0.1647,  ..., 0.1967, 0.2181, 0.2598],\n",
      "          [0.2281, 0.2126, 0.2688,  ..., 0.1792, 0.2041, 0.2563],\n",
      "          [0.2217, 0.2937, 0.4778,  ..., 0.1715, 0.1439, 0.2593],\n",
      "          ...,\n",
      "          [0.2101, 0.1797, 0.2061,  ..., 0.1908, 0.2246, 0.2371],\n",
      "          [0.2101, 0.1958, 0.2003,  ..., 0.2000, 0.2223, 0.2485],\n",
      "          [0.2402, 0.2332, 0.2355,  ..., 0.2404, 0.2585, 0.2805]],\n",
      "\n",
      "         [[0.7188, 0.8398, 0.9990,  ..., 0.6807, 0.4822, 0.5127],\n",
      "          [0.8330, 1.0654, 1.3770,  ..., 0.7646, 0.4241, 0.4202],\n",
      "          [0.9883, 1.3906, 1.8682,  ..., 0.9648, 0.5645, 0.4553],\n",
      "          ...,\n",
      "          [0.2939, 0.2751, 0.2983,  ..., 0.2952, 0.2474, 0.3213],\n",
      "          [0.2842, 0.2100, 0.2522,  ..., 0.2263, 0.1960, 0.3027],\n",
      "          [0.3784, 0.2615, 0.2476,  ..., 0.2661, 0.2715, 0.3992]],\n",
      "\n",
      "         [[1.1367, 1.0430, 1.0605,  ..., 1.0205, 0.9644, 1.0527],\n",
      "          [1.0332, 0.9155, 0.9067,  ..., 0.9326, 0.8120, 0.9614],\n",
      "          [1.0684, 0.9253, 0.9692,  ..., 0.9927, 0.8755, 0.9800],\n",
      "          ...,\n",
      "          [0.6885, 0.3372, 0.1536,  ..., 0.2876, 0.4133, 0.7222],\n",
      "          [0.7637, 0.4395, 0.3147,  ..., 0.4482, 0.5586, 0.7881],\n",
      "          [0.9644, 0.7583, 0.6807,  ..., 0.7798, 0.8198, 0.9858]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2690, 0.4990, 0.8164,  ..., 0.8770, 0.5488, 0.2424],\n",
      "          [0.5000, 1.4307, 2.0703,  ..., 2.0742, 1.3643, 0.4714],\n",
      "          [0.7939, 1.9473, 2.7930,  ..., 2.4062, 1.5527, 0.5068],\n",
      "          ...,\n",
      "          [0.3857, 0.4146, 0.4614,  ..., 0.3782, 0.3936, 0.3838],\n",
      "          [0.3687, 0.3953, 0.4265,  ..., 0.3606, 0.3611, 0.3723],\n",
      "          [0.3838, 0.3843, 0.4165,  ..., 0.3816, 0.3926, 0.3901]],\n",
      "\n",
      "         [[1.2588, 1.9561, 2.6074,  ..., 2.7402, 2.1309, 1.3213],\n",
      "          [1.7549, 3.3730, 4.4922,  ..., 4.4961, 3.2871, 1.7324],\n",
      "          [2.1758, 4.1836, 5.5742,  ..., 4.9688, 3.4688, 1.6895],\n",
      "          ...,\n",
      "          [0.4570, 0.3606, 0.3599,  ..., 0.3545, 0.3254, 0.4648],\n",
      "          [0.4414, 0.3306, 0.3423,  ..., 0.3120, 0.3079, 0.4395],\n",
      "          [0.5312, 0.4268, 0.4287,  ..., 0.4404, 0.4360, 0.5439]],\n",
      "\n",
      "         [[1.1025, 1.0879, 1.2461,  ..., 1.2715, 1.1611, 1.0781],\n",
      "          [1.0117, 1.3721, 1.5674,  ..., 1.5742, 1.3799, 1.0566],\n",
      "          [1.0977, 1.4893, 1.7266,  ..., 1.6045, 1.3916, 1.0195],\n",
      "          ...,\n",
      "          [1.0020, 0.8809, 0.9316,  ..., 0.8975, 0.8765, 0.9526],\n",
      "          [0.9780, 0.8452, 0.8916,  ..., 0.8486, 0.8398, 0.9282],\n",
      "          [1.0645, 0.9526, 0.9888,  ..., 0.9722, 0.9634, 1.0430]]],\n",
      "\n",
      "\n",
      "        [[[0.3223, 0.3047, 0.2474,  ..., 0.3459, 0.3447, 0.3606],\n",
      "          [0.3313, 0.2769, 0.2269,  ..., 0.4360, 0.4517, 0.3674],\n",
      "          [0.3105, 0.2400, 0.2272,  ..., 0.4561, 0.4453, 0.3684],\n",
      "          ...,\n",
      "          [0.3831, 0.4028, 0.4414,  ..., 0.4075, 0.4263, 0.3884],\n",
      "          [0.3662, 0.3862, 0.4080,  ..., 0.3867, 0.3921, 0.3738],\n",
      "          [0.3845, 0.3845, 0.4124,  ..., 0.3889, 0.3987, 0.3943]],\n",
      "\n",
      "         [[0.5874, 0.5439, 0.6636,  ..., 0.4668, 0.4614, 0.5459],\n",
      "          [0.4570, 0.3511, 0.5991,  ..., 0.3691, 0.3572, 0.4565],\n",
      "          [0.4614, 0.4141, 0.7778,  ..., 0.3662, 0.3423, 0.4297],\n",
      "          ...,\n",
      "          [0.4570, 0.3569, 0.3481,  ..., 0.3665, 0.3374, 0.4619],\n",
      "          [0.4409, 0.3281, 0.3306,  ..., 0.3303, 0.3237, 0.4355],\n",
      "          [0.5347, 0.4380, 0.4370,  ..., 0.4399, 0.4307, 0.5347]],\n",
      "\n",
      "         [[1.0195, 0.8730, 0.8926,  ..., 0.8545, 0.8794, 0.9692],\n",
      "          [0.8857, 0.6582, 0.6875,  ..., 0.7168, 0.7559, 0.8770],\n",
      "          [0.9009, 0.6743, 0.7817,  ..., 0.6660, 0.7300, 0.8623],\n",
      "          ...,\n",
      "          [1.0107, 0.9023, 0.9517,  ..., 0.9204, 0.8936, 0.9546],\n",
      "          [0.9878, 0.8677, 0.9111,  ..., 0.8726, 0.8604, 0.9272],\n",
      "          [1.0732, 0.9731, 1.0088,  ..., 0.9810, 0.9683, 1.0391]]],\n",
      "\n",
      "\n",
      "        [[[0.3379, 0.3364, 0.3369,  ..., 0.3569, 0.3501, 0.3630],\n",
      "          [0.3579, 0.4153, 0.4958,  ..., 0.3713, 0.3770, 0.3691],\n",
      "          [0.3445, 0.4360, 0.4917,  ..., 0.3760, 0.3618, 0.3750],\n",
      "          ...,\n",
      "          [0.3706, 0.4233, 0.5068,  ..., 0.4731, 0.4951, 0.3792],\n",
      "          [0.3584, 0.4019, 0.4604,  ..., 0.4260, 0.4321, 0.3682],\n",
      "          [0.3721, 0.3745, 0.3984,  ..., 0.3857, 0.3972, 0.3914]],\n",
      "\n",
      "         [[0.5425, 0.4678, 0.4683,  ..., 0.4834, 0.4736, 0.5742],\n",
      "          [0.4292, 0.3804, 0.3940,  ..., 0.3501, 0.3291, 0.4619],\n",
      "          [0.4072, 0.3853, 0.4243,  ..., 0.3296, 0.3162, 0.4438],\n",
      "          ...,\n",
      "          [0.4287, 0.3572, 0.3633,  ..., 0.3862, 0.3491, 0.4468],\n",
      "          [0.4146, 0.3237, 0.3364,  ..., 0.3271, 0.3306, 0.4199],\n",
      "          [0.5195, 0.4028, 0.4053,  ..., 0.4111, 0.4141, 0.5220]],\n",
      "\n",
      "         [[0.9692, 0.8042, 0.8013,  ..., 0.9390, 0.9272, 0.9995],\n",
      "          [0.8213, 0.5991, 0.5610,  ..., 0.8550, 0.8218, 0.9155],\n",
      "          [0.7954, 0.5132, 0.4534,  ..., 0.9004, 0.8574, 0.9346],\n",
      "          ...,\n",
      "          [0.8979, 0.7300, 0.6973,  ..., 0.6826, 0.7363, 0.8760],\n",
      "          [0.8975, 0.7305, 0.7153,  ..., 0.7524, 0.7827, 0.8804],\n",
      "          [1.0244, 0.8813, 0.8931,  ..., 0.9204, 0.9321, 1.0186]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[0.5220, 0.5645, 0.5801,  ..., 0.3123, 0.2949, 0.3853],\n",
      "          [0.5757, 0.6816, 0.7021,  ..., 0.2971, 0.2341, 0.3025],\n",
      "          [0.5918, 0.6895, 0.7070,  ..., 0.4912, 0.3201, 0.2983],\n",
      "          ...,\n",
      "          [0.5820, 0.8350, 0.9307,  ..., 0.8584, 0.8760, 0.6211],\n",
      "          [0.5635, 0.8018, 0.8770,  ..., 0.8242, 0.8252, 0.5957],\n",
      "          [0.5078, 0.5732, 0.6172,  ..., 0.5908, 0.5918, 0.5298]],\n",
      "\n",
      "         [[0.6289, 0.5840, 0.5977,  ..., 0.5264, 0.5264, 0.5854],\n",
      "          [0.5762, 0.5166, 0.5312,  ..., 0.5684, 0.4678, 0.4932],\n",
      "          [0.5869, 0.5308, 0.5654,  ..., 1.1074, 0.9131, 0.6250],\n",
      "          ...,\n",
      "          [0.5332, 0.5107, 0.5420,  ..., 0.5322, 0.4907, 0.5625],\n",
      "          [0.5186, 0.4590, 0.4929,  ..., 0.4807, 0.4644, 0.5322],\n",
      "          [0.5742, 0.5054, 0.5107,  ..., 0.5186, 0.5127, 0.5767]],\n",
      "\n",
      "         [[1.1826, 1.1602, 1.2129,  ..., 0.7080, 0.7207, 0.8672],\n",
      "          [1.2002, 1.2168, 1.2949,  ..., 0.4392, 0.4182, 0.6445],\n",
      "          [1.2676, 1.3242, 1.4170,  ..., 0.5811, 0.5391, 0.6357],\n",
      "          ...,\n",
      "          [0.9453, 0.6855, 0.5811,  ..., 0.7559, 0.7930, 0.9678],\n",
      "          [0.9697, 0.7344, 0.6650,  ..., 0.7969, 0.8301, 0.9775],\n",
      "          [1.0840, 0.9727, 0.9453,  ..., 1.0176, 1.0293, 1.0889]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5752, 0.5977,  ..., 1.2285, 0.8535, 0.3992],\n",
      "          [0.5654, 0.7773, 0.8574,  ..., 2.7539, 2.0684, 0.8271],\n",
      "          [0.5728, 0.8037, 0.8721,  ..., 3.5156, 2.6992, 1.1689],\n",
      "          ...,\n",
      "          [0.5977, 0.6865, 0.7256,  ..., 0.7080, 0.7246, 0.5986],\n",
      "          [0.5757, 0.6699, 0.6855,  ..., 0.6973, 0.6992, 0.5801],\n",
      "          [0.5449, 0.5918, 0.6182,  ..., 0.5967, 0.5918, 0.5547]],\n",
      "\n",
      "         [[0.6035, 0.5732, 0.5801,  ..., 2.9453, 2.3477, 1.4219],\n",
      "          [0.5474, 0.4844, 0.5068,  ..., 5.1211, 4.0039, 2.1445],\n",
      "          [0.5400, 0.4841, 0.4990,  ..., 6.2773, 4.9336, 2.5977],\n",
      "          ...,\n",
      "          [0.6060, 0.5576, 0.5845,  ..., 0.5679, 0.5186, 0.5820],\n",
      "          [0.5703, 0.5127, 0.5312,  ..., 0.5200, 0.4851, 0.5513],\n",
      "          [0.6309, 0.5674, 0.5806,  ..., 0.5664, 0.5400, 0.6040]],\n",
      "\n",
      "         [[1.0918, 0.9844, 0.9697,  ..., 1.4121, 1.2324, 1.0557],\n",
      "          [1.0479, 0.8672, 0.8359,  ..., 2.0352, 1.7324, 1.1621],\n",
      "          [1.0625, 0.8770, 0.8418,  ..., 2.3027, 1.9814, 1.2988],\n",
      "          ...,\n",
      "          [1.2910, 1.3623, 1.4531,  ..., 1.3604, 1.2529, 1.2002],\n",
      "          [1.2354, 1.2725, 1.3506,  ..., 1.2637, 1.1777, 1.1514],\n",
      "          [1.2324, 1.2383, 1.2949,  ..., 1.2412, 1.1885, 1.1807]]],\n",
      "\n",
      "\n",
      "        [[[0.4902, 0.5752, 0.5938,  ..., 0.5615, 0.5435, 0.5239],\n",
      "          [0.5664, 0.7910, 0.8848,  ..., 0.6484, 0.6455, 0.5684],\n",
      "          [0.5723, 0.8311, 0.9092,  ..., 0.6719, 0.6367, 0.5869],\n",
      "          ...,\n",
      "          [0.5820, 0.8301, 0.9209,  ..., 0.7012, 0.7266, 0.5830],\n",
      "          [0.5630, 0.7969, 0.8662,  ..., 0.6836, 0.6680, 0.5649],\n",
      "          [0.5107, 0.5723, 0.6104,  ..., 0.5850, 0.5791, 0.5479]],\n",
      "\n",
      "         [[0.5986, 0.5674, 0.5762,  ..., 0.5869, 0.5620, 0.6187],\n",
      "          [0.5400, 0.4807, 0.5239,  ..., 0.5171, 0.4775, 0.5645],\n",
      "          [0.5288, 0.4993, 0.5488,  ..., 0.5449, 0.4956, 0.5713],\n",
      "          ...,\n",
      "          [0.5342, 0.5039, 0.5288,  ..., 0.5352, 0.4856, 0.5586],\n",
      "          [0.5205, 0.4578, 0.4792,  ..., 0.4971, 0.4629, 0.5361],\n",
      "          [0.5762, 0.5083, 0.5146,  ..., 0.5571, 0.5371, 0.6060]],\n",
      "\n",
      "         [[1.0547, 0.9102, 0.8633,  ..., 1.1816, 1.1367, 1.1328],\n",
      "          [0.9746, 0.7275, 0.6191,  ..., 1.2578, 1.1729, 1.1582],\n",
      "          [0.9619, 0.6738, 0.5352,  ..., 1.3750, 1.2676, 1.2188],\n",
      "          ...,\n",
      "          [0.9570, 0.7178, 0.6475,  ..., 1.2646, 1.1572, 1.1396],\n",
      "          [0.9814, 0.7656, 0.7295,  ..., 1.1973, 1.1299, 1.1221],\n",
      "          [1.0918, 0.9922, 0.9854,  ..., 1.2129, 1.1748, 1.1768]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[0.7412, 0.8398, 0.8643,  ..., 0.5049, 0.4028, 0.4636],\n",
      "          [0.8369, 1.1016, 1.1152,  ..., 1.1582, 0.5952, 0.4216],\n",
      "          [0.8550, 1.1270, 1.1113,  ..., 1.7227, 1.0225, 0.4570],\n",
      "          ...,\n",
      "          [0.8574, 1.2324, 1.3242,  ..., 1.3125, 1.3027, 0.9497],\n",
      "          [0.8306, 1.1953, 1.2695,  ..., 1.2676, 1.2461, 0.9229],\n",
      "          [0.7104, 0.8540, 0.9111,  ..., 0.9014, 0.9009, 0.7314]],\n",
      "\n",
      "         [[0.7749, 0.7759, 0.7988,  ..., 1.3242, 0.9556, 0.7959],\n",
      "          [0.7378, 0.7231, 0.7710,  ..., 2.2422, 1.3574, 0.8477],\n",
      "          [0.7417, 0.7446, 0.7905,  ..., 3.0273, 1.9600, 1.0273],\n",
      "          ...,\n",
      "          [0.6851, 0.6558, 0.6802,  ..., 0.7109, 0.6621, 0.7061],\n",
      "          [0.6768, 0.6123, 0.6338,  ..., 0.6597, 0.6182, 0.6816],\n",
      "          [0.7065, 0.6553, 0.6523,  ..., 0.6567, 0.6523, 0.7119]],\n",
      "\n",
      "         [[1.3408, 1.3701, 1.4834,  ..., 0.9517, 0.8877, 0.9971],\n",
      "          [1.3467, 1.4111, 1.6025,  ..., 1.1475, 0.7842, 0.8301],\n",
      "          [1.3779, 1.4785, 1.7090,  ..., 1.4150, 1.0195, 0.8208],\n",
      "          ...,\n",
      "          [0.9326, 0.5239, 0.3064,  ..., 0.2959, 0.4783, 0.8643],\n",
      "          [1.0303, 0.6934, 0.5361,  ..., 0.4993, 0.6577, 0.9536],\n",
      "          [1.2129, 1.0479, 0.9644,  ..., 0.9482, 1.0195, 1.1787]]],\n",
      "\n",
      "\n",
      "        [[[0.7603, 0.8252, 0.8296,  ..., 0.6958, 0.5312, 0.4653],\n",
      "          [0.8438, 1.0400, 1.1074,  ..., 1.7305, 1.0889, 0.5098],\n",
      "          [0.8535, 1.0840, 1.1367,  ..., 2.3750, 1.5762, 0.6089],\n",
      "          ...,\n",
      "          [0.8496, 1.1855, 1.2578,  ..., 0.7158, 0.7666, 0.7461],\n",
      "          [0.8325, 1.1562, 1.2188,  ..., 0.7686, 0.7861, 0.7583],\n",
      "          [0.7476, 0.8398, 0.8853,  ..., 0.7759, 0.7871, 0.7485]],\n",
      "\n",
      "         [[0.8110, 0.7690, 0.7637,  ..., 1.8447, 1.3906, 1.0029],\n",
      "          [0.7720, 0.7104, 0.7148,  ..., 3.2461, 2.2363, 1.2412],\n",
      "          [0.7656, 0.7256, 0.7168,  ..., 4.1719, 2.9219, 1.4736],\n",
      "          ...,\n",
      "          [0.7295, 0.6934, 0.6963,  ..., 0.6904, 0.6440, 0.7271],\n",
      "          [0.7119, 0.6665, 0.6753,  ..., 0.6484, 0.6128, 0.7021],\n",
      "          [0.7383, 0.6924, 0.6973,  ..., 0.7471, 0.7192, 0.7773]],\n",
      "\n",
      "         [[1.4326, 1.4150, 1.3682,  ..., 1.1709, 1.0723, 1.0967],\n",
      "          [1.4893, 1.4717, 1.3838,  ..., 1.6514, 1.2324, 1.0215],\n",
      "          [1.5029, 1.4551, 1.3516,  ..., 1.9912, 1.5234, 1.0625],\n",
      "          ...,\n",
      "          [1.2627, 1.1025, 1.0342,  ..., 1.3271, 1.3291, 1.3516],\n",
      "          [1.2715, 1.1182, 1.0801,  ..., 1.3604, 1.3418, 1.3496],\n",
      "          [1.3369, 1.2754, 1.2559,  ..., 1.4395, 1.4121, 1.3994]]],\n",
      "\n",
      "\n",
      "        [[[0.5137, 0.5977, 0.8101,  ..., 0.5801, 0.4470, 0.4739],\n",
      "          [0.6084, 1.3574, 2.0293,  ..., 1.2949, 0.6763, 0.4524],\n",
      "          [0.7832, 1.9453, 2.7617,  ..., 1.7754, 1.0020, 0.4810],\n",
      "          ...,\n",
      "          [0.9014, 1.0625, 1.1055,  ..., 1.0898, 1.0752, 0.9092],\n",
      "          [0.8755, 1.0449, 1.0723,  ..., 1.0576, 1.0508, 0.8853],\n",
      "          [0.7993, 0.8901, 0.9204,  ..., 0.9092, 0.8911, 0.8101]],\n",
      "\n",
      "         [[1.1279, 1.5352, 2.0742,  ..., 1.5352, 1.0879, 0.8569],\n",
      "          [1.4404, 2.6777, 3.7012,  ..., 2.5742, 1.5479, 0.9312],\n",
      "          [1.8125, 3.5215, 4.7500,  ..., 3.2188, 1.9980, 1.0469],\n",
      "          ...,\n",
      "          [0.8423, 0.8257, 0.8633,  ..., 0.8740, 0.7993, 0.8164],\n",
      "          [0.7974, 0.7690, 0.8013,  ..., 0.8037, 0.7510, 0.7725],\n",
      "          [0.8223, 0.7803, 0.8066,  ..., 0.8140, 0.7705, 0.8027]],\n",
      "\n",
      "         [[1.1572, 1.1201, 1.2607,  ..., 1.1016, 0.9932, 1.0645],\n",
      "          [1.0947, 1.4277, 1.8447,  ..., 1.3848, 0.9600, 0.9468],\n",
      "          [1.1650, 1.7832, 2.2324,  ..., 1.6494, 1.1318, 0.9380],\n",
      "          ...,\n",
      "          [1.6572, 1.8477, 1.9463,  ..., 1.9463, 1.8008, 1.6152],\n",
      "          [1.5859, 1.7324, 1.8301,  ..., 1.8271, 1.7051, 1.5479],\n",
      "          [1.5205, 1.6006, 1.6660,  ..., 1.6680, 1.5850, 1.4980]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6973, 0.5723, 0.5308,  ..., 0.4949, 0.5103, 0.6436],\n",
      "          [0.6377, 0.5078, 0.6934,  ..., 0.6240, 0.4939, 0.5459],\n",
      "          [0.5840, 0.6211, 1.1660,  ..., 1.0732, 0.6338, 0.4827],\n",
      "          ...,\n",
      "          [1.0400, 1.2832, 1.3223,  ..., 1.4229, 1.4336, 1.0664],\n",
      "          [1.0234, 1.2520, 1.2939,  ..., 1.4141, 1.3945, 1.0430],\n",
      "          [0.9492, 1.0400, 1.0752,  ..., 1.0381, 1.0254, 0.9258]],\n",
      "\n",
      "         [[0.7656, 0.6650, 0.8408,  ..., 0.7803, 0.6504, 0.7031],\n",
      "          [0.6846, 0.6904, 1.2324,  ..., 1.1592, 0.6836, 0.6055],\n",
      "          [0.7314, 1.0469, 1.9746,  ..., 1.8242, 1.0820, 0.6074],\n",
      "          ...,\n",
      "          [0.9102, 0.9629, 0.9902,  ..., 0.9395, 0.8896, 0.8799],\n",
      "          [0.8857, 0.9229, 0.9541,  ..., 0.9053, 0.8662, 0.8467],\n",
      "          [0.8984, 0.8838, 0.9023,  ..., 0.8604, 0.8311, 0.8350]],\n",
      "\n",
      "         [[1.1943, 0.9385, 0.9062,  ..., 0.8218, 0.8613, 1.0488],\n",
      "          [1.0303, 0.7427, 0.8428,  ..., 0.7529, 0.6548, 0.8594],\n",
      "          [0.9873, 0.7744, 1.1299,  ..., 1.0176, 0.7173, 0.7529],\n",
      "          ...,\n",
      "          [1.6426, 1.7949, 1.8857,  ..., 1.4434, 1.3887, 1.4062],\n",
      "          [1.6230, 1.7539, 1.8477,  ..., 1.4229, 1.4043, 1.4062],\n",
      "          [1.5732, 1.6543, 1.7109,  ..., 1.5000, 1.4668, 1.4404]]],\n",
      "\n",
      "\n",
      "        [[[0.6377, 0.8828, 1.0615,  ..., 2.0664, 1.4893, 0.6885],\n",
      "          [0.8447, 1.7783, 2.0664,  ..., 4.1250, 3.1328, 1.4102],\n",
      "          [0.9619, 1.9736, 2.2695,  ..., 5.2578, 4.0586, 1.9316],\n",
      "          ...,\n",
      "          [1.0088, 1.3701, 1.4346,  ..., 1.3301, 1.3633, 1.0518],\n",
      "          [0.9961, 1.3535, 1.4092,  ..., 1.3486, 1.3438, 1.0312],\n",
      "          [0.9199, 1.0049, 1.0479,  ..., 1.0342, 1.0166, 0.9385]],\n",
      "\n",
      "         [[1.2568, 1.8730, 2.1504,  ..., 3.6641, 2.7910, 1.5039],\n",
      "          [1.6650, 3.0117, 3.4258,  ..., 6.7227, 5.1328, 2.5332],\n",
      "          [1.7861, 3.2109, 3.6211,  ..., 8.4062, 6.4883, 3.2754],\n",
      "          ...,\n",
      "          [0.8789, 0.9150, 0.9316,  ..., 0.9756, 0.9180, 0.8994],\n",
      "          [0.8604, 0.8867, 0.9102,  ..., 0.9326, 0.8857, 0.8613],\n",
      "          [0.8496, 0.8496, 0.8643,  ..., 0.8818, 0.8467, 0.8477]],\n",
      "\n",
      "         [[1.1055, 1.1475, 1.2754,  ..., 1.9502, 1.5527, 1.1035],\n",
      "          [1.0791, 1.6426, 1.8428,  ..., 3.2793, 2.5938, 1.4355],\n",
      "          [1.1211, 1.7393, 1.9277,  ..., 3.9922, 3.1895, 1.7773],\n",
      "          ...,\n",
      "          [1.4902, 1.4795, 1.5117,  ..., 1.7031, 1.5947, 1.5195],\n",
      "          [1.4883, 1.4639, 1.5215,  ..., 1.6152, 1.5547, 1.4883],\n",
      "          [1.4775, 1.5137, 1.5469,  ..., 1.5908, 1.5410, 1.4814]]],\n",
      "\n",
      "\n",
      "        [[[0.9238, 1.0000, 1.0127,  ..., 0.9600, 0.9717, 0.8760],\n",
      "          [1.0244, 1.1543, 1.1748,  ..., 1.2559, 1.3096, 0.9990],\n",
      "          [1.0518, 1.1953, 1.2031,  ..., 1.3467, 1.3760, 1.0439],\n",
      "          ...,\n",
      "          [0.9980, 1.4453, 1.5381,  ..., 1.4736, 1.4834, 1.0830],\n",
      "          [0.9824, 1.4199, 1.4980,  ..., 1.4512, 1.4307, 1.0527],\n",
      "          [0.8770, 1.0020, 1.0605,  ..., 1.0410, 1.0312, 0.9121]],\n",
      "\n",
      "         [[0.9160, 0.9023, 0.9170,  ..., 0.8701, 0.8604, 0.8447],\n",
      "          [0.9287, 0.9111, 0.9463,  ..., 0.8643, 0.8457, 0.8516],\n",
      "          [0.9561, 0.9629, 0.9902,  ..., 0.8848, 0.8604, 0.8477],\n",
      "          ...,\n",
      "          [0.8271, 0.8408, 0.8330,  ..., 0.9092, 0.8633, 0.8604],\n",
      "          [0.8145, 0.8203, 0.8232,  ..., 0.8828, 0.8477, 0.8320],\n",
      "          [0.8115, 0.7988, 0.8008,  ..., 0.8447, 0.8164, 0.8271]],\n",
      "\n",
      "         [[1.5518, 1.6064, 1.6465,  ..., 1.4121, 1.4141, 1.3799],\n",
      "          [1.6719, 1.8174, 1.8672,  ..., 1.4189, 1.3848, 1.3926],\n",
      "          [1.7510, 1.9404, 1.9756,  ..., 1.3730, 1.3398, 1.3545],\n",
      "          ...,\n",
      "          [1.2285, 0.9766, 0.8599,  ..., 1.2148, 1.1836, 1.2910],\n",
      "          [1.2705, 1.0439, 0.9785,  ..., 1.2646, 1.2637, 1.3271],\n",
      "          [1.3652, 1.2861, 1.2480,  ..., 1.4268, 1.4023, 1.4053]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[1.1309, 1.3320, 1.3516,  ..., 1.9805, 1.5459, 0.7930],\n",
      "          [1.3252, 1.8164, 1.8828,  ..., 3.8691, 3.1465, 1.4141],\n",
      "          [1.3486, 1.8662, 1.9014,  ..., 4.5469, 3.7500, 1.7627],\n",
      "          ...,\n",
      "          [1.3027, 1.8252, 1.8838,  ..., 1.8350, 1.8457, 1.4277],\n",
      "          [1.3047, 1.8359, 1.8799,  ..., 1.8457, 1.8281, 1.4131],\n",
      "          [1.1426, 1.3340, 1.3721,  ..., 1.4062, 1.3936, 1.2490]],\n",
      "\n",
      "         [[1.0938, 1.1484, 1.1426,  ..., 3.3398, 2.7129, 1.4854],\n",
      "          [1.1270, 1.1982, 1.1836,  ..., 6.0391, 4.9102, 2.3730],\n",
      "          [1.1406, 1.2158, 1.1885,  ..., 6.9453, 5.7188, 2.8086],\n",
      "          ...,\n",
      "          [1.0771, 1.1357, 1.1221,  ..., 1.3418, 1.2871, 1.1943],\n",
      "          [1.0771, 1.1396, 1.1377,  ..., 1.3125, 1.2637, 1.1631],\n",
      "          [1.0508, 1.0684, 1.0674,  ..., 1.1846, 1.1475, 1.1055]],\n",
      "\n",
      "         [[1.6602, 1.5518, 1.4463,  ..., 1.9004, 1.5908, 1.1523],\n",
      "          [1.6729, 1.5000, 1.2979,  ..., 3.1953, 2.6562, 1.4170],\n",
      "          [1.7158, 1.5225, 1.3076,  ..., 3.6172, 3.0547, 1.6494],\n",
      "          ...,\n",
      "          [1.4014, 1.0898, 0.9150,  ..., 2.0703, 1.9990, 1.8975],\n",
      "          [1.5371, 1.3096, 1.2070,  ..., 2.0625, 2.0215, 1.8984],\n",
      "          [1.6738, 1.6074, 1.5508,  ..., 2.0195, 1.9688, 1.8574]]],\n",
      "\n",
      "\n",
      "        [[[1.0977, 1.3232, 1.3477,  ..., 1.2656, 0.9482, 0.6958],\n",
      "          [1.2949, 1.8164, 1.8857,  ..., 2.6914, 2.1191, 0.8887],\n",
      "          [1.3086, 1.8623, 1.8994,  ..., 3.4199, 2.7402, 1.1924],\n",
      "          ...,\n",
      "          [1.3340, 1.8281, 1.8799,  ..., 1.8350, 1.8496, 1.4326],\n",
      "          [1.3340, 1.8281, 1.8760,  ..., 1.8193, 1.8115, 1.4141],\n",
      "          [1.1875, 1.3545, 1.3838,  ..., 1.4277, 1.3994, 1.2646]],\n",
      "\n",
      "         [[1.0771, 1.1289, 1.1328,  ..., 2.2930, 1.8223, 1.1230],\n",
      "          [1.0879, 1.1523, 1.1533,  ..., 4.2188, 3.3027, 1.6191],\n",
      "          [1.0791, 1.1318, 1.1240,  ..., 5.2266, 4.1719, 1.9746],\n",
      "          ...,\n",
      "          [1.1279, 1.2070, 1.1924,  ..., 1.3438, 1.2871, 1.1924],\n",
      "          [1.1182, 1.1943, 1.1934,  ..., 1.3291, 1.2754, 1.1699],\n",
      "          [1.0762, 1.1025, 1.0996,  ..., 1.2158, 1.1680, 1.1143]],\n",
      "\n",
      "         [[1.5811, 1.4355, 1.3672,  ..., 1.3662, 1.1709, 1.0684],\n",
      "          [1.4922, 1.2383, 1.0850,  ..., 2.2910, 1.8506, 1.0654],\n",
      "          [1.4072, 1.0518, 0.8711,  ..., 2.7500, 2.2832, 1.2031],\n",
      "          ...,\n",
      "          [1.6523, 1.4912, 1.3457,  ..., 2.1133, 2.0156, 1.8984],\n",
      "          [1.7158, 1.6016, 1.5166,  ..., 2.2109, 2.1172, 1.9434],\n",
      "          [1.7627, 1.7588, 1.7119,  ..., 2.1328, 2.0488, 1.8955]]],\n",
      "\n",
      "\n",
      "        [[[1.0469, 1.1221, 1.2285,  ..., 2.0742, 1.5410, 0.8003],\n",
      "          [0.9233, 0.9790, 1.2900,  ..., 4.1094, 3.1934, 1.4180],\n",
      "          [0.6807, 0.5044, 0.4780,  ..., 5.1172, 4.0156, 1.8818],\n",
      "          ...,\n",
      "          [1.4365, 1.7676, 1.8027,  ..., 1.8408, 1.8574, 1.4277],\n",
      "          [1.4150, 1.7510, 1.7891,  ..., 1.8506, 1.8379, 1.4150],\n",
      "          [1.2812, 1.4346, 1.4736,  ..., 1.4033, 1.3936, 1.2412]],\n",
      "\n",
      "         [[0.9878, 0.9961, 1.0557,  ..., 3.4980, 2.7246, 1.4980],\n",
      "          [0.8477, 0.7603, 0.9038,  ..., 6.4453, 5.0000, 2.3984],\n",
      "          [0.8516, 0.6846, 0.4805,  ..., 7.8984, 6.1719, 3.0293],\n",
      "          ...,\n",
      "          [1.2480, 1.3848, 1.4131,  ..., 1.3193, 1.2666, 1.1797],\n",
      "          [1.2197, 1.3428, 1.3809,  ..., 1.2988, 1.2520, 1.1543],\n",
      "          [1.1553, 1.2158, 1.2373,  ..., 1.1768, 1.1396, 1.1006]],\n",
      "\n",
      "         [[1.5869, 1.5234, 1.5811,  ..., 1.9854, 1.6094, 1.1777],\n",
      "          [1.3398, 1.1992, 1.3164,  ..., 3.3965, 2.7129, 1.4414],\n",
      "          [0.9790, 0.5664, 0.5273,  ..., 4.0703, 3.2832, 1.7676],\n",
      "          ...,\n",
      "          [2.1699, 2.4805, 2.5664,  ..., 1.9531, 1.8838, 1.8271],\n",
      "          [2.1328, 2.4160, 2.5156,  ..., 1.9932, 1.9531, 1.8564],\n",
      "          [1.9775, 2.1738, 2.2363,  ..., 1.9893, 1.9385, 1.8389]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[0.8750, 1.4395, 2.1035,  ..., 0.8867, 0.6777, 0.6807],\n",
      "          [1.2705, 2.9219, 4.0000,  ..., 2.1055, 1.5439, 0.6582],\n",
      "          [1.6914, 3.5938, 4.7422,  ..., 2.8691, 2.2324, 0.8760],\n",
      "          ...,\n",
      "          [1.2266, 2.9922, 4.1289,  ..., 2.2500, 2.1875, 1.7646],\n",
      "          [1.0049, 2.4023, 3.3105,  ..., 2.1973, 2.1543, 1.7227],\n",
      "          [0.7676, 0.9951, 1.4238,  ..., 1.8076, 1.7412, 1.5430]],\n",
      "\n",
      "         [[1.3027, 2.3203, 3.2910,  ..., 1.3428, 0.9814, 0.7354],\n",
      "          [1.9658, 4.2891, 5.8906,  ..., 2.8418, 2.0039, 0.8428],\n",
      "          [2.4688, 5.1875, 6.8750,  ..., 3.7715, 2.8965, 1.1221],\n",
      "          ...,\n",
      "          [1.7266, 4.1406, 5.7930,  ..., 1.8398, 1.7031, 1.5029],\n",
      "          [1.3535, 3.2129, 4.4844,  ..., 1.7480, 1.6445, 1.4434],\n",
      "          [0.8848, 1.3076, 1.8838,  ..., 1.5244, 1.4434, 1.3408]],\n",
      "\n",
      "         [[1.1455, 1.3604, 1.9043,  ..., 0.7266, 0.6875, 0.8682],\n",
      "          [1.2012, 2.3555, 3.2148,  ..., 1.4180, 1.0195, 0.5713],\n",
      "          [1.4736, 2.8027, 3.6953,  ..., 1.8369, 1.4590, 0.5952],\n",
      "          ...,\n",
      "          [1.0078, 2.1406, 3.0117,  ..., 3.1895, 2.9355, 2.5039],\n",
      "          [0.8203, 1.6816, 2.3652,  ..., 3.0449, 2.8320, 2.4238],\n",
      "          [0.9150, 0.7832, 1.1191,  ..., 2.6328, 2.4883, 2.2266]]],\n",
      "\n",
      "\n",
      "        [[[1.3330, 1.6123, 1.6484,  ..., 1.4229, 1.4238, 1.3525],\n",
      "          [1.5840, 2.2305, 2.3184,  ..., 1.6123, 1.6562, 1.4922],\n",
      "          [1.6016, 2.2832, 2.3203,  ..., 1.6035, 1.6670, 1.5283],\n",
      "          ...,\n",
      "          [1.5947, 2.2539, 2.3066,  ..., 2.2734, 2.3223, 1.7178],\n",
      "          [1.6006, 2.2832, 2.3223,  ..., 2.3066, 2.3047, 1.7061],\n",
      "          [1.3457, 1.6133, 1.6611,  ..., 1.6846, 1.6787, 1.4463]],\n",
      "\n",
      "         [[1.2480, 1.3311, 1.3301,  ..., 1.2256, 1.2256, 1.2100],\n",
      "          [1.3008, 1.4248, 1.4141,  ..., 1.2627, 1.2676, 1.2422],\n",
      "          [1.3027, 1.4150, 1.3877,  ..., 1.2715, 1.2910, 1.2598],\n",
      "          ...,\n",
      "          [1.2725, 1.3809, 1.3418,  ..., 1.5723, 1.5322, 1.3750],\n",
      "          [1.2725, 1.3896, 1.3691,  ..., 1.5557, 1.5176, 1.3457],\n",
      "          [1.2178, 1.2617, 1.2549,  ..., 1.3682, 1.3330, 1.2666]],\n",
      "\n",
      "         [[1.8506, 1.7139, 1.6055,  ..., 2.0312, 2.0391, 1.9365],\n",
      "          [1.8369, 1.6113, 1.3994,  ..., 2.2559, 2.2695, 2.0996],\n",
      "          [1.7842, 1.4648, 1.2373,  ..., 2.2988, 2.3340, 2.1641],\n",
      "          ...,\n",
      "          [1.5928, 1.2344, 0.9536,  ..., 2.0312, 2.0234, 1.9873],\n",
      "          [1.7266, 1.4609, 1.2754,  ..., 2.0859, 2.1094, 2.0176],\n",
      "          [1.8652, 1.7773, 1.6709,  ..., 2.1367, 2.1172, 2.0195]]],\n",
      "\n",
      "\n",
      "        [[[1.2930, 1.6230, 1.6533,  ..., 2.3867, 1.8633, 0.9277],\n",
      "          [1.5830, 2.2559, 2.3281,  ..., 4.5312, 3.6445, 1.6973],\n",
      "          [1.5879, 2.2988, 2.3242,  ..., 5.4492, 4.4219, 2.1562],\n",
      "          ...,\n",
      "          [1.5732, 2.2109, 2.2539,  ..., 2.2891, 2.3457, 1.7305],\n",
      "          [1.5713, 2.2363, 2.2676,  ..., 2.3223, 2.3281, 1.7217],\n",
      "          [1.3154, 1.5781, 1.6172,  ..., 1.6650, 1.6689, 1.4199]],\n",
      "\n",
      "         [[1.2295, 1.3184, 1.3301,  ..., 3.7441, 2.9648, 1.5674],\n",
      "          [1.2676, 1.3906, 1.4023,  ..., 6.7695, 5.4102, 2.5957],\n",
      "          [1.2539, 1.3613, 1.3564,  ..., 8.0547, 6.4883, 3.2246],\n",
      "          ...,\n",
      "          [1.2617, 1.3496, 1.2783,  ..., 1.5156, 1.4932, 1.3564],\n",
      "          [1.2520, 1.3428, 1.2930,  ..., 1.5078, 1.4844, 1.3301],\n",
      "          [1.1973, 1.2266, 1.2002,  ..., 1.3330, 1.3086, 1.2520]],\n",
      "\n",
      "         [[1.7305, 1.5742, 1.5557,  ..., 2.1387, 1.7334, 1.1533],\n",
      "          [1.6201, 1.3623, 1.2627,  ..., 3.6836, 2.9922, 1.5381],\n",
      "          [1.5117, 1.1318, 0.9873,  ..., 4.3203, 3.5469, 1.8672],\n",
      "          ...,\n",
      "          [1.5713, 1.1396, 0.7349,  ..., 1.7490, 1.8096, 1.8652],\n",
      "          [1.6689, 1.3105, 0.9966,  ..., 1.8564, 1.9316, 1.9150],\n",
      "          [1.8145, 1.6572, 1.4678,  ..., 2.0078, 2.0195, 1.9668]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.6133, 1.8184, 1.8750,  ..., 2.7969, 2.2246, 1.1602],\n",
      "          [1.8652, 2.4512, 2.5742,  ..., 5.1250, 4.1758, 2.0039],\n",
      "          [1.9609, 2.6055, 2.6875,  ..., 6.0039, 4.9297, 2.4512],\n",
      "          ...,\n",
      "          [1.8965, 2.5898, 2.6406,  ..., 2.6719, 2.6895, 1.9902],\n",
      "          [1.8906, 2.6016, 2.6680,  ..., 2.6836, 2.6543, 1.9648],\n",
      "          [1.6641, 1.9219, 1.9766,  ..., 1.9922, 1.9570, 1.6836]],\n",
      "\n",
      "         [[1.4727, 1.5830, 1.6289,  ..., 4.2344, 3.3926, 1.8320],\n",
      "          [1.5986, 1.8232, 1.8965,  ..., 7.4531, 6.0117, 2.9434],\n",
      "          [1.6865, 1.9531, 2.0156,  ..., 8.6875, 7.0586, 3.5508],\n",
      "          ...,\n",
      "          [1.6152, 1.8662, 1.8848,  ..., 2.0000, 1.9121, 1.6426],\n",
      "          [1.6006, 1.8486, 1.8945,  ..., 1.9580, 1.8779, 1.5967],\n",
      "          [1.4893, 1.6006, 1.6318,  ..., 1.6709, 1.6055, 1.4775]],\n",
      "\n",
      "         [[2.2070, 2.3203, 2.3887,  ..., 2.5645, 2.0918, 1.3740],\n",
      "          [2.4492, 2.6738, 2.7480,  ..., 4.3477, 3.5449, 1.8398],\n",
      "          [2.5938, 2.8652, 2.9434,  ..., 5.0273, 4.1406, 2.1875],\n",
      "          ...,\n",
      "          [2.2773, 2.3574, 2.3457,  ..., 2.7129, 2.5898, 2.3379],\n",
      "          [2.3223, 2.4355, 2.4805,  ..., 2.6914, 2.6133, 2.3301],\n",
      "          [2.2559, 2.3984, 2.4297,  ..., 2.5508, 2.4688, 2.2617]]],\n",
      "\n",
      "\n",
      "        [[[1.4531, 1.8008, 1.8516,  ..., 1.6602, 1.5000, 1.3359],\n",
      "          [1.7812, 2.4492, 2.5508,  ..., 2.3848, 2.1113, 1.5078],\n",
      "          [1.7559, 2.4023, 2.4805,  ..., 2.6230, 2.3125, 1.6230],\n",
      "          ...,\n",
      "          [1.8340, 2.5117, 2.5566,  ..., 2.5781, 2.6465, 1.9609],\n",
      "          [1.8438, 2.5547, 2.5996,  ..., 2.6289, 2.6426, 1.9609],\n",
      "          [1.5762, 1.8750, 1.9277,  ..., 1.9336, 1.9375, 1.6133]],\n",
      "\n",
      "         [[1.3789, 1.4951, 1.5342,  ..., 1.3428, 1.2617, 1.2139],\n",
      "          [1.4707, 1.6367, 1.6846,  ..., 1.4863, 1.3691, 1.2246],\n",
      "          [1.4912, 1.6484, 1.6738,  ..., 1.5566, 1.4746, 1.2900],\n",
      "          ...,\n",
      "          [1.5137, 1.6963, 1.6807,  ..., 1.7686, 1.7520, 1.5596],\n",
      "          [1.5205, 1.7119, 1.7227,  ..., 1.7812, 1.7627, 1.5420],\n",
      "          [1.4277, 1.5244, 1.5371,  ..., 1.5723, 1.5430, 1.4307]],\n",
      "\n",
      "         [[1.8994, 1.7881, 1.8691,  ..., 1.6924, 1.8047, 1.7686],\n",
      "          [1.9805, 1.8652, 1.8672,  ..., 1.7109, 1.8740, 1.8223],\n",
      "          [2.1504, 2.0332, 1.9336,  ..., 1.6348, 1.9277, 1.8789],\n",
      "          ...,\n",
      "          [1.9004, 1.7148, 1.5566,  ..., 1.8584, 1.9531, 1.9775],\n",
      "          [2.0312, 1.9326, 1.8555,  ..., 2.0449, 2.1367, 2.0625],\n",
      "          [2.1035, 2.1211, 2.0820,  ..., 2.1992, 2.2129, 2.1270]]],\n",
      "\n",
      "\n",
      "        [[[1.2168, 2.2910, 3.0039,  ..., 0.7710, 1.0332, 1.0654],\n",
      "          [2.1211, 4.3164, 5.4492,  ..., 1.7090, 1.6016, 1.1934],\n",
      "          [2.6270, 5.1172, 6.3320,  ..., 2.2930, 1.8223, 1.1914],\n",
      "          ...,\n",
      "          [2.1797, 2.7305, 2.8203,  ..., 2.1543, 1.7832, 1.5391],\n",
      "          [2.1055, 2.6406, 2.7480,  ..., 2.2070, 1.8867, 1.5996],\n",
      "          [1.8477, 2.1445, 2.2383,  ..., 2.0059, 1.8262, 1.6230]],\n",
      "\n",
      "         [[1.9033, 3.4727, 4.5312,  ..., 0.5508, 0.7666, 0.9580],\n",
      "          [3.0938, 6.2344, 7.8867,  ..., 0.7842, 0.5962, 0.7988],\n",
      "          [3.7539, 7.3164, 9.0781,  ..., 1.0801, 0.6650, 0.6787],\n",
      "          ...,\n",
      "          [1.9199, 2.2773, 2.3887,  ..., 1.8613, 1.5059, 1.3643],\n",
      "          [1.8369, 2.1543, 2.2832,  ..., 1.8291, 1.5264, 1.3789],\n",
      "          [1.6621, 1.8369, 1.9229,  ..., 1.7227, 1.5566, 1.4453]],\n",
      "\n",
      "         [[1.4404, 2.1191, 2.7266,  ..., 0.2742, 0.7617, 1.2256],\n",
      "          [1.9443, 3.6406, 4.5742,  ..., 0.1378, 0.2739, 0.8354],\n",
      "          [2.3125, 4.2305, 5.2344,  ..., 0.1726, 0.1530, 0.5630],\n",
      "          ...,\n",
      "          [3.0312, 3.7070, 3.9102,  ..., 3.0391, 2.4355, 2.1035],\n",
      "          [2.9082, 3.5176, 3.7383,  ..., 3.0391, 2.5254, 2.1719],\n",
      "          [2.5918, 2.9766, 3.1250,  ..., 2.8027, 2.5098, 2.2402]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 1.6699,  3.1621,  3.9395,  ...,  3.6641,  2.9785,  1.4600],\n",
      "          [ 2.9082,  5.5352,  6.7383,  ...,  6.2109,  5.2109,  2.7051],\n",
      "          [ 3.3516,  6.2266,  7.5078,  ...,  6.9805,  5.8828,  3.1816],\n",
      "          ...,\n",
      "          [ 1.9863,  2.7246,  2.8145,  ...,  2.6934,  2.7441,  2.0254],\n",
      "          [ 1.9512,  2.6973,  2.8086,  ...,  2.7441,  2.7168,  1.9961],\n",
      "          [ 1.7764,  1.9980,  2.0723,  ...,  2.0664,  2.0215,  1.7715]],\n",
      "\n",
      "         [[ 2.5488,  4.7070,  5.8555,  ...,  5.2617,  4.2773,  2.1855],\n",
      "          [ 4.1641,  7.9648,  9.7109,  ...,  8.6562,  7.1836,  3.7168],\n",
      "          [ 4.7617,  8.9219, 10.7734,  ...,  9.6406,  8.0625,  4.3125],\n",
      "          ...,\n",
      "          [ 1.7188,  2.0215,  2.0586,  ...,  1.9873,  1.9600,  1.6865],\n",
      "          [ 1.6855,  1.9766,  2.0508,  ...,  2.0312,  1.9727,  1.6592],\n",
      "          [ 1.5947,  1.6963,  1.7451,  ...,  1.7656,  1.6973,  1.5586]],\n",
      "\n",
      "         [[ 1.8330,  2.9727,  3.6680,  ...,  3.1758,  2.6016,  1.4121],\n",
      "          [ 2.6836,  4.9062,  5.9492,  ...,  5.1289,  4.2812,  2.2656],\n",
      "          [ 3.0430,  5.4766,  6.5938,  ...,  5.6836,  4.7812,  2.6113],\n",
      "          ...,\n",
      "          [ 2.3965,  2.5254,  2.5098,  ...,  2.3535,  2.4141,  2.2617],\n",
      "          [ 2.3984,  2.5488,  2.6074,  ...,  2.6016,  2.5996,  2.3301],\n",
      "          [ 2.3203,  2.4590,  2.5098,  ...,  2.5703,  2.5039,  2.2930]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4336,  1.3760,  1.3242,  ...,  1.6055,  0.9229,  0.6592],\n",
      "          [ 1.5508,  1.6807,  1.7266,  ...,  3.5371,  2.4551,  0.7852],\n",
      "          [ 1.6572,  1.9580,  1.9678,  ...,  4.6016,  3.3125,  1.1396],\n",
      "          ...,\n",
      "          [ 2.1406,  2.7598,  2.8770,  ...,  2.9941,  2.7988,  2.2402],\n",
      "          [ 2.0918,  2.6895,  2.8184,  ...,  2.8867,  2.6738,  2.1484],\n",
      "          [ 1.9004,  2.1699,  2.2852,  ...,  2.3574,  2.2207,  1.9170]],\n",
      "\n",
      "         [[ 1.3330,  1.2031,  1.1523,  ...,  1.9268,  1.0215,  0.6797],\n",
      "          [ 1.3613,  1.2119,  1.1641,  ...,  3.7031,  2.1035,  0.5879],\n",
      "          [ 1.4258,  1.3877,  1.3018,  ...,  4.6836,  2.8672,  0.8652],\n",
      "          ...,\n",
      "          [ 1.8770,  2.2188,  2.3418,  ...,  2.5664,  2.3262,  1.9443],\n",
      "          [ 1.8203,  2.1367,  2.2715,  ...,  2.4258,  2.1934,  1.8379],\n",
      "          [ 1.7129,  1.8486,  1.9678,  ...,  2.0566,  1.9131,  1.7051]],\n",
      "\n",
      "         [[ 1.8857,  1.7051,  1.6348,  ...,  0.9624,  0.4629,  0.6426],\n",
      "          [ 1.9746,  1.8105,  1.6582,  ...,  1.7783,  0.9028,  0.1931],\n",
      "          [ 2.1113,  1.9775,  1.7705,  ...,  2.2051,  1.2705,  0.2798],\n",
      "          ...,\n",
      "          [ 2.7617,  3.2148,  3.4473,  ...,  3.9375,  3.5742,  2.9297],\n",
      "          [ 2.7070,  3.1406,  3.3965,  ...,  3.7285,  3.3848,  2.7832],\n",
      "          [ 2.5293,  2.8184,  2.9980,  ...,  3.1582,  2.9277,  2.5469]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2090,  0.8975,  0.8174,  ...,  0.8701,  0.6533,  0.9561],\n",
      "          [ 1.1211,  0.8389,  1.2275,  ...,  1.8545,  1.0762,  0.7793],\n",
      "          [ 1.0576,  0.8301,  1.5381,  ...,  2.0000,  1.1426,  0.7891],\n",
      "          ...,\n",
      "          [ 2.1875,  2.7715,  2.8926,  ...,  2.9707,  2.7852,  2.2285],\n",
      "          [ 2.1172,  2.7129,  2.8398,  ...,  2.8691,  2.6680,  2.1387],\n",
      "          [ 1.9092,  2.1758,  2.2852,  ...,  2.3398,  2.2109,  1.9111]],\n",
      "\n",
      "         [[ 1.1494,  0.8477,  0.9395,  ...,  1.0557,  0.6787,  0.9072],\n",
      "          [ 1.0146,  0.6753,  1.2695,  ...,  1.8369,  0.7344,  0.6440],\n",
      "          [ 0.9502,  0.6768,  1.6455,  ...,  1.7783,  0.6826,  0.5967],\n",
      "          ...,\n",
      "          [ 1.9307,  2.2578,  2.3809,  ...,  2.5352,  2.3027,  1.9277],\n",
      "          [ 1.8477,  2.1641,  2.2910,  ...,  2.4004,  2.1777,  1.8252],\n",
      "          [ 1.7217,  1.8564,  1.9629,  ...,  2.0391,  1.9014,  1.6973]],\n",
      "\n",
      "         [[ 1.5693,  1.0254,  0.7993,  ...,  0.5596,  0.5850,  1.1250],\n",
      "          [ 1.3662,  0.6387,  0.7080,  ...,  0.8623,  0.2891,  0.7417],\n",
      "          [ 1.2988,  0.5435,  0.9316,  ...,  0.7646,  0.2394,  0.6992],\n",
      "          ...,\n",
      "          [ 2.8516,  3.3223,  3.5215,  ...,  3.8730,  3.5254,  2.9004],\n",
      "          [ 2.7500,  3.1855,  3.4043,  ...,  3.6738,  3.3457,  2.7617],\n",
      "          [ 2.5410,  2.8223,  2.9863,  ...,  3.1270,  2.9062,  2.5352]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 1.7549,  1.7002,  1.6982,  ...,  1.4355,  1.0957,  0.6885],\n",
      "          [ 1.8906,  2.0137,  2.1348,  ...,  3.5957,  3.0625,  1.1250],\n",
      "          [ 2.0156,  2.1660,  2.2656,  ...,  4.9492,  4.2695,  1.8379],\n",
      "          ...,\n",
      "          [ 2.3984,  3.2031,  3.3457,  ...,  3.8672,  3.5977,  2.8711],\n",
      "          [ 2.3672,  3.1836,  3.3359,  ...,  3.7676,  3.4707,  2.7480],\n",
      "          [ 1.9668,  2.4043,  2.5195,  ...,  3.0586,  2.8457,  2.4121]],\n",
      "\n",
      "         [[ 1.6230,  1.4912,  1.4990,  ...,  1.3896,  1.0566,  0.7007],\n",
      "          [ 1.6738,  1.5430,  1.6182,  ...,  3.2012,  2.5371,  0.9043],\n",
      "          [ 1.7891,  1.7402,  1.8262,  ...,  4.7969,  3.9941,  1.6934],\n",
      "          ...,\n",
      "          [ 1.9033,  2.1543,  2.1953,  ...,  3.3887,  3.0586,  2.5176],\n",
      "          [ 1.8789,  2.1289,  2.2051,  ...,  3.2246,  2.8809,  2.3535],\n",
      "          [ 1.7471,  1.9014,  1.9609,  ...,  2.6719,  2.4395,  2.1270]],\n",
      "\n",
      "         [[ 2.2480,  2.0742,  2.0762,  ...,  0.5757,  0.4482,  0.5850],\n",
      "          [ 2.3711,  2.3027,  2.3242,  ...,  1.4746,  1.1807,  0.3579],\n",
      "          [ 2.5938,  2.6367,  2.7324,  ...,  2.3398,  2.0391,  0.8071],\n",
      "          ...,\n",
      "          [ 2.2266,  2.0605,  1.9473,  ...,  5.1055,  4.6016,  3.7012],\n",
      "          [ 2.3086,  2.2188,  2.2188,  ...,  4.8281,  4.2969,  3.4648],\n",
      "          [ 2.4004,  2.4121,  2.4336,  ...,  3.9941,  3.6309,  3.1035]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7021,  2.0176,  2.0566,  ...,  4.1133,  3.4062,  1.6309],\n",
      "          [ 2.1836,  2.8555,  2.9824,  ...,  7.0352,  5.9688,  3.0137],\n",
      "          [ 2.2715,  3.0156,  3.1621,  ...,  7.9180,  6.7227,  3.5410],\n",
      "          ...,\n",
      "          [ 2.5840,  3.4746,  3.6367,  ...,  3.1816,  3.1953,  2.3711],\n",
      "          [ 2.5117,  3.3965,  3.5781,  ...,  3.1855,  3.1465,  2.3438],\n",
      "          [ 2.2168,  2.5586,  2.6973,  ...,  2.4492,  2.4023,  2.0039]],\n",
      "\n",
      "         [[ 1.5645,  1.6094,  1.5840,  ...,  5.8594,  4.8203,  2.3633],\n",
      "          [ 1.6914,  1.7822,  1.7705,  ...,  9.7578,  8.1406,  4.0859],\n",
      "          [ 1.7363,  1.8535,  1.8477,  ..., 10.9219,  9.1484,  4.7578],\n",
      "          ...,\n",
      "          [ 2.1992,  2.6543,  2.8047,  ...,  2.2617,  2.1445,  1.8467],\n",
      "          [ 2.1191,  2.5332,  2.6992,  ...,  2.2617,  2.1406,  1.8174],\n",
      "          [ 1.9717,  2.1309,  2.2383,  ...,  2.0098,  1.9062,  1.7236]],\n",
      "\n",
      "         [[ 2.0176,  1.7041,  1.5859,  ...,  3.6660,  3.0312,  1.5957],\n",
      "          [ 1.9951,  1.6523,  1.4443,  ...,  6.0195,  5.0391,  2.5820],\n",
      "          [ 2.0117,  1.6162,  1.4424,  ...,  6.7031,  5.6484,  2.9941],\n",
      "          ...,\n",
      "          [ 3.0508,  3.4863,  3.7285,  ...,  2.5820,  2.3867,  2.2285],\n",
      "          [ 2.9512,  3.3242,  3.5859,  ...,  2.7715,  2.5840,  2.3242],\n",
      "          [ 2.8027,  3.0430,  3.2031,  ...,  2.8125,  2.6406,  2.4434]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7256,  1.9902,  2.8965,  ...,  3.5254,  2.9375,  1.4736],\n",
      "          [ 1.6689,  4.4414,  5.9492,  ...,  6.0859,  5.2109,  2.5469],\n",
      "          [ 2.4180,  5.7266,  7.4844,  ...,  6.7930,  5.8555,  2.9863],\n",
      "          ...,\n",
      "          [ 2.6953,  3.4961,  3.6738,  ...,  3.5566,  3.4766,  2.5742],\n",
      "          [ 2.5918,  3.4355,  3.6094,  ...,  3.5098,  3.4004,  2.5176],\n",
      "          [ 2.3184,  2.6621,  2.8027,  ...,  2.7070,  2.5918,  2.2051]],\n",
      "\n",
      "         [[ 0.8608,  2.2910,  3.4082,  ...,  5.0273,  4.1562,  2.0957],\n",
      "          [ 1.6035,  4.5977,  6.1562,  ...,  8.4453,  7.0781,  3.4531],\n",
      "          [ 2.3672,  5.9023,  7.6602,  ...,  9.3828,  7.9414,  4.0078],\n",
      "          ...,\n",
      "          [ 2.3418,  2.7891,  2.9766,  ...,  2.8281,  2.6191,  2.1406],\n",
      "          [ 2.2266,  2.6660,  2.8379,  ...,  2.7207,  2.5312,  2.0566],\n",
      "          [ 2.0645,  2.2363,  2.3652,  ...,  2.2832,  2.1406,  1.9199]],\n",
      "\n",
      "         [[ 0.5405,  1.1328,  1.8027,  ...,  3.2051,  2.6582,  1.5322],\n",
      "          [ 0.7822,  2.3125,  3.2207,  ...,  5.2969,  4.4453,  2.2305],\n",
      "          [ 1.1934,  2.9746,  4.0078,  ...,  5.8789,  5.0000,  2.5938],\n",
      "          ...,\n",
      "          [ 3.3633,  3.9609,  4.2539,  ...,  3.9062,  3.5625,  2.9922],\n",
      "          [ 3.2031,  3.7266,  4.0078,  ...,  3.7441,  3.4629,  2.8984],\n",
      "          [ 2.9609,  3.2715,  3.4629,  ...,  3.3340,  3.1270,  2.7734]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.6875,  1.8828,  2.8066,  ...,  4.2891,  3.5547,  1.7988],\n",
      "          [ 1.4736,  4.0000,  5.4102,  ...,  7.0078,  5.9102,  3.0918],\n",
      "          [ 2.0039,  4.9180,  6.2930,  ...,  7.8164,  6.5469,  3.4961],\n",
      "          ...,\n",
      "          [ 2.3594,  3.3652,  3.5293,  ...,  2.1035,  1.5635,  1.2354],\n",
      "          [ 2.2969,  3.3047,  3.4805,  ...,  2.2051,  1.8623,  1.3906],\n",
      "          [ 1.9570,  2.3438,  2.4824,  ...,  2.0254,  1.7510,  1.5732]],\n",
      "\n",
      "         [[ 0.7822,  2.0039,  3.2461,  ...,  5.8828,  4.8281,  2.4355],\n",
      "          [ 1.2686,  3.8184,  5.5117,  ...,  9.4062,  7.7891,  4.0195],\n",
      "          [ 1.8037,  4.7500,  6.2500,  ..., 10.3438,  8.5469,  4.4961],\n",
      "          ...,\n",
      "          [ 1.9814,  2.4805,  2.6484,  ...,  1.7432,  1.1846,  1.0488],\n",
      "          [ 1.9102,  2.3750,  2.5488,  ...,  1.7305,  1.2939,  1.1279],\n",
      "          [ 1.7500,  1.9385,  2.0508,  ...,  1.7119,  1.4658,  1.3867]],\n",
      "\n",
      "         [[ 0.4661,  1.0264,  1.8477,  ...,  3.7559,  3.0918,  1.6133],\n",
      "          [ 0.5981,  2.0352,  3.1152,  ...,  5.9492,  4.9375,  2.5703],\n",
      "          [ 0.9297,  2.5566,  3.5293,  ...,  6.4883,  5.3867,  2.8711],\n",
      "          ...,\n",
      "          [ 2.5879,  3.0020,  3.3066,  ...,  2.4980,  1.5557,  1.3730],\n",
      "          [ 2.5059,  2.8613,  3.1641,  ...,  2.4395,  1.7441,  1.5293],\n",
      "          [ 2.3848,  2.5977,  2.7812,  ...,  2.4512,  2.0430,  1.8916]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8203,  3.5547,  4.3516,  ...,  4.7422,  3.8848,  1.9697],\n",
      "          [ 3.1777,  5.9570,  7.1719,  ...,  7.7070,  6.5391,  3.4648],\n",
      "          [ 3.6289,  6.6719,  7.8672,  ...,  8.6016,  7.2656,  3.9941],\n",
      "          ...,\n",
      "          [ 2.2422,  2.8750,  3.1113,  ...,  3.1797,  3.0234,  2.1152],\n",
      "          [ 2.1602,  2.8516,  3.0195,  ...,  3.1016,  2.9746,  2.0742],\n",
      "          [ 1.9961,  2.2734,  2.4473,  ...,  2.3984,  2.2031,  1.8486]],\n",
      "\n",
      "         [[ 2.4824,  4.8242,  5.9414,  ...,  6.4219,  5.1953,  2.5977],\n",
      "          [ 4.1211,  7.9141,  9.5391,  ..., 10.1719,  8.4062,  4.4102],\n",
      "          [ 4.6953,  8.8047, 10.3828,  ..., 11.2578,  9.2891,  5.0391],\n",
      "          ...,\n",
      "          [ 1.9688,  2.3203,  2.5957,  ...,  2.6348,  2.2578,  1.7607],\n",
      "          [ 1.8701,  2.1953,  2.4355,  ...,  2.4375,  2.1582,  1.6875],\n",
      "          [ 1.7930,  1.9131,  2.1094,  ...,  2.0488,  1.8311,  1.6201]],\n",
      "\n",
      "         [[ 1.6738,  3.0820,  3.7969,  ...,  4.0312,  3.2578,  1.6416],\n",
      "          [ 2.6758,  5.0117,  6.0312,  ...,  6.3320,  5.2109,  2.7461],\n",
      "          [ 3.0391,  5.5742,  6.5508,  ...,  7.0039,  5.7305,  3.1348],\n",
      "          ...,\n",
      "          [ 2.7246,  3.2539,  3.7070,  ...,  3.6816,  3.0215,  2.3965],\n",
      "          [ 2.5977,  3.0273,  3.4395,  ...,  3.3398,  2.8457,  2.2754],\n",
      "          [ 2.4766,  2.7305,  3.0020,  ...,  2.9102,  2.5684,  2.2422]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3984,  2.6816,  3.3594,  ...,  1.2109,  1.1650,  0.9795],\n",
      "          [ 2.3633,  4.5898,  5.5781,  ...,  2.5801,  2.2598,  1.1826],\n",
      "          [ 2.8027,  5.2227,  6.0977,  ...,  3.5020,  2.8496,  1.2461],\n",
      "          ...,\n",
      "          [ 2.4434,  3.3203,  3.4707,  ...,  2.6934,  2.6035,  1.7686],\n",
      "          [ 2.3086,  3.2480,  3.3828,  ...,  2.7832,  2.6895,  1.8613],\n",
      "          [ 2.0625,  2.3652,  2.4961,  ...,  2.0566,  1.9883,  1.6035]],\n",
      "\n",
      "         [[ 1.8125,  3.5566,  4.4883,  ...,  0.7793,  0.7461,  0.8555],\n",
      "          [ 2.9414,  5.9492,  7.2188,  ...,  1.4326,  0.9951,  0.6914],\n",
      "          [ 3.4961,  6.7148,  7.8203,  ...,  2.4941,  1.7119,  0.7588],\n",
      "          ...,\n",
      "          [ 2.1426,  2.6328,  2.8145,  ...,  1.6807,  1.4473,  1.2422],\n",
      "          [ 1.9834,  2.4688,  2.6172,  ...,  1.7998,  1.6143,  1.3516],\n",
      "          [ 1.8496,  2.0020,  2.1211,  ...,  1.6416,  1.5146,  1.3730]],\n",
      "\n",
      "         [[ 1.2822,  2.2441,  2.8672,  ...,  0.3613,  0.4609,  0.8374],\n",
      "          [ 1.8906,  3.7207,  4.5430,  ...,  0.6035,  0.4465,  0.4067],\n",
      "          [ 2.2461,  4.1992,  4.8945,  ...,  1.0869,  0.6904,  0.2886],\n",
      "          ...,\n",
      "          [ 2.9531,  3.5430,  3.8652,  ...,  1.7979,  1.4102,  1.3467],\n",
      "          [ 2.7441,  3.2422,  3.5234,  ...,  2.0566,  1.7676,  1.5928],\n",
      "          [ 2.5469,  2.8027,  2.9922,  ...,  2.2012,  1.9922,  1.8662]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 1.1426,  1.1416,  0.9644,  ...,  4.7578,  3.7637,  1.7842],\n",
      "          [ 1.3564,  1.8545,  1.9795,  ...,  7.5742,  6.4570,  3.2461],\n",
      "          [ 1.1426,  1.8555,  2.1797,  ...,  8.3125,  7.2070,  3.8066],\n",
      "          ...,\n",
      "          [ 2.0898,  2.9629,  3.1387,  ...,  2.9121,  2.8867,  1.9648],\n",
      "          [ 2.0547,  2.9414,  3.1211,  ...,  2.8691,  2.8301,  1.9482],\n",
      "          [ 1.7598,  2.1172,  2.2500,  ...,  2.0801,  2.0488,  1.6885]],\n",
      "\n",
      "         [[ 1.0820,  0.8799,  0.6792,  ...,  6.1758,  4.6914,  2.1602],\n",
      "          [ 0.9736,  0.9287,  0.8965,  ...,  9.5547,  7.5859,  3.7539],\n",
      "          [ 0.8135,  0.9814,  1.2012,  ..., 10.5391,  8.4219,  4.4258],\n",
      "          ...,\n",
      "          [ 1.6885,  2.0078,  2.0898,  ...,  2.1523,  1.9365,  1.5596],\n",
      "          [ 1.6504,  1.9570,  2.0566,  ...,  2.0195,  1.8682,  1.5127],\n",
      "          [ 1.5781,  1.6973,  1.7705,  ...,  1.7217,  1.6211,  1.4658]],\n",
      "\n",
      "         [[ 1.2422,  0.6777,  0.4111,  ...,  3.9023,  2.9062,  1.3174],\n",
      "          [ 0.9585,  0.5825,  0.4478,  ...,  6.0117,  4.6719,  2.2891],\n",
      "          [ 0.7739,  0.5283,  0.5400,  ...,  6.6484,  5.2031,  2.7402],\n",
      "          ...,\n",
      "          [ 1.9922,  1.9980,  2.0547,  ...,  2.5879,  2.2051,  1.8721],\n",
      "          [ 1.9717,  1.9766,  2.0762,  ...,  2.3438,  2.1035,  1.8154],\n",
      "          [ 2.0488,  2.0586,  2.1309,  ...,  2.2520,  2.0879,  1.9395]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9756,  1.4746,  1.7432,  ...,  3.7148,  2.8281,  1.3076],\n",
      "          [ 1.5010,  3.0762,  3.7949,  ...,  5.8516,  4.7148,  2.1270],\n",
      "          [ 1.5371,  3.5527,  4.3984,  ...,  5.8359,  4.7812,  2.1621],\n",
      "          ...,\n",
      "          [ 2.1602,  3.0820,  3.2793,  ...,  3.1719,  3.1016,  2.1152],\n",
      "          [ 2.1035,  3.0312,  3.2305,  ...,  3.1113,  3.0215,  2.0742],\n",
      "          [ 1.8398,  2.1719,  2.3203,  ...,  2.2480,  2.1660,  1.7676]],\n",
      "\n",
      "         [[ 0.8877,  0.9707,  1.0361,  ...,  4.8203,  3.5664,  1.5684],\n",
      "          [ 0.8281,  1.6406,  1.9326,  ...,  7.3164,  5.5156,  2.3457],\n",
      "          [ 0.8193,  2.0117,  2.3945,  ...,  7.0156,  5.3086,  2.2305],\n",
      "          ...,\n",
      "          [ 1.7969,  2.2012,  2.3477,  ...,  2.4297,  2.1582,  1.7070],\n",
      "          [ 1.7363,  2.1113,  2.2617,  ...,  2.2832,  2.0664,  1.6367],\n",
      "          [ 1.6465,  1.7803,  1.8799,  ...,  1.8916,  1.7412,  1.5410]],\n",
      "\n",
      "         [[ 0.7256,  0.4465,  0.4199,  ...,  3.1133,  2.2559,  0.9941],\n",
      "          [ 0.4675,  0.8193,  0.8760,  ...,  4.6680,  3.4297,  1.4336],\n",
      "          [ 0.3835,  0.9575,  1.0918,  ...,  4.4258,  3.2520,  1.3369],\n",
      "          ...,\n",
      "          [ 2.2285,  2.4297,  2.6445,  ...,  2.9512,  2.4883,  2.0664],\n",
      "          [ 2.1602,  2.3203,  2.5332,  ...,  2.7070,  2.3691,  1.9834],\n",
      "          [ 2.1641,  2.2500,  2.3809,  ...,  2.4863,  2.2500,  2.0430]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4502,  1.3350,  1.1465,  ...,  2.7344,  2.2188,  1.0371],\n",
      "          [ 1.5713,  1.9355,  1.7227,  ...,  4.7500,  4.1445,  1.8301],\n",
      "          [ 1.7041,  2.0840,  1.8643,  ...,  5.2695,  4.6250,  2.1855],\n",
      "          ...,\n",
      "          [ 2.1836,  3.1191,  3.3281,  ...,  3.1406,  3.0996,  2.1191],\n",
      "          [ 2.1211,  3.0625,  3.2715,  ...,  3.0898,  3.0273,  2.0820],\n",
      "          [ 1.8682,  2.1934,  2.3496,  ...,  2.2207,  2.1680,  1.7520]],\n",
      "\n",
      "         [[ 1.3301,  1.1318,  1.0078,  ...,  3.2441,  2.5645,  1.1816],\n",
      "          [ 1.3389,  1.2803,  1.0791,  ...,  5.3555,  4.3750,  1.8564],\n",
      "          [ 1.4668,  1.4736,  1.2793,  ...,  5.8359,  4.8594,  2.1895],\n",
      "          ...,\n",
      "          [ 1.8271,  2.2578,  2.4297,  ...,  2.3457,  2.1152,  1.6895],\n",
      "          [ 1.7637,  2.1621,  2.3359,  ...,  2.2207,  2.0371,  1.6260],\n",
      "          [ 1.6699,  1.8115,  1.9248,  ...,  1.8525,  1.7256,  1.5244]],\n",
      "\n",
      "         [[ 1.6953,  1.3799,  1.2031,  ...,  1.9922,  1.5410,  0.7183],\n",
      "          [ 1.7227,  1.5186,  1.2256,  ...,  3.2676,  2.6172,  1.0713],\n",
      "          [ 1.9600,  1.8555,  1.6387,  ...,  3.5684,  2.9219,  1.2910],\n",
      "          ...,\n",
      "          [ 2.2891,  2.5469,  2.8223,  ...,  2.7207,  2.3438,  1.9941],\n",
      "          [ 2.2188,  2.4355,  2.7012,  ...,  2.5332,  2.2617,  1.9297],\n",
      "          [ 2.2051,  2.3223,  2.4863,  ...,  2.3887,  2.1914,  2.0117]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 2.7988,  5.2188,  6.0859,  ...,  6.0938,  5.3047,  2.7793],\n",
      "          [ 4.6602,  8.2578,  9.5703,  ...,  9.3516,  8.4531,  4.5469],\n",
      "          [ 4.9492,  8.6719,  9.7344,  ...,  9.6328,  8.6797,  4.7500],\n",
      "          ...,\n",
      "          [ 1.5645,  2.0371,  2.1562,  ...,  1.9785,  2.1758,  1.0869],\n",
      "          [ 1.5762,  2.0664,  2.1289,  ...,  1.9922,  2.0625,  1.1650],\n",
      "          [ 1.5879,  1.6631,  1.7217,  ...,  1.1035,  1.1758,  1.1133]],\n",
      "\n",
      "         [[ 3.5957,  6.8125,  8.0469,  ...,  8.0391,  6.8281,  3.5059],\n",
      "          [ 5.8555, 10.6094, 12.3438,  ..., 12.0938, 10.4922,  5.5625],\n",
      "          [ 6.2461, 11.1875, 12.6406,  ..., 12.5234, 10.7656,  5.8398],\n",
      "          ...,\n",
      "          [ 1.2734,  1.2588,  1.3594,  ...,  1.2090,  1.1221,  0.7158],\n",
      "          [ 1.2510,  1.2451,  1.2754,  ...,  1.1377,  1.0518,  0.7495],\n",
      "          [ 1.4209,  1.2949,  1.3438,  ...,  0.7690,  0.7656,  0.9609]],\n",
      "\n",
      "         [[ 2.4023,  4.5078,  5.3359,  ...,  5.3125,  4.4414,  2.2891],\n",
      "          [ 3.9062,  7.0352,  8.1797,  ...,  7.9961,  6.7969,  3.6250],\n",
      "          [ 4.1914,  7.4805,  8.4297,  ...,  8.3516,  6.9883,  3.8438],\n",
      "          ...,\n",
      "          [ 1.4561,  1.2402,  1.4551,  ...,  0.6528,  0.5952,  0.3984],\n",
      "          [ 1.4365,  1.1738,  1.2725,  ...,  0.6636,  0.6045,  0.5098],\n",
      "          [ 1.7969,  1.5850,  1.6387,  ...,  0.7085,  0.6689,  1.0889]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9141,  1.1250,  1.2080,  ...,  3.5742,  2.6504,  0.9873],\n",
      "          [ 1.1289,  2.3652,  2.8711,  ...,  6.8086,  5.4688,  2.4043],\n",
      "          [ 0.9756,  2.5918,  3.4863,  ...,  8.2109,  6.6445,  3.1816],\n",
      "          ...,\n",
      "          [ 1.9131,  2.6172,  2.8750,  ...,  2.5176,  2.5605,  1.7490],\n",
      "          [ 1.8965,  2.6016,  2.8164,  ...,  2.5488,  2.5566,  1.7969],\n",
      "          [ 1.6904,  2.0059,  2.1484,  ...,  1.9590,  1.9346,  1.5693]],\n",
      "\n",
      "         [[ 0.9199,  0.8828,  0.8481,  ...,  3.3418,  2.0996,  0.8936],\n",
      "          [ 0.7417,  1.4785,  1.6992,  ...,  5.7930,  3.8906,  1.7197],\n",
      "          [ 0.6704,  1.8516,  2.5371,  ...,  7.0781,  4.9805,  2.3789],\n",
      "          ...,\n",
      "          [ 1.4668,  1.6621,  1.8408,  ...,  1.5117,  1.3779,  1.2070],\n",
      "          [ 1.4531,  1.6270,  1.7676,  ...,  1.5166,  1.4062,  1.2393],\n",
      "          [ 1.5195,  1.5537,  1.6514,  ...,  1.4756,  1.3877,  1.3369]],\n",
      "\n",
      "         [[ 0.7974,  0.4514,  0.3796,  ...,  1.7920,  1.0547,  0.3796],\n",
      "          [ 0.4548,  0.7910,  0.8604,  ...,  3.2383,  2.0879,  0.8130],\n",
      "          [ 0.3501,  0.9458,  1.3525,  ...,  4.0000,  2.7227,  1.1807],\n",
      "          ...,\n",
      "          [ 1.5869,  1.4531,  1.6797,  ...,  1.1172,  0.9619,  1.0078],\n",
      "          [ 1.6064,  1.4434,  1.6250,  ...,  1.1904,  1.0820,  1.1328],\n",
      "          [ 1.9043,  1.7979,  1.9043,  ...,  1.5938,  1.4697,  1.6172]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7207,  2.2637,  3.7500,  ...,  1.5518,  1.3037,  0.8828],\n",
      "          [ 1.5361,  4.1289,  6.1953,  ...,  3.2246,  2.8730,  1.3721],\n",
      "          [ 1.6660,  4.2734,  5.9414,  ...,  3.5859,  3.1191,  1.5410],\n",
      "          ...,\n",
      "          [ 1.5674,  2.0586,  2.2168,  ...,  2.1504,  2.0742,  1.4189],\n",
      "          [ 1.5820,  2.0918,  2.1875,  ...,  2.1582,  2.1191,  1.4902],\n",
      "          [ 1.5635,  1.6738,  1.7451,  ...,  1.7227,  1.6523,  1.4111]],\n",
      "\n",
      "         [[ 0.7856,  2.2656,  4.3359,  ...,  1.0869,  0.8496,  0.7769],\n",
      "          [ 1.0449,  3.4473,  6.1914,  ...,  1.9189,  1.4609,  0.8350],\n",
      "          [ 1.0264,  3.3145,  5.2812,  ...,  2.2129,  1.6680,  0.9297],\n",
      "          ...,\n",
      "          [ 1.2373,  1.2275,  1.3301,  ...,  1.3174,  1.0703,  0.9941],\n",
      "          [ 1.2275,  1.2295,  1.2686,  ...,  1.2754,  1.1094,  1.0332],\n",
      "          [ 1.4004,  1.2832,  1.3320,  ...,  1.3164,  1.1807,  1.2148]],\n",
      "\n",
      "         [[ 0.3936,  1.2109,  2.6621,  ...,  0.4976,  0.3994,  0.5566],\n",
      "          [ 0.4644,  1.8779,  3.7793,  ...,  1.0020,  0.7739,  0.4402],\n",
      "          [ 0.4714,  1.6963,  3.1191,  ...,  1.1406,  0.8452,  0.4739],\n",
      "          ...,\n",
      "          [ 1.3682,  1.1182,  1.3027,  ...,  1.1943,  0.8096,  0.8828],\n",
      "          [ 1.3789,  1.0967,  1.1865,  ...,  1.1025,  0.8735,  0.9673],\n",
      "          [ 1.7617,  1.5352,  1.5879,  ...,  1.5400,  1.3047,  1.4922]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.7607,  2.5234,  4.1836,  ...,  5.4062,  4.9492,  2.4590],\n",
      "          [ 1.9844,  5.0742,  7.6250,  ...,  8.3125,  8.1953,  4.2031],\n",
      "          [ 2.4375,  5.9375,  8.5625,  ...,  8.1250,  8.2734,  4.3750],\n",
      "          ...,\n",
      "          [ 2.1953,  3.0762,  3.4492,  ...,  3.5508,  3.1582,  2.1348],\n",
      "          [ 2.1738,  3.0371,  3.3379,  ...,  3.4141,  3.0957,  2.1387],\n",
      "          [ 1.9199,  2.3262,  2.5156,  ...,  2.5547,  2.3418,  1.8574]],\n",
      "\n",
      "         [[ 0.7334,  2.1250,  4.0664,  ...,  6.7383,  6.0273,  2.8867],\n",
      "          [ 1.1992,  3.8320,  6.5469,  ..., 10.1250,  9.4219,  4.7891],\n",
      "          [ 1.5283,  4.5352,  7.1914,  ...,  9.9219,  9.4766,  4.9922],\n",
      "          ...,\n",
      "          [ 1.7119,  2.0625,  2.3867,  ...,  2.6875,  2.0781,  1.6348],\n",
      "          [ 1.6904,  2.0039,  2.2578,  ...,  2.4922,  2.0195,  1.6191],\n",
      "          [ 1.7178,  1.8369,  1.9980,  ...,  2.1250,  1.8252,  1.6123]],\n",
      "\n",
      "         [[ 0.3438,  1.0723,  2.4277,  ...,  4.4492,  3.9062,  1.8682],\n",
      "          [ 0.6133,  2.1035,  3.9961,  ...,  6.6758,  6.1211,  3.1152],\n",
      "          [ 0.7974,  2.4844,  4.3203,  ...,  6.5742,  6.1719,  3.2930],\n",
      "          ...,\n",
      "          [ 1.9287,  2.0410,  2.5312,  ...,  3.1660,  2.1719,  1.7998],\n",
      "          [ 1.9248,  1.9814,  2.3496,  ...,  2.8516,  2.0977,  1.7959],\n",
      "          [ 2.1504,  2.1836,  2.4023,  ...,  2.6875,  2.2109,  2.0352]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0527,  4.1211,  4.8438,  ...,  2.1211,  1.8770,  0.8560],\n",
      "          [ 3.8320,  7.0508,  8.1172,  ...,  4.4609,  4.1953,  1.8750],\n",
      "          [ 4.2812,  7.5547,  8.3984,  ...,  5.3125,  5.1797,  2.5449],\n",
      "          ...,\n",
      "          [ 2.1055,  2.8828,  2.9668,  ...,  2.8535,  2.5723,  1.7422],\n",
      "          [ 2.0723,  2.8281,  2.8281,  ...,  2.8262,  2.5996,  1.8184],\n",
      "          [ 1.8750,  2.1797,  2.1680,  ...,  2.1895,  2.0332,  1.6436]],\n",
      "\n",
      "         [[ 2.4062,  4.9531,  5.8789,  ...,  1.6699,  1.3633,  0.7690],\n",
      "          [ 4.3906,  8.2500,  9.5547,  ...,  3.2227,  2.7578,  1.3271],\n",
      "          [ 4.9844,  9.0391, 10.1250,  ...,  4.0820,  3.7539,  1.9561],\n",
      "          ...,\n",
      "          [ 1.6611,  1.8965,  1.9131,  ...,  1.8994,  1.4365,  1.2266],\n",
      "          [ 1.6113,  1.8213,  1.7559,  ...,  1.8496,  1.4932,  1.2871],\n",
      "          [ 1.6719,  1.7021,  1.6543,  ...,  1.7334,  1.4961,  1.4111]],\n",
      "\n",
      "         [[ 1.5391,  3.2109,  3.8301,  ...,  0.8306,  0.6831,  0.4148],\n",
      "          [ 2.8652,  5.4219,  6.2539,  ...,  1.7617,  1.5234,  0.6514],\n",
      "          [ 3.2910,  5.9922,  6.6914,  ...,  2.2480,  2.1270,  1.0283],\n",
      "          ...,\n",
      "          [ 1.9004,  1.9062,  1.9434,  ...,  1.9385,  1.2295,  1.1709],\n",
      "          [ 1.8574,  1.7979,  1.7188,  ...,  1.8682,  1.3320,  1.2969],\n",
      "          [ 2.0996,  2.0371,  1.9531,  ...,  2.1055,  1.7178,  1.7402]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5059,  3.4102,  4.3633,  ...,  5.0938,  4.2656,  1.8916],\n",
      "          [ 2.9297,  6.1367,  7.4648,  ...,  7.8008,  7.1836,  3.3398],\n",
      "          [ 3.1621,  6.3477,  7.3359,  ...,  7.4336,  7.1211,  3.5059],\n",
      "          ...,\n",
      "          [ 1.8594,  2.8496,  3.0469,  ...,  1.5879,  2.0352,  1.1309],\n",
      "          [ 1.9082,  2.7500,  2.9258,  ...,  1.7539,  2.0234,  1.2275],\n",
      "          [ 1.6367,  2.0742,  2.1777,  ...,  1.4033,  1.2959,  1.2285]],\n",
      "\n",
      "         [[ 1.6582,  3.8008,  5.0117,  ...,  6.2500,  4.9883,  2.0781],\n",
      "          [ 2.9023,  6.3477,  7.8984,  ...,  9.1641,  7.6172,  3.3867],\n",
      "          [ 3.1992,  6.6992,  7.8320,  ...,  8.6484,  7.4062,  3.5039],\n",
      "          ...,\n",
      "          [ 1.2129,  1.5771,  1.5791,  ...,  0.9165,  1.0283,  0.7515],\n",
      "          [ 1.3145,  1.5518,  1.5762,  ...,  0.9644,  1.0449,  0.8213],\n",
      "          [ 1.4502,  1.4883,  1.5195,  ...,  1.0684,  0.9004,  1.0801]],\n",
      "\n",
      "         [[ 0.9668,  2.3418,  3.1699,  ...,  4.0938,  3.1641,  1.2793],\n",
      "          [ 1.7822,  4.0469,  5.0820,  ...,  6.0078,  4.8906,  2.1133],\n",
      "          [ 1.9873,  4.2734,  5.0625,  ...,  5.6562,  4.7422,  2.2031],\n",
      "          ...,\n",
      "          [ 0.9775,  1.0654,  1.0010,  ...,  0.6328,  0.6475,  0.5371],\n",
      "          [ 1.1934,  1.1191,  1.0986,  ...,  0.7148,  0.6904,  0.6475],\n",
      "          [ 1.7109,  1.4902,  1.4678,  ...,  1.2373,  0.9038,  1.2627]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 2.1562,  4.0391,  4.5312,  ...,  6.9883,  5.9727,  3.0098],\n",
      "          [ 3.8477,  7.1055,  8.0234,  ..., 10.8828,  9.5859,  4.9844],\n",
      "          [ 4.2070,  7.5898,  8.4609,  ..., 11.2734, 10.0391,  5.3125],\n",
      "          ...,\n",
      "          [ 2.6562,  3.6953,  4.2109,  ...,  1.7764,  2.0781,  1.6504],\n",
      "          [ 2.6055,  3.6445,  4.0820,  ...,  1.8525,  2.1152,  1.7002],\n",
      "          [ 2.4746,  2.8516,  3.2207,  ...,  1.7939,  1.7949,  1.7969]],\n",
      "\n",
      "         [[ 2.4570,  4.6484,  5.0820,  ...,  8.8516,  7.4297,  3.6562],\n",
      "          [ 4.2305,  7.6133,  8.0312,  ..., 13.5938, 11.6016,  5.9062],\n",
      "          [ 4.6445,  8.1484,  8.3672,  ..., 14.1641, 12.1484,  6.3125],\n",
      "          ...,\n",
      "          [ 2.3633,  3.0078,  3.5312,  ...,  1.3809,  1.3604,  1.3467],\n",
      "          [ 2.3047,  2.9336,  3.3945,  ...,  1.3799,  1.3809,  1.3750],\n",
      "          [ 2.2188,  2.4688,  2.8320,  ...,  1.5410,  1.4902,  1.5820]],\n",
      "\n",
      "         [[ 1.5928,  3.0410,  3.2812,  ...,  6.1055,  5.0391,  2.4766],\n",
      "          [ 2.7871,  5.0742,  5.2969,  ...,  9.4219,  7.8828,  4.0234],\n",
      "          [ 3.0742,  5.4102,  5.5156,  ...,  9.8906,  8.2891,  4.3398],\n",
      "          ...,\n",
      "          [ 2.9609,  3.6777,  4.5273,  ...,  1.6279,  1.4443,  1.5615],\n",
      "          [ 2.8965,  3.5605,  4.2969,  ...,  1.5625,  1.4570,  1.5996],\n",
      "          [ 2.8457,  3.1973,  3.7012,  ...,  1.9639,  1.8232,  1.9834]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2383,  6.0859,  7.3984,  ...,  6.3945,  5.4219,  2.6758],\n",
      "          [ 5.5430,  9.8828, 11.8359,  ..., 10.0391,  8.8594,  4.5234],\n",
      "          [ 6.1797, 10.7969, 12.5703,  ..., 10.4609,  9.3281,  4.9375],\n",
      "          ...,\n",
      "          [ 3.5977,  4.8750,  5.7539,  ...,  4.8281,  3.7148,  2.7188],\n",
      "          [ 3.3281,  4.4766,  5.2500,  ...,  4.3672,  3.4844,  2.5605],\n",
      "          [ 2.9199,  3.5840,  4.1602,  ...,  3.5957,  2.9727,  2.4434]],\n",
      "\n",
      "         [[ 4.0234,  7.6562,  9.3828,  ...,  7.9805,  6.6445,  3.1797],\n",
      "          [ 6.7188, 12.2344, 14.7734,  ..., 12.3438, 10.5078,  5.2422],\n",
      "          [ 7.5195, 13.3828, 15.7734,  ..., 12.9453, 11.1484,  5.7305],\n",
      "          ...,\n",
      "          [ 3.2188,  4.2852,  5.1367,  ...,  4.3164,  3.2500,  2.4141],\n",
      "          [ 2.9727,  3.8984,  4.6602,  ...,  3.8828,  2.9531,  2.2559],\n",
      "          [ 2.6211,  3.1602,  3.6914,  ...,  3.1953,  2.6094,  2.1719]],\n",
      "\n",
      "         [[ 2.7676,  5.2734,  6.4648,  ...,  5.4805,  4.4805,  2.1406],\n",
      "          [ 4.6250,  8.4531, 10.1953,  ...,  8.5156,  7.1094,  3.5488],\n",
      "          [ 5.2031,  9.2969, 10.9453,  ...,  9.0078,  7.5586,  3.9160],\n",
      "          ...,\n",
      "          [ 4.2188,  5.7070,  6.8867,  ...,  5.7891,  4.2852,  3.1230],\n",
      "          [ 3.8789,  5.1484,  6.2227,  ...,  5.1719,  3.8867,  2.9062],\n",
      "          [ 3.4258,  4.1953,  4.9258,  ...,  4.2617,  3.4297,  2.8203]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0898,  1.4277,  1.4678,  ...,  3.9434,  2.8262,  1.0107],\n",
      "          [ 1.4609,  2.7266,  3.0742,  ...,  7.3047,  5.7422,  2.1895],\n",
      "          [ 1.3369,  2.8047,  3.4297,  ...,  7.9141,  6.4688,  2.7559],\n",
      "          ...,\n",
      "          [ 2.5078,  3.5879,  4.0039,  ...,  4.4961,  4.0195,  2.7285],\n",
      "          [ 2.5176,  3.5918,  3.9727,  ...,  4.3242,  3.9141,  2.6680],\n",
      "          [ 2.3809,  2.7383,  3.0234,  ...,  3.3887,  2.9863,  2.4453]],\n",
      "\n",
      "         [[ 1.0400,  1.0645,  0.9385,  ...,  4.2695,  2.6602,  0.9883],\n",
      "          [ 0.9106,  1.5566,  1.5527,  ...,  7.2227,  4.7109,  1.6748],\n",
      "          [ 0.8398,  1.7148,  1.9600,  ...,  7.8125,  5.3750,  2.1738],\n",
      "          ...,\n",
      "          [ 2.1934,  2.7891,  3.1758,  ...,  3.8945,  3.2383,  2.3594],\n",
      "          [ 2.1875,  2.7852,  3.1523,  ...,  3.6875,  3.1289,  2.2930],\n",
      "          [ 2.1406,  2.3672,  2.6289,  ...,  2.9922,  2.5938,  2.1680]],\n",
      "\n",
      "         [[ 0.9424,  0.6475,  0.5166,  ...,  2.7070,  1.5771,  0.5200],\n",
      "          [ 0.6543,  1.0312,  0.9727,  ...,  4.7266,  2.9824,  0.9092],\n",
      "          [ 0.5469,  1.0586,  1.1738,  ...,  5.0977,  3.4043,  1.2285],\n",
      "          ...,\n",
      "          [ 2.6484,  3.1348,  3.7305,  ...,  4.9648,  3.9766,  2.9414],\n",
      "          [ 2.6797,  3.1699,  3.7168,  ...,  4.6719,  3.8223,  2.8633],\n",
      "          [ 2.7148,  2.9707,  3.3457,  ...,  3.9375,  3.3457,  2.7852]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 1.0479,  1.6660,  2.2109,  ...,  6.0078,  5.0000,  2.4727],\n",
      "          [ 1.2285,  3.0059,  3.8770,  ...,  9.3438,  8.2969,  4.1641],\n",
      "          [ 1.1250,  2.7871,  3.6777,  ...,  9.7812,  8.9766,  4.7422],\n",
      "          ...,\n",
      "          [ 3.0879,  4.0469,  4.4805,  ...,  6.4688,  5.5898,  4.0195],\n",
      "          [ 3.1113,  4.0859,  4.5430,  ...,  6.0391,  5.1914,  3.7754],\n",
      "          [ 2.8242,  3.3477,  3.7676,  ...,  4.6680,  4.1328,  3.1855]],\n",
      "\n",
      "         [[ 1.0801,  1.5811,  2.1055,  ...,  7.2930,  5.9961,  2.8438],\n",
      "          [ 1.0156,  2.3438,  3.0195,  ..., 11.1719,  9.5781,  4.7070],\n",
      "          [ 0.9199,  2.1621,  2.8516,  ..., 11.8281, 10.4453,  5.3945],\n",
      "          ...,\n",
      "          [ 2.8164,  3.5703,  3.9922,  ...,  5.8555,  5.0312,  3.6250],\n",
      "          [ 2.8242,  3.6016,  4.0547,  ...,  5.4648,  4.6680,  3.3984],\n",
      "          [ 2.5586,  3.0039,  3.3750,  ...,  4.2070,  3.7031,  2.8672]],\n",
      "\n",
      "         [[ 0.8281,  0.8672,  1.2490,  ...,  5.0664,  4.0859,  1.9307],\n",
      "          [ 0.5664,  1.4287,  1.9307,  ...,  7.8242,  6.5977,  3.2168],\n",
      "          [ 0.5103,  1.2588,  1.7988,  ...,  8.3438,  7.2070,  3.7363],\n",
      "          ...,\n",
      "          [ 3.5059,  4.3320,  4.9648,  ...,  7.7539,  6.6133,  4.7109],\n",
      "          [ 3.5410,  4.4219,  5.0859,  ...,  7.1992,  6.1055,  4.4023],\n",
      "          [ 3.2578,  3.8398,  4.3516,  ...,  5.5547,  4.8477,  3.7207]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0703,  4.1758,  5.3242,  ...,  5.6250,  4.7227,  2.2891],\n",
      "          [ 3.5996,  7.0000,  8.6016,  ...,  8.4062,  7.5703,  3.6211],\n",
      "          [ 4.2539,  7.6602,  8.9453,  ...,  7.8789,  7.4492,  3.6816],\n",
      "          ...,\n",
      "          [ 2.1953,  2.5449,  2.2871,  ...,  5.6680,  4.7422,  3.4336],\n",
      "          [ 2.3594,  2.7812,  2.6113,  ...,  5.2695,  4.4375,  3.2871],\n",
      "          [ 2.3789,  2.5352,  2.4805,  ...,  4.1680,  3.6621,  2.8809]],\n",
      "\n",
      "         [[ 2.3945,  4.9453,  6.3750,  ...,  6.7422,  5.5742,  2.5547],\n",
      "          [ 4.0508,  7.9219,  9.9375,  ...,  9.6797,  8.2812,  3.8438],\n",
      "          [ 4.8398,  8.8125, 10.4375,  ...,  8.9453,  7.9375,  3.7969],\n",
      "          ...,\n",
      "          [ 1.9766,  2.0781,  1.8457,  ...,  5.1211,  4.2617,  3.0977],\n",
      "          [ 2.1211,  2.3203,  2.1523,  ...,  4.7578,  3.9805,  2.9570],\n",
      "          [ 2.1504,  2.2383,  2.1875,  ...,  3.7500,  3.2773,  2.5938]],\n",
      "\n",
      "         [[ 1.6055,  3.3477,  4.3594,  ...,  4.6562,  3.7598,  1.7012],\n",
      "          [ 2.7246,  5.4844,  6.8672,  ...,  6.7148,  5.6523,  2.5742],\n",
      "          [ 3.2930,  6.1172,  7.2188,  ...,  6.1836,  5.3906,  2.5547],\n",
      "          ...,\n",
      "          [ 2.4355,  2.5078,  2.1875,  ...,  6.7539,  5.5703,  3.9902],\n",
      "          [ 2.6445,  2.8613,  2.6465,  ...,  6.2461,  5.1758,  3.7969],\n",
      "          [ 2.7148,  2.8555,  2.7812,  ...,  4.9297,  4.2656,  3.3457]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0977,  1.3223,  1.7988,  ...,  2.4238,  1.9219,  1.0215],\n",
      "          [ 1.1172,  2.5410,  3.5469,  ...,  4.4492,  3.7461,  1.5273],\n",
      "          [ 1.1035,  2.6855,  3.7812,  ...,  4.6211,  3.9746,  1.6895],\n",
      "          ...,\n",
      "          [ 3.8555,  5.0898,  5.8789,  ...,  6.6016,  5.7930,  4.1758],\n",
      "          [ 3.6836,  4.8359,  5.5625,  ...,  6.1875,  5.3828,  3.9141],\n",
      "          [ 3.1504,  3.9141,  4.4141,  ...,  4.7695,  4.2500,  3.2695]],\n",
      "\n",
      "         [[ 1.0977,  1.2500,  1.7559,  ...,  2.3516,  1.7979,  1.0234],\n",
      "          [ 0.9570,  1.9990,  2.8945,  ...,  3.8281,  2.8750,  1.2441],\n",
      "          [ 0.9746,  2.2480,  3.2461,  ...,  4.0195,  3.0664,  1.3789],\n",
      "          ...,\n",
      "          [ 3.4844,  4.5703,  5.2930,  ...,  5.9805,  5.2148,  3.7656],\n",
      "          [ 3.3320,  4.3359,  5.0039,  ...,  5.6016,  4.8398,  3.5234],\n",
      "          [ 2.8555,  3.5039,  3.9531,  ...,  4.3047,  3.8086,  2.9414]],\n",
      "\n",
      "         [[ 0.9834,  0.6763,  1.0010,  ...,  1.4180,  1.0156,  0.6562],\n",
      "          [ 0.5918,  1.1943,  1.8447,  ...,  2.4434,  1.7979,  0.6455],\n",
      "          [ 0.5479,  1.3398,  2.0918,  ...,  2.5449,  1.8955,  0.7271],\n",
      "          ...,\n",
      "          [ 4.5000,  5.9570,  6.9570,  ...,  7.9180,  6.8594,  4.9023],\n",
      "          [ 4.2891,  5.6289,  6.5547,  ...,  7.3828,  6.3398,  4.5703],\n",
      "          [ 3.6836,  4.5742,  5.1914,  ...,  5.6797,  4.9961,  3.8223]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.9512,  1.1270,  1.4326,  ...,  1.9961,  1.5664,  0.9326],\n",
      "          [ 1.0029,  2.3535,  3.1895,  ...,  4.1094,  3.3242,  1.5000],\n",
      "          [ 1.0527,  2.9512,  4.3164,  ...,  5.3242,  4.3359,  2.0078],\n",
      "          ...,\n",
      "          [ 2.8828,  3.6680,  4.0625,  ...,  5.6602,  5.0273,  3.5996],\n",
      "          [ 2.9688,  3.7812,  4.2070,  ...,  5.4531,  4.8359,  3.4941],\n",
      "          [ 2.6680,  3.1934,  3.5586,  ...,  4.2734,  3.8730,  2.9551]],\n",
      "\n",
      "         [[ 0.9585,  1.0088,  1.1836,  ...,  1.7588,  1.3223,  0.8950],\n",
      "          [ 0.7959,  1.6865,  2.2070,  ...,  3.2734,  2.3555,  1.1934],\n",
      "          [ 0.8564,  2.2715,  3.3086,  ...,  4.4688,  3.3281,  1.6279],\n",
      "          ...,\n",
      "          [ 2.6445,  3.2930,  3.6602,  ...,  5.1367,  4.5469,  3.2578],\n",
      "          [ 2.7109,  3.3984,  3.7930,  ...,  4.9531,  4.3750,  3.1562],\n",
      "          [ 2.4297,  2.8867,  3.2070,  ...,  3.8672,  3.4922,  2.6719]],\n",
      "\n",
      "         [[ 0.8071,  0.5293,  0.6406,  ...,  0.9766,  0.7163,  0.5562],\n",
      "          [ 0.4807,  1.0156,  1.3828,  ...,  2.0508,  1.4561,  0.6260],\n",
      "          [ 0.4509,  1.3594,  2.1484,  ...,  2.9062,  2.1113,  0.9204],\n",
      "          ...,\n",
      "          [ 3.2402,  3.9551,  4.5117,  ...,  6.6406,  5.8398,  4.1406],\n",
      "          [ 3.3516,  4.1602,  4.7383,  ...,  6.3867,  5.6055,  4.0078],\n",
      "          [ 3.0449,  3.6348,  4.0742,  ...,  5.0000,  4.4883,  3.4004]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8672,  7.0234,  8.4297,  ...,  2.6738,  2.1797,  1.1533],\n",
      "          [ 6.3281, 11.0156, 13.1250,  ...,  5.0039,  4.2266,  1.9512],\n",
      "          [ 7.0391, 11.9766, 13.9375,  ...,  5.8125,  5.0000,  2.4492],\n",
      "          ...,\n",
      "          [ 4.5078,  6.3281,  7.0938,  ...,  6.3906,  5.5547,  3.9141],\n",
      "          [ 4.2461,  5.9258,  6.6914,  ...,  6.0000,  5.2031,  3.7129],\n",
      "          [ 3.3984,  4.5117,  5.0430,  ...,  4.5781,  4.0703,  3.0703]],\n",
      "\n",
      "         [[ 4.6836,  8.6328, 10.4531,  ...,  2.5078,  2.0176,  1.1377],\n",
      "          [ 7.5469, 13.3984, 16.1094,  ...,  4.3125,  3.4023,  1.6328],\n",
      "          [ 8.4141, 14.5703, 17.1250,  ...,  5.1406,  4.1641,  2.0859],\n",
      "          ...,\n",
      "          [ 4.1172,  5.7656,  6.4492,  ...,  5.8242,  5.0469,  3.5625],\n",
      "          [ 3.8828,  5.3984,  6.0938,  ...,  5.4727,  4.7266,  3.3750],\n",
      "          [ 3.1055,  4.0938,  4.5742,  ...,  4.1602,  3.6836,  2.7852]],\n",
      "\n",
      "         [[ 3.3184,  6.1484,  7.4453,  ...,  1.5430,  1.1914,  0.6675],\n",
      "          [ 5.3789,  9.6094, 11.5156,  ...,  2.8223,  2.2051,  0.9272],\n",
      "          [ 6.0156, 10.4844, 12.2812,  ...,  3.4082,  2.7168,  1.2500],\n",
      "          ...,\n",
      "          [ 5.3008,  7.4961,  8.4531,  ...,  7.5898,  6.5352,  4.5586],\n",
      "          [ 4.9766,  6.9883,  7.9531,  ...,  7.1016,  6.0938,  4.3047],\n",
      "          [ 3.9766,  5.3008,  5.9648,  ...,  5.3984,  4.7500,  3.5527]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2637,  1.1904,  1.3848,  ...,  4.3711,  3.5605,  1.6973],\n",
      "          [ 1.1836,  1.7988,  2.4785,  ...,  7.2344,  6.1719,  2.8691],\n",
      "          [ 1.0781,  1.8633,  2.7109,  ...,  7.5078,  6.6406,  3.2520],\n",
      "          ...,\n",
      "          [ 3.6855,  4.8984,  5.6758,  ...,  6.6914,  5.9570,  4.2188],\n",
      "          [ 3.5781,  4.7539,  5.4648,  ...,  6.3047,  5.5742,  3.9668],\n",
      "          [ 3.0117,  3.8125,  4.2969,  ...,  4.7812,  4.3008,  3.2285]],\n",
      "\n",
      "         [[ 1.2363,  1.1230,  1.3047,  ...,  4.7500,  3.7734,  1.7559],\n",
      "          [ 1.0645,  1.3613,  1.9062,  ...,  7.3203,  5.9297,  2.6328],\n",
      "          [ 0.9609,  1.4453,  2.1680,  ...,  7.5156,  6.2812,  3.0078],\n",
      "          ...,\n",
      "          [ 3.3516,  4.4297,  5.1367,  ...,  6.0938,  5.4023,  3.8281],\n",
      "          [ 3.2578,  4.3008,  4.9492,  ...,  5.7422,  5.0547,  3.5977],\n",
      "          [ 2.7422,  3.4414,  3.8750,  ...,  4.3398,  3.8867,  2.9219]],\n",
      "\n",
      "         [[ 1.2305,  0.7544,  0.7378,  ...,  3.2031,  2.4688,  1.0859],\n",
      "          [ 0.9087,  0.8174,  1.1523,  ...,  5.0625,  4.0352,  1.6953],\n",
      "          [ 0.7622,  0.8315,  1.3271,  ...,  5.1992,  4.2695,  1.9600],\n",
      "          ...,\n",
      "          [ 4.2617,  5.6836,  6.6523,  ...,  7.9531,  7.0156,  4.9180],\n",
      "          [ 4.1328,  5.5000,  6.3906,  ...,  7.4648,  6.5352,  4.6094],\n",
      "          [ 3.4824,  4.4180,  5.0156,  ...,  5.6445,  5.0273,  3.7441]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 0.8975,  1.6152,  2.1113,  ...,  6.8203,  5.0664,  2.3828],\n",
      "          [ 1.2578,  3.1523,  4.2461,  ..., 10.4688,  8.1797,  3.7930],\n",
      "          [ 1.6348,  4.1133,  5.7461,  ..., 10.7031,  8.6328,  4.1914],\n",
      "          ...,\n",
      "          [ 3.4492,  4.4727,  5.1289,  ...,  7.5273,  6.8594,  4.8086],\n",
      "          [ 3.4492,  4.5156,  5.1367,  ...,  7.1953,  6.4805,  4.5312],\n",
      "          [ 2.9258,  3.6953,  4.1328,  ...,  5.3945,  4.8906,  3.5781]],\n",
      "\n",
      "         [[ 0.9209,  1.4365,  1.7559,  ...,  8.0000,  5.7969,  2.5098],\n",
      "          [ 1.0088,  2.4121,  3.1895,  ..., 11.8906,  8.7812,  3.7773],\n",
      "          [ 1.3018,  3.3379,  4.7500,  ..., 12.1016,  9.1250,  4.1523],\n",
      "          ...,\n",
      "          [ 3.1484,  4.0742,  4.6680,  ...,  6.9023,  6.2734,  4.3945],\n",
      "          [ 3.1523,  4.1211,  4.6836,  ...,  6.6055,  5.9336,  4.1445],\n",
      "          [ 2.6719,  3.3535,  3.7441,  ...,  4.9336,  4.4570,  3.2578]],\n",
      "\n",
      "         [[ 0.5967,  0.7949,  1.0557,  ...,  5.7188,  4.0117,  1.6826],\n",
      "          [ 0.5537,  1.5020,  2.1133,  ...,  8.5625,  6.1953,  2.5879],\n",
      "          [ 0.7524,  2.1562,  3.2168,  ...,  8.7188,  6.4297,  2.8672],\n",
      "          ...,\n",
      "          [ 3.9375,  5.1211,  5.9336,  ...,  8.9297,  8.0859,  5.6133],\n",
      "          [ 3.9375,  5.1719,  5.9414,  ...,  8.5156,  7.6133,  5.2734],\n",
      "          [ 3.3516,  4.2383,  4.7695,  ...,  6.3555,  5.7188,  4.1445]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3125,  4.5547,  5.8867,  ...,  9.0938,  7.6992,  4.1758],\n",
      "          [ 3.8477,  7.3828,  9.3047,  ..., 13.7578, 11.8984,  6.4453],\n",
      "          [ 4.4336,  7.9375,  9.5391,  ..., 14.4609, 12.6641,  6.9453],\n",
      "          ...,\n",
      "          [ 4.4727,  6.3555,  7.2148,  ...,  3.0391,  2.6133,  1.9863],\n",
      "          [ 4.2695,  6.0273,  6.8672,  ...,  3.5234,  2.8242,  2.2461],\n",
      "          [ 3.4023,  4.5820,  5.1641,  ...,  3.2773,  2.8398,  2.2969]],\n",
      "\n",
      "         [[ 2.5312,  5.1094,  6.7969,  ..., 11.0547,  9.3359,  4.8945],\n",
      "          [ 4.0625,  7.9102, 10.2031,  ..., 16.5156, 14.1328,  7.4648],\n",
      "          [ 4.7305,  8.5078, 10.3516,  ..., 17.3281, 14.9297,  8.0000],\n",
      "          ...,\n",
      "          [ 4.1055,  5.8242,  6.5977,  ...,  2.9844,  2.6348,  1.9180],\n",
      "          [ 3.9219,  5.5273,  6.2891,  ...,  3.2910,  2.6523,  2.0938],\n",
      "          [ 3.1133,  4.1836,  4.7070,  ...,  3.0078,  2.5957,  2.1074]],\n",
      "\n",
      "         [[ 1.7002,  3.5410,  4.7617,  ...,  8.0156,  6.6953,  3.4922],\n",
      "          [ 2.8047,  5.6133,  7.2500,  ..., 12.0547, 10.1953,  5.3711],\n",
      "          [ 3.2871,  6.0391,  7.3633,  ..., 12.6641, 10.7734,  5.7891],\n",
      "          ...,\n",
      "          [ 5.2109,  7.4609,  8.5391,  ...,  3.4531,  2.7305,  2.0000],\n",
      "          [ 4.9570,  7.0547,  8.1016,  ...,  4.0742,  3.1582,  2.4355],\n",
      "          [ 3.9414,  5.3438,  6.0586,  ...,  3.7832,  3.1953,  2.5410]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2832,  2.2695,  3.0586,  ...,  2.9805,  2.2422,  1.2354],\n",
      "          [ 1.7783,  3.9961,  5.3633,  ...,  5.2852,  4.1055,  1.8740],\n",
      "          [ 2.1211,  4.5508,  6.2070,  ...,  6.1836,  4.9219,  2.3594],\n",
      "          ...,\n",
      "          [ 3.6211,  4.7695,  5.4727,  ...,  7.2500,  6.5938,  4.6328],\n",
      "          [ 3.5781,  4.7422,  5.3984,  ...,  6.9414,  6.2461,  4.3828],\n",
      "          [ 3.0000,  3.8203,  4.2734,  ...,  5.2266,  4.7422,  3.4844]],\n",
      "\n",
      "         [[ 1.3184,  2.2148,  3.0547,  ...,  2.8496,  2.1172,  1.2119],\n",
      "          [ 1.6250,  3.5566,  4.9023,  ...,  4.6875,  3.3750,  1.5850],\n",
      "          [ 1.9424,  4.1250,  5.7930,  ...,  5.5703,  4.1484,  2.0020],\n",
      "          ...,\n",
      "          [ 3.3047,  4.3477,  4.9844,  ...,  6.6445,  6.0273,  4.2305],\n",
      "          [ 3.2734,  4.3320,  4.9258,  ...,  6.3672,  5.7188,  4.0039],\n",
      "          [ 2.7383,  3.4688,  3.8789,  ...,  4.7773,  4.3203,  3.1699]],\n",
      "\n",
      "         [[ 0.8828,  1.3857,  2.0059,  ...,  1.8369,  1.2900,  0.7378],\n",
      "          [ 0.9668,  2.3867,  3.3730,  ...,  3.1680,  2.2246,  0.9033],\n",
      "          [ 1.2041,  2.7871,  4.0234,  ...,  3.8066,  2.7520,  1.2100],\n",
      "          ...,\n",
      "          [ 4.1484,  5.4883,  6.3555,  ...,  8.5859,  7.7500,  5.3945],\n",
      "          [ 4.1016,  5.4531,  6.2656,  ...,  8.1953,  7.3164,  5.0859],\n",
      "          [ 3.4414,  4.3945,  4.9492,  ...,  6.1484,  5.5312,  4.0273]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 1.2178,  1.1602,  1.2715,  ..., 10.3594,  8.6406,  4.7500],\n",
      "          [ 1.1670,  1.8545,  2.3711,  ..., 15.5781, 13.1406,  7.2578],\n",
      "          [ 1.0205,  2.2246,  3.1445,  ..., 16.4688, 14.0859,  7.9102],\n",
      "          ...,\n",
      "          [ 5.7852,  8.2969,  9.2266,  ...,  8.7500,  7.9297,  5.4727],\n",
      "          [ 5.5039,  7.9062,  8.8828,  ...,  8.6172,  7.7617,  5.3398],\n",
      "          [ 4.2500,  5.8984,  6.5977,  ...,  6.4609,  5.8555,  4.1953]],\n",
      "\n",
      "         [[ 1.2070,  1.0713,  1.1006,  ..., 12.5859, 10.4844,  5.6133],\n",
      "          [ 1.0254,  1.3633,  1.6484,  ..., 18.7344, 15.7500,  8.4766],\n",
      "          [ 0.8745,  1.6719,  2.3848,  ..., 19.7812, 16.7812,  9.1875],\n",
      "          ...,\n",
      "          [ 5.3242,  7.6328,  8.4609,  ...,  8.0547,  7.2734,  5.0195],\n",
      "          [ 5.0703,  7.2773,  8.1641,  ...,  7.9336,  7.1289,  4.8945],\n",
      "          [ 3.9043,  5.4062,  6.0352,  ...,  5.9297,  5.3555,  3.8340]],\n",
      "\n",
      "         [[ 1.1406,  0.6792,  0.6328,  ...,  9.2812,  7.6797,  4.0938],\n",
      "          [ 0.8389,  0.8672,  1.0518,  ..., 13.8984, 11.5859,  6.2227],\n",
      "          [ 0.6074,  1.0352,  1.5547,  ..., 14.6953, 12.3438,  6.7656],\n",
      "          ...,\n",
      "          [ 6.7617,  9.7734, 10.9062,  ..., 10.3516,  9.3203,  6.3750],\n",
      "          [ 6.4141,  9.2891, 10.4844,  ..., 10.1797,  9.1016,  6.2070],\n",
      "          [ 4.9375,  6.8945,  7.7500,  ...,  7.6016,  6.8398,  4.8555]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0225,  1.6641,  2.4785,  ...,  4.7969,  3.5391,  1.7803],\n",
      "          [ 1.2119,  3.0586,  4.4297,  ...,  7.6211,  5.8555,  2.7090],\n",
      "          [ 1.4863,  3.8398,  5.2812,  ...,  7.9297,  6.4023,  3.2344],\n",
      "          ...,\n",
      "          [ 4.3438,  5.8750,  6.5430,  ...,  8.4219,  7.8281,  5.4766],\n",
      "          [ 4.3203,  5.9062,  6.6016,  ...,  8.2344,  7.5430,  5.2383],\n",
      "          [ 3.5273,  4.6406,  5.1562,  ...,  6.2188,  5.6992,  4.1094]],\n",
      "\n",
      "         [[ 1.0342,  1.5176,  2.2500,  ...,  5.0625,  3.6875,  1.8047],\n",
      "          [ 0.9961,  2.3359,  3.5547,  ...,  7.4570,  5.5430,  2.4375],\n",
      "          [ 1.1914,  3.0723,  4.4102,  ...,  7.6289,  5.9609,  2.8887],\n",
      "          ...,\n",
      "          [ 3.9824,  5.3828,  5.9766,  ...,  7.7461,  7.1758,  5.0156],\n",
      "          [ 3.9707,  5.4219,  6.0469,  ...,  7.5820,  6.9258,  4.7969],\n",
      "          [ 3.2324,  4.2422,  4.6992,  ...,  5.6992,  5.2070,  3.7539]],\n",
      "\n",
      "         [[ 0.7534,  0.8711,  1.4297,  ...,  3.5371,  2.4941,  1.1719],\n",
      "          [ 0.5771,  1.4932,  2.4258,  ...,  5.3359,  3.8906,  1.6045],\n",
      "          [ 0.6978,  2.0176,  3.0293,  ...,  5.4336,  4.1484,  1.9268],\n",
      "          ...,\n",
      "          [ 5.0000,  6.8125,  7.6250,  ...,  9.9453,  9.1875,  6.3750],\n",
      "          [ 4.9688,  6.8398,  7.6914,  ...,  9.7031,  8.8281,  6.0781],\n",
      "          [ 4.0508,  5.3594,  5.9844,  ...,  7.2969,  6.6445,  4.7539]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0596,  1.4062,  1.9629,  ...,  1.8291,  1.2051,  1.0088],\n",
      "          [ 1.1035,  2.5723,  3.6582,  ...,  3.5332,  2.3184,  1.2295],\n",
      "          [ 1.2520,  3.3379,  4.7266,  ...,  4.8086,  3.1289,  1.5811],\n",
      "          ...,\n",
      "          [ 4.2070,  5.5938,  6.2188,  ...,  7.3047,  6.7930,  4.8008],\n",
      "          [ 4.2227,  5.7031,  6.3750,  ...,  7.2930,  6.6875,  4.6953],\n",
      "          [ 3.4824,  4.5430,  5.0469,  ...,  5.6055,  5.1602,  3.7715]],\n",
      "\n",
      "         [[ 1.0625,  1.2959,  1.7734,  ...,  1.5723,  1.0332,  0.9927],\n",
      "          [ 0.9229,  1.9395,  2.8438,  ...,  2.6445,  1.5664,  0.9849],\n",
      "          [ 1.0469,  2.6738,  3.9375,  ...,  3.8496,  2.2461,  1.2285],\n",
      "          ...,\n",
      "          [ 3.8555,  5.1289,  5.6875,  ...,  6.7109,  6.2227,  4.3906],\n",
      "          [ 3.8789,  5.2383,  5.8398,  ...,  6.7070,  6.1367,  4.3008],\n",
      "          [ 3.1895,  4.1523,  4.5977,  ...,  5.1328,  4.7109,  3.4395]],\n",
      "\n",
      "         [[ 0.8540,  0.7334,  1.0723,  ...,  0.9106,  0.5962,  0.7231],\n",
      "          [ 0.5708,  1.2119,  1.9082,  ...,  1.7070,  1.0059,  0.5708],\n",
      "          [ 0.5952,  1.7236,  2.6973,  ...,  2.5898,  1.4414,  0.7075],\n",
      "          ...,\n",
      "          [ 4.8281,  6.4609,  7.2227,  ...,  8.5703,  7.9141,  5.5430],\n",
      "          [ 4.8477,  6.5859,  7.4102,  ...,  8.5469,  7.7852,  5.4141],\n",
      "          [ 3.9922,  5.2383,  5.8477,  ...,  6.5508,  5.9844,  4.3359]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.9727,  1.6914,  1.9990,  ...,  8.2500,  6.8047,  3.6230],\n",
      "          [ 1.2275,  3.0488,  3.6836,  ..., 12.4922, 10.6641,  5.6055],\n",
      "          [ 1.4619,  3.8105,  4.7031,  ..., 12.4922, 10.9844,  5.9883],\n",
      "          ...,\n",
      "          [ 2.3047,  2.4688,  2.4023,  ...,  4.0117,  4.1836,  3.2051],\n",
      "          [ 2.7246,  3.1523,  3.3008,  ...,  4.7734,  4.6914,  3.4785],\n",
      "          [ 2.6797,  3.0176,  3.2402,  ...,  4.2148,  4.0703,  3.1133]],\n",
      "\n",
      "         [[ 0.9824,  1.4795,  1.6670,  ...,  9.5547,  7.8867,  3.9746],\n",
      "          [ 0.9795,  2.2344,  2.6758,  ..., 13.9766, 11.7812,  5.9844],\n",
      "          [ 1.1465,  2.9590,  3.6973,  ..., 13.9062, 12.0156,  6.2852],\n",
      "          ...,\n",
      "          [ 2.1426,  2.2148,  2.1445,  ...,  3.7285,  3.8594,  2.9492],\n",
      "          [ 2.5195,  2.8633,  2.9980,  ...,  4.4102,  4.3125,  3.1875],\n",
      "          [ 2.4609,  2.7715,  2.9629,  ...,  3.8574,  3.7090,  2.8398]],\n",
      "\n",
      "         [[ 0.6855,  0.8770,  1.0273,  ...,  7.0352,  5.7266,  2.8359],\n",
      "          [ 0.5928,  1.4658,  1.8174,  ..., 10.3984,  8.6875,  4.3477],\n",
      "          [ 0.6978,  1.9746,  2.5586,  ..., 10.3359,  8.8125,  4.5781],\n",
      "          ...,\n",
      "          [ 2.4688,  2.3711,  2.3281,  ...,  4.4844,  4.6797,  3.5547],\n",
      "          [ 2.9844,  3.2930,  3.5078,  ...,  5.4102,  5.2930,  3.8828],\n",
      "          [ 2.9727,  3.3438,  3.6055,  ...,  4.8047,  4.6055,  3.4961]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8262,  5.7734,  7.6211,  ...,  2.5254,  1.7705,  1.1387],\n",
      "          [ 4.2930,  8.8281, 11.5703,  ...,  4.5352,  3.2383,  1.6816],\n",
      "          [ 4.2188,  8.5859, 11.1562,  ...,  5.5781,  4.0938,  2.1289],\n",
      "          ...,\n",
      "          [ 4.2461,  5.8047,  6.8203,  ...,  9.9062,  8.8281,  5.9922],\n",
      "          [ 4.2188,  5.7734,  6.7305,  ...,  9.4375,  8.3125,  5.6172],\n",
      "          [ 3.5137,  4.5898,  5.2500,  ...,  6.9961,  6.1953,  4.3594]],\n",
      "\n",
      "         [[ 3.1035,  6.5391,  8.8906,  ...,  2.2070,  1.5361,  1.0801],\n",
      "          [ 4.4961,  9.4531, 12.9141,  ...,  3.6191,  2.3613,  1.3281],\n",
      "          [ 4.2500,  8.9375, 12.2188,  ...,  4.6758,  3.1855,  1.6777],\n",
      "          ...,\n",
      "          [ 3.8926,  5.3281,  6.2461,  ...,  9.1328,  8.1172,  5.5039],\n",
      "          [ 3.8770,  5.3086,  6.1758,  ...,  8.7031,  7.6523,  5.1602],\n",
      "          [ 3.2168,  4.1992,  4.7891,  ...,  6.4336,  5.6797,  3.9902]],\n",
      "\n",
      "         [[ 2.1758,  4.7305,  6.4961,  ...,  1.3779,  0.9253,  0.6826],\n",
      "          [ 3.2188,  6.9688,  9.5547,  ...,  2.4766,  1.5693,  0.7861],\n",
      "          [ 3.0117,  6.5352,  8.9922,  ...,  3.2617,  2.1445,  1.0234],\n",
      "          ...,\n",
      "          [ 4.8398,  6.6719,  7.9062,  ..., 11.6562, 10.3125,  6.9414],\n",
      "          [ 4.8047,  6.6211,  7.7891,  ..., 11.0781,  9.6875,  6.4844],\n",
      "          [ 3.9961,  5.2539,  6.0469,  ...,  8.1797,  7.1875,  5.0156]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0430,  5.7930,  6.8867,  ...,  6.5312,  5.3945,  2.8086],\n",
      "          [ 4.7930,  9.0312, 10.4766,  ..., 10.1484,  8.6875,  4.5273],\n",
      "          [ 5.0820,  9.1797, 10.3047,  ..., 10.2656,  9.2656,  5.1016],\n",
      "          ...,\n",
      "          [ 4.0820,  5.4297,  6.1797,  ...,  7.4180,  6.6328,  4.5938],\n",
      "          [ 4.0547,  5.4297,  6.1523,  ...,  7.3164,  6.5156,  4.5078],\n",
      "          [ 3.4023,  4.3672,  4.8906,  ...,  5.6055,  5.0625,  3.6660]],\n",
      "\n",
      "         [[ 3.3125,  6.4258,  7.7852,  ...,  7.1953,  5.9258,  2.9121],\n",
      "          [ 5.0156,  9.4688, 11.1797,  ..., 10.6094,  9.0078,  4.4492],\n",
      "          [ 5.2578,  9.4922, 10.8672,  ..., 10.7031,  9.6016,  5.0195],\n",
      "          ...,\n",
      "          [ 3.7383,  4.9766,  5.6523,  ...,  6.8164,  6.0820,  4.2031],\n",
      "          [ 3.7246,  4.9883,  5.6406,  ...,  6.7383,  5.9844,  4.1250],\n",
      "          [ 3.1133,  3.9902,  4.4570,  ...,  5.1406,  4.6289,  3.3418]],\n",
      "\n",
      "         [[ 2.3242,  4.6289,  5.6250,  ...,  5.1992,  4.2227,  2.0137],\n",
      "          [ 3.6094,  6.9609,  8.2109,  ...,  7.8086,  6.5625,  3.1836],\n",
      "          [ 3.7773,  6.9453,  7.9453,  ...,  7.8633,  6.9609,  3.6055],\n",
      "          ...,\n",
      "          [ 4.6484,  6.2266,  7.1406,  ...,  8.6250,  7.6523,  5.2422],\n",
      "          [ 4.6133,  6.2109,  7.0938,  ...,  8.5000,  7.5078,  5.1367],\n",
      "          [ 3.8672,  4.9883,  5.6133,  ...,  6.4922,  5.8125,  4.1680]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 2.3984,  2.4043,  2.3809,  ...,  9.9297,  7.8828,  4.0664],\n",
      "          [ 2.8027,  2.9844,  2.8711,  ..., 14.9688, 11.9453,  6.0859],\n",
      "          [ 2.9375,  3.0586,  2.9258,  ..., 15.8125, 12.7578,  6.6367],\n",
      "          ...,\n",
      "          [ 6.2344,  8.8281,  9.9453,  ..., 11.2734, 10.4766,  7.2969],\n",
      "          [ 6.0977,  8.6719,  9.8438,  ..., 10.9453, 10.0703,  6.9727],\n",
      "          [ 4.8672,  6.6836,  7.5391,  ...,  8.2344,  7.5742,  5.4258]],\n",
      "\n",
      "         [[ 2.2344,  2.2539,  2.2188,  ..., 11.8906,  9.4375,  4.6641],\n",
      "          [ 2.5840,  2.7188,  2.6250,  ..., 17.7031, 14.1094,  6.9844],\n",
      "          [ 2.7070,  2.8281,  2.6973,  ..., 18.6406, 14.9688,  7.5625],\n",
      "          ...,\n",
      "          [ 5.7305,  8.1406,  9.1719,  ..., 10.4219,  9.6562,  6.6953],\n",
      "          [ 5.6133,  7.9961,  9.0781,  ..., 10.1094,  9.2812,  6.4023],\n",
      "          [ 4.4648,  6.1289,  6.9180,  ...,  7.5781,  6.9531,  4.9648]],\n",
      "\n",
      "         [[ 2.6172,  2.5703,  2.5781,  ...,  9.0000,  7.0859,  3.5254],\n",
      "          [ 3.0566,  3.1309,  3.0547,  ..., 13.4844, 10.6562,  5.2383],\n",
      "          [ 3.2344,  3.2949,  3.1777,  ..., 14.1797, 11.2969,  5.6797],\n",
      "          ...,\n",
      "          [ 7.1875, 10.2734, 11.6172,  ..., 13.2188, 12.2188,  8.4375],\n",
      "          [ 7.0156, 10.0703, 11.4844,  ..., 12.8047, 11.7188,  8.0469],\n",
      "          [ 5.5859,  7.7266,  8.7500,  ...,  9.5938,  8.7734,  6.2383]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3945,  8.2344, 10.1719,  ...,  2.6621,  1.6660,  1.2305],\n",
      "          [ 6.8164, 12.5703, 15.4922,  ...,  4.6602,  2.7812,  1.3379],\n",
      "          [ 7.5352, 13.6250, 16.4219,  ...,  5.3945,  3.2891,  1.5566],\n",
      "          ...,\n",
      "          [ 2.1328,  2.2188,  1.5723,  ...,  1.6855,  2.5234,  2.2520],\n",
      "          [ 2.7637,  3.1660,  2.8594,  ...,  2.9551,  3.5117,  2.8789],\n",
      "          [ 2.8906,  3.1484,  3.0625,  ...,  3.2168,  3.5156,  2.9180]],\n",
      "\n",
      "         [[ 5.1445,  9.8281, 12.2344,  ...,  2.5078,  1.5371,  1.2051],\n",
      "          [ 7.9141, 14.8281, 18.3906,  ...,  3.9238,  2.0977,  1.0928],\n",
      "          [ 8.7500, 16.0000, 19.4375,  ...,  4.6367,  2.5332,  1.2568],\n",
      "          ...,\n",
      "          [ 1.9326,  1.8340,  1.2021,  ...,  1.4346,  2.2324,  2.0645],\n",
      "          [ 2.5332,  2.7793,  2.4492,  ...,  2.6797,  3.1836,  2.6367],\n",
      "          [ 2.6406,  2.8672,  2.7656,  ...,  2.9336,  3.1895,  2.6582]],\n",
      "\n",
      "         [[ 3.8828,  7.4102,  9.2266,  ...,  1.6719,  0.9624,  0.9141],\n",
      "          [ 5.9648, 11.2734, 13.9453,  ...,  2.7988,  1.4043,  0.6753],\n",
      "          [ 6.5898, 12.1484, 14.7422,  ...,  3.3066,  1.6934,  0.7559],\n",
      "          ...,\n",
      "          [ 2.1523,  1.8281,  1.1416,  ...,  1.4316,  2.5371,  2.3848],\n",
      "          [ 2.9590,  3.1250,  2.7617,  ...,  3.1016,  3.8027,  3.1348],\n",
      "          [ 3.1855,  3.4375,  3.3242,  ...,  3.5664,  3.9004,  3.2266]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5977,  1.2969,  1.0684,  ...,  8.9297,  7.4219,  3.9121],\n",
      "          [ 1.5566,  1.6953,  1.5391,  ..., 13.4219, 11.2891,  5.8438],\n",
      "          [ 1.3125,  1.6582,  1.7910,  ..., 14.0469, 11.9922,  6.3438],\n",
      "          ...,\n",
      "          [ 5.2031,  7.0117,  7.6836,  ...,  9.5391,  8.8047,  6.1758],\n",
      "          [ 5.2578,  7.1719,  7.9688,  ...,  9.3750,  8.5781,  5.9805],\n",
      "          [ 4.3672,  5.7539,  6.3633,  ...,  7.1680,  6.5859,  4.7695]],\n",
      "\n",
      "         [[ 1.5264,  1.1934,  0.9272,  ..., 10.5938,  8.8281,  4.4531],\n",
      "          [ 1.3809,  1.2695,  1.0645,  ..., 15.6562, 13.1719,  6.6406],\n",
      "          [ 1.1445,  1.2383,  1.2246,  ..., 16.3125, 13.8906,  7.1523],\n",
      "          ...,\n",
      "          [ 4.7734,  6.4531,  7.0820,  ...,  8.7812,  8.0938,  5.6523],\n",
      "          [ 4.8320,  6.6094,  7.3438,  ...,  8.6406,  7.8906,  5.4805],\n",
      "          [ 4.0000,  5.2695,  5.8281,  ...,  6.5820,  6.0273,  4.3555]],\n",
      "\n",
      "         [[ 1.5947,  1.0000,  0.7012,  ...,  7.9805,  6.6016,  3.3438],\n",
      "          [ 1.3613,  0.9600,  0.7485,  ..., 11.8828,  9.9219,  4.9688],\n",
      "          [ 1.0420,  0.8564,  0.8311,  ..., 12.3594, 10.4453,  5.3555],\n",
      "          ...,\n",
      "          [ 5.9531,  8.0938,  8.9141,  ..., 11.1172, 10.2031,  7.0938],\n",
      "          [ 6.0078,  8.2656,  9.2344,  ..., 10.9062,  9.9219,  6.8555],\n",
      "          [ 4.9844,  6.6133,  7.3477,  ...,  8.3125,  7.5898,  5.4531]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 1.0977,  1.3818,  1.4531,  ..., 12.0938,  9.7734,  5.1406],\n",
      "          [ 1.1406,  2.2422,  2.4375,  ..., 18.0469, 14.7578,  7.6914],\n",
      "          [ 1.1045,  2.5996,  2.9629,  ..., 18.5312, 15.3203,  8.1797],\n",
      "          ...,\n",
      "          [ 5.2656,  7.5781,  8.9141,  ..., 10.4844,  9.5234,  6.5156],\n",
      "          [ 5.1523,  7.4219,  8.7969,  ..., 10.1562,  9.0781,  6.1523],\n",
      "          [ 4.1953,  5.7734,  6.7461,  ...,  7.6367,  6.8281,  4.8086]],\n",
      "\n",
      "         [[ 1.0801,  1.2266,  1.2510,  ..., 14.2578, 11.4922,  5.8555],\n",
      "          [ 0.9287,  1.6094,  1.7217,  ..., 20.8125, 16.8594,  8.6016],\n",
      "          [ 0.8975,  1.9141,  2.2090,  ..., 21.3125, 17.4531,  9.0859],\n",
      "          ...,\n",
      "          [ 4.8438,  6.9883,  8.2109,  ...,  9.7031,  8.8047,  6.0000],\n",
      "          [ 4.7500,  6.8555,  8.1094,  ...,  9.4062,  8.3906,  5.6680],\n",
      "          [ 3.8496,  5.2969,  6.1875,  ...,  7.0391,  6.2812,  4.4102]],\n",
      "\n",
      "         [[ 0.8906,  0.7632,  0.7783,  ..., 10.8906,  8.7188,  4.3906],\n",
      "          [ 0.6650,  1.0996,  1.1875,  ..., 15.9688, 12.8672,  6.5156],\n",
      "          [ 0.5850,  1.2910,  1.5137,  ..., 16.3438, 13.2734,  6.8750],\n",
      "          ...,\n",
      "          [ 5.9883,  8.7109, 10.3203,  ..., 12.2031, 11.0234,  7.4727],\n",
      "          [ 5.8438,  8.5078, 10.1484,  ..., 11.7891, 10.4688,  7.0273],\n",
      "          [ 4.7422,  6.5820,  7.7500,  ...,  8.8281,  7.8398,  5.4688]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7021,  3.8066,  4.6172,  ..., 11.9922,  9.6484,  5.0703],\n",
      "          [ 2.7734,  6.1484,  7.2266,  ..., 17.9062, 14.5469,  7.5547],\n",
      "          [ 3.2578,  6.7852,  7.6484,  ..., 18.4688, 15.1406,  8.0312],\n",
      "          ...,\n",
      "          [ 1.4395,  1.4404,  1.1826,  ..., 10.8203,  9.8828,  6.7695],\n",
      "          [ 1.9941,  2.1445,  1.8467,  ..., 10.4453,  9.3750,  6.3672],\n",
      "          [ 2.3262,  2.3730,  2.3105,  ...,  7.8086,  7.0117,  4.9375]],\n",
      "\n",
      "         [[ 1.6943,  3.6426,  4.5742,  ..., 14.1641, 11.3828,  5.7891],\n",
      "          [ 2.3711,  5.4727,  6.6602,  ..., 20.7031, 16.6875,  8.4922],\n",
      "          [ 2.8496,  6.1367,  7.1602,  ..., 21.2812, 17.3125,  8.9609],\n",
      "          ...,\n",
      "          [ 1.3008,  1.1055,  0.8838,  ..., 10.0156,  9.1250,  6.2305],\n",
      "          [ 1.8252,  1.8438,  1.5244,  ...,  9.6797,  8.6719,  5.8633],\n",
      "          [ 2.1348,  2.1680,  2.0898,  ...,  7.2031,  6.4492,  4.5273]],\n",
      "\n",
      "         [[ 1.0957,  2.5742,  3.2969,  ..., 10.8281,  8.6406,  4.3438],\n",
      "          [ 1.6416,  4.0469,  4.9180,  ..., 15.8984, 12.7422,  6.4336],\n",
      "          [ 1.9990,  4.5195,  5.2695,  ..., 16.3125, 13.1797,  6.7891],\n",
      "          ...,\n",
      "          [ 1.2842,  0.8779,  0.6484,  ..., 12.6016, 11.4375,  7.7695],\n",
      "          [ 1.9990,  1.8682,  1.5498,  ..., 12.1406, 10.8281,  7.2812],\n",
      "          [ 2.4766,  2.4805,  2.4102,  ...,  9.0391,  8.0625,  5.6211]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0791,  1.3916,  1.4951,  ..., 11.7500,  9.5547,  5.0391],\n",
      "          [ 1.1396,  2.2676,  2.5078,  ..., 17.5469, 14.4219,  7.5000],\n",
      "          [ 1.0928,  2.5996,  3.0684,  ..., 17.8438, 14.6797,  7.7578],\n",
      "          ...,\n",
      "          [ 5.2500,  7.4492,  8.6250,  ..., 10.9375, 10.0781,  6.9375],\n",
      "          [ 5.1250,  7.3086,  8.5703,  ..., 10.5703,  9.5781,  6.5273],\n",
      "          [ 4.1797,  5.7070,  6.6133,  ...,  7.9102,  7.1523,  5.0469]],\n",
      "\n",
      "         [[ 1.0576,  1.2207,  1.2783,  ..., 13.8047, 11.1875,  5.7148],\n",
      "          [ 0.9180,  1.6162,  1.7715,  ..., 20.1562, 16.3750,  8.3281],\n",
      "          [ 0.8838,  1.9150,  2.3203,  ..., 20.3906, 16.5469,  8.4922],\n",
      "          ...,\n",
      "          [ 4.8242,  6.8672,  7.9492,  ..., 10.1250,  9.3125,  6.3789],\n",
      "          [ 4.7227,  6.7500,  7.9062,  ...,  9.7891,  8.8516,  6.0078],\n",
      "          [ 3.8320,  5.2344,  6.0664,  ...,  7.2930,  6.5781,  4.6250]],\n",
      "\n",
      "         [[ 0.8691,  0.7578,  0.7944,  ..., 10.5312,  8.4688,  4.2734],\n",
      "          [ 0.6606,  1.1084,  1.2217,  ..., 15.4531, 12.4766,  6.2930],\n",
      "          [ 0.5776,  1.2920,  1.5898,  ..., 15.6172, 12.5547,  6.4023],\n",
      "          ...,\n",
      "          [ 5.9648,  8.5547,  9.9766,  ..., 12.7344, 11.6719,  7.9609],\n",
      "          [ 5.8086,  8.3672,  9.8828,  ..., 12.2812, 11.0547,  7.4688],\n",
      "          [ 4.7227,  6.5000,  7.5938,  ...,  9.1562,  8.2266,  5.7500]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 4.0391,  8.2188,  9.9062,  ...,  4.7500,  2.8613,  1.6406],\n",
      "          [ 6.6250, 12.9531, 15.3516,  ...,  7.6133,  4.5430,  1.7783],\n",
      "          [ 7.5430, 14.1172, 16.1562,  ...,  8.7266,  5.5273,  2.2383],\n",
      "          ...,\n",
      "          [ 5.5469,  7.9297,  9.0391,  ..., 10.9453, 10.3359,  7.1367],\n",
      "          [ 5.4180,  7.8008,  9.0234,  ..., 10.9688, 10.0938,  6.8594],\n",
      "          [ 4.3945,  6.0625,  6.9609,  ...,  8.3125,  7.5898,  5.3125]],\n",
      "\n",
      "         [[ 4.4258,  9.1797, 11.2031,  ...,  5.2578,  3.1035,  1.6318],\n",
      "          [ 7.0234, 13.9844, 16.8281,  ...,  8.1328,  4.6719,  1.6504],\n",
      "          [ 8.0391, 15.2812, 17.7812,  ...,  9.5156,  5.9102,  2.1777],\n",
      "          ...,\n",
      "          [ 5.1016,  7.3203,  8.3516,  ..., 10.1562,  9.5625,  6.5664],\n",
      "          [ 4.9883,  7.2070,  8.3438,  ..., 10.1719,  9.3438,  6.3086],\n",
      "          [ 4.0273,  5.5586,  6.3867,  ...,  7.6680,  6.9844,  4.8555]],\n",
      "\n",
      "         [[ 3.2734,  6.9688,  8.5312,  ...,  3.9336,  2.2598,  1.2949],\n",
      "          [ 5.3359, 10.7812, 12.9531,  ...,  6.2461,  3.4980,  1.1680],\n",
      "          [ 6.1016, 11.7500, 13.6484,  ...,  7.3086,  4.4414,  1.5703],\n",
      "          ...,\n",
      "          [ 6.2656,  9.0469, 10.3906,  ..., 12.6719, 11.9062,  8.1406],\n",
      "          [ 6.1016,  8.8750, 10.3516,  ..., 12.6719, 11.5938,  7.8008],\n",
      "          [ 4.9414,  6.8672,  7.9492,  ...,  9.5625,  8.6875,  6.0156]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1094,  1.4033,  1.3721,  ...,  7.0117,  5.7461,  2.9512],\n",
      "          [ 1.2197,  2.1953,  2.1875,  ..., 10.1094,  8.5547,  4.3789],\n",
      "          [ 1.1465,  2.3906,  2.4570,  ...,  9.7344,  8.5312,  4.6406],\n",
      "          ...,\n",
      "          [ 4.8242,  6.6055,  7.5859,  ..., 12.5547, 11.6172,  7.9062],\n",
      "          [ 4.8516,  6.7852,  7.9023,  ..., 12.1094, 11.0078,  7.4141],\n",
      "          [ 4.0781,  5.4922,  6.3086,  ...,  8.9688,  8.1250,  5.6367]],\n",
      "\n",
      "         [[ 1.0781,  1.2080,  1.1650,  ...,  7.4414,  6.1406,  2.9980],\n",
      "          [ 0.9727,  1.5566,  1.5078,  ..., 10.1016,  8.5547,  4.0977],\n",
      "          [ 0.9238,  1.7246,  1.7734,  ...,  9.5156,  8.3828,  4.2734],\n",
      "          ...,\n",
      "          [ 4.4414,  6.0938,  7.0078,  ..., 11.6562, 10.7578,  7.2812],\n",
      "          [ 4.4727,  6.2695,  7.3047,  ..., 11.2422, 10.2031,  6.8281],\n",
      "          [ 3.7422,  5.0352,  5.7891,  ...,  8.2891,  7.4805,  5.1602]],\n",
      "\n",
      "         [[ 0.8945,  0.7866,  0.7583,  ...,  5.5664,  4.5430,  2.1367],\n",
      "          [ 0.7407,  1.1123,  1.0869,  ...,  7.6758,  6.4453,  3.0234],\n",
      "          [ 0.6416,  1.2051,  1.2480,  ...,  7.1758,  6.2500,  3.1406],\n",
      "          ...,\n",
      "          [ 5.4062,  7.4688,  8.6641,  ..., 14.5781, 13.4219,  9.0547],\n",
      "          [ 5.4297,  7.6641,  9.0156,  ..., 14.0312, 12.6875,  8.4609],\n",
      "          [ 4.5625,  6.1875,  7.1758,  ..., 10.3516,  9.3125,  6.3984]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0312, 11.4766, 14.0000,  ..., 11.1328,  8.7891,  4.3672],\n",
      "          [ 9.3672, 17.5625, 21.1875,  ..., 16.6875, 13.4375,  6.6914],\n",
      "          [10.2734, 18.7812, 22.2344,  ..., 17.1406, 13.9531,  7.1758],\n",
      "          ...,\n",
      "          [ 2.0742,  5.0391,  5.9375,  ...,  2.1094,  1.3682,  1.2061],\n",
      "          [ 1.2852,  2.7969,  3.4453,  ...,  1.4609,  1.9805,  1.7178],\n",
      "          [ 1.5029,  1.2861,  1.2031,  ...,  1.8613,  2.3496,  2.1445]],\n",
      "\n",
      "         [[ 6.9258, 13.3672, 16.4062,  ..., 12.7344, 10.0391,  4.7734],\n",
      "          [10.5625, 19.9688, 24.3125,  ..., 18.5312, 14.7891,  7.0977],\n",
      "          [11.5781, 21.3281, 25.5156,  ..., 19.0156, 15.2891,  7.5469],\n",
      "          ...,\n",
      "          [ 1.7822,  4.4102,  5.3945,  ...,  1.6064,  1.0420,  1.0547],\n",
      "          [ 1.0850,  2.2344,  2.8828,  ...,  1.1348,  1.6621,  1.5508],\n",
      "          [ 1.3955,  1.0889,  1.0166,  ...,  1.6924,  2.1367,  1.9600]],\n",
      "\n",
      "         [[ 5.2812, 10.2969, 12.6641,  ...,  9.7656,  7.6289,  3.5508],\n",
      "          [ 8.1406, 15.5000, 18.8438,  ..., 14.3359, 11.3516,  5.3789],\n",
      "          [ 8.9062, 16.5156, 19.7344,  ..., 14.6641, 11.6875,  5.7031],\n",
      "          ...,\n",
      "          [ 1.1934,  3.2832,  4.0195,  ...,  1.0811,  0.7583,  0.8701],\n",
      "          [ 0.7725,  1.5527,  2.0234,  ...,  0.8867,  1.6582,  1.5879],\n",
      "          [ 1.4023,  0.8730,  0.7061,  ...,  1.8223,  2.4219,  2.2207]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 7.2305, 13.5938, 15.8594,  ..., 15.2656, 12.5000,  6.5508],\n",
      "          [11.0391, 19.8281, 22.8438,  ..., 21.5469, 17.8750,  9.6953],\n",
      "          [11.5938, 20.3281, 22.6406,  ..., 20.8281, 17.6562,  9.9453],\n",
      "          ...,\n",
      "          [ 5.2656,  8.2422, 10.1641,  ..., 10.2656,  9.1250,  5.9531],\n",
      "          [ 4.8086,  7.5430,  9.4766,  ...,  9.6094,  8.3750,  5.3867],\n",
      "          [ 3.7676,  5.5586,  6.8945,  ...,  6.9844,  6.1094,  4.1328]],\n",
      "\n",
      "         [[ 7.9336, 15.1328, 17.8594,  ..., 17.0156, 13.7891,  6.9727],\n",
      "          [11.7500, 21.4688, 25.0938,  ..., 23.3125, 19.0625,  9.9375],\n",
      "          [12.3438, 21.9688, 24.8594,  ..., 22.4688, 18.7500, 10.1094],\n",
      "          ...,\n",
      "          [ 4.8555,  7.6445,  9.4375,  ...,  9.5547,  8.4688,  5.4727],\n",
      "          [ 4.4414,  7.0000,  8.8047,  ...,  8.9453,  7.7852,  4.9531],\n",
      "          [ 3.4648,  5.1094,  6.3438,  ...,  6.4492,  5.6211,  3.7695]],\n",
      "\n",
      "         [[ 6.0469, 11.6953, 13.8281,  ..., 13.1641, 10.5781,  5.2617],\n",
      "          [ 9.0703, 16.7500, 19.5312,  ..., 18.1719, 14.7266,  7.6016],\n",
      "          [ 9.5078, 17.0938, 19.3281,  ..., 17.4844, 14.4062,  7.7227],\n",
      "          ...,\n",
      "          [ 5.8984,  9.3594, 11.6641,  ..., 11.8047, 10.4062,  6.6953],\n",
      "          [ 5.3516,  8.5078, 10.8281,  ..., 11.0000,  9.5000,  6.0195],\n",
      "          [ 4.1758,  6.2266,  7.8203,  ...,  7.9414,  6.8789,  4.5820]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8584,  2.2637,  2.9980,  ..., 12.0156,  9.7109,  4.9258],\n",
      "          [ 2.7930,  4.0039,  5.2695,  ..., 17.1719, 14.0625,  7.4023],\n",
      "          [ 3.8242,  5.6680,  7.2930,  ..., 17.1875, 14.4531,  7.9180],\n",
      "          ...,\n",
      "          [ 3.7383,  5.3594,  6.7266,  ...,  9.6172,  8.6719,  5.7461],\n",
      "          [ 3.5859,  5.1836,  6.5625,  ...,  9.2266,  8.0938,  5.2695],\n",
      "          [ 3.0449,  4.2070,  5.1562,  ...,  6.8555,  5.9922,  4.1016]],\n",
      "\n",
      "         [[ 1.7568,  2.1289,  2.7852,  ..., 12.9609, 10.3984,  5.0000],\n",
      "          [ 2.5781,  3.6758,  4.8359,  ..., 17.9219, 14.4688,  7.1719],\n",
      "          [ 3.5273,  5.2188,  6.6992,  ..., 17.9531, 14.8672,  7.6602],\n",
      "          ...,\n",
      "          [ 3.4609,  4.9688,  6.2109,  ...,  8.9531,  8.0547,  5.2773],\n",
      "          [ 3.3281,  4.8125,  6.0625,  ...,  8.5859,  7.5156,  4.8477],\n",
      "          [ 2.8008,  3.8711,  4.7266,  ...,  6.3242,  5.5078,  3.7461]],\n",
      "\n",
      "         [[ 1.8984,  2.2969,  3.2285,  ...,  9.9531,  7.8945,  3.7129],\n",
      "          [ 2.9668,  4.2734,  5.8320,  ..., 13.8906, 11.1016,  5.4336],\n",
      "          [ 4.1953,  6.2930,  8.2422,  ..., 13.9062, 11.3750,  5.8125],\n",
      "          ...,\n",
      "          [ 4.0898,  5.9336,  7.5820,  ..., 11.0312,  9.8750,  6.4492],\n",
      "          [ 3.9062,  5.7070,  7.3633,  ..., 10.5469,  9.1641,  5.8789],\n",
      "          [ 3.3184,  4.6211,  5.7578,  ...,  7.7852,  6.7422,  4.5469]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3320, 10.0391, 10.8281,  ..., 11.2969,  7.6484,  3.3887],\n",
      "          [ 8.2578, 14.4844, 15.1953,  ..., 15.1562, 10.2969,  4.6992],\n",
      "          [ 8.7422, 14.6875, 14.5234,  ..., 13.6250,  9.3594,  4.5508],\n",
      "          ...,\n",
      "          [ 1.7051,  2.1777,  2.3906,  ...,  9.8516,  8.7500,  5.7461],\n",
      "          [ 2.0410,  2.7168,  3.1992,  ...,  9.4219,  8.1562,  5.2656],\n",
      "          [ 2.1191,  2.5547,  3.0254,  ...,  6.9688,  6.0273,  4.0977]],\n",
      "\n",
      "         [[ 5.5273, 10.6094, 11.5469,  ..., 12.0547,  7.8398,  3.1953],\n",
      "          [ 8.2500, 14.7422, 15.6016,  ..., 15.4062,  9.8516,  4.0156],\n",
      "          [ 8.7734, 14.9297, 14.9141,  ..., 13.5391,  8.7031,  3.8281],\n",
      "          ...,\n",
      "          [ 1.5498,  1.8604,  2.0918,  ...,  9.1641,  8.1172,  5.2773],\n",
      "          [ 1.8662,  2.4023,  2.8672,  ...,  8.7734,  7.5742,  4.8398],\n",
      "          [ 1.9502,  2.3398,  2.7695,  ...,  6.4258,  5.5391,  3.7422]],\n",
      "\n",
      "         [[ 4.1328,  8.0781,  8.7891,  ...,  9.2109,  5.8672,  2.2676],\n",
      "          [ 6.2852, 11.3750, 11.9688,  ..., 11.8906,  7.4492,  2.9180],\n",
      "          [ 6.6797, 11.5000, 11.4062,  ..., 10.4141,  6.5078,  2.7617],\n",
      "          ...,\n",
      "          [ 1.6016,  1.8643,  2.2148,  ..., 11.3047,  9.9531,  6.4492],\n",
      "          [ 2.0000,  2.5371,  3.1973,  ..., 10.7734,  9.2344,  5.8750],\n",
      "          [ 2.1855,  2.6270,  3.2168,  ...,  7.9180,  6.7852,  4.5430]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 3.1680,  6.8086,  7.8516,  ..., 16.6562, 13.3906,  6.8555],\n",
      "          [ 4.5977,  9.3750, 10.8594,  ..., 23.4062, 18.9844, 10.0625],\n",
      "          [ 4.8359,  9.5703, 10.8750,  ..., 23.0000, 19.0000, 10.4219],\n",
      "          ...,\n",
      "          [ 5.7500,  9.0312, 10.9219,  ..., 12.9609, 11.7188,  7.6484],\n",
      "          [ 5.2852,  8.3125, 10.2500,  ..., 12.3047, 10.8516,  6.9570],\n",
      "          [ 4.1094,  6.1016,  7.4414,  ...,  8.8984,  7.7930,  5.1758]],\n",
      "\n",
      "         [[ 3.0332,  6.6914,  7.8906,  ..., 18.4375, 14.6562,  7.2773],\n",
      "          [ 4.0156,  8.6562, 10.3828,  ..., 25.2344, 20.1562, 10.2656],\n",
      "          [ 4.2812,  8.8750, 10.5234,  ..., 24.7500, 20.0938, 10.5625],\n",
      "          ...,\n",
      "          [ 5.3203,  8.3828, 10.1484,  ..., 12.0859, 10.9062,  7.0625],\n",
      "          [ 4.8984,  7.7266,  9.5312,  ..., 11.4766, 10.0938,  6.4219],\n",
      "          [ 3.7871,  5.6211,  6.8711,  ...,  8.2422,  7.2031,  4.7422]],\n",
      "\n",
      "         [[ 2.1660,  5.0352,  5.9844,  ..., 14.4219, 11.3828,  5.5430],\n",
      "          [ 2.9746,  6.6562,  7.9805,  ..., 19.8594, 15.7344,  7.9258],\n",
      "          [ 3.1875,  6.8281,  8.0938,  ..., 19.4375, 15.6250,  8.1406],\n",
      "          ...,\n",
      "          [ 6.4375, 10.2266, 12.4844,  ..., 14.8984, 13.3906,  8.6484],\n",
      "          [ 5.8789,  9.3516, 11.6719,  ..., 14.1016, 12.3438,  7.8281],\n",
      "          [ 4.5469,  6.8242,  8.4219,  ..., 10.1406,  8.8203,  5.7812]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1074,  6.5859,  7.6758,  ..., 14.1328, 11.3281,  5.7539],\n",
      "          [ 4.6289,  9.2812, 10.8203,  ..., 19.7500, 15.9688,  8.3672],\n",
      "          [ 5.1211,  9.8828, 11.2031,  ..., 19.6875, 16.1875,  8.8203],\n",
      "          ...,\n",
      "          [ 4.4766,  6.6445,  8.1016,  ..., 12.0547, 10.8906,  7.1172],\n",
      "          [ 4.2422,  6.3359,  7.8320,  ..., 11.4609, 10.0781,  6.4688],\n",
      "          [ 3.4863,  4.9805,  6.0078,  ...,  8.3281,  7.2773,  4.8789]],\n",
      "\n",
      "         [[ 2.9707,  6.4414,  7.6914,  ..., 15.4297, 12.2578,  6.0078],\n",
      "          [ 4.0586,  8.5625, 10.3516,  ..., 20.9219, 16.6719,  8.3359],\n",
      "          [ 4.6016,  9.2656, 10.9297,  ..., 20.8125, 16.8438,  8.7422],\n",
      "          ...,\n",
      "          [ 4.1523,  6.1602,  7.4922,  ..., 11.2344, 10.1250,  6.5625],\n",
      "          [ 3.9414,  5.8828,  7.2539,  ..., 10.6797,  9.3750,  5.9648],\n",
      "          [ 3.2188,  4.5938,  5.5312,  ...,  7.7109,  6.7188,  4.4688]],\n",
      "\n",
      "         [[ 2.1172,  4.8359,  5.8281,  ..., 12.0234,  9.4688,  4.5469],\n",
      "          [ 3.0117,  6.5820,  7.9531,  ..., 16.4062, 12.9609,  6.4023],\n",
      "          [ 3.4453,  7.1367,  8.4062,  ..., 16.2969, 13.0391,  6.7109],\n",
      "          ...,\n",
      "          [ 4.9297,  7.4023,  9.1484,  ..., 13.8203, 12.4141,  8.0234],\n",
      "          [ 4.6484,  7.0234,  8.8125,  ..., 13.1016, 11.4375,  7.2500],\n",
      "          [ 3.8145,  5.5000,  6.7305,  ...,  9.4688,  8.2109,  5.4297]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3887,  2.8457,  3.1309,  ...,  3.7695,  3.2930,  1.9688],\n",
      "          [ 1.9668,  3.9531,  4.3164,  ...,  5.2461,  4.4648,  2.5254],\n",
      "          [ 2.1523,  4.4062,  4.9609,  ...,  5.9570,  4.8555,  2.7051],\n",
      "          ...,\n",
      "          [ 4.5586,  6.8203,  8.3750,  ..., 11.8203, 10.7031,  7.0000],\n",
      "          [ 4.3047,  6.4609,  8.0234,  ..., 11.2891,  9.9453,  6.3906],\n",
      "          [ 3.5176,  5.0430,  6.0977,  ...,  8.2422,  7.2188,  4.8516]],\n",
      "\n",
      "         [[ 1.2432,  2.3496,  2.6211,  ...,  3.3086,  3.0234,  1.8115],\n",
      "          [ 1.4785,  2.9297,  3.2617,  ...,  4.2305,  3.6406,  2.0215],\n",
      "          [ 1.6494,  3.3809,  3.9902,  ...,  4.9961,  4.0469,  2.1797],\n",
      "          ...,\n",
      "          [ 4.2227,  6.3203,  7.7461,  ..., 11.0156,  9.9453,  6.4531],\n",
      "          [ 3.9961,  6.0000,  7.4336,  ..., 10.5156,  9.2422,  5.8906],\n",
      "          [ 3.2461,  4.6523,  5.6094,  ...,  7.6250,  6.6602,  4.4453]],\n",
      "\n",
      "         [[ 0.8052,  1.6074,  1.8174,  ...,  2.3613,  2.1191,  1.2197],\n",
      "          [ 1.0332,  2.1211,  2.3809,  ...,  3.1348,  2.6328,  1.3867],\n",
      "          [ 1.1562,  2.4629,  2.9512,  ...,  3.7461,  2.9453,  1.5039],\n",
      "          ...,\n",
      "          [ 5.0273,  7.6094,  9.4688,  ..., 13.5469, 12.1875,  7.8867],\n",
      "          [ 4.7188,  7.1758,  9.0391,  ..., 12.8984, 11.2812,  7.1602],\n",
      "          [ 3.8516,  5.5781,  6.8320,  ...,  9.3672,  8.1406,  5.3984]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.3184,  2.7598,  3.2793,  ..., 16.5312, 12.5156,  5.9062],\n",
      "          [ 1.8711,  3.8008,  4.5625,  ..., 23.7969, 17.9688,  8.6406],\n",
      "          [ 2.1582,  4.4727,  5.6406,  ..., 24.5469, 18.5938,  9.1250],\n",
      "          ...,\n",
      "          [ 6.3203,  9.5859, 11.2734,  ..., 13.5000, 12.4609,  8.2500],\n",
      "          [ 5.9727,  9.1328, 10.9219,  ..., 13.0781, 11.7891,  7.6992],\n",
      "          [ 4.7031,  6.9453,  8.1484,  ...,  9.6016,  8.5938,  5.8203]],\n",
      "\n",
      "         [[ 1.1904,  2.3125,  2.8281,  ..., 18.3594, 13.7812,  6.2930],\n",
      "          [ 1.4277,  2.8379,  3.5762,  ..., 25.8125, 19.2188,  8.8906],\n",
      "          [ 1.6855,  3.5039,  4.8242,  ..., 26.5625, 19.8125,  9.3438],\n",
      "          ...,\n",
      "          [ 5.8555,  8.8906, 10.4766,  ..., 12.5938, 11.5938,  7.6094],\n",
      "          [ 5.5469,  8.4766, 10.1484,  ..., 12.1875, 10.9688,  7.1016],\n",
      "          [ 4.3477,  6.4141,  7.5195,  ...,  8.8906,  7.9336,  5.3438]],\n",
      "\n",
      "         [[ 0.7935,  1.6006,  1.9990,  ..., 14.5625, 10.8516,  4.8477],\n",
      "          [ 1.0088,  2.0898,  2.6582,  ..., 20.6094, 15.2500,  6.9453],\n",
      "          [ 1.1943,  2.6055,  3.6582,  ..., 21.1719, 15.6719,  7.2773],\n",
      "          ...,\n",
      "          [ 7.0508, 10.8125, 12.8281,  ..., 15.4531, 14.1797,  9.2969],\n",
      "          [ 6.6328, 10.2656, 12.3906,  ..., 14.9297, 13.3750,  8.6328],\n",
      "          [ 5.2070,  7.7656,  9.2031,  ..., 10.9062,  9.7031,  6.4922]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0078,  4.7422,  6.2695,  ...,  1.4297,  1.2129,  1.0107],\n",
      "          [ 2.6641,  5.8320,  7.7578,  ...,  2.1504,  1.6816,  1.1367],\n",
      "          [ 2.6992,  5.8047,  7.5000,  ...,  2.3105,  1.5801,  1.0195],\n",
      "          ...,\n",
      "          [ 5.7383,  8.5781,  9.9609,  ..., 12.9375, 11.9609,  7.9531],\n",
      "          [ 5.4766,  8.2578,  9.7578,  ..., 12.5859, 11.3516,  7.4375],\n",
      "          [ 4.3945,  6.3906,  7.4570,  ...,  9.2812,  8.3125,  5.6562]],\n",
      "\n",
      "         [[ 1.8291,  4.3203,  6.0273,  ...,  1.1553,  1.0635,  0.9414],\n",
      "          [ 2.1016,  4.7500,  6.8438,  ...,  1.5127,  1.2373,  0.9150],\n",
      "          [ 2.1406,  4.7656,  6.7578,  ...,  1.6406,  1.1689,  0.8345],\n",
      "          ...,\n",
      "          [ 5.3203,  7.9570,  9.2344,  ..., 12.0703, 11.1250,  7.3398],\n",
      "          [ 5.0898,  7.6680,  9.0469,  ..., 11.7266, 10.5547,  6.8633],\n",
      "          [ 4.0625,  5.8984,  6.8789,  ...,  8.5938,  7.6719,  5.1953]],\n",
      "\n",
      "         [[ 1.2334,  3.1777,  4.5586,  ...,  0.7749,  0.7466,  0.7119],\n",
      "          [ 1.4941,  3.5723,  5.2344,  ...,  1.1338,  0.9272,  0.6934],\n",
      "          [ 1.5254,  3.5957,  5.1875,  ...,  1.2197,  0.8555,  0.6030],\n",
      "          ...,\n",
      "          [ 6.3672,  9.6250, 11.2812,  ..., 14.7969, 13.6016,  8.9453],\n",
      "          [ 6.0508,  9.2344, 11.0156,  ..., 14.3438, 12.8594,  8.3281],\n",
      "          [ 4.8477,  7.1133,  8.3828,  ..., 10.5312,  9.3750,  6.3008]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7148, 14.9453, 18.1094,  ..., 16.9844, 12.9922,  6.2305],\n",
      "          [11.6953, 21.6250, 25.9219,  ..., 24.0625, 18.5000,  9.1562],\n",
      "          [12.6250, 22.6719, 26.3125,  ..., 24.2812, 18.9219,  9.6797],\n",
      "          ...,\n",
      "          [ 3.0840,  6.7656,  8.5391,  ..., 11.4922, 10.4453,  6.8750],\n",
      "          [ 1.8379,  4.1914,  5.5820,  ..., 11.0234,  9.8125,  6.3828],\n",
      "          [ 1.0986,  1.5332,  1.7988,  ...,  8.1016,  7.2500,  4.9297]],\n",
      "\n",
      "         [[ 8.2969, 16.3281, 19.9688,  ..., 18.6875, 14.1484,  6.5586],\n",
      "          [12.2266, 23.0625, 27.9688,  ..., 25.8594, 19.5312,  9.2578],\n",
      "          [13.2188, 24.1562, 28.4219,  ..., 26.0781, 19.9219,  9.7500],\n",
      "          ...,\n",
      "          [ 2.6309,  6.0742,  8.1328,  ..., 10.6953,  9.7031,  6.3398],\n",
      "          [ 1.5410,  3.4570,  4.9570,  ..., 10.2578,  9.1172,  5.8906],\n",
      "          [ 1.0000,  1.2432,  1.4863,  ...,  7.4883,  6.6836,  4.5273]],\n",
      "\n",
      "         [[ 6.4531, 12.8906, 15.8047,  ..., 14.7891, 11.1016,  5.0312],\n",
      "          [ 9.6328, 18.3594, 22.2500,  ..., 20.5938, 15.4453,  7.2070],\n",
      "          [10.3984, 19.2031, 22.5781,  ..., 20.7344, 15.6953,  7.5703],\n",
      "          ...,\n",
      "          [ 1.8984,  4.6875,  6.2969,  ..., 13.1016, 11.8281,  7.6914],\n",
      "          [ 1.0547,  2.5605,  3.7305,  ..., 12.5234, 11.0625,  7.0977],\n",
      "          [ 0.8140,  0.8613,  0.9985,  ...,  9.1562,  8.1250,  5.4531]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 2.2422,  5.4844,  7.6641,  ..., 10.6172,  7.6484,  3.3711],\n",
      "          [ 3.1250,  7.1836, 10.1875,  ..., 14.6719, 10.1406,  4.0469],\n",
      "          [ 3.5293,  7.7891, 10.5000,  ..., 14.6562,  9.8906,  3.9980],\n",
      "          ...,\n",
      "          [ 6.0859,  9.3359, 10.8750,  ..., 13.6172, 12.6406,  8.2969],\n",
      "          [ 5.7930,  8.9609, 10.6406,  ..., 13.4609, 12.1094,  7.8086],\n",
      "          [ 4.6016,  6.8789,  8.0703,  ...,  9.9453,  8.8672,  5.9141]],\n",
      "\n",
      "         [[ 2.0156,  5.0859,  7.5352,  ..., 12.0938,  8.5938,  3.4980],\n",
      "          [ 2.5137,  6.2109,  9.5312,  ..., 16.5156, 11.1953,  4.1172],\n",
      "          [ 2.9258,  6.9492, 10.0938,  ..., 16.7344, 11.1406,  4.1367],\n",
      "          ...,\n",
      "          [ 5.6602,  8.6719, 10.0938,  ..., 12.7344, 11.7812,  7.6719],\n",
      "          [ 5.3984,  8.3359,  9.8906,  ..., 12.5703, 11.2891,  7.2227],\n",
      "          [ 4.2656,  6.3672,  7.4648,  ...,  9.2266,  8.1953,  5.4492]],\n",
      "\n",
      "         [[ 1.3945,  3.8281,  5.8203,  ...,  9.7734,  6.8984,  2.7910],\n",
      "          [ 1.8262,  4.7773,  7.4531,  ..., 13.4531,  9.1016,  3.3691],\n",
      "          [ 2.1465,  5.3906,  7.9180,  ..., 13.7188,  9.2031,  3.5293],\n",
      "          ...,\n",
      "          [ 6.7383, 10.4531, 12.2891,  ..., 15.5469, 14.3438,  9.3125],\n",
      "          [ 6.3867, 10.0000, 11.9922,  ..., 15.3203, 13.7031,  8.7266],\n",
      "          [ 5.0586,  7.6445,  9.0547,  ..., 11.2656,  9.9766,  6.5742]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5020,  8.8281, 12.8750,  ..., 18.3750, 14.2969,  6.9609],\n",
      "          [ 4.8672, 11.6719, 17.3438,  ..., 25.7344, 20.2812, 10.2266],\n",
      "          [ 5.2344, 11.8516, 16.8750,  ..., 25.8594, 20.9844, 11.1172],\n",
      "          ...,\n",
      "          [ 4.6172,  6.8750,  8.2812,  ..., 12.3750, 11.4062,  7.6250],\n",
      "          [ 4.5625,  6.8672,  8.3438,  ..., 12.1797, 10.9609,  7.1875],\n",
      "          [ 3.8379,  5.5625,  6.5820,  ...,  9.1641,  8.2188,  5.5117]],\n",
      "\n",
      "         [[ 3.2734,  8.8672, 13.4844,  ..., 19.8906, 15.2656,  7.1328],\n",
      "          [ 4.1758, 11.1250, 17.5781,  ..., 27.2969, 21.0938, 10.1406],\n",
      "          [ 4.5586, 11.3438, 17.1406,  ..., 27.5312, 21.8750, 11.0781],\n",
      "          ...,\n",
      "          [ 4.3008,  6.4023,  7.6992,  ..., 11.5391, 10.6016,  7.0586],\n",
      "          [ 4.2617,  6.4023,  7.7617,  ..., 11.3359, 10.1953,  6.6562],\n",
      "          [ 3.5586,  5.1523,  6.0938,  ...,  8.4922,  7.6094,  5.0781]],\n",
      "\n",
      "         [[ 2.3984,  6.8672, 10.6172,  ..., 15.8672, 12.0781,  5.5273],\n",
      "          [ 3.1504,  8.7344, 13.9219,  ..., 21.9375, 16.8125,  7.9609],\n",
      "          [ 3.4570,  8.8984, 13.5547,  ..., 22.1250, 17.4062,  8.7109],\n",
      "          ...,\n",
      "          [ 5.0195,  7.5703,  9.2500,  ..., 14.0703, 12.8906,  8.5156],\n",
      "          [ 4.9492,  7.5469,  9.2969,  ..., 13.8047, 12.3438,  7.9922],\n",
      "          [ 4.1680,  6.1016,  7.3164,  ..., 10.3438,  9.2188,  6.0938]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5156, 14.7891, 17.8906,  ..., 10.8672,  6.6797,  2.5098],\n",
      "          [11.2344, 21.0469, 25.1562,  ..., 12.8516,  7.6602,  2.9082],\n",
      "          [12.1484, 21.9688, 25.2969,  ..., 10.3438,  6.1797,  2.6211],\n",
      "          ...,\n",
      "          [ 6.9531, 10.7188, 12.4844,  ..., 12.4219, 11.0781,  7.2461],\n",
      "          [ 6.5391, 10.2031, 12.1328,  ..., 12.3750, 10.8750,  7.0508],\n",
      "          [ 5.0625,  7.6758,  9.0156,  ...,  9.2812,  8.2109,  5.4648]],\n",
      "\n",
      "         [[ 7.8398, 15.7969, 19.3281,  ..., 11.3047,  6.6562,  2.3008],\n",
      "          [11.3906, 21.9375, 26.6250,  ..., 12.5703,  6.9023,  2.3086],\n",
      "          [12.3750, 22.9531, 26.8594,  ...,  9.7031,  5.2695,  2.0371],\n",
      "          ...,\n",
      "          [ 6.4570,  9.9531, 11.6094,  ..., 11.5781, 10.2969,  6.7070],\n",
      "          [ 6.0859,  9.4844, 11.2812,  ..., 11.5234, 10.1094,  6.5312],\n",
      "          [ 4.6914,  7.1055,  8.3359,  ...,  8.6016,  7.6016,  5.0352]],\n",
      "\n",
      "         [[ 6.1172, 12.5312, 15.3984,  ...,  8.8672,  5.0977,  1.6143],\n",
      "          [ 9.0156, 17.5781, 21.3438,  ...,  9.9219,  5.2969,  1.6494],\n",
      "          [ 9.7812, 18.3750, 21.5000,  ...,  7.5938,  3.9609,  1.4600],\n",
      "          ...,\n",
      "          [ 7.7461, 12.0781, 14.1797,  ..., 14.1172, 12.5000,  8.0781],\n",
      "          [ 7.2578, 11.4531, 13.7422,  ..., 14.0312, 12.2422,  7.8320],\n",
      "          [ 5.6016,  8.5781, 10.1641,  ..., 10.4844,  9.2031,  6.0430]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 5.8594, 12.7891, 16.5625,  ..., 14.6719, 10.2344,  4.1016],\n",
      "          [ 9.3516, 19.0312, 24.3438,  ..., 21.6719, 15.2734,  6.2500],\n",
      "          [11.0625, 21.3438, 26.2656,  ..., 23.6250, 17.2031,  7.6406],\n",
      "          ...,\n",
      "          [ 9.0469, 13.5234, 14.7266,  ..., 16.2656, 15.2734, 10.1953],\n",
      "          [ 8.6953, 13.1328, 14.5703,  ..., 15.9531, 14.7656,  9.7734],\n",
      "          [ 6.7031,  9.8672, 10.8984,  ..., 11.8359, 10.9375,  7.4453]],\n",
      "\n",
      "         [[ 6.1445, 13.7500, 17.9688,  ..., 15.9922, 11.0547,  4.1758],\n",
      "          [ 9.5391, 20.0469, 25.9375,  ..., 23.1875, 16.0781,  6.1797],\n",
      "          [11.3672, 22.5625, 28.0938,  ..., 25.3281, 18.1406,  7.6484],\n",
      "          ...,\n",
      "          [ 8.4219, 12.6094, 13.7578,  ..., 15.2188, 14.2578,  9.4531],\n",
      "          [ 8.1016, 12.2422, 13.6094,  ..., 14.9219, 13.7891,  9.0625],\n",
      "          [ 6.2227,  9.1562, 10.1172,  ..., 11.0156, 10.1484,  6.8789]],\n",
      "\n",
      "         [[ 4.8203, 11.0156, 14.4531,  ..., 12.8750,  8.8203,  3.2422],\n",
      "          [ 7.6367, 16.2344, 21.0156,  ..., 18.8125, 12.9688,  4.8750],\n",
      "          [ 9.0938, 18.2500, 22.7344,  ..., 20.5156, 14.5938,  6.0469],\n",
      "          ...,\n",
      "          [10.1406, 15.2969, 16.7188,  ..., 18.5000, 17.2969, 11.4453],\n",
      "          [ 9.7188, 14.8047, 16.5156,  ..., 18.1250, 16.7031, 10.9375],\n",
      "          [ 7.4648, 11.0781, 12.2969,  ..., 13.3906, 12.3203,  8.2969]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3281, 11.8984, 15.5859,  ...,  6.6367,  4.8672,  2.5273],\n",
      "          [ 8.4531, 17.6250, 22.7969,  ...,  9.5391,  6.8516,  3.5234],\n",
      "          [ 9.9297, 19.5469, 24.2812,  ..., 10.3125,  7.5352,  4.0859],\n",
      "          ...,\n",
      "          [ 8.3984, 12.3984, 13.4766,  ..., 15.4922, 14.6875,  9.8594],\n",
      "          [ 8.1562, 12.1875, 13.5234,  ..., 15.6250, 14.5312,  9.6328],\n",
      "          [ 6.3672,  9.3203, 10.2656,  ..., 11.7109, 10.8516,  7.3984]],\n",
      "\n",
      "         [[ 5.5859, 12.8047, 16.9219,  ...,  7.2891,  5.1367,  2.4375],\n",
      "          [ 8.6016, 18.5625, 24.2812,  ..., 10.4453,  7.1328,  3.3125],\n",
      "          [10.1641, 20.6250, 25.9219,  ..., 11.2734,  7.8398,  3.8438],\n",
      "          ...,\n",
      "          [ 7.8164, 11.5547, 12.5859,  ..., 14.5078, 13.7188,  9.1406],\n",
      "          [ 7.5977, 11.3594, 12.6250,  ..., 14.6172, 13.5625,  8.9375],\n",
      "          [ 5.9102,  8.6562,  9.5234,  ..., 10.8984, 10.0703,  6.8359]],\n",
      "\n",
      "         [[ 4.3750, 10.2578, 13.6094,  ...,  6.5430,  4.8867,  2.5156],\n",
      "          [ 6.8750, 15.0234, 19.6719,  ...,  9.6953,  7.2305,  3.6660],\n",
      "          [ 8.1172, 16.6719, 20.9688,  ..., 10.7266,  8.1953,  4.3867],\n",
      "          ...,\n",
      "          [ 9.3828, 13.9844, 15.2734,  ..., 17.6250, 16.6406, 11.0625],\n",
      "          [ 9.0859, 13.7109, 15.2969,  ..., 17.7344, 16.4219, 10.7812],\n",
      "          [ 7.0742, 10.4453, 11.5625,  ..., 13.2500, 12.2266,  8.2422]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7119,  1.6084,  1.1455,  ...,  5.0820,  1.6523,  1.2070],\n",
      "          [ 2.2500,  2.4609,  1.4834,  ...,  7.3438,  2.2402,  1.3467],\n",
      "          [ 1.8291,  1.6504,  0.9243,  ...,  9.0938,  2.8711,  1.0400],\n",
      "          ...,\n",
      "          [ 6.6016,  9.5625, 10.3828,  ..., 15.1641, 14.3359,  9.6562],\n",
      "          [ 6.6367,  9.7422, 10.7734,  ..., 15.0703, 14.0078,  9.3281],\n",
      "          [ 5.4180,  7.7578,  8.5234,  ..., 11.2969, 10.4688,  7.1719]],\n",
      "\n",
      "         [[ 1.6318,  1.5215,  1.0889,  ...,  5.0977,  1.5430,  1.1211],\n",
      "          [ 2.1055,  2.1719,  1.3008,  ...,  6.9805,  1.7861,  1.1367],\n",
      "          [ 1.7275,  1.4502,  0.7812,  ...,  8.8594,  2.3359,  0.8779],\n",
      "          ...,\n",
      "          [ 6.1484,  8.9141,  9.6797,  ..., 14.1953, 13.3750,  8.9609],\n",
      "          [ 6.1875,  9.0859, 10.0469,  ..., 14.1016, 13.0781,  8.6562],\n",
      "          [ 5.0273,  7.1953,  7.9141,  ..., 10.5156,  9.7188,  6.6250]],\n",
      "\n",
      "         [[ 1.6709,  1.4297,  0.9521,  ...,  3.9375,  1.1133,  0.9814],\n",
      "          [ 2.1934,  2.1699,  1.1182,  ...,  5.5352,  1.3242,  0.9761],\n",
      "          [ 1.7510,  1.3232,  0.5586,  ...,  7.0391,  1.7051,  0.6436],\n",
      "          ...,\n",
      "          [ 7.2969, 10.6797, 11.6797,  ..., 17.2344, 16.2188, 10.8203],\n",
      "          [ 7.3203, 10.8672, 12.1016,  ..., 17.1094, 15.8203, 10.4297],\n",
      "          [ 5.9688,  8.6172,  9.5391,  ..., 12.7734, 11.7812,  7.9805]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.4395,  3.0020,  4.1172,  ...,  5.0117,  5.0078,  3.4805],\n",
      "          [ 1.8916,  3.8301,  5.4688,  ...,  8.4375,  8.4922,  5.7500],\n",
      "          [ 2.4668,  5.2891,  7.3477,  ...,  9.8047,  9.8047,  6.6484],\n",
      "          ...,\n",
      "          [ 8.0078, 11.9141, 12.7422,  ..., 14.4844, 13.8984,  9.3281],\n",
      "          [ 7.8203, 11.8359, 12.9844,  ..., 14.6016, 13.7031,  9.0625],\n",
      "          [ 6.1172,  9.0625,  9.9375,  ..., 11.0469, 10.2969,  6.9531]],\n",
      "\n",
      "         [[ 1.3057,  2.6758,  3.7285,  ...,  4.6914,  4.6953,  3.2461],\n",
      "          [ 1.5176,  3.0586,  4.6094,  ...,  7.8594,  7.9141,  5.3398],\n",
      "          [ 2.0078,  4.5273,  6.7188,  ...,  9.1406,  9.1484,  6.1836],\n",
      "          ...,\n",
      "          [ 7.4766, 11.1406, 11.9375,  ..., 13.5938, 13.0078,  8.6719],\n",
      "          [ 7.3086, 11.0625, 12.1562,  ..., 13.6953, 12.8281,  8.4219],\n",
      "          [ 5.6992,  8.4297,  9.2500,  ..., 10.3047,  9.5859,  6.4453]],\n",
      "\n",
      "         [[ 0.9390,  1.9561,  2.8125,  ...,  5.4258,  5.4102,  3.6875],\n",
      "          [ 1.1084,  2.3633,  3.5645,  ...,  9.3203,  9.3594,  6.2383],\n",
      "          [ 1.4805,  3.5410,  5.2930,  ..., 10.9453, 10.9219,  7.3008],\n",
      "          ...,\n",
      "          [ 8.9062, 13.3828, 14.3750,  ..., 16.3906, 15.6562, 10.4062],\n",
      "          [ 8.6719, 13.2578, 14.6172,  ..., 16.5000, 15.4141, 10.0781],\n",
      "          [ 6.7617, 10.1094, 11.1484,  ..., 12.4297, 11.5391,  7.6992]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1963,  2.4219,  3.3691,  ..., 17.6250, 13.5234,  6.3906],\n",
      "          [ 1.6357,  3.1777,  4.3984,  ..., 25.6875, 19.6875,  9.5547],\n",
      "          [ 2.1074,  4.2305,  5.9727,  ..., 28.3750, 22.1719, 11.3438],\n",
      "          ...,\n",
      "          [ 7.0859, 10.4141, 11.1641,  ..., 15.2031, 14.6250,  9.8047],\n",
      "          [ 7.0000, 10.4453, 11.4609,  ..., 15.2109, 14.3125,  9.4609],\n",
      "          [ 5.5938,  8.1797,  8.9453,  ..., 11.4375, 10.6797,  7.2031]],\n",
      "\n",
      "         [[ 1.0918,  2.0820,  2.9316,  ..., 19.0312, 14.4922,  6.6484],\n",
      "          [ 1.2920,  2.4043,  3.4980,  ..., 27.3125, 20.7031,  9.7109],\n",
      "          [ 1.6729,  3.4043,  5.2148,  ..., 30.3125, 23.3906, 11.6250],\n",
      "          ...,\n",
      "          [ 6.6172,  9.7266, 10.4531,  ..., 14.2656, 13.6875,  9.1094],\n",
      "          [ 6.5469,  9.7578, 10.7188,  ..., 14.2578, 13.3984,  8.7891],\n",
      "          [ 5.2109,  7.6133,  8.3203,  ..., 10.6719,  9.9453,  6.6758]],\n",
      "\n",
      "         [[ 0.7710,  1.5039,  2.1582,  ..., 15.4453, 11.7031,  5.2656],\n",
      "          [ 0.9448,  1.8496,  2.6680,  ..., 22.2969, 16.8438,  7.7969],\n",
      "          [ 1.2373,  2.6191,  4.0312,  ..., 24.7500, 19.0000,  9.3516],\n",
      "          ...,\n",
      "          [ 7.8320, 11.6328, 12.5469,  ..., 17.2188, 16.5000, 10.9531],\n",
      "          [ 7.7188, 11.6406, 12.8516,  ..., 17.2031, 16.1094, 10.5312],\n",
      "          [ 6.1523,  9.0859,  9.9922,  ..., 12.8828, 11.9844,  7.9883]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6953,  3.6797,  4.7734,  ..., 19.4688, 14.6094,  6.9297],\n",
      "          [ 2.4023,  4.7383,  6.2500,  ..., 27.7656, 20.9062, 10.1875],\n",
      "          [ 3.0664,  6.2344,  7.9414,  ..., 29.1406, 22.3438, 11.3672],\n",
      "          ...,\n",
      "          [ 8.1797, 12.1328, 12.8672,  ..., 15.7891, 15.0156,  9.9844],\n",
      "          [ 7.9492, 12.0000, 13.0703,  ..., 15.7109, 14.6641,  9.6250],\n",
      "          [ 6.1953,  9.1641,  9.9922,  ..., 11.7500, 10.9141,  7.3203]],\n",
      "\n",
      "         [[ 1.5010,  3.2559,  4.3398,  ..., 21.0781, 15.6797,  7.2344],\n",
      "          [ 1.8984,  3.8301,  5.3242,  ..., 29.6094, 22.0000, 10.3672],\n",
      "          [ 2.4883,  5.3984,  7.2773,  ..., 31.1094, 23.4844, 11.5625],\n",
      "          ...,\n",
      "          [ 7.6328, 11.3516, 12.0547,  ..., 14.8047, 14.0469,  9.2734],\n",
      "          [ 7.4258, 11.2266, 12.2422,  ..., 14.7266, 13.7266,  8.9453],\n",
      "          [ 5.7695,  8.5234,  9.2969,  ..., 10.9609, 10.1641,  6.7812]],\n",
      "\n",
      "         [[ 1.0605,  2.4219,  3.3086,  ..., 17.1406, 12.6875,  5.7422],\n",
      "          [ 1.4121,  2.9746,  4.1211,  ..., 24.1875, 17.9062,  8.3438],\n",
      "          [ 1.8545,  4.2344,  5.7188,  ..., 25.4062, 19.0781,  9.2969],\n",
      "          ...,\n",
      "          [ 9.0938, 13.6328, 14.5156,  ..., 17.8906, 16.9375, 11.1562],\n",
      "          [ 8.8203, 13.4531, 14.7188,  ..., 17.7656, 16.5156, 10.7266],\n",
      "          [ 6.8516, 10.2188, 11.2031,  ..., 13.2422, 12.2500,  8.1250]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 5.4102, 12.0703, 15.9766,  ...,  6.2148,  6.5078,  4.7227],\n",
      "          [ 8.5391, 18.0000, 23.5312,  ..., 10.1172, 10.7578,  7.5508],\n",
      "          [11.1719, 21.7656, 27.0469,  ..., 11.0859, 11.9609,  8.4297],\n",
      "          ...,\n",
      "          [ 9.9531, 14.6172, 15.1016,  ..., 16.4219, 16.0312, 10.8906],\n",
      "          [ 9.7812, 14.6250, 15.4844,  ..., 16.9531, 16.1875, 10.8281],\n",
      "          [ 7.5625, 11.1484, 11.9062,  ..., 12.9766, 12.3125,  8.3203]],\n",
      "\n",
      "         [[ 5.5469, 12.7656, 16.9844,  ...,  5.8359,  6.0938,  4.4023],\n",
      "          [ 8.5469, 18.6719, 24.6250,  ...,  9.5312, 10.0938,  7.0234],\n",
      "          [11.3516, 22.7656, 28.5000,  ..., 10.4688, 11.2500,  7.8555],\n",
      "          ...,\n",
      "          [ 9.3281, 13.7422, 14.2266,  ..., 15.4844, 15.0781, 10.1719],\n",
      "          [ 9.1719, 13.7500, 14.5781,  ..., 15.9688, 15.2266, 10.1094],\n",
      "          [ 7.0547, 10.4375, 11.1562,  ..., 12.1797, 11.5312,  7.7305]],\n",
      "\n",
      "         [[ 4.4023, 10.3516, 13.8125,  ...,  6.8242,  7.1250,  5.0977],\n",
      "          [ 6.8945, 15.3125, 20.1406,  ..., 11.2969, 11.9688,  8.2969],\n",
      "          [ 9.1797, 18.6406, 23.3125,  ..., 12.4609, 13.3984,  9.3359],\n",
      "          ...,\n",
      "          [11.1016, 16.4219, 17.0156,  ..., 18.5469, 18.0312, 12.1406],\n",
      "          [10.8828, 16.4062, 17.4219,  ..., 19.1094, 18.2031, 12.0547],\n",
      "          [ 8.3906, 12.4688, 13.3594,  ..., 14.5938, 13.8047,  9.2266]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6270,  4.1875,  6.5938,  ...,  6.6484,  3.5449,  1.4473],\n",
      "          [ 2.3203,  5.8438,  9.4375,  ...,  8.6719,  4.5508,  1.8223],\n",
      "          [ 3.5176,  8.7031, 12.4062,  ..., 10.5547,  6.3711,  2.3926],\n",
      "          ...,\n",
      "          [10.3281, 15.2500, 15.8828,  ..., 17.5625, 16.9688, 11.4688],\n",
      "          [10.1328, 15.2109, 16.1875,  ..., 17.7188, 16.8438, 11.2344],\n",
      "          [ 7.7852, 11.5391, 12.3672,  ..., 13.4062, 12.6953,  8.5625]],\n",
      "\n",
      "         [[ 1.4805,  3.9180,  6.4062,  ...,  6.6719,  3.3730,  1.3242],\n",
      "          [ 1.8926,  5.1328,  8.8594,  ...,  8.3047,  3.9629,  1.4453],\n",
      "          [ 2.9746,  8.2031, 12.1562,  ..., 10.3672,  5.8438,  1.9316],\n",
      "          ...,\n",
      "          [ 9.6797, 14.3359, 14.9531,  ..., 16.5469, 15.9531, 10.7109],\n",
      "          [ 9.5000, 14.2969, 15.2422,  ..., 16.6875, 15.8516, 10.4922],\n",
      "          [ 7.2656, 10.8047, 11.5938,  ..., 12.5859, 11.8906,  7.9609]],\n",
      "\n",
      "         [[ 1.0840,  3.0059,  5.0547,  ...,  5.2461,  2.5195,  0.9736],\n",
      "          [ 1.4102,  4.0898,  7.0898,  ...,  6.6055,  3.0254,  1.0771],\n",
      "          [ 2.2441,  6.6016,  9.7812,  ...,  8.2656,  4.5117,  1.4385],\n",
      "          ...,\n",
      "          [11.5234, 17.1562, 17.9062,  ..., 19.8438, 19.1094, 12.8047],\n",
      "          [11.2891, 17.0781, 18.2344,  ..., 20.0000, 18.9531, 12.5234],\n",
      "          [ 8.6484, 12.9141, 13.8906,  ..., 15.0859, 14.2422,  9.5078]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2334,  2.5020,  3.8613,  ...,  6.3906,  6.5508,  4.7266],\n",
      "          [ 1.6699,  3.3828,  5.2344,  ..., 10.4609, 10.8281,  7.5859],\n",
      "          [ 2.4707,  5.5391,  7.8711,  ..., 11.6641, 12.1250,  8.4922],\n",
      "          ...,\n",
      "          [10.2344, 15.1250, 15.7891,  ..., 17.4844, 16.8906, 11.4141],\n",
      "          [10.0547, 15.0938, 16.1094,  ..., 17.6719, 16.7812, 11.1953],\n",
      "          [ 7.7344, 11.4688, 12.3203,  ..., 13.3750, 12.6641,  8.5391]],\n",
      "\n",
      "         [[ 1.1455,  2.2129,  3.4707,  ...,  5.9883,  6.1328,  4.4102],\n",
      "          [ 1.3555,  2.6758,  4.3867,  ...,  9.8281, 10.1484,  7.0625],\n",
      "          [ 2.0195,  4.8359,  7.2695,  ..., 10.9922, 11.3984,  7.9141],\n",
      "          ...,\n",
      "          [ 9.5938, 14.2188, 14.8594,  ..., 16.4688, 15.8828, 10.6641],\n",
      "          [ 9.4297, 14.1953, 15.1641,  ..., 16.6406, 15.7891, 10.4531],\n",
      "          [ 7.2188, 10.7344, 11.5469,  ..., 12.5547, 11.8594,  7.9375]],\n",
      "\n",
      "         [[ 0.8359,  1.6221,  2.6094,  ...,  7.0195,  7.1680,  5.1016],\n",
      "          [ 1.0010,  2.0859,  3.4062,  ..., 11.6641, 12.0312,  8.3281],\n",
      "          [ 1.5117,  3.8340,  5.7578,  ..., 13.0938, 13.5625,  9.3906],\n",
      "          ...,\n",
      "          [11.4219, 17.0000, 17.7969,  ..., 19.7500, 19.0156, 12.7422],\n",
      "          [11.1953, 16.9375, 18.1406,  ..., 19.9375, 18.8750, 12.4766],\n",
      "          [ 8.5859, 12.8281, 13.8281,  ..., 15.0547, 14.2031,  9.4766]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 7.3047, 15.3438, 19.9062,  ..., 19.7969, 14.6172,  7.0234],\n",
      "          [10.9688, 22.1250, 28.4219,  ..., 27.7500, 20.6406, 10.3359],\n",
      "          [13.6797, 25.9531, 31.9375,  ..., 30.4219, 23.8125, 12.8828],\n",
      "          ...,\n",
      "          [10.7344, 16.1250, 17.0156,  ..., 17.6094, 16.8750, 11.2344],\n",
      "          [10.3672, 15.8047, 17.0156,  ..., 17.6250, 16.6406, 10.9453],\n",
      "          [ 7.8633, 11.8281, 12.7891,  ..., 13.2500, 12.4922,  8.3047]],\n",
      "\n",
      "         [[ 7.5391, 16.2500, 21.2031,  ..., 21.1562, 15.3984,  7.1602],\n",
      "          [11.0703, 23.0469, 29.8438,  ..., 29.2344, 21.3125, 10.3203],\n",
      "          [13.9531, 27.1875, 33.6875,  ..., 32.2812, 24.7344, 13.0547],\n",
      "          ...,\n",
      "          [10.0938, 15.2109, 16.0781,  ..., 16.6562, 15.9297, 10.5312],\n",
      "          [ 9.7500, 14.9062, 16.0625,  ..., 16.6562, 15.7109, 10.2500],\n",
      "          [ 7.3555, 11.1094, 12.0312,  ..., 12.4844, 11.7422,  7.7344]],\n",
      "\n",
      "         [[ 6.0625, 13.3203, 17.4219,  ..., 17.3750, 12.5469,  5.7500],\n",
      "          [ 9.0234, 19.0469, 24.6094,  ..., 24.1250, 17.4688,  8.3828],\n",
      "          [11.3906, 22.4531, 27.7656,  ..., 26.6250, 20.2656, 10.6406],\n",
      "          ...,\n",
      "          [11.9453, 18.0781, 19.1406,  ..., 19.8281, 18.9375, 12.4922],\n",
      "          [11.5156, 17.7031, 19.1094,  ..., 19.8125, 18.6562, 12.1406],\n",
      "          [ 8.6953, 13.1953, 14.3125,  ..., 14.8516, 13.9531,  9.1719]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0508, 13.3750, 17.9688,  ..., 19.9062, 14.7734,  7.1445],\n",
      "          [ 9.2734, 19.6875, 26.0312,  ..., 27.9219, 20.8438, 10.4844],\n",
      "          [12.0703, 23.6250, 29.4531,  ..., 30.6562, 24.0312, 13.0312],\n",
      "          ...,\n",
      "          [ 9.5156, 14.1328, 14.7031,  ..., 15.6719, 16.0781, 10.9609],\n",
      "          [ 9.4219, 14.2734, 15.2344,  ..., 15.9688, 15.9062, 10.6641],\n",
      "          [ 7.3242, 10.9297, 11.7578,  ..., 12.2188, 12.0000,  8.1016]],\n",
      "\n",
      "         [[ 6.3008, 14.3359, 19.3125,  ..., 21.2656, 15.5391,  7.2773],\n",
      "          [ 9.4766, 20.7656, 27.5781,  ..., 29.3906, 21.4844, 10.4531],\n",
      "          [12.4688, 25.0156, 31.3125,  ..., 32.5000, 24.9375, 13.1953],\n",
      "          ...,\n",
      "          [ 8.9297, 13.3281, 13.8984,  ..., 14.8438, 15.1797, 10.2656],\n",
      "          [ 8.8438, 13.4531, 14.3906,  ..., 15.1016, 15.0156,  9.9844],\n",
      "          [ 6.8477, 10.2500, 11.0547,  ..., 11.5078, 11.2734,  7.5391]],\n",
      "\n",
      "         [[ 5.0820, 11.7656, 15.8828,  ..., 17.4531, 12.6562,  5.8438],\n",
      "          [ 7.7422, 17.2031, 22.7812,  ..., 24.2500, 17.6094,  8.4922],\n",
      "          [10.1953, 20.7031, 25.8594,  ..., 26.8125, 20.4219, 10.7500],\n",
      "          ...,\n",
      "          [10.5469, 15.8125, 16.5000,  ..., 17.6250, 18.0312, 12.1797],\n",
      "          [10.4219, 15.9375, 17.0781,  ..., 17.9375, 17.8125, 11.8203],\n",
      "          [ 8.0781, 12.1562, 13.1328,  ..., 13.6797, 13.3906,  8.9375]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0879,  8.1016, 11.8750,  ..., 17.2188, 11.6875,  4.9805],\n",
      "          [ 4.4883, 10.9922, 16.1406,  ..., 24.6875, 16.7812,  7.2500],\n",
      "          [ 6.7305, 14.3047, 18.9062,  ..., 27.7812, 19.9531,  9.5703],\n",
      "          ...,\n",
      "          [10.3516, 15.5078, 16.3438,  ..., 17.6875, 16.9375, 11.2656],\n",
      "          [10.0234, 15.2578, 16.4062,  ..., 17.7344, 16.7500, 11.0078],\n",
      "          [ 7.6445, 11.4844, 12.3984,  ..., 13.3359, 12.5781,  8.3594]],\n",
      "\n",
      "         [[ 2.8457,  8.0781, 12.1484,  ..., 18.5156, 12.4453,  5.0664],\n",
      "          [ 3.8848, 10.5859, 16.0781,  ..., 26.1875, 17.5156,  7.2383],\n",
      "          [ 6.2109, 14.2266, 19.1406,  ..., 29.6094, 20.9375,  9.7422],\n",
      "          ...,\n",
      "          [ 9.7266, 14.6328, 15.4531,  ..., 16.7188, 15.9844, 10.5625],\n",
      "          [ 9.4219, 14.3906, 15.5000,  ..., 16.7656, 15.8047, 10.3125],\n",
      "          [ 7.1484, 10.7734, 11.6641,  ..., 12.5625, 11.8203,  7.7812]],\n",
      "\n",
      "         [[ 2.1250,  6.5039,  9.8516,  ..., 15.2266, 10.1484,  4.0625],\n",
      "          [ 3.0215,  8.6484, 13.1016,  ..., 21.6562, 14.4062,  5.8672],\n",
      "          [ 4.9414, 11.6484, 15.6094,  ..., 24.4688, 17.1875,  7.9219],\n",
      "          ...,\n",
      "          [11.5078, 17.3906, 18.3750,  ..., 19.9219, 19.0000, 12.5312],\n",
      "          [11.1172, 17.0625, 18.4219,  ..., 19.9531, 18.7656, 12.2188],\n",
      "          [ 8.4453, 12.7969, 13.8672,  ..., 14.9531, 14.0469,  9.2266]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.2031,  2.7344,  2.7871,  ...,  6.2656,  3.4238,  1.7627],\n",
      "          [ 3.6543,  4.8086,  4.6602,  ...,  7.9688,  4.0625,  1.8643],\n",
      "          [ 3.9648,  5.1211,  4.9688,  ..., 10.9531,  6.4922,  2.8047],\n",
      "          ...,\n",
      "          [ 9.7969, 15.0234, 16.2188,  ..., 17.4531, 16.6562, 10.9453],\n",
      "          [ 9.3750, 14.6172, 16.1406,  ..., 17.3906, 16.2500, 10.5156],\n",
      "          [ 7.1328, 10.9453, 12.1328,  ..., 13.0234, 12.1172,  7.8984]],\n",
      "\n",
      "         [[ 2.0820,  2.5879,  2.6367,  ...,  6.1016,  3.1465,  1.6045],\n",
      "          [ 3.4395,  4.5156,  4.3984,  ...,  7.4531,  3.4199,  1.4971],\n",
      "          [ 3.7344,  4.8359,  4.6875,  ..., 10.8125,  5.9766,  2.3926],\n",
      "          ...,\n",
      "          [ 9.2109, 14.1875, 15.3594,  ..., 16.5469, 15.7656, 10.2734],\n",
      "          [ 8.8203, 13.8047, 15.2812,  ..., 16.4688, 15.3828,  9.8750],\n",
      "          [ 6.6797, 10.2891, 11.4219,  ..., 12.2891, 11.4141,  7.3750]],\n",
      "\n",
      "         [[ 2.1934,  2.7207,  2.8184,  ...,  4.8828,  2.3945,  1.2080],\n",
      "          [ 3.7969,  5.0195,  4.9297,  ...,  6.0469,  2.6621,  1.1328],\n",
      "          [ 4.1797,  5.4570,  5.3203,  ...,  8.8594,  4.7461,  1.8252],\n",
      "          ...,\n",
      "          [10.8203, 16.7656, 18.1719,  ..., 19.5938, 18.6406, 12.1172],\n",
      "          [10.3359, 16.2656, 18.0469,  ..., 19.4844, 18.1562, 11.6250],\n",
      "          [ 7.8320, 12.1406, 13.5156,  ..., 14.5391, 13.4844,  8.6875]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1328, 15.8594, 19.7500,  ..., 20.3438, 16.3125,  9.0078],\n",
      "          [11.0469, 21.2656, 26.5938,  ..., 27.5625, 22.1250, 12.5156],\n",
      "          [12.7188, 23.4844, 28.5156,  ..., 29.9531, 24.9219, 14.9062],\n",
      "          ...,\n",
      "          [ 7.8281, 12.0078, 13.1328,  ..., 15.4531, 14.8438,  9.7969],\n",
      "          [ 7.6992, 11.9453, 13.3281,  ..., 15.6641, 14.6641,  9.5078],\n",
      "          [ 6.1445,  9.2266, 10.2656,  ..., 11.9141, 11.0859,  7.2656]],\n",
      "\n",
      "         [[ 8.2109, 16.4844, 20.6875,  ..., 21.4375, 16.9375,  9.1328],\n",
      "          [10.8516, 21.6562, 27.3906,  ..., 28.6562, 22.5312, 12.4453],\n",
      "          [12.6250, 24.0781, 29.5156,  ..., 31.4375, 25.6094, 15.0781],\n",
      "          ...,\n",
      "          [ 7.3438, 11.3281, 12.4219,  ..., 14.6484, 14.0391,  9.1875],\n",
      "          [ 7.2344, 11.2656, 12.5938,  ..., 14.8359, 13.8672,  8.9141],\n",
      "          [ 5.7500,  8.6484,  9.6484,  ..., 11.2344, 10.4297,  6.7734]],\n",
      "\n",
      "         [[ 6.6289, 13.5312, 17.0156,  ..., 17.6719, 13.8828,  7.4062],\n",
      "          [ 8.8438, 17.8906, 22.5625,  ..., 23.7031, 18.5156, 10.1875],\n",
      "          [10.3047, 19.8750, 24.3125,  ..., 26.0625, 21.0781, 12.3828],\n",
      "          ...,\n",
      "          [ 8.5859, 13.3203, 14.6406,  ..., 17.3125, 16.5625, 10.8203],\n",
      "          [ 8.4297, 13.2188, 14.8359,  ..., 17.5156, 16.3438, 10.4766],\n",
      "          [ 6.7031, 10.1797, 11.3906,  ..., 13.2812, 12.3125,  7.9609]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7402,  7.9258,  9.5625,  ...,  2.3086,  2.2656,  1.9629],\n",
      "          [ 4.8633, 10.1094, 12.3828,  ...,  2.4375,  3.8613,  3.2578],\n",
      "          [ 6.7148, 12.9141, 14.8828,  ...,  2.1152,  3.8203,  3.5215],\n",
      "          ...,\n",
      "          [ 9.3984, 14.4141, 15.5781,  ..., 16.5781, 15.8672, 10.4453],\n",
      "          [ 9.0234, 14.0547, 15.5547,  ..., 16.6250, 15.5625, 10.0781],\n",
      "          [ 6.9141, 10.5781, 11.7344,  ..., 12.5469, 11.6797,  7.6211]],\n",
      "\n",
      "         [[ 3.4805,  7.8203,  9.5234,  ...,  2.2266,  2.1621,  1.8350],\n",
      "          [ 4.2734,  9.6172, 11.9844,  ...,  2.1309,  3.5781,  3.0371],\n",
      "          [ 6.2500, 12.7969, 14.8750,  ...,  1.8994,  3.6133,  3.2891],\n",
      "          ...,\n",
      "          [ 8.8359, 13.6094, 14.7500,  ..., 15.7266, 15.0156,  9.8047],\n",
      "          [ 8.4844, 13.2734, 14.7109,  ..., 15.7500, 14.7188,  9.4531],\n",
      "          [ 6.4766,  9.9375, 11.0469,  ..., 11.8359, 10.9922,  7.1094]],\n",
      "\n",
      "         [[ 2.6758,  6.3086,  7.6992,  ...,  1.7666,  2.1562,  1.8867],\n",
      "          [ 3.3574,  7.8555,  9.7266,  ...,  1.8018,  3.8594,  3.3125],\n",
      "          [ 4.9922, 10.5000, 12.1172,  ...,  1.5264,  3.9863,  3.6602],\n",
      "          ...,\n",
      "          [10.3750, 16.0625, 17.4375,  ..., 18.5938, 17.7344, 11.5547],\n",
      "          [ 9.9375, 15.6328, 17.3750,  ..., 18.6250, 17.3750, 11.1250],\n",
      "          [ 7.5820, 11.7188, 13.0625,  ..., 14.0000, 12.9844,  8.3672]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[11.1484, 20.4375, 24.0469,  ..., 24.8438, 20.2344, 11.5469],\n",
      "          [15.1094, 27.4375, 32.1875,  ..., 32.8750, 26.6719, 15.4766],\n",
      "          [16.9844, 29.7969, 33.9062,  ..., 34.0000, 28.4375, 17.2031],\n",
      "          ...,\n",
      "          [ 7.9219, 11.9141, 12.7031,  ..., 18.4062, 17.3906, 11.3750],\n",
      "          [ 7.5664, 11.5703, 12.8047,  ..., 18.2500, 16.8750, 10.8672],\n",
      "          [ 6.0898,  9.0625, 10.0781,  ..., 13.7266, 12.6406,  8.2188]],\n",
      "\n",
      "         [[11.4688, 21.4219, 25.3281,  ..., 26.2656, 21.1406, 11.8516],\n",
      "          [15.2266, 28.2969, 33.4062,  ..., 34.2812, 27.3594, 15.5703],\n",
      "          [17.2500, 30.8750, 35.3438,  ..., 35.6875, 29.3281, 17.4688],\n",
      "          ...,\n",
      "          [ 7.4609, 11.2812, 12.0547,  ..., 17.4844, 16.4844, 10.7031],\n",
      "          [ 7.1367, 10.9609, 12.1484,  ..., 17.3281, 16.0000, 10.2266],\n",
      "          [ 5.7148,  8.5312,  9.5078,  ..., 12.9844, 11.9375,  7.6875]],\n",
      "\n",
      "         [[ 9.4141, 17.7656, 21.0469,  ..., 21.8281, 17.4844,  9.7188],\n",
      "          [12.5703, 23.5625, 27.8125,  ..., 28.5781, 22.6719, 12.8359],\n",
      "          [14.2656, 25.7188, 29.4375,  ..., 29.7656, 24.2969, 14.4297],\n",
      "          ...,\n",
      "          [ 8.6641, 13.1797, 14.1328,  ..., 20.6094, 19.4062, 12.5703],\n",
      "          [ 8.2578, 12.7734, 14.2188,  ..., 20.4062, 18.7969, 11.9844],\n",
      "          [ 6.6250,  9.9688, 11.1562,  ..., 15.2969, 14.0391,  9.0234]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9746,  2.8223,  2.5410,  ...,  6.6328,  3.0977,  1.8359],\n",
      "          [ 2.6152,  3.7148,  3.4668,  ...,  8.8984,  3.5215,  2.2891],\n",
      "          [ 2.5742,  3.6641,  3.3047,  ..., 11.7812,  4.2695,  2.1641],\n",
      "          ...,\n",
      "          [ 7.6172, 11.7344, 13.2266,  ..., 16.9531, 16.0625, 10.5625],\n",
      "          [ 7.4766, 11.6250, 13.3281,  ..., 16.9688, 15.6953, 10.1406],\n",
      "          [ 6.1133,  9.1484, 10.3828,  ..., 12.9141, 11.8750,  7.7656]],\n",
      "\n",
      "         [[ 1.8799,  2.7070,  2.4219,  ...,  6.8047,  2.9688,  1.6963],\n",
      "          [ 2.4219,  3.3633,  3.1875,  ...,  8.9141,  3.1367,  2.0527],\n",
      "          [ 2.4238,  3.4004,  3.1230,  ..., 12.2109,  4.0391,  1.9727],\n",
      "          ...,\n",
      "          [ 7.1680, 11.0938, 12.5234,  ..., 16.0938, 15.2266,  9.9297],\n",
      "          [ 7.0430, 10.9922, 12.6172,  ..., 16.1094, 14.8828,  9.5312],\n",
      "          [ 5.7383,  8.6016,  9.7734,  ..., 12.2031, 11.2031,  7.2539]],\n",
      "\n",
      "         [[ 1.7412,  2.3789,  2.2324,  ...,  5.5664,  2.3867,  1.4893],\n",
      "          [ 2.4688,  3.4062,  3.3555,  ...,  7.3867,  2.7070,  2.0078],\n",
      "          [ 2.4492,  3.4102,  3.3594,  ..., 10.1641,  3.3711,  1.9209],\n",
      "          ...,\n",
      "          [ 8.3125, 12.9531, 14.6875,  ..., 18.9531, 17.8906, 11.6406],\n",
      "          [ 8.1406, 12.8125, 14.7812,  ..., 18.9531, 17.4531, 11.1484],\n",
      "          [ 6.6445, 10.0547, 11.4766,  ..., 14.3672, 13.1719,  8.5000]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4141, 10.3984, 11.7188,  ..., 12.3984, 10.4922,  6.0508],\n",
      "          [ 6.6758, 12.6953, 14.3125,  ..., 15.1406, 12.6484,  7.4766],\n",
      "          [ 8.0938, 14.5156, 15.5781,  ..., 16.3125, 14.3906,  9.1641],\n",
      "          ...,\n",
      "          [ 9.2969, 14.3594, 15.8672,  ..., 18.1094, 17.1250, 11.2188],\n",
      "          [ 8.8750, 13.8828, 15.6953,  ..., 18.0000, 16.6406, 10.7344],\n",
      "          [ 6.9414, 10.5781, 11.9297,  ..., 13.5703, 12.5000,  8.1328]],\n",
      "\n",
      "         [[ 5.1992, 10.4297, 11.8281,  ..., 12.6250, 10.4766,  5.8320],\n",
      "          [ 6.1016, 12.3281, 14.0312,  ..., 15.0156, 12.1562,  6.9141],\n",
      "          [ 7.6875, 14.4688, 15.6328,  ..., 16.5781, 14.1797,  8.8203],\n",
      "          ...,\n",
      "          [ 8.7578, 13.5859, 15.0391,  ..., 17.2031, 16.2344, 10.5547],\n",
      "          [ 8.3594, 13.1406, 14.8672,  ..., 17.0781, 15.7891, 10.0938],\n",
      "          [ 6.5117,  9.9531, 11.2500,  ..., 12.8359, 11.7969,  7.6094]],\n",
      "\n",
      "         [[ 4.1289,  8.5000,  9.6484,  ..., 10.3281,  8.4922,  4.6484],\n",
      "          [ 4.8789, 10.1094, 11.4375,  ..., 12.3281,  9.8750,  5.5508],\n",
      "          [ 6.1992, 11.8984, 12.7734,  ..., 13.6719, 11.5547,  7.1602],\n",
      "          ...,\n",
      "          [10.2188, 15.9453, 17.6875,  ..., 20.2656, 19.0938, 12.3906],\n",
      "          [ 9.7266, 15.3906, 17.4688,  ..., 20.1094, 18.5469, 11.8281],\n",
      "          [ 7.5859, 11.6797, 13.2344,  ..., 15.1172, 13.8828,  8.9297]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 5.8047, 10.7734, 12.0078,  ...,  3.5352,  2.5020,  1.9248],\n",
      "          [ 6.8672, 12.6562, 14.1484,  ...,  3.0312,  2.9629,  2.4746],\n",
      "          [ 8.0859, 14.2031, 15.2031,  ...,  2.9805,  2.3965,  2.3164],\n",
      "          ...,\n",
      "          [ 8.8984, 13.7109, 15.5156,  ..., 18.2344, 17.3125, 11.5312],\n",
      "          [ 8.6797, 13.4688, 15.4844,  ..., 18.1562, 16.8281, 11.0078],\n",
      "          [ 7.1016, 10.6016, 12.0469,  ..., 13.9688, 12.8750,  8.5547]],\n",
      "\n",
      "         [[ 5.6328, 10.7969, 12.1094,  ...,  3.3203,  2.3418,  1.7822],\n",
      "          [ 6.3086, 12.1953, 13.8047,  ...,  2.5391,  2.6426,  2.2266],\n",
      "          [ 7.6641, 14.0078, 15.1406,  ...,  2.5586,  2.1680,  2.1309],\n",
      "          ...,\n",
      "          [ 8.3906, 12.9844, 14.7109,  ..., 17.3281, 16.4219, 10.8594],\n",
      "          [ 8.1953, 12.7656, 14.6797,  ..., 17.2500, 15.9688, 10.3750],\n",
      "          [ 6.6875, 10.0000, 11.3750,  ..., 13.2188, 12.1797,  8.0234]],\n",
      "\n",
      "         [[ 4.4961,  8.8203,  9.9141,  ...,  2.5977,  1.9023,  1.5781],\n",
      "          [ 5.0703, 10.0078, 11.2891,  ...,  2.0059,  2.4512,  2.2031],\n",
      "          [ 6.1914, 11.5156, 12.3906,  ...,  2.0039,  1.9932,  2.1406],\n",
      "          ...,\n",
      "          [ 9.7266, 15.1406, 17.2344,  ..., 20.3281, 19.2344, 12.6953],\n",
      "          [ 9.4766, 14.8594, 17.1719,  ..., 20.2344, 18.6719, 12.1016],\n",
      "          [ 7.7383, 11.6641, 13.3281,  ..., 15.5078, 14.2578,  9.3594]]],\n",
      "\n",
      "\n",
      "        [[[12.5078, 22.7344, 26.5469,  ..., 19.0781, 16.7812,  9.8438],\n",
      "          [16.7656, 30.2188, 35.0938,  ..., 23.9219, 21.0312, 12.5469],\n",
      "          [18.4688, 32.1250, 36.0000,  ..., 23.8281, 21.7812, 13.6484],\n",
      "          ...,\n",
      "          [10.1484, 15.6016, 17.4219,  ..., 19.9688, 18.8125, 12.4453],\n",
      "          [ 9.7266, 15.1172, 17.2188,  ..., 19.7812, 18.2656, 11.9062],\n",
      "          [ 7.7266, 11.6641, 13.2031,  ..., 15.0312, 13.8438,  9.1328]],\n",
      "\n",
      "         [[12.9609, 23.8906, 28.0312,  ..., 19.9219, 17.3594, 10.0078],\n",
      "          [17.0469, 31.2500, 36.5000,  ..., 24.5469, 21.2656, 12.4297],\n",
      "          [18.8750, 33.3438, 37.5938,  ..., 24.6875, 22.2031, 13.6797],\n",
      "          ...,\n",
      "          [ 9.5781, 14.7812, 16.5156,  ..., 18.9688, 17.8438, 11.7266],\n",
      "          [ 9.1875, 14.3281, 16.3281,  ..., 18.7812, 17.3281, 11.2266],\n",
      "          [ 7.2734, 11.0078, 12.4766,  ..., 14.2422, 13.0938,  8.5703]],\n",
      "\n",
      "         [[10.7266, 19.9688, 23.4844,  ..., 16.5469, 14.3828,  8.1953],\n",
      "          [14.1953, 26.2344, 30.6406,  ..., 20.4375, 17.6562, 10.2344],\n",
      "          [15.7188, 27.9688, 31.5625,  ..., 20.5781, 18.4219, 11.2891],\n",
      "          ...,\n",
      "          [11.1406, 17.2969, 19.3750,  ..., 22.2969, 20.9531, 13.7266],\n",
      "          [10.6562, 16.7344, 19.1250,  ..., 22.0625, 20.3125, 13.1094],\n",
      "          [ 8.4453, 12.8672, 14.6328,  ..., 16.7188, 15.3516, 10.0156]]],\n",
      "\n",
      "\n",
      "        [[[11.8672, 21.5000, 24.9531,  ..., 21.1562, 17.2969,  9.7188],\n",
      "          [16.1875, 29.1406, 33.8438,  ..., 26.2812, 21.3906, 12.1953],\n",
      "          [18.3906, 32.2188, 36.5625,  ..., 25.7500, 22.0156, 13.3281],\n",
      "          ...,\n",
      "          [10.3359, 15.8672, 17.6562,  ..., 19.3438, 18.2344, 12.0703],\n",
      "          [ 9.8828, 15.3438, 17.4219,  ..., 19.2344, 17.7656, 11.5859],\n",
      "          [ 7.8164, 11.8047, 13.3438,  ..., 14.6797, 13.5156,  8.9297]],\n",
      "\n",
      "         [[12.2578, 22.5312, 26.2656,  ..., 22.1719, 17.8906,  9.8438],\n",
      "          [16.3906, 30.0625, 35.1250,  ..., 27.0469, 21.6250, 12.0156],\n",
      "          [18.7656, 33.4375, 38.1875,  ..., 26.7031, 22.4062, 13.2969],\n",
      "          ...,\n",
      "          [ 9.7578, 15.0312, 16.7500,  ..., 18.3750, 17.2969, 11.3750],\n",
      "          [ 9.3359, 14.5469, 16.5312,  ..., 18.2656, 16.8438, 10.9219],\n",
      "          [ 7.3594, 11.1406, 12.6094,  ..., 13.8984, 12.7812,  8.3672]],\n",
      "\n",
      "         [[10.1250, 18.8125, 21.9688,  ..., 18.4375, 14.8281,  8.0547],\n",
      "          [13.6328, 25.2031, 29.4688,  ..., 22.5469, 17.9531,  9.8750],\n",
      "          [15.6328, 28.0469, 32.0312,  ..., 22.2656, 18.5938, 10.9609],\n",
      "          ...,\n",
      "          [11.3516, 17.5938, 19.6562,  ..., 21.5781, 20.2812, 13.3125],\n",
      "          [10.8281, 16.9844, 19.3750,  ..., 21.4375, 19.7344, 12.7500],\n",
      "          [ 8.5469, 13.0234, 14.7891,  ..., 16.3125, 14.9844,  9.7812]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[10.6641, 18.8438, 22.1250,  ..., 32.5000, 27.8594, 16.5625],\n",
      "          [13.2500, 23.1094, 27.1250,  ..., 42.1875, 36.0625, 21.6719],\n",
      "          [14.3672, 23.8594, 26.5156,  ..., 41.8438, 36.6562, 22.6875],\n",
      "          ...,\n",
      "          [ 5.5508,  8.2812, 10.5859,  ..., 19.2656, 17.7656, 11.7188],\n",
      "          [ 5.8711,  8.7734, 10.9297,  ..., 19.2344, 17.3438, 11.2578],\n",
      "          [ 5.5234,  7.9062,  9.2969,  ..., 14.8359, 13.3828,  8.8516]],\n",
      "\n",
      "         [[10.8828, 19.4844, 23.0625,  ..., 34.4688, 29.3281, 17.2344],\n",
      "          [13.1406, 23.3438, 27.7344,  ..., 44.1875, 37.4375, 22.1875],\n",
      "          [14.3906, 24.2500, 27.2344,  ..., 44.0000, 38.1562, 23.3125],\n",
      "          ...,\n",
      "          [ 5.2695,  7.8594, 10.0234,  ..., 18.3125, 16.8750, 11.0625],\n",
      "          [ 5.5820,  8.3359, 10.3594,  ..., 18.2656, 16.4844, 10.6328],\n",
      "          [ 5.2188,  7.4766,  8.7891,  ..., 14.0625, 12.6719,  8.3281]],\n",
      "\n",
      "         [[ 8.9766, 16.2188, 19.2812,  ..., 29.0000, 24.6562, 14.3672],\n",
      "          [10.8984, 19.5000, 23.1875,  ..., 37.2812, 31.5156, 18.5625],\n",
      "          [11.9375, 20.2500, 22.7500,  ..., 37.1562, 32.0938, 19.5312],\n",
      "          ...,\n",
      "          [ 5.9219,  8.9609, 11.5859,  ..., 21.4375, 19.7031, 12.8750],\n",
      "          [ 6.2812,  9.5078, 11.9609,  ..., 21.3750, 19.2188, 12.3438],\n",
      "          [ 5.9336,  8.5781, 10.1719,  ..., 16.4531, 14.7891,  9.6719]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6289, 13.0000, 13.8906,  ..., 14.3359, 13.3047,  8.2188],\n",
      "          [ 8.6484, 14.6875, 15.7344,  ..., 16.2500, 15.1016,  9.4688],\n",
      "          [ 9.2188, 15.2266, 15.8672,  ..., 16.0625, 15.6484, 10.3516],\n",
      "          ...,\n",
      "          [ 3.9180,  5.4102,  6.7422,  ..., 19.1094, 17.7031, 11.6875],\n",
      "          [ 4.6836,  6.6641,  8.1250,  ..., 18.7969, 17.0156, 11.0625],\n",
      "          [ 4.8398,  6.6875,  7.7227,  ..., 14.4453, 13.0625,  8.6875]],\n",
      "\n",
      "         [[ 7.6094, 13.1797, 14.1641,  ..., 14.6719, 13.5156,  8.1953],\n",
      "          [ 8.2422, 14.3516, 15.5469,  ..., 16.1562, 14.8359,  9.0625],\n",
      "          [ 8.9141, 15.0938, 15.9141,  ..., 16.2344, 15.6016, 10.1172],\n",
      "          ...,\n",
      "          [ 3.7285,  5.1406,  6.4023,  ..., 18.1562, 16.8125, 11.0312],\n",
      "          [ 4.4609,  6.3398,  7.7266,  ..., 17.8438, 16.1719, 10.4453],\n",
      "          [ 4.5781,  6.3242,  7.3008,  ..., 13.6797, 12.3750,  8.1719]],\n",
      "\n",
      "         [[ 6.1992, 10.8672, 11.6953,  ..., 12.1094, 11.1484,  6.6758],\n",
      "          [ 6.7227, 11.8438, 12.8047,  ..., 13.3359, 12.2344,  7.3984],\n",
      "          [ 7.2734, 12.4375, 13.0859,  ..., 13.4062, 12.8672,  8.2891],\n",
      "          ...,\n",
      "          [ 4.0664,  5.6953,  7.2578,  ..., 21.2500, 19.6250, 12.8359],\n",
      "          [ 4.9297,  7.1094,  8.8047,  ..., 20.8750, 18.8438, 12.1250],\n",
      "          [ 5.1641,  7.2109,  8.3906,  ..., 16.0000, 14.4297,  9.4844]]],\n",
      "\n",
      "\n",
      "        [[[10.6953, 18.9531, 22.3281,  ..., 32.5312, 27.8594, 16.5625],\n",
      "          [13.2266, 23.1875, 27.3438,  ..., 42.2188, 36.0625, 21.6719],\n",
      "          [14.3047, 23.8438, 26.6406,  ..., 41.8750, 36.6562, 22.6875],\n",
      "          ...,\n",
      "          [ 5.5625,  8.2969, 10.5938,  ..., 19.1562, 17.6719, 11.6562],\n",
      "          [ 5.8828,  8.7891, 10.9453,  ..., 19.1406, 17.2656, 11.2031],\n",
      "          [ 5.5312,  7.9219,  9.3125,  ..., 14.7891, 13.3281,  8.8203]],\n",
      "\n",
      "         [[10.9141, 19.6094, 23.2812,  ..., 34.4688, 29.3281, 17.2344],\n",
      "          [13.1250, 23.4219, 27.9688,  ..., 44.2188, 37.4375, 22.1875],\n",
      "          [14.3125, 24.2344, 27.3750,  ..., 44.0312, 38.1562, 23.3125],\n",
      "          ...,\n",
      "          [ 5.2812,  7.8750, 10.0234,  ..., 18.2031, 16.7812, 11.0078],\n",
      "          [ 5.5938,  8.3594, 10.3750,  ..., 18.1875, 16.4062, 10.5859],\n",
      "          [ 5.2305,  7.4883,  8.7969,  ..., 14.0156, 12.6328,  8.2969]],\n",
      "\n",
      "         [[ 9.0000, 16.3281, 19.4688,  ..., 29.0312, 24.6562, 14.3672],\n",
      "          [10.8750, 19.5625, 23.4062,  ..., 37.3125, 31.5156, 18.5781],\n",
      "          [11.8750, 20.2344, 22.8594,  ..., 37.1875, 32.0938, 19.5312],\n",
      "          ...,\n",
      "          [ 5.9375,  8.9766, 11.5859,  ..., 21.3125, 19.5938, 12.8047],\n",
      "          [ 6.2969,  9.5312, 11.9766,  ..., 21.2656, 19.1250, 12.2891],\n",
      "          [ 5.9453,  8.6016, 10.1875,  ..., 16.4062, 14.7344,  9.6406]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 3.8750,  4.7734,  5.1406,  ..., 10.9688,  9.6562,  5.5273],\n",
      "          [ 6.0078,  8.1094,  8.7734,  ..., 12.0391, 10.4453,  5.7852],\n",
      "          [ 6.8516,  9.4609, 10.6016,  ..., 12.8125, 11.7812,  6.9766],\n",
      "          ...,\n",
      "          [10.6406, 15.8906, 17.7500,  ..., 22.9219, 21.8281, 14.8594],\n",
      "          [10.5234, 15.8672, 17.9688,  ..., 23.0781, 21.5469, 14.4453],\n",
      "          [ 8.8438, 12.8672, 14.4062,  ..., 18.0000, 16.7500, 11.3750]],\n",
      "\n",
      "         [[ 3.7090,  4.5742,  4.9141,  ..., 11.1328,  9.7422,  5.4102],\n",
      "          [ 5.7227,  7.7109,  8.3438,  ..., 11.7266, 10.0625,  5.3203],\n",
      "          [ 6.5117,  8.9844, 10.0469,  ..., 12.7344, 11.5859,  6.6172],\n",
      "          ...,\n",
      "          [10.0781, 15.0859, 16.8594,  ..., 21.8281, 20.7656, 14.0469],\n",
      "          [ 9.9766, 15.0781, 17.0938,  ..., 21.9688, 20.5156, 13.6719],\n",
      "          [ 8.3672, 12.1797, 13.6484,  ..., 17.0938, 15.8984, 10.7266]],\n",
      "\n",
      "         [[ 4.0312,  4.9688,  5.4297,  ...,  9.1875,  8.0312,  4.3828],\n",
      "          [ 6.4062,  8.7031,  9.4922,  ...,  9.7031,  8.3047,  4.2812],\n",
      "          [ 7.3672, 10.2578, 11.5625,  ..., 10.5234,  9.5703,  5.3750],\n",
      "          ...,\n",
      "          [11.6328, 17.5000, 19.6250,  ..., 25.4844, 24.2188, 16.3594],\n",
      "          [11.4922, 17.4688, 19.8750,  ..., 25.6406, 23.8906, 15.8984],\n",
      "          [ 9.6562, 14.1484, 15.9062,  ..., 19.9688, 18.5469, 12.4922]]],\n",
      "\n",
      "\n",
      "        [[[15.8359, 28.2344, 33.2812,  ..., 11.7734, 10.7109,  6.2109],\n",
      "          [21.3281, 37.6875, 44.3125,  ..., 13.1016, 11.8984,  6.8594],\n",
      "          [23.4688, 40.2812, 45.9375,  ..., 13.7969, 13.1953,  8.1250],\n",
      "          ...,\n",
      "          [13.0156, 19.5156, 21.4062,  ..., 25.3125, 23.8906, 16.0781],\n",
      "          [12.6797, 19.2344, 21.5156,  ..., 25.1406, 23.3750, 15.5547],\n",
      "          [10.1719, 15.0781, 16.7969,  ..., 19.3125, 17.9375, 12.1016]],\n",
      "\n",
      "         [[16.6250, 29.8438, 35.2812,  ..., 11.9688, 10.8438,  6.1328],\n",
      "          [22.0469, 39.2812, 46.4688,  ..., 12.8438, 11.5625,  6.4062],\n",
      "          [24.3125, 42.0938, 48.2812,  ..., 13.7734, 13.0469,  7.8008],\n",
      "          ...,\n",
      "          [12.3281, 18.5312, 20.3438,  ..., 24.1094, 22.7344, 15.2188],\n",
      "          [12.0234, 18.2812, 20.4531,  ..., 23.9375, 22.2500, 14.7188],\n",
      "          [ 9.6094, 14.2891, 15.9219,  ..., 18.3594, 17.0312, 11.4141]],\n",
      "\n",
      "         [[13.9766, 25.2344, 29.8906,  ...,  9.8828,  8.9531,  4.9688],\n",
      "          [18.6406, 33.3438, 39.4688,  ..., 10.6250,  9.5625,  5.1953],\n",
      "          [20.5469, 35.7188, 41.0312,  ..., 11.3906, 10.7891,  6.3672],\n",
      "          ...,\n",
      "          [14.3047, 21.5938, 23.7500,  ..., 28.1875, 26.5469, 17.7344],\n",
      "          [13.9219, 21.2656, 23.8594,  ..., 27.9844, 25.9531, 17.1406],\n",
      "          [11.1484, 16.6406, 18.5938,  ..., 21.4531, 19.8906, 13.3047]]],\n",
      "\n",
      "\n",
      "        [[[15.2812, 27.3281, 32.2500,  ..., 20.9844, 17.6875,  9.9609],\n",
      "          [20.4531, 36.2812, 42.7188,  ..., 23.4375, 19.8125, 11.2969],\n",
      "          [22.5000, 38.7500, 44.2812,  ..., 19.6562, 17.9062, 10.9062],\n",
      "          ...,\n",
      "          [12.4141, 17.9062, 18.4844,  ..., 25.3281, 23.9062, 16.0938],\n",
      "          [12.1562, 17.8750, 19.1094,  ..., 25.1719, 23.4062, 15.5781],\n",
      "          [ 9.8359, 14.2266, 15.3359,  ..., 19.3438, 17.9688, 12.1250]],\n",
      "\n",
      "         [[16.0156, 28.8438, 34.1562,  ..., 21.9219, 18.3594, 10.1562],\n",
      "          [21.1094, 37.7500, 44.7188,  ..., 23.8594, 19.9844, 11.1016],\n",
      "          [23.2656, 40.4062, 46.4375,  ..., 19.9688, 18.0156, 10.7188],\n",
      "          ...,\n",
      "          [11.7578, 17.0156, 17.5938,  ..., 24.1094, 22.7344, 15.2266],\n",
      "          [11.5234, 17.0000, 18.1875,  ..., 23.9688, 22.2656, 14.7422],\n",
      "          [ 9.2969, 13.4844, 14.5391,  ..., 18.3906, 17.0625, 11.4375]],\n",
      "\n",
      "         [[13.4531, 24.3906, 28.9219,  ..., 18.3594, 15.3672,  8.3984],\n",
      "          [17.8281, 32.0312, 37.9688,  ..., 20.0000, 16.7188,  9.1953],\n",
      "          [19.6406, 34.2500, 39.4375,  ..., 16.6406, 15.0234,  8.8516],\n",
      "          ...,\n",
      "          [13.6328, 19.7969, 20.4844,  ..., 28.2031, 26.5625, 17.7500],\n",
      "          [13.3359, 19.7344, 21.1562,  ..., 28.0156, 25.9844, 17.1562],\n",
      "          [10.7812, 15.6875, 16.9531,  ..., 21.4844, 19.9219, 13.3281]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[13.8672, 24.9219, 29.0312,  ..., 11.7812, 10.7734,  6.2344],\n",
      "          [17.7969, 31.7344, 36.9688,  ..., 12.9219, 11.7656,  6.6211],\n",
      "          [19.1250, 32.8750, 36.9688,  ..., 13.8281, 13.3438,  8.0703],\n",
      "          ...,\n",
      "          [14.1719, 21.2969, 23.3594,  ..., 25.5781, 24.0312, 16.1719],\n",
      "          [13.6328, 20.7656, 23.2344,  ..., 25.4531, 23.5156, 15.6250],\n",
      "          [10.9375, 16.2188, 18.0938,  ..., 19.7031, 18.1875, 12.2656]],\n",
      "\n",
      "         [[14.4375, 26.1562, 30.6094,  ..., 11.9922, 10.9375,  6.1445],\n",
      "          [18.1875, 32.7812, 38.5000,  ..., 12.6641, 11.4688,  6.1680],\n",
      "          [19.5938, 34.0312, 38.6250,  ..., 13.8047, 13.2578,  7.7578],\n",
      "          ...,\n",
      "          [13.4375, 20.2500, 22.2188,  ..., 24.3594, 22.8750, 15.3125],\n",
      "          [12.9453, 19.7656, 22.1094,  ..., 24.2500, 22.4062, 14.8047],\n",
      "          [10.3594, 15.3984, 17.1719,  ..., 18.7188, 17.2656, 11.5859]],\n",
      "\n",
      "         [[12.1328, 22.1562, 25.9844,  ...,  9.9453,  9.0859,  5.0312],\n",
      "          [15.3672, 27.8438, 32.7812,  ..., 10.5234,  9.5391,  5.0312],\n",
      "          [16.5469, 28.8906, 32.8438,  ..., 11.4766, 11.0391,  6.3750],\n",
      "          ...,\n",
      "          [15.5625, 23.5625, 25.8906,  ..., 28.4062, 26.6250, 17.7969],\n",
      "          [14.9609, 22.9375, 25.7344,  ..., 28.2500, 26.0469, 17.1875],\n",
      "          [11.9844, 17.8906, 20.0156,  ..., 21.8281, 20.1094, 13.4531]]],\n",
      "\n",
      "\n",
      "        [[[13.8750, 24.9219, 29.0469,  ..., 27.8594, 22.7969, 12.6875],\n",
      "          [17.8125, 31.7344, 37.0000,  ..., 34.7188, 28.2812, 15.8281],\n",
      "          [19.1250, 32.8750, 37.0000,  ..., 33.3438, 28.5000, 16.7812],\n",
      "          ...,\n",
      "          [13.5625, 20.3281, 22.3281,  ..., 23.6875, 22.4062, 15.1875],\n",
      "          [13.1172, 19.9531, 22.3750,  ..., 23.8281, 22.0781, 14.7422],\n",
      "          [10.6328, 15.7188, 17.5625,  ..., 18.6562, 17.2500, 11.7031]],\n",
      "\n",
      "         [[14.4375, 26.1562, 30.6250,  ..., 29.3281, 23.8594, 13.0781],\n",
      "          [18.1875, 32.7812, 38.5312,  ..., 36.0000, 29.0938, 15.9531],\n",
      "          [19.5938, 34.0625, 38.6250,  ..., 34.6875, 29.3750, 16.9844],\n",
      "          ...,\n",
      "          [12.8594, 19.3281, 21.2344,  ..., 22.5625, 21.3281, 14.3750],\n",
      "          [12.4531, 18.9844, 21.2812,  ..., 22.6875, 21.0156, 13.9609],\n",
      "          [10.0703, 14.9219, 16.6562,  ..., 17.7188, 16.3750, 11.0547]],\n",
      "\n",
      "         [[12.1328, 22.1562, 25.9844,  ..., 24.8281, 20.1719, 10.9219],\n",
      "          [15.3750, 27.8438, 32.7812,  ..., 30.5625, 24.6562, 13.3750],\n",
      "          [16.5469, 28.8906, 32.8750,  ..., 29.3906, 24.8438, 14.2422],\n",
      "          ...,\n",
      "          [14.8828, 22.4688, 24.7344,  ..., 26.2812, 24.7969, 16.6875],\n",
      "          [14.3828, 22.0312, 24.7656,  ..., 26.4062, 24.4219, 16.1875],\n",
      "          [11.6484, 17.3281, 19.4062,  ..., 20.6562, 19.0625, 12.8203]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7734, 10.1406, 11.2422,  ..., 12.8438, 11.8828,  6.9453],\n",
      "          [ 5.9297, 10.7578, 12.2578,  ..., 13.9141, 12.8828,  7.5156],\n",
      "          [ 6.8945, 11.9531, 13.2188,  ..., 14.3047, 13.8906,  8.5938],\n",
      "          ...,\n",
      "          [ 2.0820,  2.3066,  2.3574,  ..., 19.5469, 18.3906, 12.5469],\n",
      "          [ 3.7148,  4.4102,  3.2910,  ..., 19.7031, 18.2031, 12.2500],\n",
      "          [ 4.9766,  6.0156,  5.5742,  ..., 15.7109, 14.5469, 10.0625]],\n",
      "\n",
      "         [[ 5.7305, 10.2422, 11.4453,  ..., 13.0859, 12.0703,  6.8867],\n",
      "          [ 5.5234, 10.3516, 12.0312,  ..., 13.6641, 12.5859,  7.0586],\n",
      "          [ 6.6016, 11.7344, 13.2188,  ..., 14.2812, 13.7812,  8.2656],\n",
      "          ...,\n",
      "          [ 1.9375,  2.0430,  2.0586,  ..., 18.5938, 17.4844, 11.8750],\n",
      "          [ 3.5547,  4.1172,  3.0957,  ..., 18.7500, 17.3281, 11.6016],\n",
      "          [ 4.7227,  5.7109,  5.3047,  ..., 14.9141, 13.8125,  9.5078]],\n",
      "\n",
      "         [[ 4.7031,  8.4844,  9.5234,  ..., 10.8438, 10.0234,  5.6211],\n",
      "          [ 4.5273,  8.5938, 10.0000,  ..., 11.3281, 10.4375,  5.7617],\n",
      "          [ 5.4180,  9.7344, 10.9844,  ..., 11.8359, 11.4219,  6.7734],\n",
      "          ...,\n",
      "          [ 1.8262,  1.7393,  1.6221,  ..., 21.6094, 20.2969, 13.7266],\n",
      "          [ 3.7656,  4.2969,  3.1250,  ..., 21.7812, 20.0781, 13.3906],\n",
      "          [ 5.2773,  6.3945,  5.9219,  ..., 17.3438, 16.0312, 10.9844]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 8.2266, 13.5781, 14.3281,  ..., 24.4062, 21.7500, 13.0781],\n",
      "          [ 9.0391, 14.8438, 15.7734,  ..., 26.7500, 24.2812, 14.9219],\n",
      "          [ 9.6719, 15.4453, 16.0000,  ..., 22.0156, 21.7656, 14.3125],\n",
      "          ...,\n",
      "          [ 2.7168,  3.3242,  2.5898,  ..., 23.5625, 21.8750, 14.5234],\n",
      "          [ 3.8516,  5.1211,  4.9492,  ..., 23.1719, 21.0469, 13.7734],\n",
      "          [ 4.6875,  6.0352,  6.2656,  ..., 17.8281, 16.1719, 10.7969]],\n",
      "\n",
      "         [[ 8.2891, 13.8047, 14.6484,  ..., 25.4531, 22.5938, 13.3984],\n",
      "          [ 8.7266, 14.5547, 15.6641,  ..., 27.2344, 24.5938, 14.8359],\n",
      "          [ 9.4688, 15.3281, 16.1094,  ..., 22.3438, 21.9844, 14.2344],\n",
      "          ...,\n",
      "          [ 2.5430,  3.0156,  2.3945,  ..., 22.4375, 20.8125, 13.7500],\n",
      "          [ 3.6660,  4.7852,  4.6992,  ..., 22.0625, 20.0625, 13.0547],\n",
      "          [ 4.4492,  5.7188,  5.9570,  ..., 16.9375, 15.3750, 10.2031]],\n",
      "\n",
      "         [[ 6.8477, 11.4922, 12.2266,  ..., 21.4531, 19.0312, 11.1797],\n",
      "          [ 7.2227, 12.1250, 13.0547,  ..., 22.9375, 20.7031, 12.3906],\n",
      "          [ 7.8398, 12.7578, 13.4141,  ..., 18.7188, 18.4531, 11.8672],\n",
      "          ...,\n",
      "          [ 2.5215,  2.9043,  2.2578,  ..., 26.1406, 24.2188, 15.9531],\n",
      "          [ 3.8770,  5.0586,  5.0508,  ..., 25.6875, 23.2969, 15.1094],\n",
      "          [ 4.9492,  6.4023,  6.7070,  ..., 19.7344, 17.8750, 11.8203]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1172, 13.4609, 14.2500,  ..., 20.8750, 18.7500, 11.1562],\n",
      "          [ 8.9141, 14.6953, 15.6875,  ..., 22.2656, 20.1719, 12.1094],\n",
      "          [ 9.5625, 15.3047, 15.8984,  ..., 18.3594, 17.7656, 11.3438],\n",
      "          ...,\n",
      "          [ 4.4570,  6.0117,  6.8984,  ..., 21.9219, 20.4062, 13.6094],\n",
      "          [ 5.3203,  7.4336,  8.5781,  ..., 21.6719, 19.7031, 12.9453],\n",
      "          [ 5.6016,  7.6016,  8.5000,  ..., 16.8438, 15.2969, 10.2734]],\n",
      "\n",
      "         [[ 8.1797, 13.6797, 14.5703,  ..., 21.6562, 19.3750, 11.3516],\n",
      "          [ 8.6016, 14.3984, 15.5781,  ..., 22.4688, 20.2500, 11.8750],\n",
      "          [ 9.3516, 15.1875, 16.0000,  ..., 18.5000, 17.8125, 11.1328],\n",
      "          ...,\n",
      "          [ 4.2617,  5.7109,  6.5938,  ..., 20.8750, 19.4219, 12.8906],\n",
      "          [ 5.0859,  7.0859,  8.1953,  ..., 20.6406, 18.7812, 12.2734],\n",
      "          [ 5.3203,  7.2188,  8.0781,  ..., 16.0000, 14.5391,  9.7109]],\n",
      "\n",
      "         [[ 6.7578, 11.3906, 12.1641,  ..., 18.1875, 16.2812,  9.4375],\n",
      "          [ 7.1172, 12.0000, 12.9844,  ..., 18.8594, 17.0000,  9.8750],\n",
      "          [ 7.7422, 12.6406, 13.3281,  ..., 15.4688, 14.8906,  9.2266],\n",
      "          ...,\n",
      "          [ 4.6484,  6.2969,  7.3906,  ..., 24.2969, 22.5781, 14.9375],\n",
      "          [ 5.6172,  7.9062,  9.2656,  ..., 24.0000, 21.7812, 14.1875],\n",
      "          [ 5.9961,  8.2031,  9.2266,  ..., 18.6250, 16.8750, 11.2266]]],\n",
      "\n",
      "\n",
      "        [[[15.3047, 26.4219, 29.9062,  ..., 31.8906, 27.8594, 16.6875],\n",
      "          [19.2344, 33.1250, 37.6562,  ..., 40.0000, 34.9688, 21.1719],\n",
      "          [20.0469, 33.6250, 37.1875,  ..., 38.7188, 35.0625, 21.9375],\n",
      "          ...,\n",
      "          [12.0312, 18.6094, 21.1406,  ..., 23.9844, 22.3125, 14.8359],\n",
      "          [11.4297, 17.8438, 20.6406,  ..., 23.6250, 21.5156, 14.0938],\n",
      "          [ 9.2891, 13.9531, 15.9609,  ..., 18.1562, 16.5156, 11.0078]],\n",
      "\n",
      "         [[15.9062, 27.6562, 31.4375,  ..., 33.5625, 29.2188, 17.3125],\n",
      "          [19.6094, 34.1250, 39.0938,  ..., 41.5938, 36.1562, 21.5781],\n",
      "          [20.5000, 34.7188, 38.7500,  ..., 40.4062, 36.3125, 22.4375],\n",
      "          ...,\n",
      "          [11.4141, 17.7031, 20.1094,  ..., 22.8438, 21.2500, 14.0469],\n",
      "          [10.8594, 17.0000, 19.6406,  ..., 22.5156, 20.5000, 13.3594],\n",
      "          [ 8.8125, 13.2500, 15.1562,  ..., 17.2656, 15.6953, 10.3984]],\n",
      "\n",
      "         [[13.3750, 23.4062, 26.6719,  ..., 28.4688, 24.7656, 14.5469],\n",
      "          [16.5625, 28.9688, 33.2500,  ..., 35.3438, 30.6875, 18.2031],\n",
      "          [17.2969, 29.4375, 32.9375,  ..., 34.3125, 30.8125, 18.9062],\n",
      "          ...,\n",
      "          [13.1719, 20.5312, 23.4062,  ..., 26.6250, 24.7188, 16.3125],\n",
      "          [12.5000, 19.6719, 22.8281,  ..., 26.2031, 23.8125, 15.4688],\n",
      "          [10.1484, 15.3516, 17.6250,  ..., 20.1094, 18.2500, 12.0547]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[11.3125, 17.2031, 17.1719,  ..., 37.5938, 34.0625, 21.4219],\n",
      "          [11.9922, 18.0781, 17.8906,  ..., 45.6250, 41.2188, 26.0156],\n",
      "          [11.7578, 17.3438, 16.6719,  ..., 42.2188, 39.2188, 25.4375],\n",
      "          ...,\n",
      "          [ 5.4375,  9.0156,  9.4141,  ..., 20.7031, 18.3750, 11.7578],\n",
      "          [ 4.5781,  7.0508,  6.4922,  ..., 19.3906, 16.8906, 10.6875],\n",
      "          [ 3.8457,  5.0039,  4.5312,  ..., 14.7969, 13.0234,  8.5547]],\n",
      "\n",
      "         [[11.4922, 17.5312, 17.5938,  ..., 39.5000, 35.6875, 22.2188],\n",
      "          [11.7734, 17.8281, 17.8281,  ..., 47.3125, 42.5625, 26.5469],\n",
      "          [11.6250, 17.2656, 16.8125,  ..., 43.9375, 40.5625, 25.9688],\n",
      "          ...,\n",
      "          [ 5.0938,  8.5938,  9.0781,  ..., 19.7188, 17.5312, 11.1719],\n",
      "          [ 4.2500,  6.6211,  6.1055,  ..., 18.5000, 16.1562, 10.1797],\n",
      "          [ 3.5527,  4.5352,  4.1641,  ..., 14.0938, 12.4219,  8.1094]],\n",
      "\n",
      "         [[ 9.6250, 14.7188, 14.7969,  ..., 33.6250, 30.3438, 18.8125],\n",
      "          [ 9.8594, 14.9531, 14.9375,  ..., 40.3125, 36.2188, 22.4844],\n",
      "          [ 9.7188, 14.4531, 14.0859,  ..., 37.4062, 34.4688, 22.0000],\n",
      "          ...,\n",
      "          [ 4.2031,  7.1562,  7.5703,  ..., 22.8594, 20.2500, 12.8438],\n",
      "          [ 3.5527,  5.5664,  5.0820,  ..., 21.3906, 18.5781, 11.6484],\n",
      "          [ 3.4629,  4.3945,  3.9980,  ..., 16.2969, 14.3047,  9.2891]]],\n",
      "\n",
      "\n",
      "        [[[11.2656, 17.1094, 17.0156,  ..., 17.6562, 18.1562, 12.3516],\n",
      "          [11.9141, 17.9375, 17.6875,  ..., 17.9219, 18.9844, 13.1875],\n",
      "          [11.6484, 17.1875, 16.5156,  ..., 16.4062, 18.1719, 13.1328],\n",
      "          ...,\n",
      "          [ 4.5820,  6.8945,  8.4922,  ..., 20.7344, 18.3906, 11.7734],\n",
      "          [ 5.0117,  7.5781,  8.9297,  ..., 19.4844, 16.9375, 10.7109],\n",
      "          [ 5.0430,  7.1797,  8.2734,  ..., 14.8828, 13.0781,  8.5703]],\n",
      "\n",
      "         [[11.4531, 17.4531, 17.4375,  ..., 18.0312, 18.5469, 12.4922],\n",
      "          [11.6953, 17.7031, 17.6250,  ..., 17.7344, 18.8281, 12.8828],\n",
      "          [11.5156, 17.0938, 16.6562,  ..., 16.4375, 18.1719, 12.9375],\n",
      "          ...,\n",
      "          [ 4.3516,  6.5000,  8.1406,  ..., 19.7500, 17.5469, 11.1797],\n",
      "          [ 4.7578,  7.1680,  8.5625,  ..., 18.5938, 16.2031, 10.2031],\n",
      "          [ 4.7969,  6.8008,  7.8906,  ..., 14.1797, 12.4766,  8.1250]],\n",
      "\n",
      "         [[ 9.5859, 14.6406, 14.6484,  ..., 15.0859, 15.5547, 10.4219],\n",
      "          [ 9.7891, 14.8359, 14.7734,  ..., 14.7734, 15.7422, 10.7266],\n",
      "          [ 9.6328, 14.3125, 13.9453,  ..., 13.6875, 15.1719, 10.7734],\n",
      "          ...,\n",
      "          [ 4.6250,  7.0977,  9.1797,  ..., 22.9062, 20.2656, 12.8594],\n",
      "          [ 5.0508,  7.7891,  9.6250,  ..., 21.5000, 18.6406, 11.6641],\n",
      "          [ 5.2812,  7.6172,  8.9609,  ..., 16.4062, 14.3672,  9.3047]]],\n",
      "\n",
      "\n",
      "        [[[11.5938, 17.6094, 17.5625,  ..., 39.0000, 36.0000, 22.7344],\n",
      "          [12.3906, 18.6406, 18.4688,  ..., 47.0312, 43.8750, 27.9531],\n",
      "          [12.1406, 17.8750, 17.2188,  ..., 41.3125, 40.4688, 26.6406],\n",
      "          ...,\n",
      "          [ 7.5430, 12.2188, 15.5312,  ..., 21.2656, 18.9375, 12.1484],\n",
      "          [ 7.1172, 11.4922, 14.5156,  ..., 20.0625, 17.4844, 11.0703],\n",
      "          [ 6.3945,  9.6328, 11.5625,  ..., 15.3125, 13.4688,  8.8047]],\n",
      "\n",
      "         [[11.7891, 17.9688, 18.0156,  ..., 41.0625, 37.7500, 23.6562],\n",
      "          [12.1953, 18.4219, 18.4375,  ..., 48.8750, 45.4375, 28.6250],\n",
      "          [12.0312, 17.8125, 17.3750,  ..., 43.0000, 41.8750, 27.2656],\n",
      "          ...,\n",
      "          [ 7.2109, 11.6797, 14.7969,  ..., 20.2500, 18.0781, 11.5391],\n",
      "          [ 6.8164, 11.0156, 13.8750,  ..., 19.1562, 16.7344, 10.5391],\n",
      "          [ 6.0977,  9.1797, 11.0156,  ..., 14.5859, 12.8438,  8.3438]],\n",
      "\n",
      "         [[ 9.8750, 15.0859, 15.1406,  ..., 34.9375, 32.1562, 20.0312],\n",
      "          [10.2109, 15.4531, 15.4453,  ..., 41.6562, 38.6875, 24.2969],\n",
      "          [10.0703, 14.9141, 14.5625,  ..., 36.5938, 35.6562, 23.1250],\n",
      "          ...,\n",
      "          [ 8.1406, 13.3281, 17.0625,  ..., 23.5000, 20.8906, 13.2734],\n",
      "          [ 7.6484, 12.5078, 15.9219,  ..., 22.1562, 19.2656, 12.0703],\n",
      "          [ 6.8906, 10.4766, 12.6641,  ..., 16.8906, 14.8047,  9.5703]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[16.3125, 24.3281, 23.8594,  ..., 20.1094, 20.9062, 14.2891],\n",
      "          [17.0781, 24.9219, 24.0625,  ..., 19.5156, 21.0312, 14.7500],\n",
      "          [15.3594, 21.7344, 20.1406,  ..., 16.5312, 18.8906, 13.9609],\n",
      "          ...,\n",
      "          [ 9.3750, 15.3672, 18.7344,  ..., 22.7344, 20.2812, 13.0156],\n",
      "          [ 8.6875, 14.2266, 17.4844,  ..., 21.5781, 18.8125, 11.9062],\n",
      "          [ 7.4336, 11.5547, 13.7109,  ..., 16.5469, 14.5703,  9.4297]],\n",
      "\n",
      "         [[16.7188, 25.0312, 24.6250,  ..., 20.6094, 21.4375, 14.4922],\n",
      "          [17.0469, 24.9375, 24.2344,  ..., 19.3594, 20.9219, 14.4688],\n",
      "          [15.3203, 21.7969, 20.4219,  ..., 16.5469, 18.8906, 13.7656],\n",
      "          ...,\n",
      "          [ 8.9766, 14.7188, 17.9219,  ..., 21.7188, 19.4219, 12.3984],\n",
      "          [ 8.3438, 13.6719, 16.7812,  ..., 20.6562, 18.0625, 11.3750],\n",
      "          [ 7.0938, 11.0547, 13.1094,  ..., 15.8125, 13.9297,  8.9609]],\n",
      "\n",
      "         [[14.1328, 21.1719, 20.8281,  ..., 17.3750, 18.0938, 12.2031],\n",
      "          [14.3906, 21.0156, 20.4062,  ..., 16.2500, 17.6094, 12.1484],\n",
      "          [12.9219, 18.3281, 17.1562,  ..., 13.8750, 15.8906, 11.5547],\n",
      "          ...,\n",
      "          [10.1797, 16.8125, 20.6250,  ..., 25.0938, 22.3594, 14.2266],\n",
      "          [ 9.4062, 15.5547, 19.2344,  ..., 23.7969, 20.7188, 12.9844],\n",
      "          [ 8.0312, 12.6172, 15.0547,  ..., 18.2344, 16.0156, 10.2500]]],\n",
      "\n",
      "\n",
      "        [[[16.9375, 27.0781, 29.5000,  ..., 43.8125, 40.3125, 25.6562],\n",
      "          [18.3906, 28.6094, 30.7969,  ..., 51.3438, 47.5625, 30.5312],\n",
      "          [16.9688, 24.8281, 24.7656,  ..., 44.8438, 43.3750, 28.8125],\n",
      "          ...,\n",
      "          [ 5.1172,  7.3711,  8.5391,  ..., 20.6562, 17.8594, 11.2969],\n",
      "          [ 5.7891,  8.4219,  9.4922,  ..., 19.5156, 16.5781, 10.3828],\n",
      "          [ 5.4766,  7.8281,  8.7500,  ..., 15.1484, 13.1250,  8.4688]],\n",
      "\n",
      "         [[17.3906, 27.9844, 30.6719,  ..., 46.0312, 42.2188, 26.6562],\n",
      "          [18.4219, 28.8438, 31.3750,  ..., 53.2500, 49.1250, 31.2188],\n",
      "          [17.0156, 25.0156, 25.2656,  ..., 46.6250, 44.8438, 29.4531],\n",
      "          ...,\n",
      "          [ 4.8203,  6.9219,  8.1641,  ..., 19.7500, 17.1250, 10.7812],\n",
      "          [ 5.4766,  7.9609,  9.1016,  ..., 18.7031, 15.9375,  9.9375],\n",
      "          [ 5.2031,  7.3828,  8.3594,  ..., 14.4766, 12.5547,  8.0469]],\n",
      "\n",
      "         [[14.7188, 23.7344, 26.0781,  ..., 39.3125, 36.0312, 22.6719],\n",
      "          [15.5859, 24.4219, 26.5938,  ..., 45.5000, 41.9375, 26.5781],\n",
      "          [14.3828, 21.1250, 21.3594,  ..., 39.8125, 38.2500, 25.0469],\n",
      "          ...,\n",
      "          [ 4.9609,  7.3867,  9.1328,  ..., 22.7812, 19.6406, 12.3125],\n",
      "          [ 5.6523,  8.5000, 10.1562,  ..., 21.5000, 18.2031, 11.2891],\n",
      "          [ 5.6523,  8.2109,  9.4609,  ..., 16.6562, 14.3906,  9.1797]]],\n",
      "\n",
      "\n",
      "        [[[21.6875, 34.2812, 35.0000,  ..., 29.0312, 26.4688, 16.5469],\n",
      "          [24.5938, 38.0000, 37.4688,  ..., 29.8125, 27.9062, 17.7188],\n",
      "          [22.2969, 32.5000, 29.5156,  ..., 23.4219, 24.0156, 16.3750],\n",
      "          ...,\n",
      "          [ 8.8203, 14.4609, 17.7969,  ..., 23.0625, 20.5781, 13.1953],\n",
      "          [ 8.2578, 13.4609, 16.5469,  ..., 21.8906, 19.0938, 12.0703],\n",
      "          [ 7.1875, 11.0625, 13.0625,  ..., 16.7656, 14.7578,  9.5312]],\n",
      "\n",
      "         [[22.5000, 35.7188, 36.6250,  ..., 30.1406, 27.3750, 16.9062],\n",
      "          [25.0625, 38.8750, 38.5000,  ..., 30.2500, 28.1719, 17.6094],\n",
      "          [22.6875, 33.2188, 30.3438,  ..., 23.7500, 24.2656, 16.2812],\n",
      "          ...,\n",
      "          [ 8.4453, 13.8516, 17.0156,  ..., 22.0312, 19.7031, 12.5703],\n",
      "          [ 7.9375, 12.9453, 15.8750,  ..., 20.9688, 18.3281, 11.5312],\n",
      "          [ 6.8594, 10.5781, 12.4844,  ..., 16.0312, 14.1094,  9.0625]],\n",
      "\n",
      "         [[19.1250, 30.4531, 31.2188,  ..., 25.5781, 23.2188, 14.2500],\n",
      "          [21.3125, 33.0938, 32.7812,  ..., 25.5938, 23.8281, 14.8203],\n",
      "          [19.2656, 28.2031, 25.7656,  ..., 20.0469, 20.4688, 13.7109],\n",
      "          ...,\n",
      "          [ 9.5625, 15.8125, 19.5625,  ..., 25.4531, 22.6875, 14.4297],\n",
      "          [ 8.9141, 14.6953, 18.1719,  ..., 24.1562, 21.0312, 13.1719],\n",
      "          [ 7.7500, 12.0625, 14.3281,  ..., 18.4844, 16.2188, 10.3750]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[22.0156, 36.3438, 40.3750,  ..., 50.5000, 45.2500, 28.2031],\n",
      "          [26.4844, 43.4688, 47.8438,  ..., 62.8125, 56.2188, 35.1250],\n",
      "          [25.8906, 40.7188, 42.1562,  ..., 59.9375, 55.0000, 35.2812],\n",
      "          ...,\n",
      "          [13.7031, 21.4844, 24.2500,  ..., 25.8281, 23.5469, 15.4141],\n",
      "          [12.9375, 20.5312, 23.6719,  ..., 25.2500, 22.5000, 14.5234],\n",
      "          [10.5312, 16.2656, 18.5625,  ..., 19.6875, 17.6250, 11.5703]],\n",
      "\n",
      "         [[22.8281, 37.9062, 42.3125,  ..., 53.1250, 47.4688, 29.3750],\n",
      "          [27.0781, 44.7500, 49.5938,  ..., 65.5000, 58.3750, 36.1562],\n",
      "          [26.5156, 41.9688, 43.7500,  ..., 62.6875, 57.1875, 36.3750],\n",
      "          ...,\n",
      "          [13.1094, 20.5625, 23.1875,  ..., 24.7031, 22.5469, 14.7188],\n",
      "          [12.4062, 19.6875, 22.6875,  ..., 24.1875, 21.5938, 13.8906],\n",
      "          [10.0781, 15.5781, 17.7656,  ..., 18.8438, 16.8750, 11.0312]],\n",
      "\n",
      "         [[19.5000, 32.4375, 36.2188,  ..., 45.5625, 40.6875, 25.1094],\n",
      "          [23.1562, 38.2812, 42.4375,  ..., 56.1562, 50.0312, 30.9375],\n",
      "          [22.6406, 35.8750, 37.4375,  ..., 53.7812, 49.0000, 31.1250],\n",
      "          ...,\n",
      "          [14.9844, 23.6094, 26.7344,  ..., 28.5000, 25.9375, 16.8750],\n",
      "          [14.1250, 22.5469, 26.0938,  ..., 27.8438, 24.7812, 15.8750],\n",
      "          [11.5000, 17.8594, 20.4375,  ..., 21.7031, 19.3906, 12.6250]]],\n",
      "\n",
      "\n",
      "        [[[24.4062, 39.3438, 41.8125,  ..., 28.2656, 25.6406, 16.1875],\n",
      "          [28.8750, 46.3125, 48.7500,  ..., 28.4062, 26.3906, 17.0156],\n",
      "          [27.5156, 42.7188, 42.6875,  ..., 22.8125, 23.2344, 16.1094],\n",
      "          ...,\n",
      "          [13.0859, 23.1562, 27.7188,  ..., 25.7969, 23.6250, 15.5156],\n",
      "          [10.3438, 17.9062, 20.2969,  ..., 25.2500, 22.5938, 14.6172],\n",
      "          [ 6.0508,  9.1328,  9.2422,  ..., 19.6875, 17.6875, 11.6250]],\n",
      "\n",
      "         [[25.3906, 41.1562, 43.8438,  ..., 29.2500, 26.4219, 16.5000],\n",
      "          [29.6094, 47.7812, 50.5625,  ..., 28.7031, 26.5312, 16.8438],\n",
      "          [28.2188, 44.0938, 44.3438,  ..., 23.0625, 23.3750, 15.9844],\n",
      "          ...,\n",
      "          [13.0781, 23.3594, 28.1719,  ..., 24.6719, 22.6250, 14.8125],\n",
      "          [10.2500, 17.9375, 20.4688,  ..., 24.1875, 21.6875, 13.9844],\n",
      "          [ 5.7109,  8.7500,  9.0000,  ..., 18.8438, 16.9375, 11.0938]],\n",
      "\n",
      "         [[21.7031, 35.2188, 37.5625,  ..., 24.8906, 22.4688, 13.9688],\n",
      "          [25.3438, 40.9062, 43.2812,  ..., 24.3594, 22.4844, 14.2344],\n",
      "          [24.1406, 37.7188, 37.9375,  ..., 19.5469, 19.7812, 13.5156],\n",
      "          ...,\n",
      "          [11.1016, 19.9219, 24.0312,  ..., 28.4531, 26.0312, 16.9844],\n",
      "          [ 8.6953, 15.3047, 17.4375,  ..., 27.8438, 24.8750, 15.9844],\n",
      "          [ 5.3281,  7.9141,  7.8594,  ..., 21.7031, 19.4531, 12.6875]]],\n",
      "\n",
      "\n",
      "        [[[13.3516, 20.2031, 20.4062,  ..., 22.8125, 20.9062, 13.5078],\n",
      "          [13.6016, 20.3594, 20.5000,  ..., 22.0156, 20.7188, 13.6797],\n",
      "          [12.8594, 18.8594, 18.3750,  ..., 18.0312, 18.8906, 13.4375],\n",
      "          ...,\n",
      "          [13.6719, 21.4375, 24.2188,  ..., 26.0469, 23.8906, 15.7031],\n",
      "          [12.9062, 20.4844, 23.6406,  ..., 25.5156, 22.8750, 14.8047],\n",
      "          [10.5156, 16.2344, 18.5312,  ..., 19.8906, 17.8750, 11.7500]],\n",
      "\n",
      "         [[13.6094, 20.6719, 20.9531,  ..., 23.4531, 21.4062, 13.6719],\n",
      "          [13.4219, 20.1875, 20.5000,  ..., 21.9531, 20.5938, 13.3750],\n",
      "          [12.7344, 18.8125, 18.5156,  ..., 18.0469, 18.8594, 13.2344],\n",
      "          ...,\n",
      "          [13.0781, 20.5156, 23.1562,  ..., 24.9062, 22.8750, 15.0000],\n",
      "          [12.3906, 19.6562, 22.6562,  ..., 24.4531, 21.9531, 14.1719],\n",
      "          [10.0625, 15.5469, 17.7344,  ..., 19.0312, 17.1250, 11.2031]],\n",
      "\n",
      "         [[11.5391, 17.5312, 17.7969,  ..., 19.8906, 18.1562, 11.5547],\n",
      "          [11.3672, 17.0938, 17.3594,  ..., 18.5781, 17.4219, 11.2734],\n",
      "          [10.7812, 15.9141, 15.6797,  ..., 15.2500, 15.9453, 11.1719],\n",
      "          ...,\n",
      "          [14.9453, 23.5625, 26.7031,  ..., 28.7344, 26.3281, 17.1875],\n",
      "          [14.0938, 22.5156, 26.0625,  ..., 28.1562, 25.1875, 16.1875],\n",
      "          [11.4844, 17.8281, 20.4219,  ..., 21.9375, 19.6719, 12.8281]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[12.8281, 19.2969, 18.7188,  ..., 43.9375, 39.9688, 25.1719],\n",
      "          [12.5234, 18.7500, 18.1094,  ..., 51.7500, 47.0625, 29.7812],\n",
      "          [11.8594, 17.5156, 16.6406,  ..., 46.9375, 44.3438, 29.0469],\n",
      "          ...,\n",
      "          [14.1250, 22.1719, 24.8906,  ..., 27.1094, 24.9219, 16.3594],\n",
      "          [13.4609, 21.4062, 24.5625,  ..., 26.8281, 24.0938, 15.5781],\n",
      "          [11.0859, 17.1875, 19.5000,  ..., 21.1562, 19.0469, 12.4766]],\n",
      "\n",
      "         [[13.0312, 19.6875, 19.1250,  ..., 45.9375, 41.6562, 26.0312],\n",
      "          [12.2891, 18.5156, 17.9844,  ..., 53.4688, 48.4375, 30.3594],\n",
      "          [11.6875, 17.4219, 16.6875,  ..., 48.6250, 45.6562, 29.6094],\n",
      "          ...,\n",
      "          [13.5469, 21.2656, 23.8438,  ..., 25.9844, 23.9062, 15.6641],\n",
      "          [12.9453, 20.5781, 23.5625,  ..., 25.7500, 23.1562, 14.9453],\n",
      "          [10.6328, 16.4844, 18.7031,  ..., 20.2812, 18.2656, 11.9297]],\n",
      "\n",
      "         [[11.1016, 16.7812, 16.3125,  ..., 39.4688, 35.7812, 22.2969],\n",
      "          [10.4531, 15.7422, 15.2734,  ..., 45.9375, 41.5625, 25.9844],\n",
      "          [ 9.9375, 14.7969, 14.1875,  ..., 41.7500, 39.1562, 25.3438],\n",
      "          ...,\n",
      "          [15.4219, 24.3438, 27.3906,  ..., 29.8594, 27.4062, 17.9062],\n",
      "          [14.6875, 23.4844, 27.0156,  ..., 29.5469, 26.4844, 17.0312],\n",
      "          [12.1016, 18.8594, 21.4531,  ..., 23.2969, 20.9375, 13.6172]]],\n",
      "\n",
      "\n",
      "        [[[24.5000, 39.7500, 42.4062,  ..., 18.8281, 20.0469, 13.8203],\n",
      "          [28.9062, 46.7812, 49.8438,  ..., 18.0781, 19.7812, 13.9531],\n",
      "          [27.9531, 44.0312, 44.9688,  ..., 16.7812, 18.9844, 13.9766],\n",
      "          ...,\n",
      "          [13.8281, 21.7344, 24.4531,  ..., 26.2969, 24.1562, 15.8672],\n",
      "          [13.1562, 20.9219, 24.0312,  ..., 26.0156, 23.3438, 15.1016],\n",
      "          [10.8750, 16.8438, 19.1250,  ..., 20.5625, 18.5156, 12.1484]],\n",
      "\n",
      "         [[25.4219, 41.4062, 44.3125,  ..., 19.1719, 20.4531, 13.9844],\n",
      "          [29.5781, 48.1562, 51.5312,  ..., 17.8125, 19.5781, 13.6484],\n",
      "          [28.6250, 45.3438, 46.5938,  ..., 16.7031, 18.9062, 13.7656],\n",
      "          ...,\n",
      "          [13.2578, 20.8438, 23.4375,  ..., 25.2031, 23.1719, 15.1953],\n",
      "          [12.6484, 20.1094, 23.0781,  ..., 24.9688, 22.4375, 14.4844],\n",
      "          [10.4297, 16.1562, 18.3281,  ..., 19.7188, 17.7656, 11.6172]],\n",
      "\n",
      "         [[21.7969, 35.5625, 38.0938,  ..., 16.3125, 17.4219, 11.8828],\n",
      "          [25.3906, 41.3438, 44.2500,  ..., 15.1172, 16.6406, 11.5781],\n",
      "          [24.5469, 38.9062, 40.0312,  ..., 14.1953, 16.0625, 11.6953],\n",
      "          ...,\n",
      "          [15.0859, 23.8438, 26.9062,  ..., 28.9531, 26.5625, 17.3438],\n",
      "          [14.3438, 22.9531, 26.4375,  ..., 28.6406, 25.6562, 16.5000],\n",
      "          [11.8672, 18.4688, 21.0156,  ..., 22.6406, 20.3594, 13.2578]]],\n",
      "\n",
      "\n",
      "        [[[25.0156, 41.0938, 45.0312,  ..., 43.9688, 40.0000, 25.1719],\n",
      "          [29.6562, 48.8438, 53.7812,  ..., 51.7812, 47.0938, 29.7969],\n",
      "          [28.8125, 46.5000, 49.5625,  ..., 47.0312, 44.3750, 29.0625],\n",
      "          ...,\n",
      "          [14.5156, 22.7500, 25.4531,  ..., 27.5469, 25.2500, 16.5469],\n",
      "          [13.8438, 21.9844, 25.1406,  ..., 27.2188, 24.3750, 15.7344],\n",
      "          [11.3438, 17.5781, 19.9219,  ..., 21.4062, 19.2188, 12.5781]],\n",
      "\n",
      "         [[25.9688, 42.8750, 47.1250,  ..., 45.9375, 41.6562, 26.0469],\n",
      "          [30.3594, 50.3438, 55.7500,  ..., 53.5000, 48.4375, 30.3750],\n",
      "          [29.5312, 47.9688, 51.4688,  ..., 48.6875, 45.6875, 29.6406],\n",
      "          ...,\n",
      "          [13.9219, 21.8125, 24.3750,  ..., 26.3906, 24.2188, 15.8359],\n",
      "          [13.3047, 21.1250, 24.1250,  ..., 26.1250, 23.4219, 15.0859],\n",
      "          [10.8828, 16.8750, 19.0938,  ..., 20.5312, 18.4375, 12.0234]],\n",
      "\n",
      "         [[22.2812, 36.8438, 40.5000,  ..., 39.4688, 35.7812, 22.2969],\n",
      "          [26.0625, 43.2500, 47.9062,  ..., 45.9375, 41.5938, 26.0000],\n",
      "          [25.3438, 41.1875, 44.2500,  ..., 41.8125, 39.1875, 25.3750],\n",
      "          ...,\n",
      "          [15.8594, 24.9844, 28.0156,  ..., 30.3438, 27.7812, 18.0938],\n",
      "          [15.1094, 24.1250, 27.6562,  ..., 29.9844, 26.8125, 17.2031],\n",
      "          [12.3906, 19.2969, 21.9219,  ..., 23.5781, 21.1406, 13.7266]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[13.7969, 20.9844, 21.4531,  ..., 24.0781, 22.7500, 14.8750],\n",
      "          [13.8672, 21.0000, 21.7812,  ..., 23.7969, 22.7031, 15.0312],\n",
      "          [13.7266, 20.4531, 20.6562,  ..., 21.2188, 21.6094, 15.1875],\n",
      "          ...,\n",
      "          [16.6562, 25.2500, 27.0156,  ..., 30.1562, 28.7344, 19.4375],\n",
      "          [16.5625, 25.5312, 28.0156,  ..., 30.9688, 28.8125, 19.1562],\n",
      "          [13.7500, 20.8594, 22.8594,  ..., 24.9219, 23.0781, 15.4375]],\n",
      "\n",
      "         [[14.0859, 21.5000, 22.0000,  ..., 24.7500, 23.3438, 15.1406],\n",
      "          [13.7734, 20.9688, 21.8438,  ..., 23.8438, 22.7188, 14.8594],\n",
      "          [13.6719, 20.5000, 20.8125,  ..., 21.3125, 21.6562, 15.0781],\n",
      "          ...,\n",
      "          [16.0000, 24.2500, 25.9375,  ..., 28.9688, 27.5938, 18.6562],\n",
      "          [15.9297, 24.5625, 26.9375,  ..., 29.7812, 27.7188, 18.3750],\n",
      "          [13.2188, 20.0312, 21.9688,  ..., 23.9375, 22.1875, 14.7969]],\n",
      "\n",
      "         [[12.0547, 18.4062, 18.8594,  ..., 21.1719, 19.9844, 12.9375],\n",
      "          [11.7812, 17.9219, 18.6562,  ..., 20.3750, 19.4062, 12.6719],\n",
      "          [11.6953, 17.5312, 17.7969,  ..., 18.2188, 18.4844, 12.8750],\n",
      "          ...,\n",
      "          [18.2188, 27.7188, 29.7031,  ..., 33.1875, 31.6094, 21.2812],\n",
      "          [18.0938, 28.0312, 30.8125,  ..., 34.0938, 31.6875, 20.9531],\n",
      "          [15.0469, 22.9062, 25.1406,  ..., 27.4375, 25.3906, 16.8906]]],\n",
      "\n",
      "\n",
      "        [[[12.6250, 18.9688, 19.2031,  ..., 32.0000, 29.0000, 18.2656],\n",
      "          [12.2266, 18.4219, 18.9219,  ..., 35.9688, 32.8750, 20.7031],\n",
      "          [12.1953, 18.2344, 18.3750,  ..., 33.3750, 32.6250, 21.7969],\n",
      "          ...,\n",
      "          [16.7031, 25.3438, 27.1875,  ..., 30.0938, 28.6719, 19.4062],\n",
      "          [16.6094, 25.6562, 28.2344,  ..., 30.9375, 28.7500, 19.1094],\n",
      "          [13.7969, 20.9531, 23.0156,  ..., 24.8906, 23.0625, 15.4141]],\n",
      "\n",
      "         [[12.8594, 19.3750, 19.6562,  ..., 33.1562, 29.9688, 18.7188],\n",
      "          [12.0625, 18.2812, 18.8750,  ..., 36.7188, 33.4375, 20.8438],\n",
      "          [12.0859, 18.1875, 18.4688,  ..., 34.1250, 33.2188, 22.0000],\n",
      "          ...,\n",
      "          [16.0312, 24.3438, 26.0938,  ..., 28.9062, 27.5312, 18.5938],\n",
      "          [15.9844, 24.6875, 27.1250,  ..., 29.7188, 27.6562, 18.3438],\n",
      "          [13.2578, 20.1250, 22.0938,  ..., 23.9375, 22.1562, 14.7812]],\n",
      "\n",
      "         [[11.0000, 16.5781, 16.8125,  ..., 28.4688, 25.7188, 16.0312],\n",
      "          [10.3047, 15.6094, 16.1094,  ..., 31.4844, 28.6719, 17.8281],\n",
      "          [10.3203, 15.5469, 15.7734,  ..., 29.2344, 28.4531, 18.8438],\n",
      "          ...,\n",
      "          [18.2500, 27.8125, 29.8906,  ..., 33.1250, 31.5312, 21.2344],\n",
      "          [18.1562, 28.1562, 31.0469,  ..., 34.0625, 31.6250, 20.9219],\n",
      "          [15.0938, 23.0000, 25.3281,  ..., 27.4219, 25.3750, 16.8594]]],\n",
      "\n",
      "\n",
      "        [[[26.0469, 42.2500, 46.2812,  ..., 25.2500, 24.2031, 15.8672],\n",
      "          [31.6875, 51.5000, 56.7500,  ..., 29.2031, 27.8750, 18.1562],\n",
      "          [32.3438, 51.4375, 54.8750,  ..., 29.4531, 29.2031, 19.7500],\n",
      "          ...,\n",
      "          [15.4141, 23.2812, 24.8750,  ..., 29.7812, 28.3750, 19.2031],\n",
      "          [15.5781, 23.9844, 26.3281,  ..., 30.5938, 28.4531, 18.9219],\n",
      "          [13.1953, 19.9688, 21.8750,  ..., 24.6562, 22.8438, 15.2812]],\n",
      "\n",
      "         [[27.0625, 44.0625, 48.3750,  ..., 26.0000, 24.9062, 16.1875],\n",
      "          [32.5625, 53.1875, 58.8125,  ..., 29.5938, 28.2188, 18.1875],\n",
      "          [33.2500, 53.1875, 57.0000,  ..., 30.0000, 29.6562, 19.8750],\n",
      "          ...,\n",
      "          [14.8125, 22.3750, 23.8750,  ..., 28.5938, 27.2812, 18.4062],\n",
      "          [15.0000, 23.0938, 25.3125,  ..., 29.4062, 27.3750, 18.1875],\n",
      "          [12.6797, 19.1875, 21.0312,  ..., 23.6875, 21.9688, 14.6562]],\n",
      "\n",
      "         [[23.3125, 37.9688, 41.6875,  ..., 22.2500, 21.3281, 13.8438],\n",
      "          [28.0469, 45.8125, 50.6562,  ..., 25.3438, 24.1406, 15.5312],\n",
      "          [28.6406, 45.8125, 49.1250,  ..., 25.7031, 25.3906, 17.0000],\n",
      "          ...,\n",
      "          [16.8281, 25.5312, 27.3125,  ..., 32.7812, 31.2031, 21.0156],\n",
      "          [17.0156, 26.2969, 28.9219,  ..., 33.6875, 31.2812, 20.7031],\n",
      "          [14.4219, 21.9062, 24.0625,  ..., 27.1562, 25.1250, 16.7188]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[14.3047, 23.2969, 26.9531,  ..., 19.1406, 17.7344, 11.8984],\n",
      "          [14.8047, 24.3438, 29.4688,  ..., 18.9062, 17.3281, 11.5234],\n",
      "          [15.4531, 24.6719, 28.6094,  ..., 19.8906, 19.0156, 12.7969],\n",
      "          ...,\n",
      "          [20.1875, 30.1406, 31.6719,  ..., 35.0312, 33.8125, 23.1562],\n",
      "          [20.6250, 31.3906, 33.7500,  ..., 36.5625, 34.5625, 23.2812],\n",
      "          [17.1094, 25.7500, 27.7969,  ..., 29.6406, 27.8750, 18.7969]],\n",
      "\n",
      "         [[14.6328, 23.9531, 27.7969,  ..., 19.5781, 18.1406, 12.0703],\n",
      "          [14.7812, 24.5156, 29.9062,  ..., 18.8125, 17.2344, 11.3438],\n",
      "          [15.4766, 24.8906, 29.0781,  ..., 19.9375, 19.0312, 12.6875],\n",
      "          ...,\n",
      "          [19.3906, 28.9688, 30.4219,  ..., 33.6562, 32.5000, 22.2188],\n",
      "          [19.8438, 30.2031, 32.4688,  ..., 35.1875, 33.2812, 22.3750],\n",
      "          [16.4531, 24.7656, 26.7344,  ..., 28.5156, 26.8125, 18.0469]],\n",
      "\n",
      "         [[12.5781, 20.6094, 23.9219,  ..., 16.7969, 15.5625, 10.3906],\n",
      "          [12.7031, 21.0625, 25.6875,  ..., 16.1250, 14.7656,  9.7578],\n",
      "          [13.2891, 21.3906, 24.9844,  ..., 17.1094, 16.3125, 10.8750],\n",
      "          ...,\n",
      "          [22.0938, 33.0938, 34.8125,  ..., 38.5312, 37.1562, 25.3594],\n",
      "          [22.5938, 34.4688, 37.1250,  ..., 40.2500, 38.0000, 25.5156],\n",
      "          [18.7500, 28.2969, 30.5938,  ..., 32.6250, 30.6719, 20.5938]]],\n",
      "\n",
      "\n",
      "        [[[20.1406, 32.4062, 35.5312,  ..., 25.2031, 22.4844, 14.1797],\n",
      "          [23.6719, 38.2188, 42.4062,  ..., 27.3125, 23.9219, 14.8203],\n",
      "          [25.0938, 39.4688, 42.1250,  ..., 27.5938, 25.3125, 16.3438],\n",
      "          ...,\n",
      "          [18.4844, 27.2969, 28.2188,  ..., 31.3906, 30.8281, 21.3594],\n",
      "          [19.0781, 28.7969, 30.6719,  ..., 33.6562, 32.1562, 21.8281],\n",
      "          [16.0938, 24.0781, 25.8125,  ..., 27.8594, 26.3594, 17.8750]],\n",
      "\n",
      "         [[20.8125, 33.6562, 36.9062,  ..., 25.9375, 23.1250, 14.4609],\n",
      "          [24.1406, 39.1875, 43.5938,  ..., 27.5781, 24.0781, 14.7500],\n",
      "          [25.6250, 40.5312, 43.4062,  ..., 27.9375, 25.5312, 16.3281],\n",
      "          ...,\n",
      "          [17.7656, 26.2344, 27.1250,  ..., 30.1719, 29.6406, 20.5000],\n",
      "          [18.3594, 27.7188, 29.5000,  ..., 32.4062, 30.9531, 20.9688],\n",
      "          [15.4922, 23.1719, 24.8281,  ..., 26.7969, 25.3594, 17.1562]],\n",
      "\n",
      "         [[17.9531, 29.0312, 31.8594,  ..., 22.2969, 19.8906, 12.4219],\n",
      "          [20.8281, 33.8125, 37.5938,  ..., 23.7031, 20.6562, 12.6484],\n",
      "          [22.0938, 34.9375, 37.4062,  ..., 24.0000, 21.9219, 14.0156],\n",
      "          ...,\n",
      "          [20.2031, 29.9375, 30.9844,  ..., 34.4688, 33.8438, 23.3750],\n",
      "          [20.8594, 31.6094, 33.6875,  ..., 37.0312, 35.3125, 23.8906],\n",
      "          [17.6250, 26.4531, 28.3750,  ..., 30.6562, 28.9844, 19.5781]]],\n",
      "\n",
      "\n",
      "        [[[11.5859, 17.4531, 18.2031,  ..., 26.5469, 26.5156, 17.4219],\n",
      "          [10.9062, 16.7812, 18.1562,  ..., 30.3438, 30.8125, 20.1094],\n",
      "          [11.5547, 17.7812, 19.0625,  ..., 31.5625, 32.7188, 22.0625],\n",
      "          ...,\n",
      "          [19.1250, 28.3438, 29.4375,  ..., 33.5625, 32.5938, 22.4531],\n",
      "          [19.6562, 29.7344, 31.7188,  ..., 35.3125, 33.5000, 22.6719],\n",
      "          [16.4688, 24.6719, 26.4531,  ..., 28.8594, 27.2188, 18.4062]],\n",
      "\n",
      "         [[11.8125, 17.8594, 18.6250,  ..., 27.3750, 27.3906, 17.9062],\n",
      "          [10.7578, 16.6719, 18.1094,  ..., 30.7969, 31.3438, 20.3125],\n",
      "          [11.4609, 17.7969, 19.1562,  ..., 32.1250, 33.3125, 22.3125],\n",
      "          ...,\n",
      "          [18.3750, 27.2500, 28.2812,  ..., 32.2812, 31.3594, 21.5469],\n",
      "          [18.9062, 28.6094, 30.5000,  ..., 33.9688, 32.2812, 21.7812],\n",
      "          [15.8359, 23.7344, 25.4375,  ..., 27.7656, 26.1875, 17.6719]],\n",
      "\n",
      "         [[10.1641, 15.3438, 16.0000,  ..., 23.5469, 23.5938, 15.3984],\n",
      "          [ 9.2422, 14.3125, 15.5234,  ..., 26.4844, 26.9844, 17.4688],\n",
      "          [ 9.8359, 15.2656, 16.4375,  ..., 27.6250, 28.6719, 19.1875],\n",
      "          ...,\n",
      "          [20.9062, 31.1094, 32.3125,  ..., 36.9062, 35.8125, 24.5781],\n",
      "          [21.5000, 32.6250, 34.8438,  ..., 38.8438, 36.8438, 24.8281],\n",
      "          [18.0312, 27.0938, 29.1094,  ..., 31.7656, 29.9375, 20.1562]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[12.4922, 18.9062, 20.2344,  ..., 18.3438, 17.0469, 11.6953],\n",
      "          [12.1719, 18.7500, 21.0938,  ..., 18.5312, 16.8125, 11.4688],\n",
      "          [13.7500, 21.0312, 23.2500,  ..., 21.4531, 19.5938, 12.9141],\n",
      "          ...,\n",
      "          [18.4062, 27.0781, 27.7656,  ..., 31.4219, 31.2188, 21.8281],\n",
      "          [19.4688, 29.3438, 31.0000,  ..., 34.0625, 32.9062, 22.5000],\n",
      "          [16.6719, 24.9688, 26.5938,  ..., 28.5781, 27.3125, 18.6094]],\n",
      "\n",
      "         [[12.7500, 19.3750, 20.7344,  ..., 18.8125, 17.5000, 11.8906],\n",
      "          [12.0781, 18.7500, 21.1719,  ..., 18.5156, 16.8125, 11.3438],\n",
      "          [13.7500, 21.1875, 23.5000,  ..., 21.6094, 19.7031, 12.8594],\n",
      "          ...,\n",
      "          [17.7031, 26.0781, 26.7188,  ..., 30.2656, 30.0781, 20.9844],\n",
      "          [18.7500, 28.2812, 29.8750,  ..., 32.7812, 31.7031, 21.6719],\n",
      "          [16.0625, 24.0625, 25.6250,  ..., 27.5469, 26.3281, 17.9062]],\n",
      "\n",
      "         [[10.9766, 16.6562, 17.8281,  ..., 16.1875, 15.0469, 10.3047],\n",
      "          [10.3906, 16.1094, 18.1562,  ..., 15.9297, 14.4688,  9.9062],\n",
      "          [11.8203, 18.2031, 20.1875,  ..., 18.5938, 16.9219, 11.0703],\n",
      "          ...,\n",
      "          [20.0938, 29.6719, 30.4375,  ..., 34.5000, 34.2500, 23.8594],\n",
      "          [21.2656, 32.1875, 34.0312,  ..., 37.4062, 36.0938, 24.6094],\n",
      "          [18.2500, 27.4062, 29.2188,  ..., 31.4219, 30.0156, 20.3594]]],\n",
      "\n",
      "\n",
      "        [[[13.6016, 20.7656, 22.2812,  ..., 41.2188, 36.5625, 22.9531],\n",
      "          [13.2188, 20.5000, 22.9062,  ..., 49.5938, 44.0625, 27.5312],\n",
      "          [13.8906, 21.3750, 23.4375,  ..., 50.0312, 46.3750, 30.1406],\n",
      "          ...,\n",
      "          [19.8281, 29.4531, 30.5781,  ..., 34.8750, 33.9688, 23.4219],\n",
      "          [20.6406, 31.2812, 33.3125,  ..., 36.9688, 35.2500, 23.9062],\n",
      "          [17.3906, 26.1562, 28.0000,  ..., 30.4375, 28.8281, 19.5156]],\n",
      "\n",
      "         [[13.9375, 21.3594, 22.8906,  ..., 42.8750, 38.0000, 23.7500],\n",
      "          [13.2031, 20.6094, 23.0781,  ..., 51.0625, 45.2812, 28.1562],\n",
      "          [13.9062, 21.5469, 23.7031,  ..., 51.5312, 47.6562, 30.8281],\n",
      "          ...,\n",
      "          [19.0781, 28.3438, 29.4219,  ..., 33.5312, 32.6562, 22.5156],\n",
      "          [19.8750, 30.1250, 32.0625,  ..., 35.5938, 33.9688, 23.0156],\n",
      "          [16.7500, 25.2031, 26.9688,  ..., 29.3281, 27.7969, 18.7656]],\n",
      "\n",
      "         [[12.0234, 18.3906, 19.7344,  ..., 37.1562, 32.9375, 20.5312],\n",
      "          [11.3750, 17.7344, 19.8438,  ..., 44.2500, 39.2500, 24.3438],\n",
      "          [11.9844, 18.5312, 20.3906,  ..., 44.6250, 41.2812, 26.6562],\n",
      "          ...,\n",
      "          [21.6719, 32.3125, 33.5938,  ..., 38.3125, 37.2812, 25.6250],\n",
      "          [22.5625, 34.3438, 36.5938,  ..., 40.6562, 38.7188, 26.1719],\n",
      "          [19.0469, 28.7344, 30.7969,  ..., 33.5000, 31.7031, 21.3594]]],\n",
      "\n",
      "\n",
      "        [[[12.4219, 18.7969, 20.3438,  ..., 42.2500, 37.2500, 23.2969],\n",
      "          [11.9609, 18.6094, 21.4062,  ..., 51.1250, 45.0312, 28.0625],\n",
      "          [13.3438, 20.7656, 23.6406,  ..., 51.7500, 47.4375, 30.7188],\n",
      "          ...,\n",
      "          [20.0469, 29.7969, 31.0000,  ..., 34.7500, 33.8438, 23.3438],\n",
      "          [20.8906, 31.7031, 33.8438,  ..., 36.9062, 35.1875, 23.8594],\n",
      "          [17.5781, 26.4688, 28.3750,  ..., 30.4062, 28.7969, 19.4844]],\n",
      "\n",
      "         [[12.6875, 19.2812, 20.8438,  ..., 43.9688, 38.6875, 24.1250],\n",
      "          [11.8750, 18.6250, 21.5156,  ..., 52.6875, 46.3125, 28.7188],\n",
      "          [13.3281, 20.9062, 23.9062,  ..., 53.3125, 48.7812, 31.4531],\n",
      "          ...,\n",
      "          [19.2812, 28.6719, 29.8125,  ..., 33.4062, 32.5625, 22.4531],\n",
      "          [20.1250, 30.5469, 32.5625,  ..., 35.5312, 33.9062, 22.9688],\n",
      "          [16.9375, 25.5000, 27.3281,  ..., 29.2969, 27.7656, 18.7344]],\n",
      "\n",
      "         [[10.9297, 16.5938, 17.9531,  ..., 38.1250, 33.5625, 20.8594],\n",
      "          [10.2188, 16.0156, 18.4688,  ..., 45.6562, 40.1562, 24.8438],\n",
      "          [11.4688, 17.9844, 20.5469,  ..., 46.1875, 42.2500, 27.1875],\n",
      "          ...,\n",
      "          [21.9062, 32.6875, 34.0312,  ..., 38.1875, 37.1875, 25.5469],\n",
      "          [22.8594, 34.8125, 37.1562,  ..., 40.5938, 38.6562, 26.1250],\n",
      "          [19.2500, 29.0625, 31.2031,  ..., 33.4688, 31.6719, 21.3438]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[26.2656, 40.9688, 44.9375,  ..., 33.5938, 30.3906, 20.2500],\n",
      "          [30.7656, 48.3438, 53.8438,  ..., 36.5000, 32.5000, 21.4531],\n",
      "          [32.3750, 49.8750, 53.7500,  ..., 36.5000, 33.5000, 23.0625],\n",
      "          ...,\n",
      "          [17.3125, 25.5000, 25.4219,  ..., 29.2969, 29.8594, 20.9531],\n",
      "          [18.4531, 27.9375, 28.9219,  ..., 32.5938, 32.0625, 21.9375],\n",
      "          [15.9375, 24.0469, 25.2188,  ..., 27.7500, 26.8594, 18.2188]],\n",
      "\n",
      "         [[27.1719, 42.5000, 46.6562,  ..., 34.6562, 31.3125, 20.7656],\n",
      "          [31.5000, 49.7188, 55.4375,  ..., 37.1250, 33.0000, 21.6406],\n",
      "          [33.1562, 51.3125, 55.3750,  ..., 37.1562, 34.0000, 23.2969],\n",
      "          ...,\n",
      "          [16.6562, 24.5469, 24.4688,  ..., 28.2188, 28.7656, 20.1562],\n",
      "          [17.7812, 26.9375, 27.8750,  ..., 31.4375, 30.9219, 21.1250],\n",
      "          [15.3750, 23.1875, 24.3125,  ..., 26.7656, 25.9062, 17.5312]],\n",
      "\n",
      "         [[23.6094, 36.9375, 40.5312,  ..., 30.0000, 27.1406, 17.9688],\n",
      "          [27.3750, 43.2188, 48.1250,  ..., 32.0938, 28.5312, 18.6875],\n",
      "          [28.7812, 44.5625, 48.0938,  ..., 32.0938, 29.3594, 20.1406],\n",
      "          ...,\n",
      "          [18.8750, 27.8906, 27.8125,  ..., 32.1250, 32.7188, 22.8906],\n",
      "          [20.1250, 30.5781, 31.7031,  ..., 35.7812, 35.1562, 23.9688],\n",
      "          [17.4219, 26.3594, 27.6719,  ..., 30.4844, 29.5000, 19.9219]]],\n",
      "\n",
      "\n",
      "        [[[22.0469, 34.5312, 39.0938,  ..., 57.2812, 51.6875, 33.6875],\n",
      "          [24.3906, 38.1562, 43.8750,  ..., 71.0625, 63.9375, 41.5000],\n",
      "          [25.6250, 38.4062, 41.6875,  ..., 72.0000, 66.5000, 44.3438],\n",
      "          ...,\n",
      "          [19.7656, 29.5625, 30.2969,  ..., 30.4062, 30.2812, 21.1406],\n",
      "          [20.6250, 31.5312, 33.2188,  ..., 33.8438, 32.7188, 22.2812],\n",
      "          [17.3281, 26.3281, 27.9375,  ..., 28.7031, 27.4688, 18.5469]],\n",
      "\n",
      "         [[22.7031, 35.7188, 40.4375,  ..., 59.6875, 53.7812, 34.9688],\n",
      "          [24.7812, 38.9375, 44.9062,  ..., 73.5000, 66.0000, 42.7188],\n",
      "          [26.0469, 39.1875, 42.6250,  ..., 74.5625, 68.6250, 45.6250],\n",
      "          ...,\n",
      "          [19.0156, 28.4531, 29.1562,  ..., 29.2969, 29.2031, 20.3594],\n",
      "          [19.8750, 30.3906, 32.0312,  ..., 32.6562, 31.5938, 21.4688],\n",
      "          [16.7031, 25.3906, 26.9219,  ..., 27.6875, 26.5000, 17.8594]],\n",
      "\n",
      "         [[19.6875, 30.9844, 35.0938,  ..., 51.9375, 46.8438, 30.3906],\n",
      "          [21.4688, 33.7500, 38.9062,  ..., 64.0000, 57.5000, 37.1562],\n",
      "          [22.5781, 33.9062, 36.8750,  ..., 64.8750, 59.7812, 39.6875],\n",
      "          ...,\n",
      "          [21.5938, 32.4062, 33.2188,  ..., 33.3438, 33.2188, 23.1094],\n",
      "          [22.5469, 34.5625, 36.4688,  ..., 37.1562, 35.9062, 24.3594],\n",
      "          [18.9688, 28.9062, 30.7031,  ..., 31.5469, 30.1719, 20.2969]]],\n",
      "\n",
      "\n",
      "        [[[28.1406, 44.0000, 47.9688,  ..., 25.5000, 24.3281, 17.1719],\n",
      "          [33.3125, 52.1875, 57.0625,  ..., 27.2344, 25.0938, 17.4844],\n",
      "          [34.5000, 52.4688, 54.8125,  ..., 30.0938, 27.8750, 19.7188],\n",
      "          ...,\n",
      "          [19.8906, 29.7188, 30.3906,  ..., 34.3438, 33.9688, 23.3906],\n",
      "          [20.7344, 31.6719, 33.3125,  ..., 36.5938, 35.3438, 23.8906],\n",
      "          [17.3906, 26.4219, 27.9844,  ..., 30.1562, 28.8594, 19.4219]],\n",
      "\n",
      "         [[29.1406, 45.7188, 49.8438,  ..., 26.1719, 24.9688, 17.5625],\n",
      "          [34.1875, 53.7500, 58.8125,  ..., 27.5000, 25.2812, 17.5469],\n",
      "          [35.3750, 54.0000, 56.5000,  ..., 30.5312, 28.2031, 19.8750],\n",
      "          ...,\n",
      "          [19.1250, 28.5938, 29.2344,  ..., 33.0938, 32.7188, 22.5000],\n",
      "          [19.9844, 30.5312, 32.0938,  ..., 35.2812, 34.0938, 23.0156],\n",
      "          [16.7500, 25.4688, 26.9688,  ..., 29.0781, 27.8438, 18.6875]],\n",
      "\n",
      "         [[25.3281, 39.7500, 43.3438,  ..., 22.6094, 21.5938, 15.1797],\n",
      "          [29.7344, 46.7188, 51.1250,  ..., 23.7344, 21.8125, 15.1484],\n",
      "          [30.7500, 46.9375, 49.0938,  ..., 26.3594, 24.3438, 17.1719],\n",
      "          ...,\n",
      "          [21.7188, 32.5625, 33.3438,  ..., 37.7188, 37.2500, 25.5938],\n",
      "          [22.6719, 34.7188, 36.5625,  ..., 40.1875, 38.7812, 26.1406],\n",
      "          [19.0312, 29.0000, 30.7500,  ..., 33.1562, 31.7188, 21.2656]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[24.7188, 38.5938, 42.8750,  ..., 35.6250, 34.4375, 23.3750],\n",
      "          [28.5781, 45.1250, 51.2188,  ..., 41.5312, 40.4375, 27.2031],\n",
      "          [30.3281, 47.0000, 51.6562,  ..., 43.9688, 43.6250, 30.0625],\n",
      "          ...,\n",
      "          [20.8906, 30.5469, 30.5781,  ..., 37.3125, 37.4062, 26.2500],\n",
      "          [22.6562, 33.9062, 35.0000,  ..., 40.7500, 39.9375, 27.5312],\n",
      "          [19.5469, 29.2188, 30.5156,  ..., 34.2812, 33.2812, 22.7500]],\n",
      "\n",
      "         [[25.6094, 40.0938, 44.5000,  ..., 36.8750, 35.6875, 24.1875],\n",
      "          [29.2969, 46.4375, 52.6875,  ..., 42.5000, 41.4688, 27.8281],\n",
      "          [31.0781, 48.3125, 53.0938,  ..., 44.9375, 44.6875, 30.7188],\n",
      "          ...,\n",
      "          [20.0781, 29.3906, 29.4219,  ..., 35.9375, 36.0938, 25.2656],\n",
      "          [21.8125, 32.7188, 33.7500,  ..., 39.2812, 38.5625, 26.5156],\n",
      "          [18.8438, 28.1875, 29.4219,  ..., 33.1250, 32.1562, 21.9062]],\n",
      "\n",
      "         [[22.2969, 34.9375, 38.7500,  ..., 32.0312, 31.0938, 21.0312],\n",
      "          [25.5312, 40.5000, 45.8750,  ..., 36.9375, 36.1250, 24.2188],\n",
      "          [27.0469, 42.0625, 46.2188,  ..., 39.0000, 38.8750, 26.7188],\n",
      "          ...,\n",
      "          [22.8125, 33.4375, 33.5000,  ..., 40.9375, 41.0625, 28.7344],\n",
      "          [24.7656, 37.1875, 38.4062,  ..., 44.7188, 43.8438, 30.1406],\n",
      "          [21.4062, 32.0625, 33.5000,  ..., 37.7188, 36.5938, 24.9375]]],\n",
      "\n",
      "\n",
      "        [[[14.7656, 21.4688, 23.3125,  ..., 30.4219, 27.5469, 18.2656],\n",
      "          [14.6562, 21.3906, 24.5156,  ..., 34.0625, 30.8125, 20.4062],\n",
      "          [15.8594, 23.9844, 27.4688,  ..., 36.8750, 34.3125, 22.6562],\n",
      "          ...,\n",
      "          [19.0312, 27.4062, 26.8125,  ..., 31.9219, 33.1562, 23.7500],\n",
      "          [21.1094, 31.3750, 31.9688,  ..., 36.2188, 36.3438, 25.3906],\n",
      "          [18.5938, 27.6562, 28.6562,  ..., 31.5000, 31.0156, 21.3906]],\n",
      "\n",
      "         [[15.2344, 22.2031, 24.0156,  ..., 31.4531, 28.5156, 18.8281],\n",
      "          [14.8438, 21.7188, 24.8594,  ..., 34.7812, 31.5000, 20.7656],\n",
      "          [16.0938, 24.3906, 27.9219,  ..., 37.6250, 35.0625, 23.0781],\n",
      "          ...,\n",
      "          [18.2969, 26.3594, 25.7969,  ..., 30.7500, 31.9531, 22.8594],\n",
      "          [20.3281, 30.2344, 30.7969,  ..., 34.9375, 35.0625, 24.4531],\n",
      "          [17.9219, 26.6719, 27.6406,  ..., 30.3906, 29.9375, 20.6094]],\n",
      "\n",
      "         [[13.2578, 19.2656, 20.8125,  ..., 27.3125, 24.8125, 16.4062],\n",
      "          [13.0000, 18.8594, 21.5000,  ..., 30.1875, 27.4219, 18.2031],\n",
      "          [13.9297, 21.1094, 24.1562,  ..., 32.5938, 30.4375, 20.0156],\n",
      "          ...,\n",
      "          [20.7500, 29.9688, 29.3281,  ..., 34.9688, 36.3125, 25.9531],\n",
      "          [23.0625, 34.3438, 35.0000,  ..., 39.7500, 39.8438, 27.7656],\n",
      "          [20.3594, 30.3438, 31.4688,  ..., 34.5938, 34.0625, 23.4219]]],\n",
      "\n",
      "\n",
      "        [[[17.2500, 26.2656, 28.9688,  ..., 23.0938, 21.0156, 15.2500],\n",
      "          [17.4531, 27.0781, 31.6250,  ..., 24.2500, 22.1875, 16.2656],\n",
      "          [18.4375, 28.3594, 32.8438,  ..., 28.2969, 24.5781, 16.9219],\n",
      "          ...,\n",
      "          [18.9844, 27.2969, 26.6250,  ..., 31.3125, 32.6562, 23.4688],\n",
      "          [21.0625, 31.2656, 31.7656,  ..., 35.6875, 35.8438, 25.1094],\n",
      "          [18.5625, 27.5625, 28.5000,  ..., 31.1406, 30.7031, 21.2031]],\n",
      "\n",
      "         [[17.7969, 27.1719, 29.9062,  ..., 23.8125, 21.7188, 15.6016],\n",
      "          [17.7188, 27.5938, 32.2188,  ..., 24.5781, 22.5312, 16.2969],\n",
      "          [18.7344, 28.8906, 33.4688,  ..., 28.7656, 24.9844, 17.1562],\n",
      "          ...,\n",
      "          [18.2344, 26.2656, 25.6094,  ..., 30.1562, 31.4844, 22.5781],\n",
      "          [20.2812, 30.1250, 30.6094,  ..., 34.4062, 34.6250, 24.1875],\n",
      "          [17.8906, 26.5938, 27.4844,  ..., 30.0625, 29.6406, 20.4219]],\n",
      "\n",
      "         [[15.4531, 23.6250, 25.9688,  ..., 20.6406, 18.9531, 13.9062],\n",
      "          [15.3828, 23.9531, 27.8906,  ..., 21.2812, 19.8750, 14.8828],\n",
      "          [16.2344, 25.0156, 28.9688,  ..., 24.8906, 21.6406, 15.0391],\n",
      "          ...,\n",
      "          [20.6875, 29.8438, 29.1250,  ..., 34.2812, 35.7500, 25.6406],\n",
      "          [23.0000, 34.2188, 34.7812,  ..., 39.1250, 39.3125, 27.4531],\n",
      "          [20.3125, 30.2500, 31.2969,  ..., 34.1875, 33.7188, 23.2188]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[21.7812, 34.7812, 40.2188,  ..., 45.3125, 40.1875, 25.9375],\n",
      "          [25.3281, 41.0000, 48.4688,  ..., 55.1562, 48.9375, 31.2969],\n",
      "          [27.8281, 43.9688, 49.8438,  ..., 57.9062, 53.3125, 35.4375],\n",
      "          ...,\n",
      "          [21.9062, 31.9844, 32.5625,  ..., 39.1562, 39.1875, 27.7031],\n",
      "          [24.2344, 36.1250, 37.4375,  ..., 42.8438, 42.1562, 29.3281],\n",
      "          [21.1875, 31.4375, 32.8750,  ..., 36.4062, 35.5000, 24.4688]],\n",
      "\n",
      "         [[22.5781, 36.0938, 41.6562,  ..., 47.0625, 41.7188, 26.9219],\n",
      "          [26.0000, 42.1562, 49.7812,  ..., 56.8438, 50.4062, 32.1875],\n",
      "          [28.5156, 45.1562, 51.1562,  ..., 59.5938, 54.8438, 36.4375],\n",
      "          ...,\n",
      "          [21.0781, 30.7969, 31.3438,  ..., 37.7188, 37.7812, 26.6875],\n",
      "          [23.3594, 34.8125, 36.0938,  ..., 41.3125, 40.6562, 28.2656],\n",
      "          [20.4375, 30.3594, 31.7188,  ..., 35.1562, 34.2500, 23.5938]],\n",
      "\n",
      "         [[19.6562, 31.5156, 36.3750,  ..., 41.1250, 36.5000, 23.4688],\n",
      "          [22.6719, 36.8438, 43.4688,  ..., 49.6875, 44.1250, 28.1094],\n",
      "          [24.8281, 39.4062, 44.5938,  ..., 52.0625, 47.9688, 31.7969],\n",
      "          ...,\n",
      "          [23.9375, 35.0625, 35.6875,  ..., 42.9375, 43.0000, 30.3125],\n",
      "          [26.5000, 39.6250, 41.0625,  ..., 47.0312, 46.2500, 32.1250],\n",
      "          [23.2031, 34.5312, 36.0938,  ..., 40.0312, 39.0000, 26.8281]]],\n",
      "\n",
      "\n",
      "        [[[13.6641, 19.9219, 22.6562,  ..., 27.4531, 24.1875, 16.9062],\n",
      "          [13.3984, 19.9688, 24.3125,  ..., 28.7344, 25.2188, 17.7812],\n",
      "          [15.7188, 24.1094, 28.6094,  ..., 30.5938, 26.5312, 17.8906],\n",
      "          ...,\n",
      "          [18.6719, 26.0312, 24.6406,  ..., 31.0312, 32.7812, 24.0156],\n",
      "          [21.2344, 30.7969, 30.4844,  ..., 36.1562, 36.7812, 26.1875],\n",
      "          [19.2188, 27.9844, 28.3750,  ..., 32.2812, 32.1250, 22.5000]],\n",
      "\n",
      "         [[14.0938, 20.5625, 23.3125,  ..., 28.4375, 25.1094, 17.3906],\n",
      "          [13.5625, 20.2812, 24.6406,  ..., 29.3281, 25.7969, 18.0000],\n",
      "          [15.9375, 24.5469, 29.0781,  ..., 31.2188, 27.0781, 18.2500],\n",
      "          ...,\n",
      "          [17.9375, 25.0469, 23.7188,  ..., 29.9062, 31.5938, 23.1094],\n",
      "          [20.4531, 29.6719, 29.3750,  ..., 34.8438, 35.4688, 25.2344],\n",
      "          [18.5312, 27.0000, 27.3906,  ..., 31.1719, 31.0312, 21.6875]],\n",
      "\n",
      "         [[12.2656, 17.8281, 20.1875,  ..., 24.7031, 21.8906, 15.4766],\n",
      "          [11.8281, 17.5625, 21.3125,  ..., 25.4531, 22.6094, 16.2812],\n",
      "          [13.8047, 21.2344, 25.1562,  ..., 27.0625, 23.5000, 15.9531],\n",
      "          ...,\n",
      "          [20.3281, 28.4375, 26.9062,  ..., 33.9688, 35.8750, 26.2188],\n",
      "          [23.1719, 33.6875, 33.3750,  ..., 39.6250, 40.3125, 28.6250],\n",
      "          [21.0156, 30.6719, 31.1250,  ..., 35.4688, 35.2812, 24.6406]]],\n",
      "\n",
      "\n",
      "        [[[13.7109, 19.9375, 22.5469,  ..., 41.6250, 37.2188, 24.1250],\n",
      "          [13.4688, 20.0156, 24.1719,  ..., 49.5625, 44.2500, 28.2969],\n",
      "          [15.7578, 24.1250, 28.4531,  ..., 51.2188, 47.6562, 31.7344],\n",
      "          ...,\n",
      "          [17.9688, 25.0312, 23.9219,  ..., 31.8906, 33.3750, 24.3281],\n",
      "          [20.6875, 30.0469, 30.0781,  ..., 36.8750, 37.2500, 26.4375],\n",
      "          [18.8594, 27.5312, 28.1406,  ..., 32.7188, 32.4062, 22.6406]],\n",
      "\n",
      "         [[14.1406, 20.5938, 23.2188,  ..., 43.1875, 38.6250, 25.0156],\n",
      "          [13.6406, 20.3281, 24.5156,  ..., 51.0000, 45.5000, 29.0781],\n",
      "          [15.9844, 24.5625, 28.9375,  ..., 52.5938, 48.9375, 32.5625],\n",
      "          ...,\n",
      "          [17.2812, 24.0781, 23.0156,  ..., 30.7500, 32.1562, 23.4219],\n",
      "          [19.9219, 28.9688, 28.9844,  ..., 35.5625, 35.9375, 25.4688],\n",
      "          [18.2031, 26.5625, 27.1719,  ..., 31.5781, 31.2969, 21.8281]],\n",
      "\n",
      "         [[12.3203, 17.8438, 20.1094,  ..., 37.7188, 33.7812, 21.7969],\n",
      "          [11.9062, 17.6250, 21.1875,  ..., 44.5312, 39.8125, 25.3594],\n",
      "          [13.8438, 21.2500, 25.0312,  ..., 45.8438, 42.7500, 28.3750],\n",
      "          ...,\n",
      "          [19.5625, 27.3281, 26.1094,  ..., 34.9375, 36.5625, 26.5781],\n",
      "          [22.5625, 32.8750, 32.9062,  ..., 40.4062, 40.8438, 28.9062],\n",
      "          [20.6406, 30.1719, 30.8750,  ..., 35.9375, 35.5938, 24.7969]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[27.8750, 44.1875, 49.6875,  ..., 49.8125, 45.5312, 30.2031],\n",
      "          [32.9062, 52.6562, 60.1562,  ..., 59.8438, 54.8438, 36.3750],\n",
      "          [35.1562, 55.2188, 60.8125,  ..., 61.0000, 57.9062, 39.8125],\n",
      "          ...,\n",
      "          [18.8906, 26.9375, 26.3438,  ..., 31.7188, 32.4688, 23.2344],\n",
      "          [20.1250, 29.7969, 30.2500,  ..., 34.7188, 34.5312, 24.1719],\n",
      "          [17.6719, 26.1094, 26.9219,  ..., 29.8594, 29.2969, 20.2812]],\n",
      "\n",
      "         [[28.8125, 45.8125, 51.4688,  ..., 51.6562, 47.1562, 31.2188],\n",
      "          [33.7500, 54.1875, 61.9062,  ..., 61.5938, 56.3750, 37.3125],\n",
      "          [36.0625, 56.8125, 62.6250,  ..., 62.8125, 59.5000, 40.8438],\n",
      "          ...,\n",
      "          [18.1562, 25.9219, 25.3594,  ..., 30.5625, 31.2812, 22.3594],\n",
      "          [19.3594, 28.7031, 29.1562,  ..., 33.5000, 33.3125, 23.2656],\n",
      "          [17.0156, 25.1719, 25.9688,  ..., 28.8125, 28.2812, 19.5312]],\n",
      "\n",
      "         [[25.1562, 40.0625, 45.0312,  ..., 45.1562, 41.2500, 27.2500],\n",
      "          [29.5000, 47.4688, 54.1562,  ..., 53.8750, 49.3438, 32.5938],\n",
      "          [31.4844, 49.7188, 54.8125,  ..., 54.9375, 52.0625, 35.6875],\n",
      "          ...,\n",
      "          [20.5625, 29.4219, 28.7812,  ..., 34.6875, 35.5000, 25.3594],\n",
      "          [21.9062, 32.5312, 33.0625,  ..., 38.0000, 37.7812, 26.3750],\n",
      "          [19.2969, 28.5781, 29.5000,  ..., 32.7500, 32.1250, 22.1719]]],\n",
      "\n",
      "\n",
      "        [[[27.2031, 43.0312, 48.4375,  ..., 26.8594, 25.9531, 18.7031],\n",
      "          [31.8750, 50.9062, 58.2500,  ..., 28.4531, 26.8906, 19.2656],\n",
      "          [34.0000, 53.2812, 58.7188,  ..., 32.3125, 30.7500, 22.3906],\n",
      "          ...,\n",
      "          [20.2500, 29.4844, 29.5312,  ..., 33.6562, 33.9688, 24.1094],\n",
      "          [21.4844, 32.1250, 33.0938,  ..., 36.4062, 35.8750, 24.9688],\n",
      "          [18.5781, 27.6406, 28.7500,  ..., 30.9219, 30.1719, 20.7969]],\n",
      "\n",
      "         [[28.1250, 44.5938, 50.1562,  ..., 27.6094, 26.6562, 19.2031],\n",
      "          [32.6562, 52.3750, 59.9062,  ..., 28.8594, 27.2344, 19.5000],\n",
      "          [34.8438, 54.7812, 60.4062,  ..., 32.9062, 31.2188, 22.7344],\n",
      "          ...,\n",
      "          [19.4531, 28.3906, 28.4375,  ..., 32.4375, 32.7500, 23.2031],\n",
      "          [20.6875, 30.9531, 31.8906,  ..., 35.1250, 34.6250, 24.0312],\n",
      "          [17.8906, 26.6562, 27.7344,  ..., 29.8438, 29.1250, 20.0312]],\n",
      "\n",
      "         [[24.5469, 39.0000, 43.8750,  ..., 23.9531, 23.1562, 16.6719],\n",
      "          [28.5312, 45.8438, 52.4062,  ..., 25.0156, 23.6250, 16.9219],\n",
      "          [30.4062, 47.9062, 52.8438,  ..., 28.5000, 27.0938, 19.7344],\n",
      "          ...,\n",
      "          [22.0625, 32.2500, 32.3125,  ..., 36.8438, 37.1875, 26.3281],\n",
      "          [23.4375, 35.1250, 36.2188,  ..., 39.8438, 39.2812, 27.2500],\n",
      "          [20.2969, 30.2656, 31.5156,  ..., 33.9062, 33.0625, 22.7344]]],\n",
      "\n",
      "\n",
      "        [[[18.2188, 27.7969, 32.1562,  ..., 49.7188, 45.5312, 30.2031],\n",
      "          [18.5469, 28.4375, 34.2812,  ..., 59.6875, 54.8438, 36.3750],\n",
      "          [20.1562, 30.0781, 34.2500,  ..., 60.7812, 57.8438, 39.8125],\n",
      "          ...,\n",
      "          [18.3906, 26.0781, 25.3438,  ..., 32.5938, 33.3438, 23.8125],\n",
      "          [19.6094, 28.9688, 29.3125,  ..., 35.3438, 35.1875, 24.6250],\n",
      "          [17.3594, 25.5781, 26.2969,  ..., 30.1562, 29.6562, 20.5312]],\n",
      "\n",
      "         [[18.7344, 28.6250, 33.0938,  ..., 51.5625, 47.1250, 31.2188],\n",
      "          [18.7812, 28.8750, 34.8438,  ..., 61.4375, 56.3438, 37.3125],\n",
      "          [20.4375, 30.5938, 34.8438,  ..., 62.5938, 59.4375, 40.8438],\n",
      "          ...,\n",
      "          [17.6875, 25.0938, 24.3906,  ..., 31.4062, 32.1562, 22.9062],\n",
      "          [18.8750, 27.9219, 28.2344,  ..., 34.0938, 33.9688, 23.7031],\n",
      "          [16.7344, 24.6562, 25.3594,  ..., 29.1094, 28.6250, 19.7656]],\n",
      "\n",
      "         [[16.2812, 24.8906, 28.7500,  ..., 45.0625, 41.2500, 27.2500],\n",
      "          [16.3281, 25.0781, 30.2344,  ..., 53.7188, 49.3125, 32.5938],\n",
      "          [17.7500, 26.5312, 30.2188,  ..., 54.7188, 52.0000, 35.6562],\n",
      "          ...,\n",
      "          [20.0156, 28.4531, 27.6719,  ..., 35.6562, 36.5000, 26.0000],\n",
      "          [21.3594, 31.6406, 32.0312,  ..., 38.6875, 38.5312, 26.8750],\n",
      "          [18.9531, 27.9688, 28.7969,  ..., 33.0625, 32.5000, 22.4375]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[24.1250, 37.7500, 42.2500,  ..., 29.7188, 28.2344, 20.1875],\n",
      "          [27.0469, 42.7500, 49.0000,  ..., 30.3281, 28.7812, 20.7656],\n",
      "          [29.0781, 44.9688, 49.5312,  ..., 31.4531, 31.0156, 23.2812],\n",
      "          ...,\n",
      "          [16.6875, 23.1250, 21.9062,  ..., 25.8125, 27.4062, 20.2812],\n",
      "          [17.8125, 25.9219, 26.0781,  ..., 29.8125, 30.0938, 21.3594],\n",
      "          [16.2188, 23.5938, 24.2344,  ..., 26.7656, 26.4219, 18.5000]],\n",
      "\n",
      "         [[24.8125, 38.9375, 43.5938,  ..., 30.5156, 28.9531, 20.6875],\n",
      "          [27.5312, 43.7188, 50.1250,  ..., 30.7344, 29.0938, 20.9844],\n",
      "          [29.6406, 46.0312, 50.7188,  ..., 31.9844, 31.4375, 23.6094],\n",
      "          ...,\n",
      "          [16.0781, 22.2656, 21.0781,  ..., 24.8594, 26.4062, 19.5156],\n",
      "          [17.1719, 24.9688, 25.1250,  ..., 28.7344, 29.0156, 20.5625],\n",
      "          [15.6406, 22.7500, 23.3594,  ..., 25.8125, 25.5000, 17.8125]],\n",
      "\n",
      "         [[21.6250, 34.0000, 38.0625,  ..., 26.5156, 25.1719, 17.9688],\n",
      "          [24.0000, 38.1875, 43.7500,  ..., 26.6562, 25.2500, 18.2031],\n",
      "          [25.8281, 40.1562, 44.2500,  ..., 27.7188, 27.2812, 20.5156],\n",
      "          ...,\n",
      "          [18.1094, 25.1719, 23.8594,  ..., 28.1562, 29.8906, 22.0625],\n",
      "          [19.3438, 28.2344, 28.4375,  ..., 32.5312, 32.8438, 23.2500],\n",
      "          [17.6719, 25.7656, 26.4844,  ..., 29.2812, 28.9062, 20.1719]]],\n",
      "\n",
      "\n",
      "        [[[29.0156, 46.2812, 52.0000,  ..., 54.0000, 49.6562, 33.1875],\n",
      "          [34.1562, 55.3125, 63.2812,  ..., 65.6250, 60.2188, 40.2500],\n",
      "          [36.1562, 57.8125, 64.3125,  ..., 67.6875, 63.5625, 43.8750],\n",
      "          ...,\n",
      "          [19.6406, 28.1250, 27.7344,  ..., 28.1562, 29.9844, 22.0469],\n",
      "          [20.4531, 30.4219, 31.2344,  ..., 31.5000, 31.8281, 22.5781],\n",
      "          [17.8906, 26.4688, 27.5312,  ..., 27.8438, 27.4375, 19.1562]],\n",
      "\n",
      "         [[29.9219, 47.8750, 53.7812,  ..., 55.8750, 51.3125, 34.2500],\n",
      "          [34.9688, 56.8125, 65.0000,  ..., 67.5000, 61.8125, 41.2500],\n",
      "          [37.0000, 59.4062, 66.1250,  ..., 69.6250, 65.2500, 45.0000],\n",
      "          ...,\n",
      "          [18.9062, 27.0625, 26.7031,  ..., 27.1406, 28.9219, 21.2188],\n",
      "          [19.6875, 29.3125, 30.0938,  ..., 30.3906, 30.7188, 21.7500],\n",
      "          [17.2344, 25.5156, 26.5625,  ..., 26.8750, 26.4844, 18.4531]],\n",
      "\n",
      "         [[26.1406, 41.9062, 47.0938,  ..., 48.9062, 44.9375, 29.9219],\n",
      "          [30.5781, 49.7812, 56.9688,  ..., 59.0938, 54.1562, 36.0625],\n",
      "          [32.3438, 52.0312, 58.0000,  ..., 61.0625, 57.1875, 39.3438],\n",
      "          ...,\n",
      "          [21.3750, 30.6875, 30.2812,  ..., 30.7656, 32.7500, 24.0312],\n",
      "          [22.2500, 33.1875, 34.1250,  ..., 34.4375, 34.7500, 24.6094],\n",
      "          [19.5156, 28.9375, 30.1406,  ..., 30.4844, 30.0312, 20.9062]]],\n",
      "\n",
      "\n",
      "        [[[27.7031, 44.1562, 49.4375,  ..., 43.6250, 37.4688, 24.4688],\n",
      "          [31.8750, 51.6250, 59.0938,  ..., 49.1875, 41.5000, 26.9219],\n",
      "          [33.3125, 53.2812, 59.2188,  ..., 47.9688, 42.1250, 28.9688],\n",
      "          ...,\n",
      "          [20.7969, 30.1875, 30.1875,  ..., 32.0312, 32.6562, 23.3594],\n",
      "          [21.5469, 32.2500, 33.3438,  ..., 34.7500, 34.2812, 23.9062],\n",
      "          [18.5469, 27.6406, 28.8594,  ..., 29.6875, 28.9062, 19.9688]],\n",
      "\n",
      "         [[28.5312, 45.6562, 51.0625,  ..., 45.0312, 38.5625, 25.1094],\n",
      "          [32.5625, 52.9688, 60.6562,  ..., 50.3438, 42.2812, 27.3438],\n",
      "          [34.0625, 54.6562, 60.8750,  ..., 49.0938, 42.9375, 29.4531],\n",
      "          ...,\n",
      "          [20.0000, 29.0625, 29.0781,  ..., 30.8594, 31.5000, 22.4688],\n",
      "          [20.7344, 31.0781, 32.1250,  ..., 33.5000, 33.0625, 23.0156],\n",
      "          [17.8750, 26.6406, 27.8438,  ..., 28.6406, 27.9062, 19.2344]],\n",
      "\n",
      "         [[24.9219, 39.9375, 44.6875,  ..., 39.3125, 33.6562, 21.8594],\n",
      "          [28.4531, 46.3438, 53.0938,  ..., 43.9062, 36.8750, 23.7812],\n",
      "          [29.7344, 47.8125, 53.2812,  ..., 42.7812, 37.3750, 25.6250],\n",
      "          ...,\n",
      "          [22.6562, 32.9688, 32.9688,  ..., 35.0000, 35.7188, 25.4688],\n",
      "          [23.4688, 35.2188, 36.4688,  ..., 38.0000, 37.4688, 26.0625],\n",
      "          [20.2500, 30.2344, 31.6094,  ..., 32.5000, 31.6562, 21.7969]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[26.6719, 43.7188, 50.1250,  ..., 42.3750, 35.2188, 22.0000],\n",
      "          [31.7656, 52.8125, 61.7500,  ..., 49.3438, 40.0938, 24.6094],\n",
      "          [34.9688, 57.1562, 64.5625,  ..., 51.4375, 43.6875, 28.2188],\n",
      "          ...,\n",
      "          [22.6094, 32.1250, 31.5312,  ..., 35.5312, 36.3125, 26.5469],\n",
      "          [24.1094, 35.2500, 35.7812,  ..., 38.6250, 38.4688, 27.5469],\n",
      "          [21.0625, 30.6094, 31.5312,  ..., 33.4375, 32.9375, 23.3281]],\n",
      "\n",
      "         [[27.5469, 45.1875, 51.7812,  ..., 43.7500, 36.2500, 22.6250],\n",
      "          [32.5000, 54.2188, 63.4375,  ..., 50.5625, 40.8750, 25.0312],\n",
      "          [35.7812, 58.7188, 66.3750,  ..., 52.7188, 44.5938, 28.7656],\n",
      "          ...,\n",
      "          [21.7969, 30.9531, 30.4219,  ..., 34.2812, 35.0000, 25.5938],\n",
      "          [23.2500, 33.9688, 34.5000,  ..., 37.2500, 37.1250, 26.5625],\n",
      "          [20.3438, 29.5625, 30.4531,  ..., 32.2812, 31.8125, 22.5000]],\n",
      "\n",
      "         [[24.0781, 39.6250, 45.4062,  ..., 38.2812, 31.6875, 19.6875],\n",
      "          [28.4688, 47.6250, 55.6562,  ..., 44.2188, 35.7500, 21.7969],\n",
      "          [31.3438, 51.5312, 58.2500,  ..., 46.1250, 38.9688, 25.0625],\n",
      "          ...,\n",
      "          [24.6406, 35.0625, 34.4688,  ..., 38.8438, 39.6562, 28.9375],\n",
      "          [26.2656, 38.4688, 39.0938,  ..., 42.2188, 42.0625, 30.0312],\n",
      "          [23.0000, 33.5000, 34.5312,  ..., 36.6250, 36.0312, 25.4688]]],\n",
      "\n",
      "\n",
      "        [[[14.5625, 21.5625, 23.6250,  ..., 23.8438, 23.0000, 16.5781],\n",
      "          [13.7578, 20.3125, 23.5000,  ..., 23.5781, 22.7812, 16.9688],\n",
      "          [15.8984, 23.3125, 25.8594,  ..., 26.4219, 26.2500, 19.2812],\n",
      "          ...,\n",
      "          [18.2188, 24.5938, 23.2031,  ..., 27.4688, 29.6719, 22.6094],\n",
      "          [20.1094, 28.5625, 28.4062,  ..., 32.0312, 33.0000, 24.2188],\n",
      "          [18.5625, 26.4531, 26.9219,  ..., 29.3594, 29.5000, 21.2344]],\n",
      "\n",
      "         [[14.9297, 22.1562, 24.2188,  ..., 24.5000, 23.6094, 17.0000],\n",
      "          [13.8594, 20.5156, 23.7500,  ..., 23.8750, 23.0312, 17.1250],\n",
      "          [16.0781, 23.6719, 26.2656,  ..., 26.8594, 26.6250, 19.5938],\n",
      "          ...,\n",
      "          [17.5781, 23.7031, 22.3906,  ..., 26.5156, 28.6406, 21.7969],\n",
      "          [19.4062, 27.5469, 27.4062,  ..., 30.9062, 31.8438, 23.3594],\n",
      "          [17.9219, 25.5469, 26.0156,  ..., 28.3750, 28.5000, 20.4844]],\n",
      "\n",
      "         [[12.9766, 19.2500, 21.0312,  ..., 21.2812, 20.5312, 14.8438],\n",
      "          [12.0312, 17.7969, 20.5625,  ..., 20.7031, 20.0156, 15.0547],\n",
      "          [13.9375, 20.5156, 22.7344,  ..., 23.2812, 23.1250, 17.0156],\n",
      "          ...,\n",
      "          [19.7812, 26.7500, 25.2656,  ..., 29.9531, 32.3750, 24.5938],\n",
      "          [21.8594, 31.0938, 30.9688,  ..., 34.9375, 36.0000, 26.3594],\n",
      "          [20.2188, 28.8750, 29.4219,  ..., 32.1250, 32.2500, 23.1562]]],\n",
      "\n",
      "\n",
      "        [[[18.0938, 27.7812, 30.8125,  ..., 42.8750, 40.1562, 27.0156],\n",
      "          [20.6094, 31.9531, 36.3125,  ..., 50.7500, 47.8125, 32.3438],\n",
      "          [25.3906, 39.1875, 42.6562,  ..., 53.9375, 52.3750, 36.7812],\n",
      "          ...,\n",
      "          [23.6875, 34.0938, 34.5000,  ..., 38.7812, 38.9375, 28.0625],\n",
      "          [24.9844, 36.8125, 38.0312,  ..., 41.4375, 40.7812, 28.9062],\n",
      "          [21.6562, 31.6250, 32.9375,  ..., 35.1875, 34.3750, 24.1875]],\n",
      "\n",
      "         [[18.6094, 28.5938, 31.6719,  ..., 44.2500, 41.4062, 27.8594],\n",
      "          [20.9531, 32.5625, 36.9688,  ..., 52.0312, 48.9062, 33.0625],\n",
      "          [25.8906, 40.0312, 43.5938,  ..., 55.3125, 53.6250, 37.6250],\n",
      "          ...,\n",
      "          [22.8281, 32.8438, 33.2500,  ..., 37.4062, 37.5312, 27.0469],\n",
      "          [24.1094, 35.4688, 36.6562,  ..., 39.9688, 39.3438, 27.8750],\n",
      "          [20.9062, 30.5469, 31.7969,  ..., 33.9688, 33.1875, 23.3281]],\n",
      "\n",
      "         [[16.2031, 24.9219, 27.6094,  ..., 38.7188, 36.2812, 24.3281],\n",
      "          [18.2500, 28.4062, 32.2188,  ..., 45.5312, 42.8438, 28.9062],\n",
      "          [22.5625, 34.9688, 38.0312,  ..., 48.4062, 46.9688, 32.9062],\n",
      "          ...,\n",
      "          [25.8125, 37.2500, 37.7188,  ..., 42.4062, 42.5625, 30.6094],\n",
      "          [27.2344, 40.1875, 41.5938,  ..., 45.3438, 44.5938, 31.5312],\n",
      "          [23.6406, 34.6250, 36.0625,  ..., 38.5625, 37.6562, 26.4062]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[26.5312, 43.0938, 48.6250,  ..., 26.7656, 25.9844, 18.2344],\n",
      "          [31.2188, 51.2500, 58.8438,  ..., 26.8438, 26.2812, 18.6562],\n",
      "          [34.1250, 54.9688, 60.8438,  ..., 28.5469, 29.0000, 21.3750],\n",
      "          ...,\n",
      "          [22.8438, 32.7812, 33.1875,  ..., 31.1562, 32.5000, 24.2656],\n",
      "          [23.7656, 34.9375, 36.2188,  ..., 34.4062, 34.6250, 25.1094],\n",
      "          [20.6406, 30.0625, 31.3750,  ..., 30.4062, 30.1094, 21.5312]],\n",
      "\n",
      "         [[27.3125, 44.4688, 50.1875,  ..., 27.4375, 26.5781, 18.6562],\n",
      "          [31.8906, 52.5625, 60.3750,  ..., 27.1562, 26.5312, 18.8281],\n",
      "          [34.9062, 56.4375, 62.5312,  ..., 28.9844, 29.3750, 21.6406],\n",
      "          ...,\n",
      "          [22.0312, 31.6406, 32.0625,  ..., 30.1094, 31.4062, 23.3906],\n",
      "          [22.9219, 33.7500, 35.0000,  ..., 33.2500, 33.4688, 24.2188],\n",
      "          [19.9219, 29.0312, 30.3125,  ..., 29.3906, 29.0938, 20.7656]],\n",
      "\n",
      "         [[23.8906, 39.0000, 44.0000,  ..., 23.8906, 23.1719, 16.2344],\n",
      "          [27.9219, 46.1250, 52.9688,  ..., 23.6094, 23.0938, 16.3750],\n",
      "          [30.5469, 49.5000, 54.8438,  ..., 25.1719, 25.5469, 18.8438],\n",
      "          ...,\n",
      "          [24.8594, 35.7812, 36.2500,  ..., 33.9688, 35.4375, 26.3906],\n",
      "          [25.8594, 38.1250, 39.5625,  ..., 37.5312, 37.7812, 27.3125],\n",
      "          [22.5000, 32.8438, 34.3125,  ..., 33.2500, 32.9062, 23.4531]]],\n",
      "\n",
      "\n",
      "        [[[15.6719, 23.3438, 25.0625,  ..., 31.3750, 29.6250, 19.9531],\n",
      "          [15.0234, 22.1250, 24.6250,  ..., 33.0000, 31.4531, 21.2969],\n",
      "          [16.9531, 24.4375, 26.0000,  ..., 32.9688, 33.2188, 23.7812],\n",
      "          ...,\n",
      "          [20.2656, 28.2031, 27.5156,  ..., 32.8438, 33.8438, 25.0156],\n",
      "          [21.4375, 30.9844, 31.4219,  ..., 35.8438, 35.8125, 25.8125],\n",
      "          [19.1562, 27.5781, 28.4062,  ..., 31.2969, 30.8750, 21.9844]],\n",
      "\n",
      "         [[16.0312, 23.9219, 25.6406,  ..., 32.2188, 30.3750, 20.4531],\n",
      "          [15.1250, 22.3281, 24.8594,  ..., 33.5312, 31.8906, 21.5469],\n",
      "          [17.1250, 24.7812, 26.3750,  ..., 33.5312, 33.7188, 24.1250],\n",
      "          ...,\n",
      "          [19.5312, 27.2188, 26.5781,  ..., 31.7344, 32.6875, 24.1250],\n",
      "          [20.6719, 29.8906, 30.3438,  ..., 34.6250, 34.6250, 24.8906],\n",
      "          [18.4844, 26.6250, 27.4531,  ..., 30.2344, 29.8281, 21.2031]],\n",
      "\n",
      "         [[13.9453, 20.8281, 22.3125,  ..., 28.0938, 26.5156, 17.8125],\n",
      "          [13.1328, 19.4062, 21.5625,  ..., 29.2344, 27.8125, 18.7812],\n",
      "          [14.8672, 21.5156, 22.8438,  ..., 29.1875, 29.3750, 21.0312],\n",
      "          ...,\n",
      "          [22.0000, 30.7188, 29.9844,  ..., 35.8438, 36.9062, 27.2188],\n",
      "          [23.2812, 33.7500, 34.2500,  ..., 39.1250, 39.0938, 28.0938],\n",
      "          [20.8750, 30.0938, 31.0312,  ..., 34.2188, 33.7188, 23.9688]]],\n",
      "\n",
      "\n",
      "        [[[17.2969, 26.4062, 28.9375,  ..., 50.3438, 45.4688, 29.8281],\n",
      "          [17.7656, 27.1562, 30.8281,  ..., 60.2812, 53.9688, 35.4062],\n",
      "          [20.4531, 30.4062, 32.6250,  ..., 60.3438, 54.8750, 37.1562],\n",
      "          ...,\n",
      "          [22.7500, 32.5625, 32.8125,  ..., 38.4062, 38.3438, 27.6250],\n",
      "          [23.7188, 34.8125, 36.0000,  ..., 40.5625, 39.6875, 28.1094],\n",
      "          [20.6094, 30.0000, 31.2500,  ..., 34.2500, 33.3125, 23.4375]],\n",
      "\n",
      "         [[17.7344, 27.0938, 29.6719,  ..., 52.0000, 46.9062, 30.7188],\n",
      "          [17.9531, 27.5156, 31.2500,  ..., 61.9062, 55.2500, 36.1875],\n",
      "          [20.7344, 30.9062, 33.1562,  ..., 62.0312, 56.1875, 38.0000],\n",
      "          ...,\n",
      "          [21.9375, 31.4219, 31.7031,  ..., 37.1250, 37.0312, 26.6406],\n",
      "          [22.8750, 33.6250, 34.7812,  ..., 39.1875, 38.3438, 27.1094],\n",
      "          [19.8906, 28.9688, 30.2031,  ..., 33.0938, 32.1875, 22.6094]],\n",
      "\n",
      "         [[15.4531, 23.6250, 25.8750,  ..., 45.5938, 41.1250, 26.8750],\n",
      "          [15.6406, 24.0000, 27.2031,  ..., 54.3125, 48.4688, 31.6875],\n",
      "          [18.0625, 26.9219, 28.8438,  ..., 54.3750, 49.2500, 33.2500],\n",
      "          ...,\n",
      "          [24.7500, 35.5312, 35.8438,  ..., 41.9688, 41.8750, 30.1094],\n",
      "          [25.8125, 37.9688, 39.3125,  ..., 44.3125, 43.3438, 30.6250],\n",
      "          [22.4688, 32.7500, 34.1875,  ..., 37.4688, 36.4062, 25.5625]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[18.2812, 26.8281, 27.7500,  ..., 64.0000, 59.1562, 39.1250],\n",
      "          [17.5938, 25.3125, 26.6562,  ..., 78.3750, 72.6875, 48.3125],\n",
      "          [18.9531, 26.5938, 26.8594,  ..., 79.1250, 75.5000, 51.6875],\n",
      "          ...,\n",
      "          [20.5312, 28.9062, 28.3594,  ..., 39.5938, 39.5625, 28.4531],\n",
      "          [21.4375, 31.2500, 32.0000,  ..., 41.2812, 40.3125, 28.4531],\n",
      "          [19.1250, 27.6875, 28.6875,  ..., 34.4688, 33.4688, 23.5312]],\n",
      "\n",
      "         [[18.6875, 27.4375, 28.3750,  ..., 66.1875, 61.0625, 40.3438],\n",
      "          [17.7031, 25.5156, 26.8906,  ..., 80.6250, 74.6250, 49.5312],\n",
      "          [19.1406, 26.9219, 27.2188,  ..., 81.5000, 77.5000, 53.0312],\n",
      "          ...,\n",
      "          [19.8281, 27.9375, 27.4375,  ..., 38.3125, 38.2500, 27.4688],\n",
      "          [20.7031, 30.2031, 30.9531,  ..., 39.9375, 39.0000, 27.4844],\n",
      "          [18.4844, 26.7656, 27.7344,  ..., 33.3438, 32.3750, 22.7188]],\n",
      "\n",
      "         [[16.2969, 23.9531, 24.7500,  ..., 58.1562, 53.6875, 35.4062],\n",
      "          [15.4219, 22.2344, 23.3594,  ..., 70.9375, 65.6250, 43.5312],\n",
      "          [16.6719, 23.4375, 23.6250,  ..., 71.6875, 68.1875, 46.5938],\n",
      "          ...,\n",
      "          [22.2812, 31.4375, 30.8750,  ..., 43.2188, 43.1562, 30.9688],\n",
      "          [23.2656, 34.0000, 34.8438,  ..., 45.0625, 44.0000, 30.9688],\n",
      "          [20.8125, 30.1719, 31.2969,  ..., 37.6562, 36.5625, 25.6250]]],\n",
      "\n",
      "\n",
      "        [[[18.2344, 26.7656, 27.7188,  ..., 64.7500, 58.9062, 38.9062],\n",
      "          [17.5469, 25.2812, 26.6406,  ..., 80.0000, 72.4375, 47.9688],\n",
      "          [18.8750, 26.5469, 26.7969,  ..., 82.9375, 76.4375, 52.0000],\n",
      "          ...,\n",
      "          [20.7500, 29.2969, 28.8438,  ..., 39.5000, 39.4688, 28.3906],\n",
      "          [21.7812, 31.7969, 32.5625,  ..., 41.2500, 40.2812, 28.4219],\n",
      "          [19.3906, 28.0938, 29.1094,  ..., 34.4688, 33.4688, 23.5312]],\n",
      "\n",
      "         [[18.6250, 27.3750, 28.3438,  ..., 66.9375, 60.8125, 40.0938],\n",
      "          [17.6562, 25.4688, 26.8750,  ..., 82.3125, 74.3125, 49.1875],\n",
      "          [19.0625, 26.8594, 27.1406,  ..., 85.4375, 78.5000, 53.3438],\n",
      "          ...,\n",
      "          [20.0312, 28.3125, 27.9062,  ..., 38.2188, 38.1562, 27.4062],\n",
      "          [21.0312, 30.7344, 31.5156,  ..., 39.9062, 38.9688, 27.4531],\n",
      "          [18.7344, 27.1562, 28.1406,  ..., 33.3750, 32.3750, 22.7188]],\n",
      "\n",
      "         [[16.2500, 23.9062, 24.7188,  ..., 58.8438, 53.4688, 35.1875],\n",
      "          [15.3828, 22.2031, 23.3594,  ..., 72.4375, 65.3750, 43.1875],\n",
      "          [16.5938, 23.3906, 23.5625,  ..., 75.1875, 69.0625, 46.8750],\n",
      "          ...,\n",
      "          [22.5156, 31.8750, 31.4062,  ..., 43.1250, 43.0625, 30.9062],\n",
      "          [23.6406, 34.5938, 35.5000,  ..., 45.0312, 43.9688, 30.9375],\n",
      "          [21.0938, 30.6250, 31.7656,  ..., 37.6875, 36.5625, 25.6250]]],\n",
      "\n",
      "\n",
      "        [[[30.6406, 50.8750, 58.9688,  ..., 37.4375, 37.0625, 25.4219],\n",
      "          [35.7500, 60.5625, 72.0000,  ..., 40.0000, 40.4688, 28.2344],\n",
      "          [38.1875, 63.7812, 74.0000,  ..., 40.1250, 42.7188, 31.1562],\n",
      "          ...,\n",
      "          [24.2812, 35.1250, 35.6562,  ..., 34.3438, 35.0938, 25.7656],\n",
      "          [24.7031, 36.5938, 38.1875,  ..., 37.0625, 36.6875, 26.2344],\n",
      "          [21.1406, 31.0000, 32.4688,  ..., 31.9688, 31.2812, 22.1562]],\n",
      "\n",
      "         [[31.5312, 52.5000, 60.8750,  ..., 38.4688, 38.0312, 26.0469],\n",
      "          [36.5312, 62.1250, 73.9375,  ..., 40.6875, 41.1250, 28.6406],\n",
      "          [39.0625, 65.4375, 76.1250,  ..., 40.9062, 43.4688, 31.6719],\n",
      "          ...,\n",
      "          [23.4531, 33.9375, 34.5000,  ..., 33.2500, 33.9688, 24.8750],\n",
      "          [23.8594, 35.3750, 36.9375,  ..., 35.8750, 35.5000, 25.3281],\n",
      "          [20.4375, 29.9531, 31.4219,  ..., 30.9219, 30.2500, 21.4062]],\n",
      "\n",
      "         [[27.6562, 46.1250, 53.5312,  ..., 33.6250, 33.3125, 22.7656],\n",
      "          [32.0625, 54.6250, 65.0000,  ..., 35.5312, 35.9688, 25.0469],\n",
      "          [34.2500, 57.5312, 66.9375,  ..., 35.6875, 37.9688, 27.7031],\n",
      "          ...,\n",
      "          [26.4219, 38.2812, 38.9062,  ..., 37.4375, 38.2500, 28.0156],\n",
      "          [26.8594, 39.9062, 41.6875,  ..., 40.4375, 40.0000, 28.5312],\n",
      "          [23.0312, 33.8125, 35.4688,  ..., 34.9062, 34.1250, 24.1250]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[19.9844, 28.9844, 29.0156,  ..., 31.6875, 32.5625, 23.5312],\n",
      "          [18.5156, 26.1719, 26.5312,  ..., 30.1094, 31.9531, 23.9062],\n",
      "          [19.0000, 26.1406, 25.4688,  ..., 29.4062, 33.0000, 25.7500],\n",
      "          ...,\n",
      "          [25.3281, 36.6562, 36.6250,  ..., 38.9062, 39.6875, 28.7344],\n",
      "          [25.6094, 38.0625, 39.3125,  ..., 41.2188, 40.7812, 28.7812],\n",
      "          [21.9375, 32.2812, 33.5312,  ..., 34.8438, 34.0938, 23.9219]],\n",
      "\n",
      "         [[20.3906, 29.5781, 29.6094,  ..., 32.3750, 33.2188, 24.0000],\n",
      "          [18.5781, 26.2812, 26.6719,  ..., 30.3438, 32.1875, 24.0625],\n",
      "          [19.1250, 26.3750, 25.7344,  ..., 29.7656, 33.3125, 26.0156],\n",
      "          ...,\n",
      "          [24.4844, 35.4375, 35.4375,  ..., 37.6562, 38.4062, 27.7969],\n",
      "          [24.7656, 36.7812, 38.0000,  ..., 39.8750, 39.4375, 27.8438],\n",
      "          [21.2344, 31.2031, 32.4375,  ..., 33.6875, 32.9688, 23.1250]],\n",
      "\n",
      "         [[17.8281, 25.8594, 25.8594,  ..., 28.3125, 29.0781, 21.0000],\n",
      "          [16.2188, 22.9375, 23.2031,  ..., 26.4688, 28.1406, 21.0469],\n",
      "          [16.6719, 22.9688, 22.3438,  ..., 25.9375, 29.0938, 22.7344],\n",
      "          ...,\n",
      "          [27.5156, 39.9062, 39.9062,  ..., 42.4062, 43.2812, 31.2656],\n",
      "          [27.8125, 41.4375, 42.8438,  ..., 44.9688, 44.4375, 31.2969],\n",
      "          [23.8906, 35.1875, 36.5938,  ..., 38.0312, 37.2188, 26.0312]]],\n",
      "\n",
      "\n",
      "        [[[34.4062, 54.8750, 60.1250,  ..., 61.9375, 57.5312, 38.3438],\n",
      "          [39.7500, 63.8750, 71.0625,  ..., 73.0625, 67.6250, 45.3750],\n",
      "          [41.7500, 66.0625, 71.5625,  ..., 73.8125, 69.9375, 48.4062],\n",
      "          ...,\n",
      "          [28.5312, 41.9688, 43.0000,  ..., 40.8125, 41.2500, 29.5312],\n",
      "          [28.4531, 42.7500, 44.7812,  ..., 42.7812, 41.9375, 29.3438],\n",
      "          [23.7031, 35.1562, 36.9062,  ..., 35.5938, 34.6250, 24.1719]],\n",
      "\n",
      "         [[35.3125, 56.4688, 61.9062,  ..., 63.8125, 59.1562, 39.3438],\n",
      "          [40.5000, 65.3125, 72.8750,  ..., 74.9375, 69.1875, 46.2812],\n",
      "          [42.5938, 67.6875, 73.5000,  ..., 75.8125, 71.6250, 49.4375],\n",
      "          ...,\n",
      "          [27.5938, 40.5625, 41.5625,  ..., 39.4688, 39.8750, 28.5469],\n",
      "          [27.5312, 41.3125, 43.3125,  ..., 41.3750, 40.5312, 28.3750],\n",
      "          [22.9219, 34.0000, 35.6875,  ..., 34.4375, 33.4688, 23.3594]],\n",
      "\n",
      "         [[31.0469, 49.7188, 54.5000,  ..., 56.1562, 52.0625, 34.5938],\n",
      "          [35.6250, 57.5312, 64.0625,  ..., 65.9375, 60.8750, 40.6875],\n",
      "          [37.4688, 59.5625, 64.6250,  ..., 66.6875, 63.0000, 43.4688],\n",
      "          ...,\n",
      "          [31.0469, 45.7812, 46.9062,  ..., 44.5000, 44.9688, 32.1250],\n",
      "          [30.9688, 46.6250, 48.9062,  ..., 46.6562, 45.7188, 31.9219],\n",
      "          [25.8125, 38.3750, 40.3125,  ..., 38.8750, 37.7812, 26.3125]]],\n",
      "\n",
      "\n",
      "        [[[19.7969, 28.6250, 28.4531,  ..., 30.4219, 32.0625, 23.4219],\n",
      "          [18.3594, 25.8281, 25.8594,  ..., 27.7969, 30.4688, 23.2344],\n",
      "          [18.9688, 26.0000, 25.0156,  ..., 26.7656, 30.7656, 24.6250],\n",
      "          ...,\n",
      "          [24.0469, 34.6250, 34.3125,  ..., 39.6875, 40.5312, 29.2969],\n",
      "          [24.4844, 36.2812, 37.3125,  ..., 41.7188, 41.3125, 29.1719],\n",
      "          [21.2656, 31.1719, 32.2812,  ..., 35.0625, 34.3750, 24.1250]],\n",
      "\n",
      "         [[20.1875, 29.2188, 29.0312,  ..., 31.0781, 32.6875, 23.8750],\n",
      "          [18.4219, 25.9375, 25.9844,  ..., 27.9844, 30.6719, 23.3750],\n",
      "          [19.0938, 26.2031, 25.2500,  ..., 27.0781, 31.0625, 24.8438],\n",
      "          ...,\n",
      "          [23.2500, 33.4688, 33.2188,  ..., 38.4062, 39.1875, 28.3281],\n",
      "          [23.6875, 35.0938, 36.0938,  ..., 40.3750, 39.9688, 28.2031],\n",
      "          [20.5625, 30.1562, 31.2500,  ..., 33.9375, 33.2500, 23.3281]],\n",
      "\n",
      "         [[17.6562, 25.5625, 25.3750,  ..., 27.1406, 28.5938, 20.8750],\n",
      "          [16.0938, 22.6406, 22.6094,  ..., 24.3594, 26.7344, 20.4062],\n",
      "          [16.6562, 22.8438, 21.9531,  ..., 23.5469, 27.0625, 21.7031],\n",
      "          ...,\n",
      "          [26.1094, 37.6875, 37.3750,  ..., 43.2812, 44.1875, 31.8750],\n",
      "          [26.5938, 39.5000, 40.6562,  ..., 45.5000, 45.0312, 31.7188],\n",
      "          [23.1250, 34.0000, 35.2500,  ..., 38.3125, 37.5312, 26.2656]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[21.9844, 31.2188, 29.8594,  ..., 35.9375, 38.1250, 27.7500],\n",
      "          [19.9219, 27.2344, 25.8594,  ..., 32.6562, 36.5312, 27.7969],\n",
      "          [19.5312, 25.8750, 23.6406,  ..., 29.0469, 34.8438, 28.0312],\n",
      "          ...,\n",
      "          [24.9062, 36.6250, 36.8125,  ..., 42.6250, 42.9688, 30.5625],\n",
      "          [24.9688, 37.6250, 39.1562,  ..., 44.2188, 43.1875, 30.0312],\n",
      "          [21.6719, 32.1562, 33.5000,  ..., 36.6875, 35.6562, 24.7344]],\n",
      "\n",
      "         [[22.3750, 31.7969, 30.3906,  ..., 36.6562, 38.8750, 28.2500],\n",
      "          [19.9375, 27.2656, 25.9062,  ..., 32.8438, 36.7500, 27.9375],\n",
      "          [19.6094, 26.0000, 23.7969,  ..., 29.2812, 35.1562, 28.2500],\n",
      "          ...,\n",
      "          [24.1094, 35.4688, 35.6875,  ..., 41.3125, 41.6250, 29.5625],\n",
      "          [24.1719, 36.4688, 37.9688,  ..., 42.8438, 41.8438, 29.0469],\n",
      "          [20.9688, 31.1250, 32.4688,  ..., 35.5312, 34.5312, 23.9219]],\n",
      "\n",
      "         [[19.6250, 27.8750, 26.5938,  ..., 32.1250, 34.0938, 24.7812],\n",
      "          [17.4531, 23.8281, 22.5469,  ..., 28.6875, 32.1562, 24.5000],\n",
      "          [17.1406, 22.6875, 20.6719,  ..., 25.5469, 30.7188, 24.7500],\n",
      "          ...,\n",
      "          [27.0312, 39.8438, 40.0938,  ..., 46.4688, 46.8125, 33.2188],\n",
      "          [27.1094, 40.9375, 42.6562,  ..., 48.1875, 47.0625, 32.6250],\n",
      "          [23.5625, 35.0312, 36.5312,  ..., 40.0312, 38.8750, 26.9062]]],\n",
      "\n",
      "\n",
      "        [[[38.5000, 61.1875, 66.2500,  ..., 50.3125, 48.6875, 33.1875],\n",
      "          [44.2500, 70.8750, 77.8750,  ..., 53.2188, 52.3750, 36.4375],\n",
      "          [45.5938, 72.1250, 77.5625,  ..., 49.2188, 51.4062, 37.6562],\n",
      "          ...,\n",
      "          [28.1406, 41.5000, 42.0938,  ..., 46.4688, 46.3438, 32.7188],\n",
      "          [27.7500, 41.9062, 43.7812,  ..., 47.5312, 46.1562, 31.9219],\n",
      "          [23.3125, 34.7500, 36.3125,  ..., 38.7188, 37.4688, 25.8906]],\n",
      "\n",
      "         [[39.5312, 62.9688, 68.1875,  ..., 51.6562, 49.9062, 33.9375],\n",
      "          [45.1250, 72.5000, 79.8125,  ..., 54.1875, 53.2188, 36.9375],\n",
      "          [46.5312, 73.8750, 79.6250,  ..., 50.1562, 52.2812, 38.2188],\n",
      "          ...,\n",
      "          [27.2188, 40.1875, 40.7812,  ..., 45.0312, 44.9062, 31.6406],\n",
      "          [26.8594, 40.5938, 42.4062,  ..., 46.0312, 44.7188, 30.8750],\n",
      "          [22.5625, 33.6250, 35.1562,  ..., 37.5000, 36.2812, 25.0312]],\n",
      "\n",
      "         [[34.8125, 55.5000, 60.1562,  ..., 45.4062, 43.8750, 29.8281],\n",
      "          [39.7500, 63.9062, 70.3125,  ..., 47.5625, 46.7188, 32.4375],\n",
      "          [40.9688, 65.0625, 70.1875,  ..., 43.9688, 45.8750, 33.5625],\n",
      "          ...,\n",
      "          [30.5781, 45.2188, 45.8750,  ..., 50.6875, 50.5312, 35.5938],\n",
      "          [30.1562, 45.6562, 47.7188,  ..., 51.8438, 50.3438, 34.7188],\n",
      "          [25.3750, 37.8438, 39.6250,  ..., 42.2812, 40.9062, 28.1875]]],\n",
      "\n",
      "\n",
      "        [[[21.9844, 31.3125, 30.1250,  ..., 36.9375, 35.8438, 25.2344],\n",
      "          [19.9844, 27.4219, 26.2656,  ..., 33.1562, 33.1562, 24.2969],\n",
      "          [19.6406, 26.1094, 24.0469,  ..., 28.0000, 30.9219, 24.3281],\n",
      "          ...,\n",
      "          [24.6562, 36.2188, 36.3750,  ..., 40.9688, 41.5000, 29.6406],\n",
      "          [24.8281, 37.3750, 38.8438,  ..., 42.6562, 41.8438, 29.1875],\n",
      "          [21.5781, 32.0312, 33.3125,  ..., 35.6875, 34.7812, 24.2188]],\n",
      "\n",
      "         [[22.3750, 31.8750, 30.6562,  ..., 37.7188, 36.5625, 25.6719],\n",
      "          [20.0000, 27.4375, 26.2969,  ..., 33.3750, 33.3438, 24.3594],\n",
      "          [19.7031, 26.2188, 24.1875,  ..., 28.2188, 31.1250, 24.4531],\n",
      "          ...,\n",
      "          [23.8750, 35.0938, 35.2500,  ..., 39.7188, 40.2188, 28.6719],\n",
      "          [24.0312, 36.1875, 37.6250,  ..., 41.3438, 40.5625, 28.2500],\n",
      "          [20.8906, 30.9844, 32.2812,  ..., 34.5938, 33.6875, 23.4062]],\n",
      "\n",
      "         [[19.6250, 27.9531, 26.8594,  ..., 33.0625, 32.0312, 22.5156],\n",
      "          [17.5156, 24.0000, 22.9219,  ..., 29.1875, 29.1562, 21.3438],\n",
      "          [17.2344, 22.8906, 21.0469,  ..., 24.6250, 27.1875, 21.4062],\n",
      "          ...,\n",
      "          [26.7656, 39.4062, 39.5938,  ..., 44.6250, 45.2188, 32.2188],\n",
      "          [26.9375, 40.6562, 42.2812,  ..., 46.4688, 45.5938, 31.7188],\n",
      "          [23.4688, 34.8750, 36.3438,  ..., 38.9375, 37.9375, 26.3438]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[26.7969, 37.5938, 34.2812,  ..., 32.9688, 37.0938, 27.6562],\n",
      "          [25.4062, 33.9062, 29.7344,  ..., 27.5312, 33.4062, 26.4219],\n",
      "          [24.3438, 31.2031, 25.9688,  ..., 23.3594, 30.6250, 25.5625],\n",
      "          ...,\n",
      "          [26.3906, 39.7812, 40.8750,  ..., 40.1875, 40.0312, 28.0625],\n",
      "          [25.7969, 39.7500, 42.0938,  ..., 41.1875, 39.7188, 27.2656],\n",
      "          [22.1094, 33.4375, 35.2500,  ..., 34.6250, 33.3750, 22.9844]],\n",
      "\n",
      "         [[27.2969, 38.2812, 34.9062,  ..., 33.5312, 37.7500, 28.1094],\n",
      "          [25.5000, 34.0000, 29.7812,  ..., 27.5000, 33.5000, 26.4688],\n",
      "          [24.4531, 31.3281, 26.0781,  ..., 23.4062, 30.7656, 25.6719],\n",
      "          ...,\n",
      "          [25.5625, 38.5625, 39.6562,  ..., 39.0000, 38.8438, 27.1875],\n",
      "          [25.0000, 38.5312, 40.8125,  ..., 39.9375, 38.5312, 26.4219],\n",
      "          [21.4219, 32.3750, 34.1562,  ..., 33.5938, 32.3438, 22.2500]],\n",
      "\n",
      "         [[24.0312, 33.6562, 30.6719,  ..., 29.4531, 33.1875, 24.7344],\n",
      "          [22.4219, 29.8438, 26.0625,  ..., 24.0625, 29.3594, 23.2656],\n",
      "          [21.4844, 27.4688, 22.7969,  ..., 20.4531, 26.9531, 22.5469],\n",
      "          ...,\n",
      "          [28.6562, 43.2500, 44.5312,  ..., 43.7500, 43.5625, 30.4844],\n",
      "          [28.0000, 43.1875, 45.8125,  ..., 44.8125, 43.2188, 29.6094],\n",
      "          [24.0312, 36.4062, 38.4062,  ..., 37.7500, 36.3438, 24.9688]]],\n",
      "\n",
      "\n",
      "        [[[39.7812, 62.6562, 66.9375,  ..., 68.7500, 65.2500, 43.7188],\n",
      "          [44.4062, 70.3125, 76.3125,  ..., 78.3125, 74.0625, 50.0938],\n",
      "          [44.7188, 69.9375, 74.3750,  ..., 76.5000, 73.8125, 51.3125],\n",
      "          ...,\n",
      "          [28.3438, 42.6562, 43.9062,  ..., 45.8125, 45.3438, 31.6562],\n",
      "          [27.5312, 42.4062, 44.9688,  ..., 46.5625, 44.7812, 30.5625],\n",
      "          [23.1562, 35.0938, 37.0625,  ..., 38.1250, 36.6250, 25.0469]],\n",
      "\n",
      "         [[40.7812, 64.3750, 68.8125,  ..., 70.6875, 66.9375, 44.7812],\n",
      "          [45.1875, 71.6875, 78.0000,  ..., 80.0625, 75.5625, 51.0000],\n",
      "          [45.5312, 71.3750, 76.1875,  ..., 78.3750, 75.4375, 52.3125],\n",
      "          ...,\n",
      "          [27.4688, 41.3438, 42.5625,  ..., 44.4375, 43.9688, 30.6562],\n",
      "          [26.6719, 41.0938, 43.6250,  ..., 45.1562, 43.4375, 29.6094],\n",
      "          [22.4375, 34.0000, 35.9375,  ..., 36.9688, 35.5000, 24.2500]],\n",
      "\n",
      "         [[35.9688, 56.8125, 60.7500,  ..., 62.3750, 59.1250, 39.4688],\n",
      "          [39.8125, 63.2500, 68.8125,  ..., 70.6875, 66.6875, 44.9062],\n",
      "          [40.1250, 62.9688, 67.2500,  ..., 69.1875, 66.5000, 46.0938],\n",
      "          ...,\n",
      "          [30.7969, 46.4062, 47.8125,  ..., 49.9062, 49.3750, 34.4062],\n",
      "          [29.9062, 46.1562, 49.0000,  ..., 50.7188, 48.7500, 33.1875],\n",
      "          [25.1875, 38.1875, 40.4062,  ..., 41.5625, 39.9062, 27.2500]]],\n",
      "\n",
      "\n",
      "        [[[24.0312, 33.5312, 30.7969,  ..., 60.5312, 56.9688, 38.0625],\n",
      "          [21.2656, 28.1562, 25.1562,  ..., 65.6250, 62.2188, 42.4062],\n",
      "          [19.7188, 25.1094, 21.4688,  ..., 61.4688, 61.4375, 43.8750],\n",
      "          ...,\n",
      "          [27.1094, 40.7812, 41.8750,  ..., 44.6562, 44.3125, 30.9531],\n",
      "          [26.4219, 40.6875, 43.0938,  ..., 45.4375, 43.7812, 29.9062],\n",
      "          [22.4844, 34.0312, 35.9062,  ..., 37.3750, 35.9688, 24.6406]],\n",
      "\n",
      "         [[24.4375, 34.1250, 31.3125,  ..., 62.1875, 58.4062, 38.9375],\n",
      "          [21.2500, 28.0938, 25.0938,  ..., 66.8750, 63.3125, 43.0000],\n",
      "          [19.7500, 25.1094, 21.5156,  ..., 62.8438, 62.6250, 44.5938],\n",
      "          ...,\n",
      "          [26.2656, 39.5312, 40.6250,  ..., 43.3438, 42.9688, 29.9844],\n",
      "          [25.6250, 39.4375, 41.8125,  ..., 44.0625, 42.4375, 28.9688],\n",
      "          [21.7969, 32.9688, 34.7812,  ..., 36.2500, 34.8438, 23.8438]],\n",
      "\n",
      "         [[21.5000, 29.9688, 27.4844,  ..., 54.8125, 51.4688, 34.2812],\n",
      "          [18.6562, 24.6094, 21.8906,  ..., 58.9062, 55.7188, 37.8438],\n",
      "          [17.3125, 21.9531, 18.7344,  ..., 55.2812, 55.0625, 39.2188],\n",
      "          ...,\n",
      "          [29.4375, 44.3750, 45.6250,  ..., 48.6562, 48.2500, 33.6250],\n",
      "          [28.6875, 44.2500, 46.9375,  ..., 49.4688, 47.6562, 32.4688],\n",
      "          [24.4531, 37.0312, 39.1250,  ..., 40.7500, 39.1875, 26.7812]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[29.6406, 40.5938, 37.2188,  ..., 80.3125, 77.2500, 52.6250],\n",
      "          [27.6562, 36.1250, 32.1562,  ..., 93.6875, 89.6250, 61.4375],\n",
      "          [25.8125, 32.4688, 27.6562,  ..., 93.1250, 90.3125, 63.0625],\n",
      "          ...,\n",
      "          [26.1406, 39.7812, 40.8125,  ..., 44.8125, 44.5625, 30.8281],\n",
      "          [25.3438, 39.3750, 41.5938,  ..., 45.3438, 43.6875, 29.5625],\n",
      "          [21.7969, 33.2188, 34.8750,  ..., 37.2812, 35.8750, 24.3906]],\n",
      "\n",
      "         [[30.2031, 41.3125, 37.8750,  ..., 82.7500, 79.4375, 53.9688],\n",
      "          [27.7969, 36.1875, 32.2188,  ..., 96.0000, 91.6875, 62.6562],\n",
      "          [25.9844, 32.5938, 27.8125,  ..., 95.6250, 92.5000, 64.4375],\n",
      "          ...,\n",
      "          [25.3594, 38.5625, 39.5938,  ..., 43.4688, 43.2188, 29.8906],\n",
      "          [24.6094, 38.1875, 40.3750,  ..., 44.0000, 42.3750, 28.6875],\n",
      "          [21.1406, 32.1875, 33.8125,  ..., 36.1562, 34.7812, 23.6406]],\n",
      "\n",
      "         [[26.6406, 36.4375, 33.3750,  ..., 73.1250, 70.2500, 47.7188],\n",
      "          [24.4844, 31.8281, 28.2812,  ..., 84.8750, 81.0000, 55.3750],\n",
      "          [22.8750, 28.6406, 24.3750,  ..., 84.5000, 81.6875, 56.9062],\n",
      "          ...,\n",
      "          [28.3438, 43.2188, 44.4062,  ..., 48.7812, 48.4688, 33.4688],\n",
      "          [27.4844, 42.7500, 45.2500,  ..., 49.3750, 47.5000, 32.0938],\n",
      "          [23.6719, 36.1250, 37.9375,  ..., 40.5938, 39.0312, 26.4688]]],\n",
      "\n",
      "\n",
      "        [[[40.9688, 61.3438, 62.6875,  ..., 44.0312, 46.3125, 34.1875],\n",
      "          [44.7500, 66.7500, 68.8750,  ..., 40.3125, 44.0312, 33.9062],\n",
      "          [44.6875, 65.6875, 66.1250,  ..., 34.7500, 40.2500, 32.4688],\n",
      "          ...,\n",
      "          [25.1719, 38.2500, 39.0625,  ..., 41.6875, 41.3125, 28.4844],\n",
      "          [24.4219, 37.8750, 39.8438,  ..., 42.3750, 40.7188, 27.5156],\n",
      "          [21.2188, 32.2500, 33.7188,  ..., 35.2812, 33.9375, 23.1094]],\n",
      "\n",
      "         [[41.9375, 62.9062, 64.3750,  ..., 44.9062, 47.2188, 34.8125],\n",
      "          [45.4375, 68.0000, 70.2500,  ..., 40.5938, 44.3750, 34.1250],\n",
      "          [45.4375, 67.0000, 67.5625,  ..., 35.0625, 40.5938, 32.7188],\n",
      "          ...,\n",
      "          [24.4219, 37.0938, 37.9062,  ..., 40.4375, 40.0625, 27.6094],\n",
      "          [23.7188, 36.7188, 38.6562,  ..., 41.1250, 39.5000, 26.6875],\n",
      "          [20.5781, 31.2656, 32.6875,  ..., 34.2188, 32.9062, 22.3906]],\n",
      "\n",
      "         [[37.0625, 55.5938, 56.8438,  ..., 39.5938, 41.6562, 30.7188],\n",
      "          [40.1250, 59.9688, 61.9375,  ..., 35.6875, 39.0312, 30.0625],\n",
      "          [40.1250, 59.0625, 59.5938,  ..., 30.7812, 35.6875, 28.8281],\n",
      "          ...,\n",
      "          [27.2969, 41.5312, 42.4688,  ..., 45.3438, 44.9375, 30.8906],\n",
      "          [26.4688, 41.0938, 43.3438,  ..., 46.0938, 44.2500, 29.8438],\n",
      "          [23.0312, 35.0625, 36.7188,  ..., 38.4062, 36.9375, 25.0781]]],\n",
      "\n",
      "\n",
      "        [[[34.0312, 48.8750, 47.8438,  ..., 81.1250, 77.4375, 52.7188],\n",
      "          [34.2812, 47.8125, 46.6250,  ..., 94.9375, 89.9375, 61.5938],\n",
      "          [32.7500, 44.1562, 41.1875,  ..., 94.6250, 90.6875, 63.2500],\n",
      "          ...,\n",
      "          [29.0469, 44.1875, 45.5312,  ..., 47.8750, 47.4375, 32.7500],\n",
      "          [28.0000, 43.5625, 46.2500,  ..., 48.3750, 46.4375, 31.3281],\n",
      "          [23.4062, 35.8125, 37.7812,  ..., 39.2188, 37.6250, 25.4844]],\n",
      "\n",
      "         [[34.7188, 49.9062, 48.8750,  ..., 83.5625, 79.6250, 54.0938],\n",
      "          [34.6250, 48.2812, 47.1250,  ..., 97.3125, 92.0000, 62.8438],\n",
      "          [33.0938, 44.6250, 41.7188,  ..., 97.1875, 92.8750, 64.6250],\n",
      "          ...,\n",
      "          [28.1719, 42.8125, 44.1250,  ..., 46.4375, 46.0000, 31.7344],\n",
      "          [27.1719, 42.2188, 44.8438,  ..., 46.9062, 45.0312, 30.3906],\n",
      "          [22.7031, 34.6875, 36.6250,  ..., 38.0312, 36.4688, 24.7031]],\n",
      "\n",
      "         [[30.6406, 44.0625, 43.1250,  ..., 73.8750, 70.3750, 47.8125],\n",
      "          [30.5312, 42.5625, 41.4688,  ..., 86.0000, 81.3125, 55.5312],\n",
      "          [29.1875, 39.2812, 36.6875,  ..., 85.9375, 82.0625, 57.0938],\n",
      "          ...,\n",
      "          [31.5312, 48.0312, 49.5312,  ..., 52.1250, 51.6250, 35.5625],\n",
      "          [30.3906, 47.3438, 50.3125,  ..., 52.6562, 50.5312, 34.0312],\n",
      "          [25.4219, 38.9375, 41.1562,  ..., 42.7188, 40.9688, 27.6719]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[29.2812, 39.7500, 37.0938,  ..., 38.7812, 42.6562, 32.3438],\n",
      "          [28.3125, 36.9062, 34.0938,  ..., 35.7500, 41.2812, 32.6250],\n",
      "          [27.1875, 34.3750, 30.7656,  ..., 32.5000, 39.5938, 32.5000],\n",
      "          ...,\n",
      "          [26.4531, 39.9375, 40.7812,  ..., 41.5000, 41.5312, 28.8750],\n",
      "          [25.8438, 39.8125, 41.8438,  ..., 42.5000, 41.2188, 28.0938],\n",
      "          [22.1562, 33.5625, 35.1562,  ..., 35.5625, 34.4375, 23.5000]],\n",
      "\n",
      "         [[29.8594, 40.5625, 37.8438,  ..., 39.5625, 43.5625, 33.0000],\n",
      "          [28.5312, 37.1562, 34.3438,  ..., 36.0000, 41.6875, 32.9375],\n",
      "          [27.4375, 34.6562, 31.0625,  ..., 32.8125, 40.0312, 32.8438],\n",
      "          ...,\n",
      "          [25.6562, 38.7500, 39.5938,  ..., 40.3125, 40.3125, 27.9844],\n",
      "          [25.0781, 38.6562, 40.6562,  ..., 41.2812, 40.0625, 27.2344],\n",
      "          [21.4844, 32.5625, 34.1250,  ..., 34.5312, 33.4062, 22.7656]],\n",
      "\n",
      "         [[26.4219, 35.8125, 33.4062,  ..., 34.9375, 38.4688, 29.1562],\n",
      "          [25.2344, 32.7812, 30.2500,  ..., 31.7344, 36.7812, 29.0781],\n",
      "          [24.2656, 30.5625, 27.3594,  ..., 28.9062, 35.2812, 29.0156],\n",
      "          ...,\n",
      "          [28.6719, 43.3438, 44.3125,  ..., 45.0938, 45.0938, 31.2969],\n",
      "          [28.0156, 43.2188, 45.4688,  ..., 46.1875, 44.7812, 30.4375],\n",
      "          [24.0312, 36.4688, 38.2188,  ..., 38.6875, 37.4375, 25.4844]]],\n",
      "\n",
      "\n",
      "        [[[29.7812, 40.7188, 38.5312,  ..., 69.0625, 66.7500, 46.1250],\n",
      "          [29.0469, 38.2500, 35.8438,  ..., 77.6875, 75.0625, 52.2812],\n",
      "          [28.3594, 36.2188, 32.7812,  ..., 75.3125, 74.3125, 53.1562],\n",
      "          ...,\n",
      "          [29.4688, 44.5000, 45.8125,  ..., 47.9375, 47.4688, 32.8125],\n",
      "          [28.5938, 44.1562, 46.6562,  ..., 48.4062, 46.7188, 31.6250],\n",
      "          [23.8281, 36.2500, 38.1875,  ..., 39.3125, 37.8750, 25.6719]],\n",
      "\n",
      "         [[30.3750, 41.5625, 39.3125,  ..., 71.0625, 68.5625, 47.3125],\n",
      "          [29.2969, 38.5312, 36.1250,  ..., 79.5000, 76.6875, 53.2812],\n",
      "          [28.6406, 36.5625, 33.1250,  ..., 77.1875, 76.0000, 54.2188],\n",
      "          ...,\n",
      "          [28.5781, 43.1875, 44.4688,  ..., 46.5625, 46.0938, 31.8125],\n",
      "          [27.7344, 42.8750, 45.3125,  ..., 47.0312, 45.3750, 30.6719],\n",
      "          [23.0938, 35.1875, 37.0625,  ..., 38.1562, 36.7812, 24.8750]],\n",
      "\n",
      "         [[26.8906, 36.7188, 34.7188,  ..., 62.9062, 60.7188, 41.8438],\n",
      "          [25.9219, 34.0000, 31.8438,  ..., 70.3125, 67.8125, 47.1250],\n",
      "          [25.3281, 32.2500, 29.1719,  ..., 68.2500, 67.2500, 47.9375],\n",
      "          ...,\n",
      "          [31.9531, 48.3750, 49.7812,  ..., 52.1250, 51.6250, 35.5938],\n",
      "          [31.0000, 47.9688, 50.7188,  ..., 52.6562, 50.7812, 34.3125],\n",
      "          [25.8594, 39.4062, 41.5312,  ..., 42.7812, 41.2188, 27.8594]]],\n",
      "\n",
      "\n",
      "        [[[34.4062, 48.0312, 45.5625,  ..., 66.6875, 65.1875, 45.3125],\n",
      "          [34.9688, 47.2812, 44.3750,  ..., 74.1250, 72.7500, 51.0312],\n",
      "          [33.0625, 43.2188, 39.1250,  ..., 71.3750, 71.6250, 51.6562],\n",
      "          ...,\n",
      "          [28.0000, 42.0938, 42.8125,  ..., 48.2812, 47.8438, 33.0625],\n",
      "          [27.0156, 41.5000, 43.5000,  ..., 48.8438, 47.1562, 31.9062],\n",
      "          [22.7969, 34.5312, 36.1562,  ..., 39.5938, 38.1562, 25.8594]],\n",
      "\n",
      "         [[35.1875, 49.0938, 46.5938,  ..., 68.5625, 67.0000, 46.4375],\n",
      "          [35.4062, 47.8125, 44.9375,  ..., 75.7500, 74.2500, 51.9688],\n",
      "          [33.4688, 43.7188, 39.6250,  ..., 73.0625, 73.1875, 52.6562],\n",
      "          ...,\n",
      "          [27.1406, 40.8438, 41.5625,  ..., 46.9062, 46.4375, 32.0625],\n",
      "          [26.2188, 40.3125, 42.2500,  ..., 47.4375, 45.8125, 30.9375],\n",
      "          [22.1094, 33.5000, 35.0938,  ..., 38.4688, 37.0625, 25.0469]],\n",
      "\n",
      "         [[31.1250, 43.4062, 41.1562,  ..., 60.7188, 59.3125, 41.0938],\n",
      "          [31.3125, 42.2188, 39.6250,  ..., 67.0000, 65.6875, 45.9375],\n",
      "          [29.6094, 38.5938, 34.9375,  ..., 64.6250, 64.6875, 46.5312],\n",
      "          ...,\n",
      "          [30.3438, 45.7188, 46.5312,  ..., 52.5312, 52.0000, 35.8750],\n",
      "          [29.2812, 45.0625, 47.2812,  ..., 53.1250, 51.2500, 34.5938],\n",
      "          [24.7500, 37.5312, 39.3125,  ..., 43.0938, 41.5312, 28.0625]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[34.2500, 46.8750, 46.1562,  ..., 45.1250, 47.2500, 36.0625],\n",
      "          [35.1562, 47.2188, 47.0625,  ..., 44.3750, 47.5938, 37.3750],\n",
      "          [34.4062, 45.2812, 44.2500,  ..., 41.2188, 45.7812, 37.1250],\n",
      "          ...,\n",
      "          [24.1562, 37.4062, 38.5938,  ..., 39.7188, 39.0938, 26.4531],\n",
      "          [23.5938, 37.1250, 39.2812,  ..., 39.6250, 38.1562, 25.5938],\n",
      "          [20.6250, 31.4375, 33.0000,  ..., 32.9062, 31.8594, 21.8750]],\n",
      "\n",
      "         [[35.0312, 47.9375, 47.2188,  ..., 46.1562, 48.3125, 36.8438],\n",
      "          [35.6250, 47.8438, 47.7500,  ..., 44.9375, 48.2500, 37.8438],\n",
      "          [34.9375, 45.9375, 44.9688,  ..., 41.8125, 46.4375, 37.6562],\n",
      "          ...,\n",
      "          [23.4375, 36.3125, 37.4688,  ..., 38.5625, 38.0000, 25.6562],\n",
      "          [22.9219, 36.0625, 38.1875,  ..., 38.5000, 37.0938, 24.8594],\n",
      "          [20.0312, 30.5312, 32.0312,  ..., 31.9688, 30.9531, 21.2031]],\n",
      "\n",
      "         [[31.0469, 42.4375, 41.7812,  ..., 40.8125, 42.7500, 32.6250],\n",
      "          [31.5625, 42.3125, 42.1875,  ..., 39.6875, 42.6250, 33.4688],\n",
      "          [30.9375, 40.5938, 39.7500,  ..., 36.9375, 41.0625, 33.3125],\n",
      "          ...,\n",
      "          [26.1406, 40.5312, 41.8750,  ..., 43.0938, 42.4375, 28.6250],\n",
      "          [25.5469, 40.2500, 42.6250,  ..., 43.0000, 41.4062, 27.7031],\n",
      "          [22.3438, 34.1250, 35.8438,  ..., 35.7500, 34.5938, 23.6250]]],\n",
      "\n",
      "\n",
      "        [[[43.5625, 61.6875, 60.2812,  ..., 71.3750, 69.2500, 49.0312],\n",
      "          [48.2812, 67.4375, 65.4375,  ..., 80.1875, 78.3750, 55.8438],\n",
      "          [47.9062, 65.3750, 61.8125,  ..., 76.1250, 76.8750, 56.3125],\n",
      "          ...,\n",
      "          [27.9531, 42.9062, 44.2188,  ..., 44.0000, 43.6250, 29.7031],\n",
      "          [27.0156, 42.3438, 44.7500,  ..., 44.2812, 42.6875, 28.5469],\n",
      "          [22.5000, 34.7188, 36.5000,  ..., 36.1250, 34.8438, 23.3906]],\n",
      "\n",
      "         [[44.6875, 63.3438, 61.9062,  ..., 73.5000, 71.2500, 50.3438],\n",
      "          [49.2500, 68.8125, 66.7500,  ..., 82.1250, 80.1250, 57.0312],\n",
      "          [48.8750, 66.7500, 63.1250,  ..., 78.0000, 78.6875, 57.5000],\n",
      "          ...,\n",
      "          [27.1406, 41.6875, 42.9375,  ..., 42.7500, 42.4062, 28.8281],\n",
      "          [26.2500, 41.1562, 43.5000,  ..., 43.0312, 41.5000, 27.7188],\n",
      "          [21.8438, 33.7188, 35.4375,  ..., 35.0938, 33.8438, 22.6719]],\n",
      "\n",
      "         [[39.6250, 56.1562, 54.8750,  ..., 65.1875, 63.2188, 44.6250],\n",
      "          [43.6250, 60.9375, 59.0625,  ..., 72.8125, 71.0625, 50.5312],\n",
      "          [43.3125, 59.0938, 55.8125,  ..., 69.1250, 69.7500, 50.9375],\n",
      "          ...,\n",
      "          [30.2969, 46.5938, 48.0312,  ..., 47.8125, 47.3750, 32.2188],\n",
      "          [29.2812, 45.9688, 48.6250,  ..., 48.0938, 46.3750, 30.9219],\n",
      "          [24.4062, 37.6875, 39.6562,  ..., 39.2500, 37.8438, 25.3438]]],\n",
      "\n",
      "\n",
      "        [[[34.7500, 46.8750, 45.3438,  ..., 71.8750, 69.4375, 49.0625],\n",
      "          [36.4688, 48.0938, 46.6875,  ..., 81.8750, 78.9375, 56.0312],\n",
      "          [36.9375, 47.8750, 45.4062,  ..., 80.6250, 78.8125, 57.0938],\n",
      "          ...,\n",
      "          [27.5312, 42.2812, 43.4688,  ..., 43.6875, 43.3125, 29.5156],\n",
      "          [26.6250, 41.7188, 44.0312,  ..., 43.9688, 42.4062, 28.3750],\n",
      "          [22.2812, 34.3125, 36.0312,  ..., 35.9062, 34.6562, 23.2812]],\n",
      "\n",
      "         [[35.5312, 47.9375, 46.3438,  ..., 74.0000, 71.4375, 50.3750],\n",
      "          [36.9688, 48.7188, 47.3438,  ..., 83.8750, 80.7500, 57.2188],\n",
      "          [37.5312, 48.5938, 46.1562,  ..., 82.7500, 80.6875, 58.3438],\n",
      "          ...,\n",
      "          [26.7188, 41.0625, 42.2188,  ..., 42.4375, 42.0938, 28.6406],\n",
      "          [25.8750, 40.5625, 42.8125,  ..., 42.7500, 41.2500, 27.5469],\n",
      "          [21.6250, 33.3438, 35.0000,  ..., 34.8750, 33.6562, 22.5781]],\n",
      "\n",
      "         [[31.4844, 42.4062, 41.0312,  ..., 65.6250, 63.3750, 44.6562],\n",
      "          [32.7500, 43.0625, 41.8125,  ..., 74.3750, 71.6250, 50.6875],\n",
      "          [33.2500, 42.9688, 40.7812,  ..., 73.3750, 71.5625, 51.6875],\n",
      "          ...,\n",
      "          [29.8281, 45.8750, 47.2188,  ..., 47.4688, 47.0625, 31.9844],\n",
      "          [28.8594, 45.2812, 47.8438,  ..., 47.7500, 46.0625, 30.7344],\n",
      "          [24.1562, 37.2812, 39.1875,  ..., 39.0312, 37.6562, 25.2344]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[47.1250, 67.7500, 69.8125,  ..., 46.9375, 49.4375, 37.8750],\n",
      "          [53.6250, 76.9375, 80.0000,  ..., 47.5625, 51.0625, 39.9375],\n",
      "          [54.1875, 76.9375, 78.7500,  ..., 45.4375, 50.2500, 40.3125],\n",
      "          ...,\n",
      "          [27.3125, 41.5000, 42.3750,  ..., 44.7500, 44.8750, 30.9688],\n",
      "          [26.8594, 41.6875, 43.6250,  ..., 45.6250, 44.5000, 30.1406],\n",
      "          [22.8125, 34.7500, 36.3125,  ..., 37.4375, 36.4375, 24.7031]],\n",
      "\n",
      "         [[48.4375, 69.6875, 71.8750,  ..., 48.0312, 50.6250, 38.7188],\n",
      "          [54.7812, 78.7500, 81.9375,  ..., 48.2500, 51.8750, 40.5312],\n",
      "          [55.4062, 78.8125, 80.7500,  ..., 46.1250, 51.0625, 40.9375],\n",
      "          ...,\n",
      "          [26.5312, 40.3125, 41.1250,  ..., 43.4688, 43.5938, 30.0625],\n",
      "          [26.0938, 40.4688, 42.4062,  ..., 44.3438, 43.2812, 29.2656],\n",
      "          [22.1719, 33.7500, 35.2188,  ..., 36.3438, 35.3750, 23.9688]],\n",
      "\n",
      "         [[43.0938, 62.0000, 63.9375,  ..., 42.5938, 44.9375, 34.3750],\n",
      "          [48.7500, 70.0000, 72.8125,  ..., 42.7500, 45.9688, 35.9688],\n",
      "          [49.2812, 70.0000, 71.7500,  ..., 40.8750, 45.2500, 36.3125],\n",
      "          ...,\n",
      "          [29.5781, 45.0312, 45.9688,  ..., 48.6250, 48.7188, 33.5625],\n",
      "          [29.0781, 45.2188, 47.3750,  ..., 49.5625, 48.3438, 32.6562],\n",
      "          [24.7344, 37.7188, 39.4062,  ..., 40.6562, 39.5625, 26.7500]]],\n",
      "\n",
      "\n",
      "        [[[35.4375, 47.0000, 46.1250,  ..., 81.3750, 78.1875, 54.8125],\n",
      "          [36.8125, 47.6875, 47.1875,  ..., 96.0000, 92.3125, 64.5000],\n",
      "          [36.6875, 46.5625, 45.3125,  ..., 94.5625, 92.4375, 65.6250],\n",
      "          ...,\n",
      "          [28.4375, 43.2500, 44.1875,  ..., 46.1250, 46.1875, 31.9688],\n",
      "          [27.9375, 43.3750, 45.4375,  ..., 46.9375, 45.8125, 31.0625],\n",
      "          [23.4062, 35.7500, 37.3750,  ..., 38.3125, 37.3125, 25.2188]],\n",
      "\n",
      "         [[36.2500, 48.0625, 47.1875,  ..., 83.9375, 80.5625, 56.4062],\n",
      "          [37.3750, 48.3438, 47.8750,  ..., 98.6250, 94.6875, 66.0625],\n",
      "          [37.2812, 47.2812, 46.0938,  ..., 97.1875, 94.8750, 67.2500],\n",
      "          ...,\n",
      "          [27.6094, 41.9688, 42.9375,  ..., 44.8125, 44.8750, 31.0156],\n",
      "          [27.1406, 42.0938, 44.1250,  ..., 45.6250, 44.5625, 30.1719],\n",
      "          [22.7344, 34.7188, 36.3125,  ..., 37.2500, 36.2188, 24.4688]],\n",
      "\n",
      "         [[32.1875, 42.6562, 41.8438,  ..., 74.6875, 71.6875, 50.1562],\n",
      "          [33.1875, 42.8750, 42.4375,  ..., 87.7500, 84.2500, 58.7812],\n",
      "          [33.0938, 41.9062, 40.8438,  ..., 86.5000, 84.4375, 59.8125],\n",
      "          ...,\n",
      "          [30.8125, 46.9062, 48.0000,  ..., 50.0938, 50.1562, 34.6562],\n",
      "          [30.2500, 47.0312, 49.3438,  ..., 51.0000, 49.7812, 33.6562],\n",
      "          [25.3906, 38.8438, 40.6250,  ..., 41.6875, 40.5312, 27.3281]]],\n",
      "\n",
      "\n",
      "        [[[35.2500, 46.9375, 46.3125,  ..., 55.8125, 58.1875, 43.1875],\n",
      "          [36.5625, 47.5625, 47.4375,  ..., 61.6875, 64.7500, 48.3125],\n",
      "          [36.4375, 46.4375, 45.5625,  ..., 63.7500, 67.2500, 50.6875],\n",
      "          ...,\n",
      "          [26.8125, 40.8125, 41.5625,  ..., 43.9375, 44.1250, 30.5156],\n",
      "          [26.4062, 41.0000, 42.8125,  ..., 44.8750, 43.8750, 29.7344],\n",
      "          [22.6406, 34.2500, 35.6875,  ..., 36.9375, 36.0000, 24.4688]],\n",
      "\n",
      "         [[36.0938, 48.0312, 47.4062,  ..., 57.2188, 59.6875, 44.2812],\n",
      "          [37.1250, 48.2188, 48.1250,  ..., 62.8438, 66.0625, 49.2188],\n",
      "          [37.0625, 47.1562, 46.3438,  ..., 65.1250, 68.6875, 51.6875],\n",
      "          ...,\n",
      "          [26.0312, 39.6250, 40.3750,  ..., 42.6875, 42.8750, 29.6094],\n",
      "          [25.6719, 39.8125, 41.5938,  ..., 43.5938, 42.6250, 28.8750],\n",
      "          [22.0000, 33.2812, 34.6562,  ..., 35.8750, 34.9688, 23.7344]],\n",
      "\n",
      "         [[32.0625, 42.6250, 42.0625,  ..., 50.7812, 53.0312, 39.3438],\n",
      "          [32.9688, 42.7500, 42.6562,  ..., 55.7500, 58.6562, 43.6875],\n",
      "          [32.9062, 41.8125, 41.0625,  ..., 57.7812, 60.9688, 45.8750],\n",
      "          ...,\n",
      "          [29.0312, 44.2812, 45.1250,  ..., 47.7188, 47.9375, 33.0625],\n",
      "          [28.5938, 44.4688, 46.4688,  ..., 48.7188, 47.6250, 32.2188],\n",
      "          [24.5312, 37.2188, 38.7812,  ..., 40.1562, 39.1250, 26.5000]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 49.2188,  72.0000,  77.0625,  ...,  74.5000,  71.1250,  50.0312],\n",
      "          [ 57.7188,  85.2500,  92.9375,  ...,  86.5625,  82.4375,  57.8125],\n",
      "          [ 59.6562,  87.8750,  95.3750,  ...,  83.8125,  81.0625,  58.0000],\n",
      "          ...,\n",
      "          [ 30.6562,  46.0000,  47.0938,  ...,  53.9375,  53.1875,  37.0000],\n",
      "          [ 30.6562,  46.9062,  49.0938,  ...,  54.8125,  53.0938,  36.3125],\n",
      "          [ 25.6719,  38.9062,  40.7812,  ...,  44.5625,  42.9688,  29.2188]],\n",
      "\n",
      "         [[ 50.5938,  74.1875,  79.3750,  ...,  76.7500,  73.1875,  51.4375],\n",
      "          [ 59.0938,  87.4375,  95.3750,  ...,  88.7500,  84.4375,  59.1562],\n",
      "          [ 61.0938,  90.1875,  98.0000,  ...,  85.9375,  83.0000,  59.3125],\n",
      "          ...,\n",
      "          [ 29.7500,  44.6875,  45.7500,  ...,  52.4375,  51.6875,  35.9062],\n",
      "          [ 29.7812,  45.5938,  47.7188,  ...,  53.2812,  51.6250,  35.2500],\n",
      "          [ 24.9219,  37.8125,  39.5938,  ...,  43.3125,  41.7500,  28.3438]],\n",
      "\n",
      "         [[ 45.0938,  66.1250,  70.7500,  ...,  68.3750,  65.2500,  45.7812],\n",
      "          [ 52.6875,  77.9375,  85.0625,  ...,  79.0625,  75.2500,  52.6562],\n",
      "          [ 54.4688,  80.3750,  87.3750,  ...,  76.5625,  73.9375,  52.7812],\n",
      "          ...,\n",
      "          [ 33.1875,  49.9062,  51.0938,  ...,  58.5312,  57.7188,  40.0938],\n",
      "          [ 33.2188,  50.8750,  53.2812,  ...,  59.5000,  57.6562,  39.3438],\n",
      "          [ 27.8438,  42.2500,  44.2812,  ...,  48.4062,  46.6562,  31.6719]]],\n",
      "\n",
      "\n",
      "        [[[ 35.8750,  48.1250,  47.7812,  ...,  45.0312,  47.4375,  36.5000],\n",
      "          [ 38.8125,  51.1250,  51.5938,  ...,  45.9375,  49.4062,  38.6562],\n",
      "          [ 40.0625,  52.3125,  52.3125,  ...,  44.2500,  48.9375,  39.2188],\n",
      "          ...,\n",
      "          [ 27.4844,  40.8438,  41.0938,  ...,  48.2188,  48.6562,  34.2812],\n",
      "          [ 27.9375,  42.5000,  44.0625,  ...,  49.9688,  49.1250,  33.8750],\n",
      "          [ 24.0781,  36.2812,  37.7812,  ...,  41.3750,  40.3438,  27.6406]],\n",
      "\n",
      "         [[ 36.7812,  49.2812,  48.9062,  ...,  46.0938,  48.5312,  37.3438],\n",
      "          [ 39.5000,  52.0000,  52.5000,  ...,  46.6250,  50.2188,  39.2812],\n",
      "          [ 40.8125,  53.2812,  53.3125,  ...,  45.0000,  49.7812,  39.8750],\n",
      "          ...,\n",
      "          [ 26.6719,  39.6562,  39.9062,  ...,  46.8750,  47.2812,  33.2812],\n",
      "          [ 27.1250,  41.3125,  42.8438,  ...,  48.5625,  47.7500,  32.9062],\n",
      "          [ 23.3594,  35.2500,  36.6875,  ...,  40.1875,  39.2188,  26.8125]],\n",
      "\n",
      "         [[ 32.6875,  43.8125,  43.4688,  ...,  40.9062,  43.0938,  33.1875],\n",
      "          [ 35.1250,  46.1875,  46.5938,  ...,  41.3750,  44.5625,  34.9062],\n",
      "          [ 36.3125,  47.3125,  47.3438,  ...,  39.9062,  44.1875,  35.4062],\n",
      "          ...,\n",
      "          [ 29.7500,  44.2500,  44.5312,  ...,  52.3125,  52.7812,  37.1250],\n",
      "          [ 30.2344,  46.0625,  47.8125,  ...,  54.2188,  53.3125,  36.7188],\n",
      "          [ 26.0781,  39.3750,  41.0000,  ...,  44.9375,  43.8125,  29.9531]]],\n",
      "\n",
      "\n",
      "        [[[ 34.3125,  45.6562,  45.5312,  ...,  81.6250,  76.6875,  53.2500],\n",
      "          [ 36.0625,  46.9062,  47.5000,  ...,  99.2500,  92.3750,  63.5312],\n",
      "          [ 36.5938,  46.7188,  46.5625,  ..., 102.5625,  96.0000,  66.5625],\n",
      "          ...,\n",
      "          [ 28.9375,  43.1875,  43.7500,  ...,  47.8125,  48.2812,  34.0312],\n",
      "          [ 29.1250,  44.4375,  46.2188,  ...,  49.7188,  48.8750,  33.6875],\n",
      "          [ 24.7344,  37.3750,  39.0000,  ...,  41.1562,  40.1562,  27.4844]],\n",
      "\n",
      "         [[ 35.1562,  46.7500,  46.5938,  ...,  84.1250,  79.0000,  54.7812],\n",
      "          [ 36.6875,  47.6250,  48.2812,  ..., 101.9375,  94.7500,  65.0625],\n",
      "          [ 37.2188,  47.5000,  47.3750,  ..., 105.4375,  98.5625,  68.2500],\n",
      "          ...,\n",
      "          [ 28.0781,  41.9688,  42.5312,  ...,  46.4688,  46.9375,  33.0312],\n",
      "          [ 28.2812,  43.1875,  44.9062,  ...,  48.3125,  47.5312,  32.7188],\n",
      "          [ 24.0156,  36.3125,  37.8750,  ...,  40.0000,  39.0312,  26.6562]],\n",
      "\n",
      "         [[ 31.2656,  41.5312,  41.3750,  ...,  75.0000,  70.3750,  48.7812],\n",
      "          [ 32.6250,  42.2812,  42.8438,  ...,  90.8750,  84.5000,  57.9688],\n",
      "          [ 33.0938,  42.1562,  42.0625,  ...,  94.0625,  87.8750,  60.8125],\n",
      "          ...,\n",
      "          [ 31.3281,  46.8438,  47.4688,  ...,  51.8438,  52.4062,  36.8750],\n",
      "          [ 31.5312,  48.1875,  50.1250,  ...,  53.9375,  53.0312,  36.5000],\n",
      "          [ 26.8125,  40.5625,  42.3125,  ...,  44.6875,  43.5938,  29.7812]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[44.8125, 64.4375, 68.6250,  ..., 50.6875, 50.6250, 37.4062],\n",
      "          [51.6250, 74.5000, 81.0625,  ..., 53.1562, 53.3125, 39.8438],\n",
      "          [52.9375, 76.0625, 82.3125,  ..., 50.6875, 52.1250, 39.8750],\n",
      "          ...,\n",
      "          [27.5781, 40.5938, 40.8125,  ..., 45.4688, 46.1562, 32.8750],\n",
      "          [28.1562, 42.4375, 43.9688,  ..., 48.4688, 47.6875, 33.1562],\n",
      "          [24.5938, 36.6562, 38.2188,  ..., 41.0625, 40.0312, 27.6406]],\n",
      "\n",
      "         [[46.0312, 66.1875, 70.5000,  ..., 51.9375, 51.8438, 38.2812],\n",
      "          [52.7500, 76.1875, 82.9375,  ..., 54.0625, 54.2188, 40.5000],\n",
      "          [54.0938, 77.8125, 84.2500,  ..., 51.5938, 53.0312, 40.5625],\n",
      "          ...,\n",
      "          [26.7969, 39.4688, 39.6875,  ..., 44.2188, 44.8750, 31.9531],\n",
      "          [27.3594, 41.2500, 42.7500,  ..., 47.1250, 46.3750, 32.2188],\n",
      "          [23.9062, 35.6250, 37.1250,  ..., 39.9062, 38.9062, 26.8438]],\n",
      "\n",
      "         [[41.0312, 59.0312, 62.8750,  ..., 46.1875, 46.1562, 34.0312],\n",
      "          [47.0312, 68.0000, 74.0000,  ..., 48.0625, 48.1875, 36.0312],\n",
      "          [48.2188, 69.4375, 75.1875,  ..., 45.8438, 47.1250, 36.0625],\n",
      "          ...,\n",
      "          [29.8438, 43.9688, 44.2188,  ..., 49.3125, 50.0312, 35.5938],\n",
      "          [30.4531, 45.9375, 47.6562,  ..., 52.5312, 51.6875, 35.8750],\n",
      "          [26.6406, 39.7500, 41.4375,  ..., 44.5625, 43.4375, 29.9375]]],\n",
      "\n",
      "\n",
      "        [[[43.5312, 62.1875, 66.3125,  ..., 53.3750, 53.0000, 38.6875],\n",
      "          [49.2500, 70.5625, 76.7500,  ..., 55.0938, 55.5625, 41.2812],\n",
      "          [49.8438, 70.8125, 76.3750,  ..., 50.6875, 53.4688, 41.0625],\n",
      "          ...,\n",
      "          [30.7656, 45.8438, 47.2500,  ..., 56.6875, 55.2188, 38.4688],\n",
      "          [31.0781, 47.2188, 49.7500,  ..., 57.5000, 55.1562, 37.8125],\n",
      "          [26.3750, 39.6562, 41.8438,  ..., 47.0000, 44.9062, 30.6406]],\n",
      "\n",
      "         [[44.6562, 63.9062, 68.0625,  ..., 54.7188, 54.3125, 39.6250],\n",
      "          [50.3125, 72.0000, 78.4375,  ..., 56.0625, 56.5312, 42.0000],\n",
      "          [50.9062, 72.3125, 78.1250,  ..., 51.5938, 54.4062, 41.8125],\n",
      "          ...,\n",
      "          [29.9062, 44.5625, 45.9375,  ..., 55.1250, 53.6875, 37.3750],\n",
      "          [30.2188, 45.9062, 48.3750,  ..., 55.9062, 53.6562, 36.7500],\n",
      "          [25.6406, 38.5625, 40.6875,  ..., 45.7188, 43.6562, 29.7656]],\n",
      "\n",
      "         [[39.8125, 56.9688, 60.7188,  ..., 48.6562, 48.3438, 35.2500],\n",
      "          [44.8438, 64.2500, 70.0000,  ..., 49.8438, 50.2812, 37.3438],\n",
      "          [45.3750, 64.5000, 69.6875,  ..., 45.8438, 48.3750, 37.1875],\n",
      "          ...,\n",
      "          [33.3125, 49.6875, 51.2188,  ..., 61.5000, 59.9062, 41.6562],\n",
      "          [33.6562, 51.1875, 53.9375,  ..., 62.3438, 59.8438, 40.9688],\n",
      "          [28.5938, 43.0312, 45.4062,  ..., 51.0312, 48.7500, 33.1875]]],\n",
      "\n",
      "\n",
      "        [[[33.7500, 44.5000, 44.4062,  ..., 61.2500, 59.1250, 42.0312],\n",
      "          [35.3750, 45.5000, 46.0000,  ..., 67.5625, 65.3750, 46.4062],\n",
      "          [35.4375, 44.5312, 44.3438,  ..., 63.9688, 63.4375, 46.3438],\n",
      "          ...,\n",
      "          [29.7031, 44.1250, 45.1875,  ..., 55.0312, 53.9688, 37.7812],\n",
      "          [30.1406, 45.6875, 47.9375,  ..., 56.1562, 54.0938, 37.2188],\n",
      "          [25.8125, 38.7188, 40.7188,  ..., 46.1250, 44.2188, 30.2500]],\n",
      "\n",
      "         [[34.5938, 45.5625, 45.4375,  ..., 62.9062, 60.6562, 43.0938],\n",
      "          [36.0000, 46.1875, 46.7500,  ..., 68.8750, 66.6250, 47.2812],\n",
      "          [36.0625, 45.2812, 45.0938,  ..., 65.3125, 64.6875, 47.2500],\n",
      "          ...,\n",
      "          [28.8750, 42.8750, 43.9375,  ..., 53.5312, 52.4688, 36.6875],\n",
      "          [29.2969, 44.4062, 46.6250,  ..., 54.5938, 52.6250, 36.1562],\n",
      "          [25.0938, 37.6562, 39.5938,  ..., 44.8750, 43.0000, 29.3750]],\n",
      "\n",
      "         [[30.7812, 40.5000, 40.4062,  ..., 56.0312, 54.0625, 38.3438],\n",
      "          [32.0625, 41.0625, 41.5312,  ..., 61.3750, 59.3438, 42.0625],\n",
      "          [32.1250, 40.2500, 40.0938,  ..., 58.0938, 57.5938, 42.0000],\n",
      "          ...,\n",
      "          [32.1562, 47.8125, 48.9688,  ..., 59.6875, 58.5312, 40.9062],\n",
      "          [32.6250, 49.5000, 51.9688,  ..., 60.9062, 58.6875, 40.3125],\n",
      "          [27.9688, 42.0000, 44.1875,  ..., 50.0938, 48.0000, 32.7812]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[33.4375, 44.3125, 44.2500,  ..., 44.6250, 47.1250, 35.6562],\n",
      "          [35.0000, 45.2500, 45.7188,  ..., 45.4688, 49.0000, 37.6875],\n",
      "          [34.9375, 44.0000, 43.7188,  ..., 42.8438, 47.7812, 37.6562],\n",
      "          ...,\n",
      "          [26.4062, 38.5000, 38.4688,  ..., 47.7188, 48.0312, 34.4062],\n",
      "          [27.3750, 40.8750, 42.2500,  ..., 50.2188, 49.2812, 34.5000],\n",
      "          [24.4531, 36.1562, 37.5625,  ..., 42.7188, 41.5312, 28.8438]],\n",
      "\n",
      "         [[34.2812, 45.3438, 45.2812,  ..., 45.6562, 48.2188, 36.5000],\n",
      "          [35.6250, 45.9375, 46.4375,  ..., 46.1562, 49.7812, 38.3125],\n",
      "          [35.5625, 44.6875, 44.4375,  ..., 43.5312, 48.5625, 38.3125],\n",
      "          ...,\n",
      "          [25.6562, 37.4375, 37.4062,  ..., 46.4375, 46.7500, 33.4688],\n",
      "          [26.6094, 39.7812, 41.0938,  ..., 48.8750, 47.9375, 33.5312],\n",
      "          [23.7656, 35.1562, 36.5312,  ..., 41.5625, 40.3750, 28.0156]],\n",
      "\n",
      "         [[30.5469, 40.3750, 40.3125,  ..., 40.6250, 42.9375, 32.5000],\n",
      "          [31.7656, 40.9375, 41.3125,  ..., 41.0625, 44.3125, 34.1250],\n",
      "          [31.7031, 39.8125, 39.5625,  ..., 38.7500, 43.2500, 34.1250],\n",
      "          ...,\n",
      "          [28.5469, 41.6875, 41.6250,  ..., 51.6875, 52.0625, 37.2500],\n",
      "          [29.5938, 44.2500, 45.7500,  ..., 54.4375, 53.3750, 37.3750],\n",
      "          [26.4688, 39.1875, 40.6875,  ..., 46.3125, 45.0625, 31.2344]]],\n",
      "\n",
      "\n",
      "        [[[46.2500, 67.6875, 73.6875,  ..., 70.2500, 69.0625, 48.5625],\n",
      "          [53.3125, 78.6250, 87.9375,  ..., 81.0000, 79.9375, 55.8750],\n",
      "          [53.6562, 78.9375, 88.1875,  ..., 78.6250, 78.8125, 56.0625],\n",
      "          ...,\n",
      "          [29.7344, 43.9062, 45.0000,  ..., 57.0312, 55.4688, 38.9062],\n",
      "          [30.4062, 45.8438, 48.1250,  ..., 58.0625, 55.5938, 38.4062],\n",
      "          [26.3281, 39.2812, 41.3438,  ..., 47.9062, 45.6875, 31.3906]],\n",
      "\n",
      "         [[47.4688, 69.5625, 75.6875,  ..., 72.1875, 70.9375, 49.8438],\n",
      "          [54.4375, 80.3750, 90.0000,  ..., 82.8125, 81.6875, 57.0625],\n",
      "          [54.8125, 80.7500, 90.3125,  ..., 80.4375, 80.5000, 57.2500],\n",
      "          ...,\n",
      "          [28.9062, 42.6875, 43.7812,  ..., 55.5000, 53.9688, 37.8438],\n",
      "          [29.5625, 44.5938, 46.8125,  ..., 56.4688, 54.0938, 37.3438],\n",
      "          [25.5938, 38.2188, 40.2188,  ..., 46.6250, 44.4375, 30.5000]],\n",
      "\n",
      "         [[42.3750, 62.0625, 67.6250,  ..., 64.4375, 63.3125, 44.4375],\n",
      "          [48.6250, 71.8125, 80.3750,  ..., 73.9375, 72.9375, 50.9375],\n",
      "          [48.9375, 72.0625, 80.6875,  ..., 71.7500, 71.8750, 51.0625],\n",
      "          ...,\n",
      "          [32.1875, 47.5625, 48.7500,  ..., 61.8125, 60.1250, 42.1250],\n",
      "          [32.8750, 49.6875, 52.1250,  ..., 62.9375, 60.3125, 41.6250],\n",
      "          [28.5156, 42.6250, 44.8750,  ..., 52.0000, 49.5625, 34.0000]]],\n",
      "\n",
      "\n",
      "        [[[33.5312, 44.0938, 43.7188,  ..., 78.3750, 73.8750, 50.8750],\n",
      "          [34.9375, 44.6875, 44.8125,  ..., 94.6875, 88.5000, 60.2500],\n",
      "          [34.5000, 42.9375, 42.4688,  ..., 96.8125, 91.1250, 62.7188],\n",
      "          ...,\n",
      "          [29.7344, 43.8750, 44.9688,  ..., 53.4062, 52.6250, 37.2500],\n",
      "          [30.4062, 45.8125, 48.0938,  ..., 55.0000, 53.1875, 36.9688],\n",
      "          [26.3281, 39.2812, 41.3438,  ..., 45.9062, 44.1250, 30.4531]],\n",
      "\n",
      "         [[34.3438, 45.1250, 44.7500,  ..., 80.6250, 75.9375, 52.2500],\n",
      "          [35.5312, 45.3750, 45.5312,  ..., 97.0000, 90.5625, 61.5938],\n",
      "          [35.0938, 43.6250, 43.1875,  ..., 99.1875, 93.3125, 64.1875],\n",
      "          ...,\n",
      "          [28.8906, 42.6562, 43.7500,  ..., 51.9688, 51.1875, 36.2188],\n",
      "          [29.5625, 44.5625, 46.7812,  ..., 53.5312, 51.7500, 35.9375],\n",
      "          [25.5938, 38.1875, 40.2188,  ..., 44.6562, 42.9062, 29.5938]],\n",
      "\n",
      "         [[30.6094, 40.1875, 39.8125,  ..., 72.0000, 67.8125, 46.6250],\n",
      "          [31.6719, 40.3750, 40.5000,  ..., 86.6875, 80.9375, 55.0000],\n",
      "          [31.2812, 38.8125, 38.4375,  ..., 88.6250, 83.3750, 57.2500],\n",
      "          ...,\n",
      "          [32.1562, 47.5000, 48.7500,  ..., 57.8750, 57.0625, 40.3125],\n",
      "          [32.8750, 49.6250, 52.1250,  ..., 59.6250, 57.6875, 40.0625],\n",
      "          [28.5156, 42.5625, 44.8750,  ..., 49.8125, 47.8750, 33.0000]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 34.2812,  45.4062,  44.8438,  ...,  85.3750,  79.8750,  54.6250],\n",
      "          [ 35.4062,  45.7500,  45.6250,  ..., 104.0000,  96.3750,  65.1875],\n",
      "          [ 34.9062,  43.9375,  43.0312,  ..., 106.3125,  99.3750,  68.0625],\n",
      "          ...,\n",
      "          [ 35.2500,  51.4062,  51.4375,  ...,  57.6250,  58.0312,  41.7812],\n",
      "          [ 35.9375,  53.5000,  54.9062,  ...,  60.0938,  59.3438,  41.9375],\n",
      "          [ 30.9844,  45.8125,  47.3750,  ...,  50.9375,  49.8125,  34.8125]],\n",
      "\n",
      "         [[ 35.0938,  46.4375,  45.8750,  ...,  87.7500,  82.0000,  56.0938],\n",
      "          [ 36.0000,  46.4062,  46.3125,  ..., 106.4375,  98.5625,  66.6875],\n",
      "          [ 35.5312,  44.6250,  43.7500,  ..., 108.8125, 101.6250,  69.5625],\n",
      "          ...,\n",
      "          [ 34.3125,  50.0312,  50.0938,  ...,  56.0938,  56.5000,  40.6562],\n",
      "          [ 34.9688,  52.0625,  53.4375,  ...,  58.5000,  57.7500,  40.7812],\n",
      "          [ 30.1562,  44.5938,  46.0938,  ...,  49.5625,  48.5000,  33.8750]],\n",
      "\n",
      "         [[ 31.2969,  41.3750,  40.8438,  ...,  78.4375,  73.3750,  50.0938],\n",
      "          [ 32.0938,  41.3438,  41.2188,  ...,  95.2500,  88.1875,  59.5938],\n",
      "          [ 31.6719,  39.7188,  38.9375,  ...,  97.3750,  90.9375,  62.1875],\n",
      "          ...,\n",
      "          [ 38.1562,  55.6562,  55.7188,  ...,  62.4062,  62.8438,  45.2188],\n",
      "          [ 38.8750,  57.9062,  59.4688,  ...,  65.0625,  64.2500,  45.3750],\n",
      "          [ 33.5625,  49.6562,  51.3438,  ...,  55.2188,  54.0000,  37.6875]]],\n",
      "\n",
      "\n",
      "        [[[ 34.4688,  46.1250,  45.8125,  ...,  45.6250,  48.1562,  36.7188],\n",
      "          [ 35.7812,  46.6562,  46.8750,  ...,  45.8125,  49.4688,  38.5938],\n",
      "          [ 35.3438,  44.8125,  44.1562,  ...,  42.5312,  47.8438,  38.5000],\n",
      "          ...,\n",
      "          [ 32.3438,  46.6250,  45.7500,  ...,  50.4375,  52.0312,  37.8750],\n",
      "          [ 33.3750,  49.2812,  49.9375,  ...,  53.9688,  54.0938,  38.4688],\n",
      "          [ 29.4062,  43.1875,  44.2188,  ...,  46.7188,  46.2812,  32.5312]],\n",
      "\n",
      "         [[ 35.3125,  47.1562,  46.8438,  ...,  46.6562,  49.2500,  37.5938],\n",
      "          [ 36.3750,  47.3438,  47.5938,  ...,  46.4688,  50.2188,  39.2500],\n",
      "          [ 35.9688,  45.5000,  44.8750,  ...,  43.1875,  48.5938,  39.1562],\n",
      "          ...,\n",
      "          [ 31.4844,  45.3750,  44.5312,  ...,  49.1250,  50.6250,  36.8438],\n",
      "          [ 32.4688,  47.9688,  48.6250,  ...,  52.5312,  52.6562,  37.4375],\n",
      "          [ 28.6094,  42.0312,  43.0312,  ...,  45.5000,  45.0625,  31.6406]],\n",
      "\n",
      "         [[ 31.4844,  42.0625,  41.7500,  ...,  41.5312,  43.8750,  33.5000],\n",
      "          [ 32.4375,  42.1875,  42.3750,  ...,  41.3750,  44.7500,  34.9688],\n",
      "          [ 32.0625,  40.5625,  39.9375,  ...,  38.4375,  43.2812,  34.9062],\n",
      "          ...,\n",
      "          [ 35.0000,  50.4688,  49.5000,  ...,  54.6250,  56.3125,  40.9688],\n",
      "          [ 36.0938,  53.3438,  54.0625,  ...,  58.4688,  58.5938,  41.6250],\n",
      "          [ 31.8438,  46.7812,  47.9062,  ...,  50.6562,  50.1562,  35.2188]]],\n",
      "\n",
      "\n",
      "        [[[ 43.5625,  65.7500,  75.4375,  ...,  73.1250,  69.0625,  47.8750],\n",
      "          [ 49.1875,  75.5625,  90.1875,  ...,  85.7500,  80.0000,  54.8750],\n",
      "          [ 50.0938,  76.7500,  91.5625,  ...,  85.8125,  80.7500,  56.2500],\n",
      "          ...,\n",
      "          [ 33.6875,  48.9688,  48.4688,  ...,  54.5312,  55.6250,  40.3438],\n",
      "          [ 34.4375,  51.1250,  52.0625,  ...,  57.3438,  57.1250,  40.5625],\n",
      "          [ 30.0156,  44.2500,  45.3750,  ...,  49.0312,  48.3125,  33.9062]],\n",
      "\n",
      "         [[ 44.6562,  67.4375,  77.4375,  ...,  75.0625,  70.8750,  49.0938],\n",
      "          [ 50.1562,  77.1250,  92.1875,  ...,  87.5625,  81.6250,  56.0000],\n",
      "          [ 51.0938,  78.3750,  93.6250,  ...,  87.7500,  82.4375,  57.4062],\n",
      "          ...,\n",
      "          [ 32.7812,  47.6562,  47.1875,  ...,  53.0938,  54.1250,  39.2500],\n",
      "          [ 33.5000,  49.7500,  50.6562,  ...,  55.8125,  55.5938,  39.4688],\n",
      "          [ 29.2188,  43.0625,  44.1562,  ...,  47.7188,  47.0312,  32.9688]],\n",
      "\n",
      "         [[ 39.8750,  60.2500,  69.2500,  ...,  67.0625,  63.3125,  43.8438],\n",
      "          [ 44.8125,  68.9375,  82.4375,  ...,  78.2500,  72.9375,  49.9688],\n",
      "          [ 45.6250,  70.0000,  83.7500,  ...,  78.3750,  73.6250,  51.2188],\n",
      "          ...,\n",
      "          [ 36.4375,  53.0000,  52.4688,  ...,  59.0625,  60.2188,  43.6250],\n",
      "          [ 37.2188,  55.3438,  56.3750,  ...,  62.1250,  61.8750,  43.8750],\n",
      "          [ 32.5000,  47.9375,  49.1875,  ...,  53.1562,  52.3750,  36.6875]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[32.0312, 43.2500, 42.7188,  ..., 43.7188, 46.2188, 35.0625],\n",
      "          [32.2812, 42.4062, 42.3438,  ..., 43.4062, 46.4688, 37.4375],\n",
      "          [31.7031, 40.9062, 39.8750,  ..., 41.0000, 45.8438, 36.6562],\n",
      "          ...,\n",
      "          [42.2812, 59.5312, 56.9062,  ..., 64.3125, 67.3125, 49.7812],\n",
      "          [44.0938, 63.5312, 62.5312,  ..., 69.0000, 70.5625, 51.2812],\n",
      "          [38.5938, 55.6250, 55.7188,  ..., 60.1875, 60.5938, 43.2812]],\n",
      "\n",
      "         [[32.7812, 44.2188, 43.6562,  ..., 44.6875, 47.2188, 35.8438],\n",
      "          [32.7500, 42.9688, 42.9375,  ..., 43.9688, 47.1250, 37.9062],\n",
      "          [32.2188, 41.5000, 40.5000,  ..., 41.5938, 46.5312, 37.2500],\n",
      "          ...,\n",
      "          [41.1562, 57.9375, 55.4375,  ..., 62.6250, 65.5000, 48.4688],\n",
      "          [42.9375, 61.8438, 60.8750,  ..., 67.1250, 68.7500, 49.9062],\n",
      "          [37.5938, 54.1562, 54.2500,  ..., 58.6250, 59.0000, 42.1250]],\n",
      "\n",
      "         [[29.2812, 39.4375, 38.9062,  ..., 39.8125, 42.1562, 32.0312],\n",
      "          [29.3281, 38.3438, 38.2500,  ..., 39.1875, 42.0312, 34.1562],\n",
      "          [28.7500, 37.0000, 36.0625,  ..., 37.0625, 41.5000, 33.2188],\n",
      "          ...,\n",
      "          [45.7188, 64.4375, 61.5625,  ..., 69.5625, 72.8125, 53.8438],\n",
      "          [47.6875, 68.7500, 67.6875,  ..., 74.6250, 76.3750, 55.4688],\n",
      "          [41.7812, 60.2500, 60.3750,  ..., 65.1875, 65.6250, 46.8438]]],\n",
      "\n",
      "\n",
      "        [[[40.4688, 58.6875, 62.2500,  ..., 43.1562, 45.5938, 34.6250],\n",
      "          [45.6250, 65.9375, 71.3125,  ..., 42.4688, 45.4375, 36.4688],\n",
      "          [47.4375, 68.0000, 72.0000,  ..., 39.5625, 44.1875, 35.6562],\n",
      "          ...,\n",
      "          [40.2500, 55.9062, 52.2500,  ..., 57.2188, 61.5625, 46.3125],\n",
      "          [42.2500, 60.3438, 58.5938,  ..., 63.3125, 65.8125, 48.2188],\n",
      "          [37.3750, 53.5938, 53.2188,  ..., 56.3125, 57.3125, 41.1875]],\n",
      "\n",
      "         [[41.4375, 60.1250, 63.7812,  ..., 44.0938, 46.5938, 35.4062],\n",
      "          [46.4375, 67.1250, 72.6875,  ..., 43.0000, 46.0625, 36.9375],\n",
      "          [48.3438, 69.3125, 73.4375,  ..., 40.1562, 44.8438, 36.2500],\n",
      "          ...,\n",
      "          [39.1875, 54.4062, 50.9062,  ..., 55.7500, 59.9375, 45.0938],\n",
      "          [41.1250, 58.7500, 57.0625,  ..., 61.6250, 64.0625, 46.9375],\n",
      "          [36.4062, 52.1875, 51.8438,  ..., 54.8438, 55.7812, 40.0625]],\n",
      "\n",
      "         [[37.0938, 53.7812, 57.0000,  ..., 39.3125, 41.5625, 31.6094],\n",
      "          [41.6250, 60.0625, 65.0000,  ..., 38.3438, 41.0938, 33.2188],\n",
      "          [43.1875, 61.9688, 65.5625,  ..., 35.7500, 39.9688, 32.3438],\n",
      "          ...,\n",
      "          [43.5000, 60.4688, 56.5312,  ..., 61.9062, 66.6250, 50.0938],\n",
      "          [45.6562, 65.2500, 63.4062,  ..., 68.5000, 71.1875, 52.1562],\n",
      "          [40.4688, 58.0312, 57.6562,  ..., 61.0000, 62.0625, 44.5625]]],\n",
      "\n",
      "\n",
      "        [[[40.9062, 59.8438, 64.6875,  ..., 71.1875, 66.8125, 45.8750],\n",
      "          [45.2812, 66.0000, 73.3125,  ..., 80.3125, 74.2500, 51.3438],\n",
      "          [45.7188, 65.7500, 71.6875,  ..., 73.8750, 69.2500, 48.4062],\n",
      "          ...,\n",
      "          [43.9688, 62.4688, 60.5000,  ..., 63.5938, 66.6250, 49.3750],\n",
      "          [45.6250, 66.1250, 65.6250,  ..., 68.3750, 70.0625, 50.9062],\n",
      "          [39.5312, 57.2500, 57.6562,  ..., 59.8125, 60.2188, 43.0312]],\n",
      "\n",
      "         [[41.9062, 61.2812, 66.2500,  ..., 72.9375, 68.4375, 47.0000],\n",
      "          [46.0938, 67.1875, 74.7500,  ..., 81.8750, 75.6250, 52.2500],\n",
      "          [46.5625, 66.9375, 73.1250,  ..., 75.3125, 70.5000, 49.2812],\n",
      "          ...,\n",
      "          [42.8125, 60.8125, 58.9062,  ..., 61.9375, 64.8750, 48.0625],\n",
      "          [44.4375, 64.3750, 63.8750,  ..., 66.5625, 68.1875, 49.5625],\n",
      "          [38.5000, 55.7500, 56.1250,  ..., 58.2500, 58.6562, 41.8750]],\n",
      "\n",
      "         [[37.5000, 54.8438, 59.2812,  ..., 65.2500, 61.2500, 42.0312],\n",
      "          [41.3125, 60.0938, 66.8125,  ..., 73.2500, 67.6875, 46.9062],\n",
      "          [41.5938, 59.8125, 65.3125,  ..., 67.2500, 62.9688, 44.0000],\n",
      "          ...,\n",
      "          [47.5625, 67.6250, 65.4375,  ..., 68.8125, 72.1250, 53.4062],\n",
      "          [49.3438, 71.5625, 71.0000,  ..., 74.0000, 75.8125, 55.0625],\n",
      "          [42.8125, 62.0000, 62.4375,  ..., 64.8125, 65.2500, 46.5625]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 35.6562,  48.8125,  47.4375,  ...,  55.2812,  53.2188,  38.7812],\n",
      "          [ 36.5312,  48.1250,  46.8438,  ...,  53.2500,  52.0938,  40.1562],\n",
      "          [ 34.6562,  45.3438,  42.8438,  ...,  44.4688,  47.3438,  38.2500],\n",
      "          ...,\n",
      "          [ 41.4375,  57.1875,  52.9375,  ...,  61.2188,  65.2500,  48.9062],\n",
      "          [ 43.6875,  62.1250,  59.7812,  ...,  66.4375,  69.0625,  50.6875],\n",
      "          [ 38.8125,  55.5312,  54.6875,  ...,  58.9688,  60.0938,  43.2188]],\n",
      "\n",
      "         [[ 36.4688,  49.8750,  48.4062,  ...,  56.5000,  54.3750,  39.6250],\n",
      "          [ 37.0312,  48.7500,  47.4688,  ...,  53.9688,  52.8125,  40.7188],\n",
      "          [ 35.2188,  45.9688,  43.4688,  ...,  45.0938,  48.0312,  38.8438],\n",
      "          ...,\n",
      "          [ 40.3750,  55.7188,  51.5938,  ...,  59.6250,  63.5312,  47.6250],\n",
      "          [ 42.5625,  60.5000,  58.2500,  ...,  64.7500,  67.2500,  49.3438],\n",
      "          [ 37.8438,  54.0625,  53.2812,  ...,  57.4375,  58.5312,  42.0938]],\n",
      "\n",
      "         [[ 32.6875,  44.5938,  43.2500,  ...,  50.4688,  48.6250,  35.4375],\n",
      "          [ 33.3125,  43.5938,  42.3750,  ...,  48.1875,  47.1875,  36.5625],\n",
      "          [ 31.4844,  41.0312,  38.7500,  ...,  40.2188,  42.8750,  34.6875],\n",
      "          ...,\n",
      "          [ 44.7812,  61.8125,  57.1875,  ...,  66.1875,  70.5000,  52.8438],\n",
      "          [ 47.2188,  67.1250,  64.6250,  ...,  71.8125,  74.6250,  54.7500],\n",
      "          [ 42.0000,  60.0625,  59.1562,  ...,  63.7812,  65.0000,  46.7188]]],\n",
      "\n",
      "\n",
      "        [[[ 42.7812,  63.4062,  68.1250,  ...,  98.1250,  90.6250,  61.0000],\n",
      "          [ 46.3750,  68.1250,  74.3125,  ..., 119.7500, 109.3125,  73.1250],\n",
      "          [ 45.9375,  65.1250,  68.4375,  ..., 120.6250, 111.3125,  75.6875],\n",
      "          ...,\n",
      "          [ 43.1250,  60.0312,  56.0938,  ...,  62.6875,  66.6875,  49.7812],\n",
      "          [ 45.0312,  64.2500,  61.9062,  ...,  67.8125,  70.2500,  51.4062],\n",
      "          [ 39.5312,  56.6250,  55.7812,  ...,  59.8125,  60.8438,  43.6562]],\n",
      "\n",
      "         [[ 43.8125,  64.8750,  69.7500,  ..., 100.5625,  92.8750,  62.5625],\n",
      "          [ 47.1562,  69.2500,  75.6250,  ..., 122.2500, 111.5625,  74.6250],\n",
      "          [ 46.7500,  66.2500,  69.6250,  ..., 123.1250, 113.5625,  77.2500],\n",
      "          ...,\n",
      "          [ 42.0312,  58.4688,  54.6562,  ...,  61.0938,  64.9375,  48.4688],\n",
      "          [ 43.8750,  62.5312,  60.3125,  ...,  66.0000,  68.4375,  50.0312],\n",
      "          [ 38.5312,  55.1562,  54.3438,  ...,  58.2500,  59.2500,  42.5000]],\n",
      "\n",
      "         [[ 39.2188,  58.0938,  62.4375,  ...,  90.1875,  83.3125,  56.0625],\n",
      "          [ 42.2812,  62.0312,  67.6875,  ..., 109.7500, 100.1250,  66.9375],\n",
      "          [ 41.8125,  59.2188,  62.2188,  ..., 110.5000, 101.8750,  69.2500],\n",
      "          ...,\n",
      "          [ 46.5938,  64.8750,  60.6250,  ...,  67.7500,  72.0625,  53.7812],\n",
      "          [ 48.6562,  69.3750,  66.9375,  ...,  73.2500,  76.0000,  55.5312],\n",
      "          [ 42.7812,  61.2500,  60.3438,  ...,  64.6875,  65.8750,  47.1875]]],\n",
      "\n",
      "\n",
      "        [[[ 38.8750,  53.6250,  53.1250,  ...,  48.8125,  51.7188,  39.0625],\n",
      "          [ 41.4375,  55.6562,  55.1250,  ...,  48.5312,  52.1250,  41.8438],\n",
      "          [ 37.2500,  50.9062,  51.1250,  ...,  44.6562,  50.3750,  40.6250],\n",
      "          ...,\n",
      "          [ 41.4062,  57.0625,  52.5000,  ...,  54.4688,  59.8438,  45.5625],\n",
      "          [ 43.5625,  61.7812,  59.1562,  ...,  60.5938,  64.1875,  47.5625],\n",
      "          [ 38.6562,  55.1875,  54.1875,  ...,  54.9688,  56.7500,  41.0938]],\n",
      "\n",
      "         [[ 39.7500,  54.8125,  54.2812,  ...,  49.8125,  52.8438,  39.9375],\n",
      "          [ 42.0000,  56.3750,  55.9688,  ...,  49.1250,  52.8438,  42.4062],\n",
      "          [ 37.8750,  51.6562,  51.9062,  ...,  45.2500,  51.0938,  41.2500],\n",
      "          ...,\n",
      "          [ 40.3438,  55.5625,  51.1562,  ...,  53.0938,  58.3125,  44.3750],\n",
      "          [ 42.4375,  60.1562,  57.6250,  ...,  59.0312,  62.5000,  46.3125],\n",
      "          [ 37.6875,  53.7500,  52.7812,  ...,  53.5312,  55.2812,  40.0000]],\n",
      "\n",
      "         [[ 35.8125,  49.0938,  48.5625,  ...,  44.5000,  47.2500,  35.7188],\n",
      "          [ 38.1875,  50.7188,  50.0000,  ...,  43.8750,  47.2188,  38.1875],\n",
      "          [ 33.8438,  46.1875,  46.3750,  ...,  40.4062,  45.6250,  36.8750],\n",
      "          ...,\n",
      "          [ 44.7500,  61.6562,  56.7188,  ...,  58.8750,  64.6875,  49.2188],\n",
      "          [ 47.0625,  66.7500,  63.9062,  ...,  65.5000,  69.3750,  51.3750],\n",
      "          [ 41.8125,  59.6875,  58.5938,  ...,  59.4688,  61.4062,  44.4375]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 33.7500,  46.9688,  45.0625,  ...,  68.0625,  67.0000,  47.2500],\n",
      "          [ 33.2500,  45.1562,  42.9688,  ...,  72.5625,  71.8750,  51.7500],\n",
      "          [ 31.4688,  41.4375,  38.1875,  ...,  65.5625,  67.1875,  50.0938],\n",
      "          ...,\n",
      "          [ 41.5000,  56.7812,  52.4688,  ...,  61.0000,  64.9375,  49.0625],\n",
      "          [ 44.3125,  62.5000,  60.1250,  ...,  66.8750,  69.3750,  51.1875],\n",
      "          [ 39.5312,  56.3125,  55.6562,  ...,  59.8438,  60.7812,  43.8125]],\n",
      "\n",
      "         [[ 34.4688,  47.9062,  45.9375,  ...,  69.5000,  68.4375,  48.2812],\n",
      "          [ 33.6875,  45.6875,  43.4375,  ...,  73.6875,  73.0000,  52.5312],\n",
      "          [ 31.9531,  41.9688,  38.6875,  ...,  66.5625,  68.1875,  50.8750],\n",
      "          ...,\n",
      "          [ 40.4375,  55.2812,  51.1562,  ...,  59.4062,  63.2812,  47.7500],\n",
      "          [ 43.1562,  60.8438,  58.5625,  ...,  65.1250,  67.5625,  49.8125],\n",
      "          [ 38.5312,  54.8438,  54.2188,  ...,  58.2812,  59.1875,  42.6562]],\n",
      "\n",
      "         [[ 30.8594,  42.8750,  41.0938,  ...,  62.3125,  61.4062,  43.3125],\n",
      "          [ 30.2031,  40.9062,  38.8438,  ...,  65.9375,  65.4375,  47.1562],\n",
      "          [ 28.5938,  37.5312,  34.5625,  ...,  59.5938,  61.0938,  45.5625],\n",
      "          ...,\n",
      "          [ 44.8125,  61.2812,  56.6562,  ...,  65.8125,  70.1250,  52.9375],\n",
      "          [ 47.8125,  67.4375,  64.8750,  ...,  72.1875,  74.9375,  55.2500],\n",
      "          [ 42.7188,  60.8750,  60.1562,  ...,  64.6250,  65.6875,  47.3438]]],\n",
      "\n",
      "\n",
      "        [[[ 59.2500,  91.5000,  99.2500,  ...,  55.7188,  56.4375,  41.4375],\n",
      "          [ 70.8125, 109.9375, 120.7500,  ...,  54.8438,  56.5312,  43.4375],\n",
      "          [ 71.9375, 110.6250, 119.6875,  ...,  47.0625,  52.2188,  42.2188],\n",
      "          ...,\n",
      "          [ 46.1875,  65.0625,  62.3750,  ...,  66.0625,  69.0000,  51.4062],\n",
      "          [ 48.3125,  69.5000,  68.3750,  ...,  71.2500,  73.0000,  53.3750],\n",
      "          [ 41.9688,  60.5938,  60.6562,  ...,  62.8125,  63.2500,  45.3125]],\n",
      "\n",
      "         [[ 60.6562,  93.7500, 101.6250,  ...,  56.8125,  57.5625,  42.2812],\n",
      "          [ 72.1875, 112.1250, 123.1875,  ...,  55.5000,  57.2500,  44.0312],\n",
      "          [ 73.3125, 112.8125, 122.0625,  ...,  47.6562,  52.9062,  42.8125],\n",
      "          ...,\n",
      "          [ 45.0000,  63.4062,  60.7812,  ...,  64.3750,  67.2500,  50.0312],\n",
      "          [ 47.0625,  67.6875,  66.6250,  ...,  69.3750,  71.1250,  51.9375],\n",
      "          [ 40.9062,  59.0000,  59.0625,  ...,  61.1562,  61.5938,  44.0938]],\n",
      "\n",
      "         [[ 54.5312,  84.2500,  91.3125,  ...,  50.8750,  51.5938,  37.9062],\n",
      "          [ 64.8750, 100.8125, 110.6875,  ...,  49.6875,  51.2812,  39.5000],\n",
      "          [ 65.8750, 101.3750, 109.6875,  ...,  42.5938,  47.3438,  38.3438],\n",
      "          ...,\n",
      "          [ 49.8750,  70.2500,  67.3125,  ...,  71.3125,  74.5625,  55.4688],\n",
      "          [ 52.1875,  75.1250,  73.8750,  ...,  76.9375,  78.8750,  57.6250],\n",
      "          [ 45.3750,  65.4375,  65.5625,  ...,  67.8750,  68.3750,  48.9688]]],\n",
      "\n",
      "\n",
      "        [[[ 36.1250,  48.4688,  46.6250,  ...,  55.0625,  59.6875,  45.5312],\n",
      "          [ 37.5312,  48.9062,  44.7188,  ...,  55.3750,  64.4375,  51.7188],\n",
      "          [ 33.1250,  44.0312,  40.4688,  ...,  50.0625,  59.0625,  46.5625],\n",
      "          ...,\n",
      "          [ 43.3125,  59.8125,  55.8750,  ...,  66.4375,  69.3750,  51.5938],\n",
      "          [ 45.7500,  64.8750,  62.6250,  ...,  71.5625,  73.3125,  53.5625],\n",
      "          [ 40.3750,  57.6562,  57.0312,  ...,  63.0000,  63.4062,  45.4062]],\n",
      "\n",
      "         [[ 36.8438,  49.4375,  47.5312,  ...,  56.1875,  60.9375,  46.4062],\n",
      "          [ 37.9062,  49.3125,  45.2500,  ...,  56.0938,  65.1875,  52.2500],\n",
      "          [ 33.6250,  44.5625,  40.9688,  ...,  50.6875,  59.8750,  47.2500],\n",
      "          ...,\n",
      "          [ 42.2188,  58.2500,  54.4375,  ...,  64.7500,  67.5625,  50.2188],\n",
      "          [ 44.5625,  63.1562,  60.9688,  ...,  69.7500,  71.3750,  52.1250],\n",
      "          [ 39.3438,  56.1250,  55.5625,  ...,  61.3438,  61.7500,  44.1875]],\n",
      "\n",
      "         [[ 33.4062,  44.3438,  42.5625,  ...,  50.3438,  54.6875,  41.9688],\n",
      "          [ 34.7500,  44.6875,  40.5000,  ...,  50.2500,  58.9375,  47.8438],\n",
      "          [ 30.1250,  39.9062,  36.6562,  ...,  45.4062,  53.6562,  42.3438],\n",
      "          ...,\n",
      "          [ 46.7812,  64.5625,  60.3125,  ...,  71.7500,  74.9375,  55.6875],\n",
      "          [ 49.4062,  70.0000,  67.5625,  ...,  77.3125,  79.1875,  57.8125],\n",
      "          [ 43.6562,  62.3125,  61.6562,  ...,  68.0625,  68.5625,  49.0625]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 63.0938,  99.0000, 107.4375,  ...,  74.0625,  70.6875,  48.6875],\n",
      "          [ 76.5625, 120.5625, 131.8750,  ...,  74.2500,  72.0625,  52.5312],\n",
      "          [ 78.0625, 121.5000, 130.6250,  ...,  57.6875,  60.4062,  45.8125],\n",
      "          ...,\n",
      "          [ 46.2812,  65.7500,  64.1250,  ...,  66.3750,  68.3125,  50.6875],\n",
      "          [ 48.3750,  69.8750,  69.5000,  ...,  71.5625,  72.2500,  52.5938],\n",
      "          [ 41.8438,  60.5625,  61.2500,  ...,  62.7188,  62.4062,  44.5625]],\n",
      "\n",
      "         [[ 64.5625, 101.2500, 109.8125,  ...,  75.5625,  72.1250,  49.7188],\n",
      "          [ 77.9375, 122.7500, 134.3750,  ...,  75.1875,  73.0000,  53.1875],\n",
      "          [ 79.4375, 123.7500, 133.0000,  ...,  58.4062,  61.1562,  46.4688],\n",
      "          ...,\n",
      "          [ 45.1562,  64.0000,  62.5000,  ...,  64.6875,  66.5625,  49.4062],\n",
      "          [ 47.1562,  68.0625,  67.6875,  ...,  69.6875,  70.3750,  51.2500],\n",
      "          [ 40.8125,  59.0312,  59.7188,  ...,  61.1562,  60.8125,  43.4375]],\n",
      "\n",
      "         [[ 58.0938,  91.1875,  98.9375,  ...,  67.8750,  64.8750,  44.6875],\n",
      "          [ 70.3125, 110.6875, 121.0625,  ...,  67.5625,  65.6875,  48.1562],\n",
      "          [ 71.6250, 111.5000, 119.8125,  ...,  52.3750,  54.8750,  41.6875],\n",
      "          ...,\n",
      "          [ 49.9375,  70.9375,  69.1875,  ...,  71.6250,  73.7500,  54.6875],\n",
      "          [ 52.1875,  75.4375,  75.0000,  ...,  77.1875,  78.0000,  56.7500],\n",
      "          [ 45.1875,  65.4375,  66.1875,  ...,  67.8125,  67.4375,  48.0938]]],\n",
      "\n",
      "\n",
      "        [[[ 36.6875,  51.6875,  48.6250,  ..., 109.5000, 102.4375,  67.5625],\n",
      "          [ 37.6562,  50.2188,  45.6562,  ..., 131.6250, 122.9375,  81.2500],\n",
      "          [ 34.3125,  45.3750,  39.1250,  ..., 122.6250, 117.7500,  79.4375],\n",
      "          ...,\n",
      "          [ 45.5000,  64.3750,  62.5000,  ...,  68.0625,  69.6875,  51.5000],\n",
      "          [ 47.9688,  69.2500,  68.7500,  ...,  73.0000,  73.5000,  53.3438],\n",
      "          [ 41.6562,  60.2812,  60.8750,  ...,  63.7188,  63.2188,  45.0625]],\n",
      "\n",
      "         [[ 37.4688,  52.7188,  49.5625,  ..., 111.9375, 104.6875,  69.0625],\n",
      "          [ 38.0938,  50.7500,  46.1562,  ..., 134.0000, 125.1250,  82.6875],\n",
      "          [ 34.8125,  45.9375,  39.5938,  ..., 124.8125, 119.8125,  80.8750],\n",
      "          ...,\n",
      "          [ 44.4062,  62.7500,  60.9688,  ...,  66.3125,  67.8750,  50.1875],\n",
      "          [ 46.7812,  67.4375,  66.9375,  ...,  71.1250,  71.6250,  51.9688],\n",
      "          [ 40.6562,  58.7812,  59.3438,  ...,  62.1250,  61.6562,  43.9375]],\n",
      "\n",
      "         [[ 33.7188,  47.3125,  44.4062,  ..., 100.8125,  94.3125,  62.1250],\n",
      "          [ 34.5000,  45.6250,  41.3438,  ..., 120.6875, 112.7500,  74.5000],\n",
      "          [ 31.2031,  41.1562,  35.4062,  ..., 112.4375, 107.9375,  72.8125],\n",
      "          ...,\n",
      "          [ 49.1250,  69.5000,  67.5000,  ...,  73.4375,  75.2500,  55.5625],\n",
      "          [ 51.7812,  74.7500,  74.1875,  ...,  78.8125,  79.3750,  57.5625],\n",
      "          [ 45.0000,  65.1875,  65.8125,  ...,  68.8750,  68.3750,  48.6562]]],\n",
      "\n",
      "\n",
      "        [[[ 44.5000,  64.6250,  63.6875,  ..., 107.8750,  99.7500,  66.0625],\n",
      "          [ 51.3125,  72.8750,  71.3750,  ..., 130.7500, 119.6875,  79.3125],\n",
      "          [ 50.8125,  72.8125,  69.8750,  ..., 127.8750, 118.5625,  80.0000],\n",
      "          ...,\n",
      "          [ 44.7188,  63.0000,  60.9688,  ...,  68.0625,  69.6875,  51.4688],\n",
      "          [ 47.0938,  67.8125,  67.1875,  ...,  73.0000,  73.4375,  53.2812],\n",
      "          [ 41.0625,  59.3125,  59.8125,  ...,  63.6562,  63.1562,  45.0000]],\n",
      "\n",
      "         [[ 45.4688,  65.9375,  64.9375,  ..., 110.2500, 101.9375,  67.5000],\n",
      "          [ 52.0625,  73.8750,  72.3750,  ..., 133.1250, 121.8125,  80.6875],\n",
      "          [ 51.6562,  73.8750,  70.9375,  ..., 130.2500, 120.6250,  81.4375],\n",
      "          ...,\n",
      "          [ 43.6250,  61.4375,  59.4688,  ...,  66.3125,  67.8750,  50.1562],\n",
      "          [ 45.9375,  66.0625,  65.3750,  ...,  71.0625,  71.5000,  51.9062],\n",
      "          [ 40.0938,  57.8438,  58.3125,  ...,  62.0625,  61.5625,  43.8750]],\n",
      "\n",
      "         [[ 40.9688,  59.3125,  58.3750,  ...,  99.2500,  91.7500,  60.7500],\n",
      "          [ 47.1875,  66.6250,  65.0000,  ..., 119.8750, 109.7500,  72.6875],\n",
      "          [ 46.3750,  66.3750,  63.6250,  ..., 117.2500, 108.6250,  73.3125],\n",
      "          ...,\n",
      "          [ 48.2500,  68.0000,  65.8125,  ...,  73.4375,  75.2500,  55.5000],\n",
      "          [ 50.8438,  73.1875,  72.4375,  ...,  78.7500,  79.2500,  57.4688],\n",
      "          [ 44.3750,  64.1250,  64.6250,  ...,  68.8125,  68.2500,  48.5938]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 41.9062,  60.9062,  56.4375,  ...,  58.8125,  64.0625,  46.8125],\n",
      "          [ 43.4375,  59.9688,  51.5000,  ...,  53.6562,  62.2188,  48.5312],\n",
      "          [ 37.7188,  50.1562,  40.3438,  ...,  41.0000,  52.6250,  43.4375],\n",
      "          ...,\n",
      "          [ 46.0938,  65.0000,  61.6562,  ...,  65.3750,  68.5000,  51.0625],\n",
      "          [ 48.8438,  70.7500,  69.1875,  ...,  71.6250,  73.1250,  53.1562],\n",
      "          [ 42.4688,  61.9375,  62.0000,  ...,  63.3438,  63.3438,  45.0000]],\n",
      "\n",
      "         [[ 42.7500,  62.0625,  57.4688,  ...,  59.8750,  65.2500,  47.7500],\n",
      "          [ 43.9062,  60.5000,  52.0000,  ...,  54.1250,  62.8438,  49.0938],\n",
      "          [ 38.2188,  50.7188,  40.7188,  ...,  41.3438,  53.1875,  43.9688],\n",
      "          ...,\n",
      "          [ 45.0000,  63.3750,  60.1562,  ...,  63.7188,  66.8750,  49.8125],\n",
      "          [ 47.6875,  68.9375,  67.4375,  ...,  69.8125,  71.3125,  51.8438],\n",
      "          [ 41.4688,  60.4062,  60.4688,  ...,  61.7812,  61.7812,  43.8750]],\n",
      "\n",
      "         [[ 38.5000,  55.8438,  51.6250,  ...,  53.7812,  58.6562,  42.9062],\n",
      "          [ 39.9062,  54.7188,  46.6875,  ...,  48.6562,  56.5312,  44.2188],\n",
      "          [ 34.3125,  45.5625,  36.5000,  ...,  37.0938,  47.7500,  39.5000],\n",
      "          ...,\n",
      "          [ 49.7188,  70.1250,  66.5000,  ...,  70.4375,  73.9375,  55.0625],\n",
      "          [ 52.6875,  76.3125,  74.6250,  ...,  77.2500,  78.8750,  57.3438],\n",
      "          [ 45.8438,  66.9375,  66.9375,  ...,  68.4375,  68.4375,  48.5625]]],\n",
      "\n",
      "\n",
      "        [[[ 50.7500,  79.3750,  85.0000,  ...,  59.7812,  64.5000,  46.9062],\n",
      "          [ 56.0938,  86.7500,  93.6875,  ...,  54.6875,  62.8750,  48.8438],\n",
      "          [ 52.6875,  79.3750,  82.5625,  ...,  41.7500,  52.9375,  43.2812],\n",
      "          ...,\n",
      "          [ 48.1250,  68.7500,  66.3125,  ...,  72.4375,  74.0625,  54.1562],\n",
      "          [ 50.5938,  73.7500,  72.8125,  ...,  77.2500,  77.6250,  55.7812],\n",
      "          [ 43.5625,  63.7812,  64.1875,  ...,  66.8750,  66.1875,  46.6562]],\n",
      "\n",
      "         [[ 51.8125,  80.9375,  86.6875,  ...,  60.8438,  65.7500,  47.8438],\n",
      "          [ 56.8750,  87.9375,  95.0625,  ...,  55.1875,  63.5000,  49.4062],\n",
      "          [ 53.4375,  80.4375,  83.7500,  ...,  42.1250,  53.5000,  43.8438],\n",
      "          ...,\n",
      "          [ 47.0000,  67.0625,  64.6875,  ...,  70.6250,  72.1875,  52.8125],\n",
      "          [ 49.3750,  71.9375,  71.0000,  ...,  75.3125,  75.6875,  54.4062],\n",
      "          [ 42.5312,  62.2188,  62.5625,  ...,  65.2500,  64.5625,  45.5000]],\n",
      "\n",
      "         [[ 46.6562,  72.9375,  78.0625,  ...,  54.6875,  59.0938,  43.0000],\n",
      "          [ 51.3125,  79.3125,  85.6250,  ...,  49.5938,  57.1875,  44.5938],\n",
      "          [ 48.0625,  72.3750,  75.3125,  ...,  37.7812,  48.0625,  39.3750],\n",
      "          ...,\n",
      "          [ 51.9375,  74.1250,  71.5000,  ...,  78.0625,  79.8750,  58.4062],\n",
      "          [ 54.5938,  79.5625,  78.5625,  ...,  83.3750,  83.7500,  60.1562],\n",
      "          [ 47.0312,  68.8750,  69.3125,  ...,  72.2500,  71.5000,  50.3438]]],\n",
      "\n",
      "\n",
      "        [[[ 50.0000,  78.6250,  83.7500,  ..., 129.5000, 119.2500,  77.5625],\n",
      "          [ 54.1250,  82.9375,  87.1875,  ..., 159.0000, 144.7500,  94.3750],\n",
      "          [ 48.7188,  71.2500,  69.6250,  ..., 154.2500, 141.2500,  93.2500],\n",
      "          ...,\n",
      "          [ 48.1562,  68.8125,  66.5000,  ...,  72.5000,  74.1250,  54.1875],\n",
      "          [ 50.6250,  73.8750,  72.9375,  ...,  77.1250,  77.5000,  55.6875],\n",
      "          [ 43.5625,  63.8438,  64.2500,  ...,  66.7500,  66.0625,  46.5625]],\n",
      "\n",
      "         [[ 51.0625,  80.1875,  85.3750,  ..., 132.2500, 121.8125,  79.2500],\n",
      "          [ 54.8438,  83.9375,  88.3750,  ..., 161.7500, 147.2500,  96.0625],\n",
      "          [ 49.4062,  72.1250,  70.5000,  ..., 157.1250, 143.7500,  94.8750],\n",
      "          ...,\n",
      "          [ 47.0312,  67.1250,  64.8750,  ...,  70.6875,  72.3125,  52.8438],\n",
      "          [ 49.4062,  72.0000,  71.1250,  ...,  75.1875,  75.5625,  54.3125],\n",
      "          [ 42.5312,  62.2812,  62.6562,  ...,  65.1250,  64.4375,  45.4062]],\n",
      "\n",
      "         [[ 45.9688,  72.1875,  76.9375,  ..., 119.3125, 109.8125,  71.4375],\n",
      "          [ 49.5938,  75.8125,  79.5625,  ..., 146.1250, 132.8750,  86.5625],\n",
      "          [ 44.4375,  64.8750,  63.3125,  ..., 141.7500, 129.6250,  85.5000],\n",
      "          ...,\n",
      "          [ 51.9688,  74.2500,  71.6875,  ...,  78.1875,  79.9375,  58.4375],\n",
      "          [ 54.6250,  79.6875,  78.6875,  ...,  83.1875,  83.6250,  60.0625],\n",
      "          [ 47.0625,  68.9375,  69.3750,  ...,  72.0625,  71.3750,  50.2500]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 27.3125,  40.0938,  37.3438,  ...,  81.6250,  68.6875,  42.1562],\n",
      "          [ 26.5312,  37.2812,  34.6875,  ...,  94.8125,  76.0625,  46.1875],\n",
      "          [ 23.6562,  31.6406,  27.9062,  ...,  88.3125,  69.5000,  43.1562],\n",
      "          ...,\n",
      "          [ 49.1250,  68.3125,  62.0625,  ...,  68.1875,  73.2500,  55.0312],\n",
      "          [ 53.6562,  76.6875,  72.0625,  ...,  75.1250,  79.0000,  58.0938],\n",
      "          [ 47.0000,  68.3750,  66.6250,  ...,  68.0625,  69.5000,  49.3438]],\n",
      "\n",
      "         [[ 27.8125,  40.7188,  37.9062,  ...,  83.1875,  69.9375,  42.9375],\n",
      "          [ 26.7812,  37.5625,  34.9062,  ...,  96.1875,  77.0625,  46.7188],\n",
      "          [ 23.9062,  31.9531,  28.1719,  ...,  89.6250,  70.3750,  43.6562],\n",
      "          ...,\n",
      "          [ 47.9375,  66.6250,  60.5625,  ...,  66.5000,  71.5000,  53.6562],\n",
      "          [ 52.3438,  74.8125,  70.3125,  ...,  73.2500,  77.0000,  56.6250],\n",
      "          [ 45.8750,  66.7500,  65.0000,  ...,  66.3750,  67.8125,  48.1250]],\n",
      "\n",
      "         [[ 24.9688,  36.5938,  34.0000,  ...,  75.0000,  63.0312,  38.6562],\n",
      "          [ 24.0625,  33.7500,  31.2812,  ...,  86.7500,  69.4375,  42.0625],\n",
      "          [ 21.4375,  28.6250,  25.1562,  ...,  80.7500,  63.3125,  39.2812],\n",
      "          ...,\n",
      "          [ 52.9688,  73.6875,  66.8750,  ...,  73.4375,  79.0000,  59.3125],\n",
      "          [ 57.9062,  82.7500,  77.6875,  ...,  81.0000,  85.1875,  62.6250],\n",
      "          [ 50.7500,  73.8125,  71.9375,  ...,  73.4375,  75.0000,  53.2500]]],\n",
      "\n",
      "\n",
      "        [[[ 37.0625,  55.3125,  50.9688,  ...,  43.3750,  46.6875,  33.4688],\n",
      "          [ 37.5938,  53.8750,  48.5000,  ...,  39.8125,  45.4375,  34.7812],\n",
      "          [ 32.0312,  43.7812,  37.2812,  ...,  31.5938,  39.9062,  32.4688],\n",
      "          ...,\n",
      "          [ 49.0938,  68.0625,  61.5938,  ...,  66.1875,  71.7500,  54.2500],\n",
      "          [ 53.4375,  76.1875,  71.4375,  ...,  73.9375,  78.1875,  57.7812],\n",
      "          [ 46.8125,  68.0625,  66.2500,  ...,  67.5000,  69.2500,  49.2812]],\n",
      "\n",
      "         [[ 37.7188,  56.2812,  51.7500,  ...,  44.0312,  47.4062,  34.0625],\n",
      "          [ 37.9688,  54.3750,  48.8125,  ...,  40.0312,  45.7500,  35.0938],\n",
      "          [ 32.3438,  44.1562,  37.5312,  ...,  31.8125,  40.2188,  32.8125],\n",
      "          ...,\n",
      "          [ 47.9062,  66.4375,  60.0938,  ...,  64.6250,  70.0625,  52.9062],\n",
      "          [ 52.1250,  74.3125,  69.6875,  ...,  72.1250,  76.2500,  56.3125],\n",
      "          [ 45.6875,  66.3750,  64.6250,  ...,  65.8750,  67.5625,  48.0625]],\n",
      "\n",
      "         [[ 34.0000,  50.7188,  46.5625,  ...,  39.5625,  42.6562,  30.6094],\n",
      "          [ 34.2500,  48.9688,  43.9375,  ...,  36.0000,  41.1875,  31.5781],\n",
      "          [ 29.0938,  39.6875,  33.6875,  ...,  28.5312,  36.1562,  29.4844],\n",
      "          ...,\n",
      "          [ 52.9688,  73.4375,  66.3750,  ...,  71.3125,  77.3750,  58.5000],\n",
      "          [ 57.6562,  82.1875,  77.0000,  ...,  79.6875,  84.3125,  62.2812],\n",
      "          [ 50.5625,  73.4375,  71.5000,  ...,  72.8750,  74.7500,  53.1875]]],\n",
      "\n",
      "\n",
      "        [[[ 32.9062,  53.0312,  56.6562,  ..., 108.7500,  96.0000,  59.8438],\n",
      "          [ 33.7812,  52.4688,  55.5000,  ..., 137.0000, 118.8125,  73.8125],\n",
      "          [ 31.2969,  45.0938,  43.0312,  ..., 137.2500, 119.1250,  74.8125],\n",
      "          ...,\n",
      "          [ 49.5000,  68.8750,  62.6250,  ...,  68.3125,  73.3750,  55.1562],\n",
      "          [ 53.8438,  76.9375,  72.3125,  ...,  75.3125,  79.1875,  58.3125],\n",
      "          [ 47.1250,  68.5625,  66.8125,  ...,  68.2500,  69.7500,  49.5312]],\n",
      "\n",
      "         [[ 33.4688,  53.9375,  57.5625,  ..., 111.0625,  97.9375,  61.0938],\n",
      "          [ 34.0938,  52.9062,  55.9688,  ..., 139.2500, 120.8125,  75.0625],\n",
      "          [ 31.6094,  45.4688,  43.3438,  ..., 139.6250, 121.0625,  76.0625],\n",
      "          ...,\n",
      "          [ 48.3125,  67.1875,  61.1250,  ...,  66.6250,  71.6250,  53.7812],\n",
      "          [ 52.5312,  75.0000,  70.5625,  ...,  73.4375,  77.2500,  56.8125],\n",
      "          [ 46.0000,  66.8750,  65.1875,  ...,  66.5625,  68.0625,  48.3125]],\n",
      "\n",
      "         [[ 30.1250,  48.5938,  51.8438,  ..., 100.2500,  88.4375,  55.0938],\n",
      "          [ 30.7188,  47.6875,  50.4062,  ..., 125.9375, 109.1875,  67.7500],\n",
      "          [ 28.4219,  40.9062,  38.9688,  ..., 126.1875, 109.3125,  68.6250],\n",
      "          ...,\n",
      "          [ 53.4062,  74.2500,  67.5000,  ...,  73.5625,  79.1250,  59.4375],\n",
      "          [ 58.0938,  83.0000,  77.9375,  ...,  81.1250,  85.4375,  62.8438],\n",
      "          [ 50.8750,  74.0000,  72.1250,  ...,  73.6250,  75.3125,  53.4375]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[13.4141, 28.6250, 29.7500,  ..., 36.7812, 35.2500, 19.3594],\n",
      "          [15.8047, 30.8750, 32.2500,  ..., 37.8750, 38.6875, 23.6875],\n",
      "          [16.8281, 30.1094, 28.1719,  ..., 31.7344, 36.9062, 24.3750],\n",
      "          ...,\n",
      "          [32.9375, 43.4688, 30.8438,  ..., 19.3594, 30.3125, 26.4375],\n",
      "          [36.0625, 49.5625, 38.7188,  ..., 27.2344, 37.6562, 30.8594],\n",
      "          [33.4375, 48.6562, 42.8438,  ..., 34.6562, 40.7812, 29.8594]],\n",
      "\n",
      "         [[13.5547, 28.9688, 30.0469,  ..., 37.2500, 35.6562, 19.6094],\n",
      "          [15.6953, 30.8750, 32.2188,  ..., 38.0000, 38.7500, 23.7344],\n",
      "          [16.7812, 30.1562, 28.1875,  ..., 31.8594, 37.0312, 24.4688],\n",
      "          ...,\n",
      "          [32.2188, 42.5000, 30.2031,  ..., 19.0156, 29.6875, 25.8438],\n",
      "          [35.2188, 48.3750, 37.8125,  ..., 26.6250, 36.7812, 30.1250],\n",
      "          [32.6562, 47.5000, 41.8438,  ..., 33.8750, 39.8438, 29.1406]],\n",
      "\n",
      "         [[12.0703, 25.9531, 26.9062,  ..., 33.4375, 32.0000, 17.5312],\n",
      "          [14.0391, 27.7188, 28.8906,  ..., 34.1562, 34.8125, 21.2656],\n",
      "          [14.9922, 27.0469, 25.2344,  ..., 28.6094, 33.2188, 21.9219],\n",
      "          ...,\n",
      "          [35.4375, 46.6875, 33.0312,  ..., 20.6406, 32.5312, 28.3594],\n",
      "          [38.7812, 53.2500, 41.5000,  ..., 29.1094, 40.4375, 33.1562],\n",
      "          [36.0312, 52.3750, 46.0938,  ..., 37.2500, 43.9062, 32.1250]]],\n",
      "\n",
      "\n",
      "        [[[15.3281, 35.0312, 36.8438,  ..., 39.1250, 35.5938, 19.2812],\n",
      "          [22.2656, 49.8750, 47.7500,  ..., 44.7188, 41.8750, 24.9219],\n",
      "          [24.5781, 52.7812, 47.6250,  ..., 41.6562, 42.5625, 26.9531],\n",
      "          ...,\n",
      "          [31.2812, 40.8125, 27.7344,  ...,  9.2734, 21.0156, 20.2656],\n",
      "          [34.4375, 46.8750, 35.5625,  ..., 18.8125, 30.1406, 26.0781],\n",
      "          [32.3438, 46.8125, 40.6250,  ..., 29.2031, 36.1250, 27.0312]],\n",
      "\n",
      "         [[15.5391, 35.5000, 37.3750,  ..., 39.6562, 36.0000, 19.5156],\n",
      "          [22.0938, 49.6250, 47.6250,  ..., 44.9375, 41.9688, 24.9844],\n",
      "          [24.5156, 52.6250, 47.4688,  ..., 41.9375, 42.7500, 27.0938],\n",
      "          ...,\n",
      "          [30.5781, 39.9062, 27.1875,  ...,  9.1953, 20.6250, 19.8438],\n",
      "          [33.6250, 45.7812, 34.7500,  ..., 18.4062, 29.4531, 25.4688],\n",
      "          [31.5781, 45.7188, 39.7188,  ..., 28.5469, 35.3125, 26.3906]],\n",
      "\n",
      "         [[13.9219, 32.1250, 33.5938,  ..., 35.5938, 32.2812, 17.4375],\n",
      "          [20.9375, 47.5000, 44.9062,  ..., 40.4062, 37.6875, 22.3750],\n",
      "          [22.8906, 50.3438, 45.4688,  ..., 37.6562, 38.3750, 24.2656],\n",
      "          ...,\n",
      "          [33.6250, 43.8438, 29.6719,  ...,  9.7422, 22.4688, 21.7188],\n",
      "          [37.0000, 50.3750, 38.1250,  ..., 20.0156, 32.3125, 27.9844],\n",
      "          [34.8438, 50.4062, 43.7188,  ..., 31.3750, 38.8750, 29.0625]]],\n",
      "\n",
      "\n",
      "        [[[14.3984, 32.3750, 34.9062,  ..., 46.7812, 43.9375, 24.1719],\n",
      "          [16.7500, 37.3125, 37.0000,  ..., 55.9375, 52.4062, 30.4375],\n",
      "          [19.5625, 38.7188, 34.9062,  ..., 56.3438, 52.2812, 30.7812],\n",
      "          ...,\n",
      "          [31.3125, 40.9688, 28.0000,  ..., 21.4531, 32.2812, 27.7500],\n",
      "          [34.5000, 47.0625, 35.8438,  ..., 29.1250, 39.3750, 32.0000],\n",
      "          [32.4062, 46.9375, 40.8125,  ..., 35.9062, 41.9062, 30.5938]],\n",
      "\n",
      "         [[14.5781, 32.8125, 35.3438,  ..., 47.4688, 44.5000, 24.5156],\n",
      "          [16.6875, 37.2812, 37.0625,  ..., 56.3750, 52.6875, 30.5781],\n",
      "          [19.5938, 38.8125, 34.9688,  ..., 56.9375, 52.6562, 30.9688],\n",
      "          ...,\n",
      "          [30.6250, 40.0625, 27.4531,  ..., 21.0625, 31.5938, 27.1250],\n",
      "          [33.6875, 45.9375, 35.0312,  ..., 28.4531, 38.4688, 31.2344],\n",
      "          [31.6406, 45.8438, 39.9062,  ..., 35.1250, 40.9688, 29.8594]],\n",
      "\n",
      "         [[13.0078, 29.4844, 31.7500,  ..., 42.6562, 39.9688, 21.9375],\n",
      "          [14.9609, 34.0938, 33.4375,  ..., 50.7500, 47.4062, 27.4375],\n",
      "          [17.5625, 35.4375, 32.0312,  ..., 51.2500, 47.3438, 27.7812],\n",
      "          ...,\n",
      "          [33.6562, 43.9688, 29.9688,  ..., 22.9062, 34.6250, 29.7969],\n",
      "          [37.0938, 50.5625, 38.4062,  ..., 31.1562, 42.2812, 34.3750],\n",
      "          [34.9062, 50.5625, 43.9062,  ..., 38.6250, 45.1250, 32.9062]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 35.2500,  66.5000,  76.8125,  ...,  83.8750,  70.9375,  39.5938],\n",
      "          [ 48.7812,  88.3125, 103.3750,  ..., 111.8125,  93.1250,  53.1250],\n",
      "          [ 53.6562,  95.0625, 109.1250,  ..., 118.2500,  98.1250,  56.2500],\n",
      "          ...,\n",
      "          [ 36.0938,  47.4688,  35.0938,  ...,  23.0469,  33.6562,  29.0938],\n",
      "          [ 39.0000,  53.2812,  42.7188,  ...,  30.7656,  40.8438,  33.4688],\n",
      "          [ 35.9062,  51.5938,  46.0312,  ...,  37.5625,  43.4688,  32.1875]],\n",
      "\n",
      "         [[ 35.8125,  67.6875,  78.0625,  ...,  85.4375,  72.1250,  40.2812],\n",
      "          [ 49.2812,  89.5000, 104.6875,  ..., 113.4375,  94.2500,  53.7812],\n",
      "          [ 54.2812,  96.4375, 110.6250,  ..., 120.0625,  99.3750,  56.9688],\n",
      "          ...,\n",
      "          [ 35.3125,  46.4062,  34.3750,  ...,  22.6094,  32.9688,  28.4375],\n",
      "          [ 38.0938,  52.0000,  41.7500,  ...,  30.0625,  39.9062,  32.6875],\n",
      "          [ 35.0938,  50.4062,  44.9688,  ...,  36.7188,  42.4688,  31.4219]],\n",
      "\n",
      "         [[ 32.2188,  61.0000,  70.3750,  ...,  77.0000,  64.9375,  36.1875],\n",
      "          [ 44.4375,  80.7500,  94.4375,  ..., 102.4375,  85.0000,  48.3750],\n",
      "          [ 48.9375,  86.9375,  99.8125,  ..., 108.4375,  89.6250,  51.2812],\n",
      "          ...,\n",
      "          [ 38.8438,  51.0312,  37.6250,  ...,  24.6094,  36.1250,  31.2344],\n",
      "          [ 41.9375,  57.2812,  45.8750,  ...,  32.9375,  43.8750,  35.9688],\n",
      "          [ 38.6875,  55.5938,  49.5625,  ...,  40.4062,  46.8125,  34.6250]]],\n",
      "\n",
      "\n",
      "        [[[ 15.2500,  28.6250,  30.0156,  ...,  38.1562,  35.1250,  20.2656],\n",
      "          [ 17.8906,  30.9062,  33.1875,  ...,  39.0938,  37.9375,  24.0312],\n",
      "          [ 18.2969,  29.9531,  29.6875,  ...,  32.0312,  36.0938,  24.7812],\n",
      "          ...,\n",
      "          [ 34.4062,  44.8438,  32.2500,  ...,  18.0156,  29.2812,  26.2656],\n",
      "          [ 37.5000,  50.8125,  39.9688,  ...,  26.4688,  37.2500,  31.2031],\n",
      "          [ 34.9375,  49.9688,  44.1250,  ...,  34.8438,  41.2188,  30.8125]],\n",
      "\n",
      "         [[ 15.4219,  28.9844,  30.3125,  ...,  38.6562,  35.5312,  20.5312],\n",
      "          [ 17.8438,  30.9688,  33.2188,  ...,  39.1875,  38.0000,  24.1094],\n",
      "          [ 18.2969,  30.0625,  29.7812,  ...,  32.1250,  36.1875,  24.9062],\n",
      "          ...,\n",
      "          [ 33.6562,  43.8438,  31.5781,  ...,  17.7188,  28.6875,  25.6875],\n",
      "          [ 36.6250,  49.6250,  39.0625,  ...,  25.8750,  36.4062,  30.4688],\n",
      "          [ 34.1250,  48.8125,  43.1250,  ...,  34.0625,  40.2812,  30.0938]],\n",
      "\n",
      "         [[ 13.7656,  25.9375,  27.1250,  ...,  34.7188,  31.8906,  18.3750],\n",
      "          [ 15.9766,  27.7500,  29.7344,  ...,  35.2500,  34.1250,  21.6094],\n",
      "          [ 16.3750,  26.9375,  26.6406,  ...,  28.8594,  32.5000,  22.3438],\n",
      "          ...,\n",
      "          [ 37.0000,  48.1875,  34.5312,  ...,  19.1875,  31.3906,  28.1875],\n",
      "          [ 40.3125,  54.6250,  42.9062,  ...,  28.2812,  39.9688,  33.5312],\n",
      "          [ 37.6250,  53.8125,  47.5000,  ...,  37.4375,  44.3750,  33.1562]]],\n",
      "\n",
      "\n",
      "        [[[ 14.9297,  29.0469,  30.2188,  ...,  86.8125,  73.4375,  41.0000],\n",
      "          [ 17.1406,  31.0312,  32.7812,  ..., 116.1250,  96.8125,  55.1562],\n",
      "          [ 18.1406,  30.4375,  29.2812,  ..., 122.4375, 101.8125,  58.2812],\n",
      "          ...,\n",
      "          [ 34.7500,  45.4062,  33.0938,  ...,  16.4375,  27.9375,  25.4219],\n",
      "          [ 37.8438,  51.4375,  40.9062,  ...,  25.1719,  36.1875,  30.5781],\n",
      "          [ 35.1875,  50.4375,  44.8125,  ...,  34.0000,  40.5625,  30.4531]],\n",
      "\n",
      "         [[ 15.1016,  29.3906,  30.5156,  ...,  88.4375,  74.6875,  41.7500],\n",
      "          [ 17.0781,  31.0469,  32.7812,  ..., 117.8750,  98.0000,  55.8438],\n",
      "          [ 18.1406,  30.5156,  29.3438,  ..., 124.3750, 103.1875,  59.0312],\n",
      "          ...,\n",
      "          [ 34.0000,  44.4062,  32.4062,  ...,  16.1719,  27.3594,  24.8750],\n",
      "          [ 36.9688,  50.2188,  39.9688,  ...,  24.6094,  35.3750,  29.8594],\n",
      "          [ 34.4062,  49.2812,  43.8125,  ...,  33.2500,  39.6562,  29.7344]],\n",
      "\n",
      "         [[ 13.4844,  26.3438,  27.3438,  ...,  79.6875,  67.3125,  37.5000],\n",
      "          [ 15.3047,  27.8750,  29.4062,  ..., 106.4375,  88.4375,  50.2812],\n",
      "          [ 16.2500,  27.3750,  26.2969,  ..., 112.3750,  93.0625,  53.1562],\n",
      "          ...,\n",
      "          [ 37.3750,  48.7812,  35.4688,  ...,  17.4688,  29.9375,  27.2812],\n",
      "          [ 40.6875,  55.3125,  43.8750,  ...,  26.8906,  38.8438,  32.8438],\n",
      "          [ 37.9375,  54.3438,  48.2500,  ...,  36.5625,  43.6562,  32.7500]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 43.4688,  71.1250,  71.6250,  ...,  92.6875,  86.5000,  53.4062],\n",
      "          [ 52.5938,  83.5625,  83.5000,  ..., 113.5625, 106.8750,  67.6250],\n",
      "          [ 51.9062,  79.7500,  76.0000,  ..., 108.0625, 103.4375,  66.1875],\n",
      "          ...,\n",
      "          [ 48.4062,  68.8125,  63.7812,  ...,  65.0625,  69.5000,  51.8438],\n",
      "          [ 53.0938,  77.2500,  73.8125,  ...,  74.6250,  77.5625,  56.5000],\n",
      "          [ 45.6250,  67.4375,  66.5000,  ...,  66.8125,  67.6875,  47.6562]],\n",
      "\n",
      "         [[ 44.2812,  72.4375,  72.8125,  ...,  94.4375,  88.1250,  54.4688],\n",
      "          [ 53.3125,  84.6875,  84.5000,  ..., 115.2500, 108.4375,  68.5625],\n",
      "          [ 52.5938,  80.8125,  76.9375,  ..., 109.6875, 104.9375,  67.1875],\n",
      "          ...,\n",
      "          [ 47.3125,  67.1875,  62.2812,  ...,  63.5000,  67.8750,  50.6250],\n",
      "          [ 51.8750,  75.4375,  72.0625,  ...,  72.8125,  75.7500,  55.1562],\n",
      "          [ 44.6250,  65.8750,  64.9375,  ...,  65.2500,  66.0625,  46.5625]],\n",
      "\n",
      "         [[ 40.0938,  65.5625,  65.8750,  ...,  85.5000,  79.8125,  49.3125],\n",
      "          [ 48.3125,  76.7500,  76.5000,  ..., 104.5000,  98.5625,  62.4688],\n",
      "          [ 47.5938,  73.1875,  69.5625,  ...,  99.4375,  95.1250,  60.8125],\n",
      "          ...,\n",
      "          [ 52.1250,  74.0625,  68.5625,  ...,  70.0000,  74.8125,  55.8125],\n",
      "          [ 57.2188,  83.2500,  79.4375,  ...,  80.3125,  83.5625,  60.8438],\n",
      "          [ 49.1875,  72.6875,  71.6875,  ...,  72.0000,  72.9375,  51.3438]]],\n",
      "\n",
      "\n",
      "        [[[ 24.8281,  38.0000,  33.2500,  ...,  83.4375,  79.3750,  49.4688],\n",
      "          [ 24.7031,  36.0000,  31.4062,  ...,  99.1875,  94.9375,  60.5312],\n",
      "          [ 22.5781,  30.9531,  25.0156,  ...,  91.6875,  90.5625,  59.1562],\n",
      "          ...,\n",
      "          [ 46.3750,  65.3750,  59.7500,  ...,  65.1875,  69.5000,  52.0312],\n",
      "          [ 51.2812,  74.1250,  70.0625,  ...,  74.6250,  77.5625,  56.6250],\n",
      "          [ 44.5000,  65.4375,  64.1250,  ...,  67.0000,  67.7500,  47.8125]],\n",
      "\n",
      "         [[ 25.2344,  38.5625,  33.6875,  ...,  85.0000,  80.8125,  50.4375],\n",
      "          [ 24.8750,  36.2188,  31.4688,  ..., 100.5625,  96.1875,  61.3750],\n",
      "          [ 22.7344,  31.1250,  25.0938,  ...,  92.9375,  91.7500,  60.0000],\n",
      "          ...,\n",
      "          [ 45.3125,  63.8438,  58.3438,  ...,  63.6562,  67.9375,  50.8125],\n",
      "          [ 50.0938,  72.3750,  68.3750,  ...,  72.8125,  75.7500,  55.3125],\n",
      "          [ 43.5000,  63.9062,  62.5938,  ...,  65.4375,  66.1875,  46.6875]],\n",
      "\n",
      "         [[ 22.7812,  34.7812,  30.3594,  ...,  76.9375,  73.1875,  45.6250],\n",
      "          [ 22.5000,  32.6875,  28.3750,  ...,  91.1250,  87.2500,  55.6875],\n",
      "          [ 20.5156,  28.0625,  22.5625,  ...,  84.1250,  83.1250,  54.2812],\n",
      "          ...,\n",
      "          [ 49.9375,  70.3750,  64.2500,  ...,  70.1250,  74.8750,  56.0000],\n",
      "          [ 55.2188,  79.8125,  75.3750,  ...,  80.3125,  83.5000,  60.9688],\n",
      "          [ 47.9688,  70.5000,  69.0625,  ...,  72.1250,  73.0625,  51.5000]]],\n",
      "\n",
      "\n",
      "        [[[ 24.4375,  37.1875,  32.3438,  ...,  58.6875,  62.6250,  41.2500],\n",
      "          [ 24.4375,  35.2188,  30.6562,  ...,  56.0938,  64.2500,  45.6875],\n",
      "          [ 22.4375,  30.4219,  24.5469,  ...,  40.1250,  51.5000,  38.5000],\n",
      "          ...,\n",
      "          [ 43.9062,  60.8438,  53.7500,  ...,  65.9375,  69.8125,  52.4375],\n",
      "          [ 49.0000,  70.0000,  64.8125,  ...,  74.8125,  77.4375,  56.7500],\n",
      "          [ 43.0312,  62.8125,  60.8125,  ...,  67.5625,  68.0625,  48.0625]],\n",
      "\n",
      "         [[ 24.8281,  37.7500,  32.7500,  ...,  59.5938,  63.6562,  41.9688],\n",
      "          [ 24.5938,  35.4375,  30.7344,  ...,  56.5000,  64.8125,  46.1562],\n",
      "          [ 22.5938,  30.5938,  24.6406,  ...,  40.3438,  51.8750,  38.8750],\n",
      "          ...,\n",
      "          [ 42.9375,  59.4375,  52.5000,  ...,  64.3750,  68.1875,  51.2188],\n",
      "          [ 47.8750,  68.3750,  63.2812,  ...,  73.0625,  75.6250,  55.4062],\n",
      "          [ 42.0625,  61.3438,  59.3750,  ...,  66.0000,  66.4375,  46.9375]],\n",
      "\n",
      "         [[ 22.4062,  34.0312,  29.5000,  ...,  53.8750,  57.5938,  37.9688],\n",
      "          [ 22.2500,  32.0000,  27.6875,  ...,  51.0625,  58.7188,  42.0312],\n",
      "          [ 20.3906,  27.5938,  22.1406,  ...,  36.3750,  46.8438,  35.0938],\n",
      "          ...,\n",
      "          [ 47.2812,  65.4375,  57.7500,  ...,  70.8750,  75.1250,  56.4375],\n",
      "          [ 52.7500,  75.3750,  69.7500,  ...,  80.5000,  83.3750,  61.0938],\n",
      "          [ 46.3750,  67.6875,  65.5000,  ...,  72.8125,  73.3125,  51.7500]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[50.4062, 70.6250, 58.4688,  ..., 56.9688, 67.8125, 49.6250],\n",
      "          [58.9375, 79.4375, 60.0625,  ..., 54.4062, 72.3125, 55.6250],\n",
      "          [50.7500, 64.7500, 42.3750,  ..., 39.9688, 53.4375, 44.2812],\n",
      "          ...,\n",
      "          [55.2188, 76.8125, 73.3750,  ..., 80.0000, 82.5000, 61.5000],\n",
      "          [59.1562, 84.0625, 82.2500,  ..., 88.1250, 89.1875, 65.1875],\n",
      "          [50.8750, 72.6875, 73.0000,  ..., 76.8125, 76.2500, 54.7812]],\n",
      "\n",
      "         [[50.7188, 71.1875, 59.0312,  ..., 57.7188, 68.5000, 50.0000],\n",
      "          [58.9688, 79.5000, 60.1875,  ..., 54.6562, 72.5625, 55.6875],\n",
      "          [50.8750, 64.9375, 42.6250,  ..., 40.1562, 53.7500, 44.4375],\n",
      "          ...,\n",
      "          [53.9688, 75.0625, 71.6250,  ..., 78.1250, 80.6250, 60.0312],\n",
      "          [57.8125, 82.1250, 80.3125,  ..., 86.0000, 87.1250, 63.6875],\n",
      "          [49.7188, 71.0625, 71.3125,  ..., 75.0625, 74.5000, 53.5000]],\n",
      "\n",
      "         [[48.9688, 67.7500, 55.1875,  ..., 52.8438, 64.3125, 47.5938],\n",
      "          [57.6562, 76.8125, 56.7812,  ..., 50.1562, 68.8750, 53.6250],\n",
      "          [48.9688, 61.5938, 38.8438,  ..., 36.4375, 49.6250, 41.8438],\n",
      "          ...,\n",
      "          [59.4375, 82.6875, 78.8750,  ..., 86.0000, 88.8125, 66.1250],\n",
      "          [63.6875, 90.5000, 88.5000,  ..., 94.8125, 96.0000, 70.1250],\n",
      "          [54.8125, 78.3125, 78.5625,  ..., 82.6875, 82.1250, 58.9688]]],\n",
      "\n",
      "\n",
      "        [[[36.8438, 49.1250, 40.0312,  ..., 61.6562, 74.5000, 54.3438],\n",
      "          [37.2500, 47.5312, 37.4375,  ..., 64.3750, 84.7500, 63.9688],\n",
      "          [27.6875, 37.1562, 30.6250,  ..., 48.1562, 68.8125, 54.6875],\n",
      "          ...,\n",
      "          [53.4062, 73.6875, 69.6250,  ..., 77.5000, 80.7500, 60.2500],\n",
      "          [57.7188, 81.5625, 79.2500,  ..., 85.5000, 87.2500, 63.9375],\n",
      "          [50.0312, 71.2500, 71.1875,  ..., 74.6250, 74.5625, 53.7188]],\n",
      "\n",
      "         [[37.1875, 49.6875, 40.5000,  ..., 62.3750, 75.1875, 54.7188],\n",
      "          [37.3438, 47.6875, 37.5625,  ..., 64.6875, 84.9375, 64.0625],\n",
      "          [27.9531, 37.3750, 30.7344,  ..., 48.5000, 69.1875, 54.8750],\n",
      "          ...,\n",
      "          [52.1875, 72.0000, 68.0000,  ..., 75.6875, 78.9375, 58.8438],\n",
      "          [56.3750, 79.6875, 77.3750,  ..., 83.5000, 85.2500, 62.4375],\n",
      "          [48.9062, 69.6250, 69.5625,  ..., 72.8750, 72.8750, 52.4375]],\n",
      "\n",
      "         [[35.1250, 45.9062, 36.7188,  ..., 57.7188, 71.0000, 52.3125],\n",
      "          [35.3750, 44.2500, 34.0625,  ..., 60.2500, 81.2500, 61.9375],\n",
      "          [25.3906, 33.9062, 27.7812,  ..., 44.0312, 64.8750, 52.2188],\n",
      "          ...,\n",
      "          [57.4688, 79.3125, 74.8750,  ..., 83.3750, 86.9375, 64.8125],\n",
      "          [62.1250, 87.8125, 85.2500,  ..., 92.0000, 93.9375, 68.7500],\n",
      "          [53.9062, 76.6875, 76.6875,  ..., 80.3750, 80.3125, 57.8125]]],\n",
      "\n",
      "\n",
      "        [[[45.5625, 62.0312, 48.5625,  ..., 63.6250, 74.8125, 54.2188],\n",
      "          [51.0312, 65.8750, 45.7188,  ..., 66.3750, 84.9375, 63.8125],\n",
      "          [41.7500, 50.2188, 35.0625,  ..., 47.2500, 69.5000, 55.0938],\n",
      "          ...,\n",
      "          [54.5312, 74.9375, 69.9375,  ..., 78.8750, 82.0625, 60.8750],\n",
      "          [57.8750, 81.5000, 78.6875,  ..., 87.3750, 88.9375, 64.7500],\n",
      "          [49.8438, 70.7500, 70.6250,  ..., 75.8125, 75.6250, 54.2812]],\n",
      "\n",
      "         [[45.8750, 62.5312, 49.0938,  ..., 64.3125, 75.4375, 54.5938],\n",
      "          [51.0312, 65.9375, 45.8750,  ..., 66.5625, 85.1250, 63.8438],\n",
      "          [41.9062, 50.4375, 35.2188,  ..., 47.5000, 69.7500, 55.2500],\n",
      "          ...,\n",
      "          [53.2812, 73.2500, 68.3125,  ..., 77.0625, 80.1875, 59.4688],\n",
      "          [56.5625, 79.5625, 76.8125,  ..., 85.3125, 86.8750, 63.2812],\n",
      "          [48.7188, 69.1875, 69.0000,  ..., 74.0625, 73.9375, 53.0312]],\n",
      "\n",
      "         [[44.0625, 59.0625, 45.2188,  ..., 59.8438, 71.4375, 52.3125],\n",
      "          [49.5938, 63.1250, 42.3125,  ..., 62.5938, 81.7500, 61.9688],\n",
      "          [39.8125, 46.9375, 31.9062,  ..., 43.3438, 65.8750, 52.8125],\n",
      "          ...,\n",
      "          [58.6875, 80.6875, 75.1875,  ..., 84.9375, 88.3750, 65.5000],\n",
      "          [62.3125, 87.6875, 84.6250,  ..., 94.0625, 95.7500, 69.6875],\n",
      "          [53.6875, 76.1875, 76.0000,  ..., 81.6250, 81.5000, 58.4375]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 36.6875,  51.4688,  45.9062,  ...,  97.6875,  96.7500,  64.2500],\n",
      "          [ 37.9062,  51.3125,  46.3438,  ..., 125.0000, 123.9375,  81.7500],\n",
      "          [ 29.1562,  40.0000,  40.0938,  ..., 122.8750, 117.9375,  78.1250],\n",
      "          ...,\n",
      "          [ 55.2812,  76.7500,  74.6250,  ...,  77.6875,  83.8125,  60.3438],\n",
      "          [ 58.7500,  83.0625,  82.3750,  ...,  79.9375,  81.9375,  60.4688],\n",
      "          [ 50.4375,  71.3750,  72.3750,  ...,  69.1250,  69.3750,  50.6875]],\n",
      "\n",
      "         [[ 36.9062,  51.9688,  46.5312,  ...,  99.3750,  98.1875,  65.0000],\n",
      "          [ 37.9062,  51.4688,  46.6250,  ..., 126.8125, 125.3750,  82.5000],\n",
      "          [ 29.2969,  40.2500,  40.2812,  ..., 124.6250, 119.5000,  79.0625],\n",
      "          ...,\n",
      "          [ 54.0625,  75.0625,  72.9375,  ...,  76.3750,  82.6250,  59.3125],\n",
      "          [ 57.4688,  81.1875,  80.4375,  ...,  78.1875,  80.1875,  59.1562],\n",
      "          [ 49.3438,  69.8125,  70.7500,  ...,  67.6250,  67.8750,  49.5625]],\n",
      "\n",
      "         [[ 35.5312,  48.6562,  42.3438,  ...,  90.7500,  91.1250,  61.3125],\n",
      "          [ 36.5312,  48.2500,  42.4062,  ..., 116.0625, 116.7500,  77.8750],\n",
      "          [ 27.1875,  36.5938,  36.5625,  ..., 113.7500, 109.8750,  73.4375],\n",
      "          ...,\n",
      "          [ 59.4688,  82.5625,  80.1875,  ...,  83.1875,  89.4375,  64.5625],\n",
      "          [ 63.2188,  89.3750,  88.5625,  ...,  86.0625,  88.1875,  65.0000],\n",
      "          [ 54.2812,  76.8125,  77.8750,  ...,  74.3750,  74.6875,  54.5312]]],\n",
      "\n",
      "\n",
      "        [[[ 36.5625,  51.0938,  45.3125,  ...,  97.6875,  96.7500,  64.2500],\n",
      "          [ 37.6875,  50.8125,  45.5938,  ..., 125.0625, 123.9375,  81.7500],\n",
      "          [ 28.9531,  39.4375,  39.4375,  ..., 122.8750, 117.9375,  78.1250],\n",
      "          ...,\n",
      "          [ 55.4688,  77.0625,  74.9375,  ...,  63.7188,  72.5625,  53.0312],\n",
      "          [ 58.9375,  83.3750,  82.6875,  ...,  62.6562,  69.3750,  52.9688],\n",
      "          [ 50.5938,  71.5625,  72.6250,  ...,  58.3750,  60.5000,  45.4688]],\n",
      "\n",
      "         [[ 36.7812,  51.5938,  45.9062,  ...,  99.4375,  98.1875,  65.0000],\n",
      "          [ 37.6875,  50.9375,  45.8438,  ..., 126.8750, 125.3750,  82.5625],\n",
      "          [ 29.0781,  39.6562,  39.5938,  ..., 124.6250, 119.5000,  79.0625],\n",
      "          ...,\n",
      "          [ 54.2500,  75.3750,  73.1875,  ...,  63.1875,  71.9375,  52.3438],\n",
      "          [ 57.6250,  81.4375,  80.7500,  ...,  61.3438,  68.1250,  51.9062],\n",
      "          [ 49.4688,  70.0000,  71.0000,  ...,  57.1250,  59.1875,  44.4688]],\n",
      "\n",
      "         [[ 35.4375,  48.3438,  41.7812,  ...,  90.8125,  91.1875,  61.3125],\n",
      "          [ 36.3750,  47.8125,  41.6875,  ..., 116.0625, 116.7500,  77.8750],\n",
      "          [ 27.0156,  36.0938,  35.9375,  ..., 113.7500, 109.8750,  73.4375],\n",
      "          ...,\n",
      "          [ 59.6562,  82.9375,  80.5625,  ...,  67.3125,  76.5625,  56.4375],\n",
      "          [ 63.4062,  89.6875,  88.8750,  ...,  67.3750,  74.6250,  56.8750],\n",
      "          [ 54.4062,  77.0000,  78.1250,  ...,  62.8125,  65.0625,  48.9062]]],\n",
      "\n",
      "\n",
      "        [[[ 43.1250,  61.8125,  56.1562,  ...,  94.3125,  94.0000,  62.6875],\n",
      "          [ 49.1562,  69.0000,  62.6562,  ..., 113.0625, 112.9375,  75.1875],\n",
      "          [ 42.0000,  59.8125,  57.5625,  ...,  97.5625,  92.8125,  62.7812],\n",
      "          ...,\n",
      "          [ 56.5312,  79.0625,  77.3750,  ..., 125.3125, 125.6875,  85.3750],\n",
      "          [ 59.8750,  85.0625,  84.8125,  ..., 115.6875, 116.2500,  79.0000],\n",
      "          [ 51.1562,  72.6250,  73.9375,  ...,  73.3750,  73.6875,  50.9062]],\n",
      "\n",
      "         [[ 43.5312,  62.5625,  57.0000,  ...,  96.0000,  95.3125,  63.4062],\n",
      "          [ 49.4062,  69.5625,  63.2188,  ..., 114.6250, 114.1250,  75.7500],\n",
      "          [ 42.4062,  60.4375,  58.0000,  ...,  98.7500,  93.9375,  63.3750],\n",
      "          ...,\n",
      "          [ 55.2812,  77.2500,  75.6250,  ..., 125.0000, 125.3125,  85.0000],\n",
      "          [ 58.5625,  83.1875,  82.8750,  ..., 115.1875, 115.6875,  78.5000],\n",
      "          [ 50.0312,  71.0000,  72.2500,  ...,  72.5000,  72.7500,  50.0625]],\n",
      "\n",
      "         [[ 41.5000,  58.2500,  51.9062,  ...,  87.6875,  88.5625,  59.8750],\n",
      "          [ 47.0000,  64.8125,  57.5938,  ..., 104.8750, 106.4375,  71.7500],\n",
      "          [ 39.0938,  55.0625,  52.7500,  ...,  90.0625,  86.3125,  59.0625],\n",
      "          ...,\n",
      "          [ 60.8125,  85.0625,  83.2500,  ..., 125.6250, 126.1250,  86.3125],\n",
      "          [ 64.3750,  91.5000,  91.1875,  ..., 117.6250, 118.3750,  81.1250],\n",
      "          [ 55.0312,  78.1875,  79.5625,  ...,  77.1875,  77.6875,  54.0625]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 59.8750,  92.3125,  93.6875,  ...,  96.0000,  93.5625,  61.9062],\n",
      "          [ 76.8750, 119.1250, 122.6250,  ..., 121.9375, 118.9375,  78.7500],\n",
      "          [ 74.8125, 115.8125, 125.1875,  ..., 116.1875, 115.1875,  77.1250],\n",
      "          ...,\n",
      "          [ 46.0312,  61.5625,  56.5312,  ...,  77.6875,  80.7500,  57.5312],\n",
      "          [ 49.4375,  68.1250,  65.6250,  ...,  74.6875,  77.2500,  57.2188],\n",
      "          [ 43.5938,  60.2500,  59.7188,  ...,  64.4375,  64.8750,  47.9062]],\n",
      "\n",
      "         [[ 60.5312,  93.5000,  95.1875,  ...,  97.3125,  94.5000,  62.3438],\n",
      "          [ 77.5000, 120.4375, 124.3125,  ..., 123.3125, 119.8125,  79.0000],\n",
      "          [ 75.6250, 117.3750, 126.8125,  ..., 117.7500, 116.3125,  77.6250],\n",
      "          ...,\n",
      "          [ 45.0625,  60.3125,  55.2812,  ...,  76.5000,  79.5625,  56.5312],\n",
      "          [ 48.3438,  66.5000,  64.1250,  ...,  72.9375,  75.5625,  56.0000],\n",
      "          [ 42.6250,  58.9062,  58.3750,  ...,  63.0000,  63.4062,  46.8125]],\n",
      "\n",
      "         [[ 57.6562,  87.5625,  87.5000,  ...,  90.5625,  89.6875,  60.2188],\n",
      "          [ 73.6250, 112.7500, 114.1250,  ..., 114.8125, 114.0625,  76.5000],\n",
      "          [ 70.4375, 108.1875, 116.2500,  ..., 108.0625, 108.9375,  73.9375],\n",
      "          ...,\n",
      "          [ 49.4375,  66.1875,  60.7188,  ...,  82.5625,  85.8750,  61.5000],\n",
      "          [ 53.1250,  73.1875,  70.5625,  ...,  80.3125,  83.0625,  61.4688],\n",
      "          [ 46.8750,  64.8125,  64.1875,  ...,  69.3125,  69.7500,  51.4688]]],\n",
      "\n",
      "\n",
      "        [[[ 44.0938,  62.3438,  54.0000,  ..., 114.8750, 110.7500,  72.3750],\n",
      "          [ 48.7812,  66.5625,  54.8438,  ..., 151.5000, 145.6250,  94.8125],\n",
      "          [ 39.2812,  50.4688,  47.7500,  ..., 148.3750, 144.0000,  94.0625],\n",
      "          ...,\n",
      "          [ 64.1875,  93.4375,  87.7500,  ..., 120.0000, 119.4375,  81.1250],\n",
      "          [ 59.0938,  83.0000,  75.4375,  ..., 109.8125, 109.4375,  74.3750],\n",
      "          [ 44.4062,  61.7500,  61.2188,  ...,  69.4375,  69.2500,  48.5938]],\n",
      "\n",
      "         [[ 44.3438,  62.9062,  54.6875,  ..., 116.5625, 112.0000,  73.0000],\n",
      "          [ 48.8438,  66.8125,  55.3125,  ..., 153.5000, 147.1250,  95.3750],\n",
      "          [ 39.4688,  50.8438,  48.0312,  ..., 150.6250, 145.7500,  94.8750],\n",
      "          ...,\n",
      "          [ 63.6250,  92.6250,  86.9375,  ..., 119.4375, 118.8750,  80.5625],\n",
      "          [ 58.3125,  81.8750,  74.1250,  ..., 109.0625, 108.6250,  73.6875],\n",
      "          [ 43.4375,  60.4062,  59.8750,  ...,  68.3750,  68.1250,  47.7188]],\n",
      "\n",
      "         [[ 43.0625,  59.6875,  50.4375,  ..., 108.3750, 105.8125,  70.0625],\n",
      "          [ 47.5938,  63.5938,  50.6250,  ..., 142.8750, 139.2500,  91.6875],\n",
      "          [ 37.4688,  46.8750,  43.8438,  ..., 138.6250, 136.2500,  89.9375],\n",
      "          ...,\n",
      "          [ 67.0000,  96.8125,  91.1250,  ..., 121.3750, 120.9375,  82.7500],\n",
      "          [ 62.7500,  88.0625,  80.6875,  ..., 112.6875, 112.4375,  77.1250],\n",
      "          [ 47.7188,  66.4375,  65.8750,  ...,  73.6250,  73.5625,  51.9062]]],\n",
      "\n",
      "\n",
      "        [[[ 26.8125,  34.9062,  32.0312,  ..., 112.1875, 108.6875,  71.1875],\n",
      "          [ 25.6250,  33.1875,  35.7812,  ..., 147.6250, 142.6250,  93.1250],\n",
      "          [ 22.1406,  33.1562,  36.3438,  ..., 144.2500, 140.7500,  92.3125],\n",
      "          ...,\n",
      "          [ 54.0312,  75.1250,  73.0625,  ...,  85.4375,  87.5625,  61.3125],\n",
      "          [ 56.8438,  80.1875,  79.2500,  ...,  78.0625,  81.1875,  59.3438],\n",
      "          [ 48.3438,  68.0625,  68.7500,  ...,  66.2500,  66.3750,  48.7812]],\n",
      "\n",
      "         [[ 26.9531,  35.2500,  32.3750,  ..., 113.8750, 109.9375,  71.8125],\n",
      "          [ 25.6719,  33.3438,  35.9062,  ..., 149.6250, 144.1250,  93.6875],\n",
      "          [ 22.2969,  33.3125,  36.4688,  ..., 146.3750, 142.5000,  93.1250],\n",
      "          ...,\n",
      "          [ 52.8438,  73.3750,  71.3750,  ...,  84.3750,  86.5000,  60.3438],\n",
      "          [ 55.5938,  78.3125,  77.3750,  ...,  76.3125,  79.5000,  58.1250],\n",
      "          [ 47.2812,  66.5000,  67.1250,  ...,  64.7500,  64.8750,  47.6875]],\n",
      "\n",
      "         [[ 26.0000,  32.7500,  29.5000,  ..., 105.7500, 103.8125,  68.8750],\n",
      "          [ 24.4531,  30.5781,  32.7188,  ..., 139.0000, 136.3750,  90.0000],\n",
      "          [ 20.3594,  30.3906,  33.1875,  ..., 134.5000, 133.0000,  88.1875],\n",
      "          ...,\n",
      "          [ 58.0938,  80.7500,  78.5625,  ...,  90.3125,  92.6250,  65.3125],\n",
      "          [ 61.1250,  86.1875,  85.1875,  ...,  83.9375,  87.1875,  63.7188],\n",
      "          [ 52.0000,  73.1875,  73.9375,  ...,  71.2500,  71.3750,  52.4062]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 72.6875, 113.0000, 118.2500,  ..., 101.3750,  98.1250,  66.0625],\n",
      "          [ 98.4375, 153.3750, 160.1250,  ..., 135.8750, 131.7500,  88.6250],\n",
      "          [103.1250, 159.0000, 162.6250,  ..., 144.5000, 141.7500,  95.5625],\n",
      "          ...,\n",
      "          [ 56.3125,  77.8125,  75.0000,  ...,  89.1875,  87.3750,  61.4688],\n",
      "          [ 58.8438,  82.1875,  80.3125,  ...,  78.8125,  80.7500,  59.6562],\n",
      "          [ 49.6562,  69.1250,  68.8750,  ...,  65.1250,  65.9375,  49.2500]],\n",
      "\n",
      "         [[ 73.0625, 113.8750, 119.4375,  ..., 101.3750,  98.0625,  65.8750],\n",
      "          [ 98.8125, 154.2500, 161.7500,  ..., 135.5000, 131.2500,  88.1250],\n",
      "          [103.7500, 160.2500, 164.6250,  ..., 144.3750, 141.6250,  95.1875],\n",
      "          ...,\n",
      "          [ 55.0312,  76.0625,  73.3125,  ...,  88.1875,  86.2500,  60.4062],\n",
      "          [ 57.5000,  80.3125,  78.5000,  ...,  77.1875,  79.1250,  58.3125],\n",
      "          [ 48.5312,  67.5625,  67.3125,  ...,  63.6562,  64.5000,  48.1250]],\n",
      "\n",
      "         [[ 72.0625, 110.5625, 114.1875,  ..., 101.1875,  98.3750,  67.0000],\n",
      "          [ 97.5625, 150.0000, 154.5000,  ..., 136.7500, 133.1250,  90.3750],\n",
      "          [100.9375, 153.7500, 155.0000,  ..., 144.7500, 142.3750,  96.6875],\n",
      "          ...,\n",
      "          [ 60.5312,  83.6250,  80.6250,  ...,  93.7500,  92.3750,  65.4375],\n",
      "          [ 63.2500,  88.3125,  86.3125,  ...,  84.5625,  86.6875,  64.0000],\n",
      "          [ 53.3750,  74.3125,  74.0625,  ...,  70.0000,  70.8750,  52.9062]]],\n",
      "\n",
      "\n",
      "        [[[ 70.0000, 108.5000, 113.4375,  ...,  69.5000,  75.3750,  53.3750],\n",
      "          [ 93.4375, 144.8750, 151.1250,  ...,  79.3750,  91.3750,  66.1875],\n",
      "          [ 96.3750, 147.6250, 150.5000,  ...,  68.8125,  87.3750,  65.5625],\n",
      "          ...,\n",
      "          [ 55.1875,  75.8750,  72.8750,  ...,  71.1875,  74.9375,  57.6562],\n",
      "          [ 57.9688,  80.7500,  78.8750,  ...,  78.0625,  80.6250,  61.0000],\n",
      "          [ 49.3438,  68.6250,  68.5625,  ...,  68.5625,  69.0625,  51.4688]],\n",
      "\n",
      "         [[ 70.3125, 109.2500, 114.5625,  ...,  69.5625,  75.3125,  53.1562],\n",
      "          [ 93.6875, 145.6250, 152.3750,  ...,  79.0000,  90.8750,  65.6875],\n",
      "          [ 96.8750, 148.7500, 152.1250,  ...,  68.6250,  87.0625,  65.2500],\n",
      "          ...,\n",
      "          [ 53.9062,  74.1250,  71.2500,  ...,  69.5625,  73.2500,  56.3125],\n",
      "          [ 56.6250,  78.9375,  77.0000,  ...,  76.2500,  78.7500,  59.5625],\n",
      "          [ 48.2188,  67.1250,  67.0000,  ...,  67.0000,  67.5000,  50.2500]],\n",
      "\n",
      "         [[ 69.5625, 106.3125, 109.6875,  ...,  68.8750,  75.5625,  54.1875],\n",
      "          [ 92.8750, 142.1250, 146.0000,  ...,  79.3125,  92.5625,  67.6250],\n",
      "          [ 94.6250, 143.2500, 143.6250,  ...,  67.9375,  87.5625,  66.2500],\n",
      "          ...,\n",
      "          [ 59.2812,  81.5000,  78.3125,  ...,  76.5000,  80.5000,  61.9062],\n",
      "          [ 62.2812,  86.8125,  84.6875,  ...,  83.8750,  86.6250,  65.5000],\n",
      "          [ 53.0312,  73.7500,  73.6250,  ...,  73.6875,  74.1875,  55.2500]]],\n",
      "\n",
      "\n",
      "        [[[ 37.6250,  48.8750,  37.5312,  ..., 135.7500, 125.1875,  80.1250],\n",
      "          [ 41.2812,  51.0312,  35.8438,  ..., 188.6250, 173.6250, 110.5625],\n",
      "          [ 35.6875,  41.4688,  34.6875,  ..., 199.7500, 186.3750, 119.1250],\n",
      "          ...,\n",
      "          [ 72.4375, 100.8750,  90.7500,  ...,  95.0625,  95.3125,  66.3750],\n",
      "          [ 79.1250, 113.0000, 106.8125,  ...,  84.3125,  86.1875,  61.9062],\n",
      "          [ 55.0938,  79.2500,  76.5000,  ...,  61.4375,  63.1250,  47.5312]],\n",
      "\n",
      "         [[ 37.4375,  48.7812,  37.6562,  ..., 137.1250, 126.0000,  80.3750],\n",
      "          [ 40.9375,  50.6875,  35.8438,  ..., 190.0000, 174.5000, 110.7500],\n",
      "          [ 35.5938,  41.5000,  34.8438,  ..., 201.5000, 187.5000, 119.5625],\n",
      "          ...,\n",
      "          [ 72.3125, 100.6875,  90.6875,  ...,  94.2500,  94.4375,  65.6250],\n",
      "          [ 78.9375, 112.7500, 106.6250,  ...,  83.1875,  85.0625,  60.8438],\n",
      "          [ 54.5625,  78.5000,  75.8125,  ...,  60.0625,  61.7188,  46.4375]],\n",
      "\n",
      "         [[ 38.2188,  48.6250,  36.2812,  ..., 131.8750, 122.8125,  79.6250],\n",
      "          [ 42.0625,  50.8125,  33.9375,  ..., 183.5000, 170.8750, 110.0625],\n",
      "          [ 35.3125,  39.6562,  31.8750,  ..., 193.1250, 182.1250, 117.5625],\n",
      "          ...,\n",
      "          [ 72.5625, 100.3125,  90.1250,  ...,  98.2500,  98.9375,  69.5625],\n",
      "          [ 79.4375, 112.7500, 106.4375,  ...,  89.1875,  91.3750,  65.9375],\n",
      "          [ 56.6875,  80.8750,  78.0000,  ...,  66.0625,  67.8750,  51.0625]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 35.0625,  46.2812,  37.0312,  ...,  36.0625,  46.0312,  35.2500],\n",
      "          [ 40.9688,  52.4688,  38.4375,  ...,  36.5312,  51.3438,  40.9688],\n",
      "          [ 39.3125,  47.8750,  36.5938,  ...,  37.1562,  47.2188,  39.2188],\n",
      "          ...,\n",
      "          [ 71.2500, 104.9375, 104.2500,  ..., 100.1875, 100.1250,  69.5000],\n",
      "          [ 70.0625, 104.1250, 105.1875,  ...,  99.6875,  97.6250,  67.1250],\n",
      "          [ 46.7500,  69.5625,  70.8750,  ...,  66.9375,  64.6875,  45.0625]],\n",
      "\n",
      "         [[ 34.7812,  46.0312,  37.0312,  ...,  36.1875,  45.9375,  35.0312],\n",
      "          [ 40.5312,  51.9375,  38.3125,  ...,  36.5312,  51.0000,  40.5312],\n",
      "          [ 39.1250,  47.7500,  36.8438,  ...,  37.3750,  47.2500,  39.0625],\n",
      "          ...,\n",
      "          [ 70.7500, 104.1875, 103.6250,  ...,  99.4375,  99.3125,  68.8125],\n",
      "          [ 69.5000, 103.3125, 104.4375,  ...,  98.9375,  96.6875,  66.3750],\n",
      "          [ 46.0938,  68.5625,  69.9375,  ...,  65.9375,  63.6562,  44.2188]],\n",
      "\n",
      "         [[ 36.0312,  46.6875,  36.3438,  ...,  34.8750,  46.0938,  36.0000],\n",
      "          [ 42.3125,  53.0625,  37.1562,  ...,  34.7812,  51.4688,  41.8750],\n",
      "          [ 39.3750,  46.6562,  33.7812,  ...,  34.2812,  45.5938,  38.8750],\n",
      "          ...,\n",
      "          [ 72.3750, 105.8750, 104.9375,  ..., 101.1875, 101.5625,  71.1250],\n",
      "          [ 71.6250, 105.6250, 106.2500,  ..., 101.2500,  99.8125,  69.3125],\n",
      "          [ 49.1250,  72.1875,  73.1875,  ...,  69.6250,  67.9375,  47.7812]]],\n",
      "\n",
      "\n",
      "        [[[ 72.2500, 116.0000, 130.0000,  ...,  75.0000,  72.3750,  49.4688],\n",
      "          [102.2500, 165.6250, 187.5000,  ...,  97.3750,  93.9375,  64.1250],\n",
      "          [113.0625, 183.2500, 207.3750,  ..., 101.5625,  98.6875,  67.5000],\n",
      "          ...,\n",
      "          [ 63.4688,  95.5000,  97.5625,  ...,  81.3125,  77.8125,  55.1250],\n",
      "          [ 59.1562,  87.9375,  88.8125,  ...,  73.3125,  74.3125,  55.3125],\n",
      "          [ 42.5938,  59.4688,  59.0312,  ...,  59.9375,  60.7500,  45.3750]],\n",
      "\n",
      "         [[ 72.4375, 116.4375, 130.7500,  ...,  74.6250,  71.9375,  49.0312],\n",
      "          [102.2500, 165.8750, 188.2500,  ...,  96.5000,  92.9375,  63.3125],\n",
      "          [113.2500, 183.7500, 208.3750,  ..., 100.8125,  97.8750,  66.8125],\n",
      "          ...,\n",
      "          [ 62.7500,  94.4375,  96.5625,  ...,  80.0625,  76.4375,  54.0000],\n",
      "          [ 58.2500,  86.6875,  87.6250,  ...,  71.7500,  72.6875,  54.0312],\n",
      "          [ 41.6562,  58.1875,  57.8125,  ...,  58.5938,  59.3750,  44.3125]],\n",
      "\n",
      "         [[ 72.1875, 114.5000, 127.3125,  ...,  75.8125,  73.6875,  51.0312],\n",
      "          [102.2500, 163.8750, 184.0000,  ...,  99.6250,  96.8125,  66.8125],\n",
      "          [112.1875, 180.1250, 202.3750,  ..., 103.3125, 101.0000,  69.7500],\n",
      "          ...,\n",
      "          [ 66.2500,  98.7500, 100.4375,  ...,  85.6250,  82.7500,  59.0312],\n",
      "          [ 62.5000,  92.2500,  92.8750,  ...,  78.6250,  79.7500,  59.3438],\n",
      "          [ 45.6875,  63.8125,  63.3438,  ...,  64.3750,  65.2500,  48.6875]]],\n",
      "\n",
      "\n",
      "        [[[ 35.9688,  48.6875,  41.5625,  ...,  82.9375,  78.5000,  52.5938],\n",
      "          [ 42.0312,  55.0312,  43.0312,  ..., 107.1875, 101.0000,  67.5625],\n",
      "          [ 40.3125,  49.9375,  35.5938,  ..., 107.4375, 101.6250,  68.0625],\n",
      "          ...,\n",
      "          [ 71.6875, 105.5000, 104.6250,  ...,  92.3750,  89.7500,  61.6250],\n",
      "          [ 70.5000, 104.6250, 105.3750,  ...,  85.9375,  83.3750,  58.0938],\n",
      "          [ 47.0000,  69.8750,  71.0000,  ...,  57.2812,  57.6875,  43.1562]],\n",
      "\n",
      "         [[ 35.6875,  48.4375,  41.5000,  ...,  82.6875,  78.1250,  52.2188],\n",
      "          [ 41.5938,  54.4688,  42.8125,  ..., 106.3750, 100.0000,  66.7500],\n",
      "          [ 40.1250,  49.7500,  35.7812,  ..., 106.6875, 100.6875,  67.3125],\n",
      "          ...,\n",
      "          [ 71.1875, 104.7500, 103.9375,  ...,  91.4375,  88.6875,  60.7812],\n",
      "          [ 69.9375, 103.8125, 104.6875,  ...,  84.8750,  82.1875,  57.0938],\n",
      "          [ 46.3438,  68.8750,  70.0625,  ...,  56.1250,  56.4062,  42.1562]],\n",
      "\n",
      "         [[ 37.0312,  49.2812,  41.2812,  ...,  83.3750,  79.5625,  54.0312],\n",
      "          [ 43.5312,  55.9688,  42.5312,  ..., 109.0000, 103.6875,  70.2500],\n",
      "          [ 40.6250,  49.1562,  33.3125,  ..., 109.0625, 104.0625,  70.5625],\n",
      "          ...,\n",
      "          [ 72.8125, 106.3750, 105.2500,  ...,  94.9375,  92.9375,  64.5000],\n",
      "          [ 71.9375, 106.0000, 106.3750,  ...,  89.6250,  87.6250,  61.6562],\n",
      "          [ 49.2812,  72.4375,  73.2500,  ...,  61.4062,  61.9062,  46.2812]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 70.1875, 116.0625, 127.3750,  ..., 152.0000, 131.3750,  77.8750],\n",
      "          [100.0625, 164.0000, 180.8750,  ..., 217.6250, 186.3750, 110.7500],\n",
      "          [109.8125, 179.3750, 197.2500,  ..., 234.2500, 200.8750, 119.3750],\n",
      "          ...,\n",
      "          [ 78.5625, 122.4375, 124.8750,  ..., 120.0000, 117.8750,  77.5000],\n",
      "          [ 73.5625, 116.0000, 120.0000,  ..., 117.1875, 113.1875,  73.7500],\n",
      "          [ 43.7812,  70.8125,  74.0625,  ...,  73.1875,  69.7500,  44.3125]],\n",
      "\n",
      "         [[ 70.2500, 116.2500, 127.7500,  ..., 152.7500, 131.8750,  77.9375],\n",
      "          [ 99.8125, 163.7500, 180.8750,  ..., 218.2500, 186.5000, 110.5625],\n",
      "          [109.7500, 179.3750, 197.5000,  ..., 235.0000, 201.1250, 119.2500],\n",
      "          ...,\n",
      "          [ 77.9375, 121.4375, 123.9375,  ..., 119.1875, 117.0000,  76.8125],\n",
      "          [ 72.9375, 115.0000, 119.0000,  ..., 116.3125, 112.2500,  73.0000],\n",
      "          [ 43.0000,  69.6875,  72.9375,  ...,  72.1250,  68.6250,  43.4688]],\n",
      "\n",
      "         [[ 69.6875, 113.8125, 124.0625,  ..., 147.0000, 128.1250,  77.0000],\n",
      "          [ 99.5000, 161.3750, 176.7500,  ..., 211.2500, 182.3750, 109.7500],\n",
      "          [108.5000, 175.6250, 192.1250,  ..., 226.7500, 195.8750, 117.7500],\n",
      "          ...,\n",
      "          [ 79.2500, 122.5000, 124.7500,  ..., 119.4375, 117.6250,  78.1250],\n",
      "          [ 74.8125, 116.7500, 120.3750,  ..., 117.0625, 113.6250,  74.8750],\n",
      "          [ 46.1250,  73.2500,  76.1875,  ...,  74.9375,  71.9375,  46.5625]]],\n",
      "\n",
      "\n",
      "        [[[ 80.0625, 135.5000, 154.7500,  ..., 151.7500, 131.1250,  77.6875],\n",
      "          [114.6875, 193.1250, 222.0000,  ..., 217.2500, 186.0000, 110.5625],\n",
      "          [125.0000, 209.5000, 239.6250,  ..., 233.8750, 200.6250, 119.2500],\n",
      "          ...,\n",
      "          [ 79.6875, 124.0000, 126.3750,  ..., 192.5000, 164.6250,  98.6875],\n",
      "          [ 74.7500, 117.6875, 121.6875,  ..., 170.5000, 146.5000,  88.3125],\n",
      "          [ 44.4375,  71.9375,  75.1875,  ...,  98.9375,  85.2500,  50.7188]],\n",
      "\n",
      "         [[ 80.3125, 136.0000, 155.6250,  ..., 152.5000, 131.6250,  77.7500],\n",
      "          [114.7500, 193.3750, 222.6250,  ..., 217.8750, 186.1250, 110.3750],\n",
      "          [125.1250, 209.8750, 240.5000,  ..., 234.6250, 200.8750, 119.1250],\n",
      "          ...,\n",
      "          [ 79.0625, 123.0625, 125.4375,  ..., 192.5000, 164.1250,  98.1250],\n",
      "          [ 74.1250, 116.6875, 120.6875,  ..., 170.0000, 145.8750,  87.6875],\n",
      "          [ 43.6875,  70.8125,  74.0625,  ...,  98.1250,  84.2500,  49.8750]],\n",
      "\n",
      "         [[ 78.8750, 132.0000, 149.6250,  ..., 146.7500, 127.8125,  76.8125],\n",
      "          [113.1250, 188.6250, 215.2500,  ..., 210.8750, 182.0000, 109.5625],\n",
      "          [122.6250, 203.7500, 231.7500,  ..., 226.5000, 195.6250, 117.5625],\n",
      "          ...,\n",
      "          [ 80.2500, 123.8750, 126.0000,  ..., 188.0000, 162.1250,  98.5000],\n",
      "          [ 75.8750, 118.2500, 121.8125,  ..., 167.7500, 145.6250,  89.1250],\n",
      "          [ 46.7500,  74.2500,  77.1875,  ...,  99.6875,  87.0625,  52.9375]]],\n",
      "\n",
      "\n",
      "        [[[ 29.9531,  43.6562,  36.0625,  ..., 154.2500, 133.2500,  78.8750],\n",
      "          [ 34.8438,  47.6250,  39.3750,  ..., 221.3750, 189.3750, 112.4375],\n",
      "          [ 33.0000,  43.3125,  45.0625,  ..., 238.3750, 204.2500, 121.2500],\n",
      "          ...,\n",
      "          [ 74.3125, 114.8750, 114.8750,  ..., 115.0000, 114.4375,  75.6250],\n",
      "          [ 70.6250, 110.5625, 112.7500,  ..., 113.3125, 110.4375,  72.1250],\n",
      "          [ 42.0625,  67.9375,  70.2500,  ...,  71.0000,  68.0625,  43.3125]],\n",
      "\n",
      "         [[ 29.8438,  43.6562,  36.3125,  ..., 155.1250, 133.7500,  78.9375],\n",
      "          [ 34.5938,  47.3750,  39.5000,  ..., 222.0000, 189.6250, 112.3125],\n",
      "          [ 33.0312,  43.4688,  45.1875,  ..., 239.2500, 204.6250, 121.1875],\n",
      "          ...,\n",
      "          [ 73.8750, 114.1250, 114.2500,  ..., 114.3125, 113.6875,  75.0000],\n",
      "          [ 70.0625, 109.6875, 112.0000,  ..., 112.5625, 109.5625,  71.4375],\n",
      "          [ 41.3750,  66.9375,  69.2500,  ...,  70.0000,  67.0000,  42.5000]],\n",
      "\n",
      "         [[ 30.0625,  42.4688,  33.9062,  ..., 149.1250, 129.8750,  77.9375],\n",
      "          [ 34.7188,  46.0000,  36.4062,  ..., 214.6250, 185.1250, 111.3125],\n",
      "          [ 31.6719,  40.2188,  41.5938,  ..., 230.6250, 199.0000, 119.4375],\n",
      "          ...,\n",
      "          [ 74.5625, 114.1250, 113.8750,  ..., 114.1250, 114.0000,  76.1250],\n",
      "          [ 71.4375, 110.5625, 112.3750,  ..., 113.0000, 110.6250,  73.1875],\n",
      "          [ 44.1875,  70.0000,  71.8750,  ...,  72.6250,  70.1875,  45.5000]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 63.8438,  99.5625, 103.2500,  ..., 169.3750, 147.6250,  89.5000],\n",
      "          [ 85.9375, 132.2500, 135.7500,  ..., 243.7500, 210.1250, 127.1250],\n",
      "          [ 91.7500, 139.0000, 139.3750,  ..., 264.2500, 227.8750, 137.6250],\n",
      "          ...,\n",
      "          [ 46.5000,  63.5938,  59.7812,  ...,  62.8750,  66.6250,  51.4375],\n",
      "          [ 48.4062,  66.8750,  63.8125,  ...,  66.0625,  69.4375,  53.1562],\n",
      "          [ 41.2812,  56.8125,  55.4062,  ...,  56.3438,  58.1562,  44.0625]],\n",
      "\n",
      "         [[ 63.5000,  99.1250, 102.8750,  ..., 169.7500, 147.7500,  89.3750],\n",
      "          [ 85.1875, 131.0000, 134.6250,  ..., 243.6250, 209.6250, 126.6250],\n",
      "          [ 91.1250, 137.8750, 138.3750,  ..., 264.7500, 227.6250, 137.1250],\n",
      "          ...,\n",
      "          [ 45.4062,  62.1250,  58.4062,  ...,  61.4375,  65.1250,  50.2500],\n",
      "          [ 47.3125,  65.3750,  62.3438,  ...,  64.6250,  67.8750,  51.9062],\n",
      "          [ 40.3438,  55.5625,  54.1562,  ...,  55.0938,  56.8438,  43.0312]],\n",
      "\n",
      "         [[ 64.0625,  98.7500, 101.7500,  ..., 164.2500, 144.2500,  88.5000],\n",
      "          [ 86.6875, 132.0000, 134.7500,  ..., 237.0000, 205.8750, 125.9375],\n",
      "          [ 91.8750, 138.1250, 137.8750,  ..., 256.5000, 222.5000, 135.7500],\n",
      "          ...,\n",
      "          [ 49.7500,  68.0000,  63.9688,  ...,  67.2500,  71.3125,  55.0312],\n",
      "          [ 51.8125,  71.6250,  68.2500,  ...,  70.7500,  74.3750,  56.8750],\n",
      "          [ 44.1875,  60.8750,  59.3125,  ...,  60.3750,  62.2812,  47.1250]]],\n",
      "\n",
      "\n",
      "        [[[ 66.5000, 105.3750, 112.0625,  ..., 169.1250, 147.3750,  89.3125],\n",
      "          [ 90.1250, 141.5000, 150.2500,  ..., 243.3750, 209.7500, 126.8750],\n",
      "          [ 95.7500, 149.0000, 156.2500,  ..., 264.2500, 227.7500, 137.3750],\n",
      "          ...,\n",
      "          [ 47.4375,  65.0000,  61.1875,  ..., 112.4375, 106.3125,  69.1250],\n",
      "          [ 49.2500,  68.1250,  65.0625,  ...,  91.8750,  92.0625,  62.0312],\n",
      "          [ 41.8438,  57.6562,  56.3125,  ...,  60.5625,  61.1250,  45.5938]],\n",
      "\n",
      "         [[ 66.1875, 104.8750, 111.6250,  ..., 169.5000, 147.5000,  89.1875],\n",
      "          [ 89.3125, 140.1250, 149.0000,  ..., 243.3750, 209.3750, 126.3750],\n",
      "          [ 95.0625, 147.7500, 155.0000,  ..., 264.7500, 227.3750, 137.0000],\n",
      "          ...,\n",
      "          [ 46.3438,  63.5000,  59.7812,  ..., 111.0000, 104.8125,  68.0000],\n",
      "          [ 48.1250,  66.6250,  63.5938,  ...,  90.3125,  90.5000,  60.8125],\n",
      "          [ 40.9062,  56.3750,  55.0625,  ...,  59.1562,  59.7188,  44.5312]],\n",
      "\n",
      "         [[ 66.7500, 104.5000, 110.5625,  ..., 164.0000, 144.0000,  88.3750],\n",
      "          [ 90.8750, 141.2500, 149.2500,  ..., 236.7500, 205.5000, 125.6875],\n",
      "          [ 96.0625, 148.1250, 154.7500,  ..., 256.5000, 222.3750, 135.5000],\n",
      "          ...,\n",
      "          [ 50.7500,  69.5625,  65.4375,  ..., 114.6250, 109.1875,  72.0625],\n",
      "          [ 52.7188,  72.9375,  69.6250,  ...,  95.9375,  96.3125,  65.6250],\n",
      "          [ 44.8125,  61.7812,  60.3125,  ...,  64.8125,  65.4375,  48.7812]]],\n",
      "\n",
      "\n",
      "        [[[ 92.1875, 152.7500, 172.8750,  ..., 168.7500, 147.5000,  89.5000],\n",
      "          [131.8750, 218.2500, 249.0000,  ..., 242.8750, 210.0000, 127.1875],\n",
      "          [144.1250, 238.0000, 270.7500,  ..., 263.5000, 228.0000, 137.8750],\n",
      "          ...,\n",
      "          [ 52.0625,  78.0625,  72.4375,  ..., 100.5625,  96.6250,  63.3125],\n",
      "          [ 51.0938,  71.8750,  69.8125,  ...,  82.6250,  84.9375,  58.0000],\n",
      "          [ 42.5938,  59.3438,  58.2812,  ...,  58.1250,  59.0625,  44.3125]],\n",
      "\n",
      "         [[ 92.1875, 152.8750, 173.2500,  ..., 169.1250, 147.6250,  89.3125],\n",
      "          [131.5000, 218.0000, 249.1250,  ..., 242.8750, 209.6250, 126.6875],\n",
      "          [143.8750, 238.0000, 271.2500,  ..., 264.0000, 227.7500, 137.3750],\n",
      "          ...,\n",
      "          [ 51.0000,  76.5625,  70.9375,  ...,  99.2500,  95.2500,  62.2500],\n",
      "          [ 49.9375,  70.2500,  68.2500,  ...,  81.1875,  83.4375,  56.8438],\n",
      "          [ 41.6250,  58.0000,  56.9688,  ...,  56.7812,  57.7188,  43.2812]],\n",
      "\n",
      "         [[ 90.7500, 148.8750, 167.5000,  ..., 163.6250, 144.1250,  88.4375],\n",
      "          [130.0000, 213.3750, 242.0000,  ..., 236.2500, 205.7500, 126.0000],\n",
      "          [141.3750, 231.8750, 262.5000,  ..., 255.8750, 222.6250, 135.8750],\n",
      "          ...,\n",
      "          [ 55.5625,  82.5000,  76.9375,  ..., 102.8750,  99.5625,  66.3125],\n",
      "          [ 54.7188,  77.0000,  74.7500,  ...,  86.7500,  89.1250,  61.5938],\n",
      "          [ 45.5938,  63.5625,  62.4062,  ...,  62.2500,  63.2500,  47.4062]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 56.0625,  87.3125,  91.6250,  ...,  91.0000,  87.6875,  58.4688],\n",
      "          [ 69.3125, 108.6875, 116.3125,  ..., 115.8750, 109.0000,  72.5000],\n",
      "          [ 67.8750, 107.7500, 117.4375,  ..., 117.5625, 107.6250,  70.4375],\n",
      "          ...,\n",
      "          [ 45.9062,  61.8750,  58.9062,  ...,  61.7500,  66.3125,  52.5625],\n",
      "          [ 48.8438,  66.9375,  64.7500,  ...,  67.1875,  70.8750,  55.1250],\n",
      "          [ 42.4688,  58.2188,  57.4375,  ...,  59.1250,  60.7812,  46.4375]],\n",
      "\n",
      "         [[ 55.6250,  86.6250,  90.9375,  ...,  90.2500,  87.0000,  57.8750],\n",
      "          [ 68.3750, 107.1875, 114.8750,  ..., 114.4375, 107.5000,  71.3750],\n",
      "          [ 67.0625, 106.3750, 116.1250,  ..., 116.2500, 106.2500,  69.4375],\n",
      "          ...,\n",
      "          [ 44.9062,  60.5000,  57.6250,  ...,  60.4375,  64.8750,  51.4375],\n",
      "          [ 47.7812,  65.5000,  63.3438,  ...,  65.7500,  69.3750,  53.9375],\n",
      "          [ 41.5938,  57.0000,  56.2188,  ...,  57.8750,  59.5000,  45.4375]],\n",
      "\n",
      "         [[ 57.3125,  88.1250,  91.9375,  ...,  91.4375,  88.6250,  59.8750],\n",
      "          [ 71.8125, 111.1250, 117.9375,  ..., 117.7500, 111.6875,  75.2500],\n",
      "          [ 70.3750, 110.0000, 118.6875,  ..., 119.1250, 110.2500,  73.3125],\n",
      "          ...,\n",
      "          [ 49.0312,  66.0625,  62.9375,  ...,  66.0000,  70.8750,  56.1562],\n",
      "          [ 52.1875,  71.5625,  69.1875,  ...,  71.8125,  75.7500,  58.9062],\n",
      "          [ 45.4062,  62.2500,  61.4062,  ...,  63.2188,  65.0000,  49.6250]]],\n",
      "\n",
      "\n",
      "        [[[ 70.9375, 113.8750, 123.0625,  ...,  98.3125,  94.5625,  62.7500],\n",
      "          [ 94.8125, 154.6250, 171.2500,  ..., 128.1250, 120.6250,  79.7500],\n",
      "          [ 98.4375, 163.2500, 184.3750,  ..., 132.6250, 121.8750,  79.3750],\n",
      "          ...,\n",
      "          [ 49.7500,  67.8750,  65.2500,  ...,  65.7500,  70.2500,  54.9375],\n",
      "          [ 52.1875,  72.1875,  70.3125,  ...,  70.4375,  74.0625,  57.0938],\n",
      "          [ 44.5312,  61.5312,  60.9688,  ...,  61.0938,  62.6250,  47.5625]],\n",
      "\n",
      "         [[ 70.5625, 113.3125, 122.6250,  ...,  97.5625,  93.8125,  62.1250],\n",
      "          [ 94.0000, 153.3750, 170.0000,  ..., 126.6250, 119.0625,  78.6250],\n",
      "          [ 97.7500, 162.1250, 183.3750,  ..., 131.1250, 120.4375,  78.3125],\n",
      "          ...,\n",
      "          [ 48.6562,  66.3750,  63.8438,  ...,  64.3750,  68.7500,  53.7500],\n",
      "          [ 51.0312,  70.6250,  68.8125,  ...,  68.9375,  72.5000,  55.8438],\n",
      "          [ 43.5938,  60.2188,  59.6875,  ...,  59.7812,  61.3125,  46.5312]],\n",
      "\n",
      "         [[ 71.5625, 113.5000, 121.9375,  ...,  98.5625,  95.3125,  64.0625],\n",
      "          [ 96.2500, 155.1250, 170.5000,  ..., 129.7500, 123.0000,  82.3750],\n",
      "          [ 99.6875, 163.2500, 182.8750,  ..., 133.7500, 124.1875,  82.0625],\n",
      "          ...,\n",
      "          [ 53.1562,  72.5000,  69.7500,  ...,  70.3125,  75.1250,  58.6875],\n",
      "          [ 55.7812,  77.1875,  75.1875,  ...,  75.3125,  79.1875,  61.0000],\n",
      "          [ 47.6250,  65.7500,  65.1875,  ...,  65.3125,  66.9375,  50.8125]]],\n",
      "\n",
      "\n",
      "        [[[ 55.6875,  86.9375,  91.1250,  ..., 144.7500, 125.5625,  77.2500],\n",
      "          [ 69.4375, 109.4375, 117.5000,  ..., 215.7500, 181.3750, 109.2500],\n",
      "          [ 68.9375, 110.4375, 121.5000,  ..., 252.5000, 207.8750, 122.5000],\n",
      "          ...,\n",
      "          [ 47.0000,  63.5625,  60.5938,  ...,  61.8125,  66.3750,  52.6250],\n",
      "          [ 49.7188,  68.2500,  66.0000,  ...,  67.1250,  70.8750,  55.1562],\n",
      "          [ 43.0000,  59.0312,  58.2188,  ...,  59.1562,  60.8125,  46.4688]],\n",
      "\n",
      "         [[ 55.2188,  86.2500,  90.4375,  ..., 144.5000, 125.1250,  76.8125],\n",
      "          [ 68.5000, 107.9375, 116.0000,  ..., 215.0000, 180.2500, 108.3750],\n",
      "          [ 68.1250, 109.0625, 120.1875,  ..., 252.1250, 207.1250, 121.8125],\n",
      "          ...,\n",
      "          [ 45.9688,  62.1875,  59.2500,  ...,  60.4688,  64.9375,  51.5000],\n",
      "          [ 48.6250,  66.8125,  64.6250,  ...,  65.7500,  69.3750,  53.9688],\n",
      "          [ 42.0938,  57.7812,  56.9688,  ...,  57.9062,  59.5312,  45.4688]],\n",
      "\n",
      "         [[ 57.0000,  87.8750,  91.6250,  ..., 142.5000, 124.5625,  77.7500],\n",
      "          [ 71.9375, 111.9375, 119.2500,  ..., 212.6250, 180.5000, 110.3125],\n",
      "          [ 71.3750, 112.6250, 122.7500,  ..., 247.2500, 205.6250, 122.8750],\n",
      "          ...,\n",
      "          [ 50.2188,  67.9375,  64.6875,  ...,  66.0000,  70.9375,  56.2188],\n",
      "          [ 53.1250,  73.0000,  70.5625,  ...,  71.8125,  75.8125,  58.9375],\n",
      "          [ 46.0000,  63.1250,  62.2500,  ...,  63.2500,  65.0000,  49.6562]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 93.3125, 157.0000, 180.6250,  ..., 174.6250, 150.3750,  90.2500],\n",
      "          [133.6250, 228.0000, 268.5000,  ..., 259.2500, 217.3750, 128.5000],\n",
      "          [147.8750, 255.5000, 306.0000,  ..., 294.7500, 242.8750, 141.5000],\n",
      "          ...,\n",
      "          [ 46.9375,  63.5625,  60.8125,  ...,  59.5938,  64.0625,  51.1562],\n",
      "          [ 49.0312,  67.1875,  64.8125,  ...,  63.7812,  67.8125,  53.2812],\n",
      "          [ 42.3438,  57.7812,  56.7188,  ...,  56.2188,  58.2500,  45.0312]],\n",
      "\n",
      "         [[ 93.0625, 156.7500, 180.5000,  ..., 174.3750, 150.0000,  89.8750],\n",
      "          [133.0000, 227.1250, 268.2500,  ..., 258.7500, 216.3750, 127.7500],\n",
      "          [147.5000, 254.7500, 305.7500,  ..., 294.5000, 242.1250, 140.8750],\n",
      "          ...,\n",
      "          [ 45.9688,  62.2188,  59.5312,  ...,  58.3750,  62.7500,  50.0938],\n",
      "          [ 48.0312,  65.6875,  63.4375,  ...,  62.4688,  66.3125,  52.1875],\n",
      "          [ 41.5312,  56.6250,  55.5938,  ...,  55.1250,  57.0938,  44.1250]],\n",
      "\n",
      "         [[ 93.0625, 154.8750, 177.1250,  ..., 171.3750, 148.5000,  90.3750],\n",
      "          [133.3750, 225.2500, 263.7500,  ..., 254.7500, 215.2500, 129.0000],\n",
      "          [147.1250, 251.3750, 299.2500,  ..., 288.7500, 239.7500, 141.3750],\n",
      "          ...,\n",
      "          [ 50.0312,  67.8125,  64.8125,  ...,  63.5312,  68.3125,  54.5000],\n",
      "          [ 52.2812,  71.6250,  69.0625,  ...,  68.0000,  72.2500,  56.7812],\n",
      "          [ 45.1562,  61.6250,  60.5000,  ...,  59.9688,  62.1562,  48.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 56.5625,  93.8125, 106.5625,  ..., 123.7500, 114.4375,  71.4375],\n",
      "          [ 68.9375, 117.1250, 138.8750,  ..., 174.3750, 157.3750,  97.0000],\n",
      "          [ 64.8750, 112.1250, 136.8750,  ..., 192.1250, 170.8750, 103.7500],\n",
      "          ...,\n",
      "          [ 44.4375,  59.7500,  56.8438,  ...,  60.9375,  65.3750,  51.9688],\n",
      "          [ 46.9688,  63.9688,  61.4688,  ...,  65.1250,  69.0625,  54.0625],\n",
      "          [ 41.0938,  55.8125,  54.6250,  ...,  57.2188,  59.1875,  45.5938]],\n",
      "\n",
      "         [[ 56.1250,  93.0000, 105.9375,  ..., 123.2500, 113.7500,  70.9375],\n",
      "          [ 68.0000, 115.5625, 137.5000,  ..., 173.2500, 156.0000,  96.0000],\n",
      "          [ 64.0000, 110.6875, 135.6250,  ..., 191.1250, 169.7500, 102.8750],\n",
      "          ...,\n",
      "          [ 43.5312,  58.5000,  55.6875,  ...,  59.6875,  64.0000,  50.9062],\n",
      "          [ 46.0000,  62.6250,  60.1875,  ...,  63.7812,  67.5625,  52.9688],\n",
      "          [ 40.2812,  54.7188,  53.5312,  ...,  56.0938,  58.0000,  44.6562]],\n",
      "\n",
      "         [[ 58.1250,  94.8750, 106.8750,  ..., 123.2500, 114.4375,  72.5000],\n",
      "          [ 71.9375, 120.0000, 140.5000,  ..., 174.2500, 158.2500,  99.0000],\n",
      "          [ 68.1875, 115.3750, 138.7500,  ..., 191.1250, 171.2500, 105.5625],\n",
      "          ...,\n",
      "          [ 47.3438,  63.6875,  60.5938,  ...,  65.0000,  69.6875,  55.3750],\n",
      "          [ 50.0625,  68.2500,  65.5000,  ...,  69.4375,  73.6250,  57.6250],\n",
      "          [ 43.8125,  59.5312,  58.2500,  ...,  61.0312,  63.1250,  48.5938]]],\n",
      "\n",
      "\n",
      "        [[[ 52.0312,  84.6250,  93.5625,  ..., 171.1250, 147.7500,  88.8125],\n",
      "          [ 61.0938, 101.4375, 116.8125,  ..., 252.7500, 212.3750, 125.8125],\n",
      "          [ 57.9062,  96.3125, 114.1250,  ..., 285.7500, 236.1250, 137.7500],\n",
      "          ...,\n",
      "          [ 44.8125,  60.4062,  57.7188,  ...,  60.6562,  65.4375,  52.0938],\n",
      "          [ 47.2812,  64.5000,  62.1250,  ...,  64.6875,  68.9375,  54.0625],\n",
      "          [ 41.2500,  56.1250,  55.0000,  ...,  56.8125,  58.9688,  45.5000]],\n",
      "\n",
      "         [[ 51.5625,  83.8125,  92.8125,  ..., 170.8750, 147.3750,  88.4375],\n",
      "          [ 60.1250,  99.8750, 115.3750,  ..., 252.0000, 211.3750, 125.0000],\n",
      "          [ 56.9375,  94.8125, 112.7500,  ..., 285.5000, 235.2500, 137.0000],\n",
      "          ...,\n",
      "          [ 43.8750,  59.1250,  56.5312,  ...,  59.4062,  64.0625,  51.0312],\n",
      "          [ 46.3125,  63.1250,  60.8438,  ...,  63.3750,  67.4375,  52.9375],\n",
      "          [ 40.4375,  55.0000,  53.9375,  ...,  55.7188,  57.8125,  44.5938]],\n",
      "\n",
      "         [[ 53.7812,  86.0625,  94.4375,  ..., 168.1250, 146.0000,  89.0000],\n",
      "          [ 64.4375, 105.0625, 119.4375,  ..., 248.6250, 210.5000, 126.3750],\n",
      "          [ 61.4375, 100.2500, 116.9375,  ..., 280.2500, 233.2500, 137.8750],\n",
      "          ...,\n",
      "          [ 47.7500,  64.3750,  61.5312,  ...,  64.6250,  69.8125,  55.5312],\n",
      "          [ 50.3750,  68.7500,  66.2500,  ...,  69.0000,  73.5000,  57.6250],\n",
      "          [ 44.0000,  59.8750,  58.6562,  ...,  60.5938,  62.9062,  48.5000]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 49.3125,  78.2500,  88.5000,  ..., 165.8750, 139.7500,  84.5000],\n",
      "          [ 59.5312,  97.5000, 115.2500,  ..., 252.6250, 206.7500, 122.0625],\n",
      "          [ 63.1250, 104.9375, 126.6875,  ..., 302.0000, 244.0000, 141.8750],\n",
      "          ...,\n",
      "          [ 42.8125,  58.0625,  57.2500,  ...,  59.2812,  62.1562,  50.2500],\n",
      "          [ 45.6562,  62.3438,  61.5000,  ...,  63.1562,  65.6875,  52.3438],\n",
      "          [ 40.8750,  55.3125,  55.0625,  ...,  56.0938,  57.3125,  44.8438]],\n",
      "\n",
      "         [[ 48.7500,  77.4375,  87.7500,  ..., 165.6250, 139.3750,  84.0625],\n",
      "          [ 58.5312,  96.0000, 113.7500,  ..., 251.8750, 205.7500, 121.2500],\n",
      "          [ 62.2188, 103.5000, 125.3125,  ..., 301.7500, 243.2500, 141.1250],\n",
      "          ...,\n",
      "          [ 41.9688,  56.9375,  56.1250,  ...,  58.1250,  60.9062,  49.2812],\n",
      "          [ 44.7500,  61.0938,  60.2812,  ...,  61.9062,  64.4375,  51.3125],\n",
      "          [ 40.0938,  54.2500,  54.0312,  ...,  55.0312,  56.2188,  43.9688]],\n",
      "\n",
      "         [[ 51.3125,  80.1875,  89.8750,  ..., 164.2500, 139.3750,  85.3750],\n",
      "          [ 62.9375, 101.2500, 118.0000,  ..., 250.0000, 206.3750, 123.3750],\n",
      "          [ 66.3750, 108.3125, 128.8750,  ..., 297.5000, 242.0000, 142.5000],\n",
      "          ...,\n",
      "          [ 45.5000,  61.7500,  60.8750,  ...,  63.0312,  66.0625,  53.4062],\n",
      "          [ 48.5312,  66.3125,  65.3750,  ...,  67.1875,  69.8750,  55.6562],\n",
      "          [ 43.5000,  58.8438,  58.5938,  ...,  59.6875,  61.0000,  47.6875]]],\n",
      "\n",
      "\n",
      "        [[[ 78.8750, 131.8750, 154.8750,  ...,  82.1250,  73.0625,  48.4688],\n",
      "          [112.5625, 192.3750, 232.1250,  ..., 112.9375,  95.1875,  60.4062],\n",
      "          [130.1250, 224.5000, 274.0000,  ..., 136.8750, 112.3750,  68.8125],\n",
      "          ...,\n",
      "          [ 43.3438,  58.8750,  58.0625,  ...,  58.7812,  61.8438,  50.0000],\n",
      "          [ 46.0938,  63.0000,  62.1875,  ...,  62.7188,  65.4375,  52.1562],\n",
      "          [ 41.0938,  55.6562,  55.4062,  ...,  55.7812,  57.0938,  44.6562]],\n",
      "\n",
      "         [[ 78.5625, 131.3750, 154.5000,  ...,  81.4375,  72.3125,  47.8125],\n",
      "          [111.9375, 191.3750, 231.2500,  ..., 111.6875,  93.8125,  59.3125],\n",
      "          [129.5000, 223.6250, 273.5000,  ..., 135.7500, 111.1250,  67.8125],\n",
      "          ...,\n",
      "          [ 42.5000,  57.7188,  56.9375,  ...,  57.6250,  60.6250,  49.0312],\n",
      "          [ 45.1562,  61.7500,  60.9688,  ...,  61.5000,  64.1875,  51.1250],\n",
      "          [ 40.3125,  54.5938,  54.3750,  ...,  54.7188,  56.0312,  43.8125]],\n",
      "\n",
      "         [[ 79.7500, 131.7500, 153.6250,  ...,  83.5000,  75.1250,  50.5938],\n",
      "          [113.9375, 192.5000, 230.2500,  ..., 115.2500,  98.8125,  63.8438],\n",
      "          [130.7500, 223.1250, 270.5000,  ..., 137.6250, 114.9375,  71.7500],\n",
      "          ...,\n",
      "          [ 46.0938,  62.5938,  61.7500,  ...,  62.5000,  65.7500,  53.1562],\n",
      "          [ 49.0000,  67.0000,  66.1250,  ...,  66.7500,  69.6250,  55.4688],\n",
      "          [ 43.7500,  59.2500,  58.9688,  ...,  59.3438,  60.7812,  47.5000]]],\n",
      "\n",
      "\n",
      "        [[[ 80.2500, 133.0000, 150.5000,  ..., 169.5000, 142.5000,  86.0000],\n",
      "          [111.3125, 186.3750, 212.3750,  ..., 259.0000, 211.7500, 124.7500],\n",
      "          [121.5625, 202.2500, 227.5000,  ..., 310.2500, 250.2500, 145.2500],\n",
      "          ...,\n",
      "          [ 42.0625,  56.7500,  55.5938,  ...,  56.5938,  59.3125,  48.3750],\n",
      "          [ 45.0625,  61.3125,  60.2500,  ...,  61.0938,  63.5625,  50.9688],\n",
      "          [ 40.5000,  54.6875,  54.3438,  ...,  54.9375,  56.1562,  44.0938]],\n",
      "\n",
      "         [[ 80.0000, 132.5000, 150.1250,  ..., 169.2500, 142.1250,  85.6250],\n",
      "          [110.6875, 185.2500, 211.3750,  ..., 258.5000, 210.8750, 124.0000],\n",
      "          [121.0000, 201.1250, 226.5000,  ..., 310.0000, 249.3750, 144.5000],\n",
      "          ...,\n",
      "          [ 41.2188,  55.6250,  54.5000,  ...,  55.5000,  58.1562,  47.4375],\n",
      "          [ 44.1875,  60.0938,  59.0625,  ...,  59.9062,  62.3125,  49.9688],\n",
      "          [ 39.7500,  53.6562,  53.3125,  ...,  53.9062,  55.0938,  43.2500]],\n",
      "\n",
      "         [[ 81.0625, 132.7500, 149.3750,  ..., 167.6250, 142.0000,  86.8125],\n",
      "          [112.6875, 186.6250, 211.2500,  ..., 256.2500, 211.1250, 125.9375],\n",
      "          [122.5000, 201.7500, 225.6250,  ..., 305.2500, 248.0000, 145.6250],\n",
      "          ...,\n",
      "          [ 44.6875,  60.3125,  59.0938,  ...,  60.1875,  63.0625,  51.4062],\n",
      "          [ 47.9062,  65.1875,  64.0625,  ...,  64.9375,  67.5625,  54.1562],\n",
      "          [ 43.0938,  58.1875,  57.8125,  ...,  58.4688,  59.7500,  46.8750]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 75.4375, 122.9375, 142.5000,  ..., 164.5000, 138.5000,  84.8750],\n",
      "          [106.8750, 178.6250, 212.3750,  ..., 251.0000, 205.6250, 122.6875],\n",
      "          [128.5000, 216.6250, 259.7500,  ..., 306.7500, 249.2500, 146.8750],\n",
      "          ...,\n",
      "          [ 43.4062,  59.0625,  58.8750,  ...,  57.4062,  59.3125,  48.2500],\n",
      "          [ 45.8750,  62.7188,  62.4375,  ...,  61.0312,  62.9062,  50.5000],\n",
      "          [ 40.9062,  55.2500,  55.3125,  ...,  54.3438,  55.3125,  43.6562]],\n",
      "\n",
      "         [[ 75.1250, 122.4375, 142.1250,  ..., 164.1250, 138.0000,  84.5000],\n",
      "          [106.2500, 177.5000, 211.3750,  ..., 250.2500, 204.6250, 121.8750],\n",
      "          [127.9375, 215.7500, 259.2500,  ..., 306.2500, 248.3750, 146.1250],\n",
      "          ...,\n",
      "          [ 42.6250,  58.0000,  57.8125,  ...,  56.4062,  58.2500,  47.3750],\n",
      "          [ 45.0312,  61.5938,  61.3125,  ...,  59.9375,  61.7812,  49.5938],\n",
      "          [ 40.2188,  54.2812,  54.3438,  ...,  53.4062,  54.3438,  42.8750]],\n",
      "\n",
      "         [[ 76.6250, 123.4375, 142.2500,  ..., 163.3750, 138.5000,  85.9375],\n",
      "          [108.6250, 179.5000, 212.0000,  ..., 249.3750, 205.7500, 124.1250],\n",
      "          [129.3750, 216.1250, 257.5000,  ..., 303.0000, 247.7500, 147.5000],\n",
      "          ...,\n",
      "          [ 46.0312,  62.6562,  62.4375,  ...,  60.9062,  62.9062,  51.1562],\n",
      "          [ 48.6562,  66.5625,  66.2500,  ...,  64.7500,  66.7500,  53.5625],\n",
      "          [ 43.4375,  58.6562,  58.7188,  ...,  57.6875,  58.7188,  46.3125]]],\n",
      "\n",
      "\n",
      "        [[[ 49.4375,  74.5000,  80.4375,  ...,  62.8125,  64.0625,  46.0312],\n",
      "          [ 60.0000,  92.3750, 101.5625,  ...,  73.1875,  76.3125,  54.6250],\n",
      "          [ 68.6875, 106.0000, 116.6875,  ...,  79.8750,  86.6875,  62.7812],\n",
      "          ...,\n",
      "          [ 41.8438,  56.3750,  55.5625,  ...,  54.5625,  56.8125,  46.6875],\n",
      "          [ 44.5000,  60.3438,  59.5625,  ...,  58.6562,  60.8438,  49.2188],\n",
      "          [ 40.0000,  53.6875,  53.4688,  ...,  52.8125,  54.0000,  42.8438]],\n",
      "\n",
      "         [[ 48.8750,  73.6875,  79.6250,  ...,  62.2188,  63.3750,  45.4688],\n",
      "          [ 59.0625,  90.8750, 100.1250,  ...,  72.1250,  75.0625,  53.6875],\n",
      "          [ 67.8125, 104.6250, 115.3125,  ...,  79.1250,  85.6875,  61.9688],\n",
      "          ...,\n",
      "          [ 41.0938,  55.3438,  54.5625,  ...,  53.6250,  55.7812,  45.8438],\n",
      "          [ 43.6875,  59.2500,  58.5000,  ...,  57.6250,  59.7500,  48.3438],\n",
      "          [ 39.3125,  52.7188,  52.5625,  ...,  51.9062,  53.0625,  42.0938]],\n",
      "\n",
      "         [[ 51.3750,  76.5000,  82.0625,  ...,  63.9062,  65.8750,  47.9062],\n",
      "          [ 63.1875,  96.0625, 104.6875,  ...,  74.9375,  79.3125,  57.5000],\n",
      "          [ 71.4375, 109.0000, 119.0625,  ...,  80.1250,  88.5000,  64.8125],\n",
      "          ...,\n",
      "          [ 44.3750,  59.7812,  58.9062,  ...,  57.8750,  60.2500,  49.5000],\n",
      "          [ 47.1875,  64.0000,  63.1562,  ...,  62.2188,  64.5625,  52.2188],\n",
      "          [ 42.4688,  56.9688,  56.7500,  ...,  56.0625,  57.3125,  45.4688]]],\n",
      "\n",
      "\n",
      "        [[[ 46.6875,  68.6875,  71.9375,  ...,  58.6562,  57.8125,  42.2812],\n",
      "          [ 55.0625,  82.1875,  87.1875,  ...,  70.1250,  68.1875,  51.2188],\n",
      "          [ 61.3438,  92.3125,  98.3750,  ...,  84.6250,  82.2500,  57.2500],\n",
      "          ...,\n",
      "          [ 41.8438,  56.4688,  55.8438,  ...,  55.0938,  57.1875,  46.9062],\n",
      "          [ 44.4688,  60.4062,  59.7812,  ...,  59.1250,  61.2188,  49.4375],\n",
      "          [ 40.0312,  53.7500,  53.6562,  ...,  53.1875,  54.2500,  43.0000]],\n",
      "\n",
      "         [[ 46.1562,  67.8750,  71.1875,  ...,  57.9688,  57.0625,  41.6250],\n",
      "          [ 54.1562,  80.7500,  85.8750,  ...,  68.9375,  66.8750,  50.2500],\n",
      "          [ 60.5312,  91.0000,  97.1250,  ...,  83.6250,  81.0625,  56.3750],\n",
      "          ...,\n",
      "          [ 41.0938,  55.4375,  54.8438,  ...,  54.1250,  56.1562,  46.0625],\n",
      "          [ 43.6875,  59.3125,  58.7188,  ...,  58.0625,  60.0938,  48.5312],\n",
      "          [ 39.3438,  52.8125,  52.7188,  ...,  52.2500,  53.3125,  42.2188]],\n",
      "\n",
      "         [[ 48.6250,  70.6875,  73.5625,  ...,  60.4688,  60.0625,  44.3750],\n",
      "          [ 58.2188,  85.8125,  90.2500,  ...,  73.2500,  72.0000,  54.3750],\n",
      "          [ 64.0625,  95.2500, 100.6250,  ...,  86.5625,  85.1250,  60.0312],\n",
      "          ...,\n",
      "          [ 44.3750,  59.8750,  59.2188,  ...,  58.4375,  60.6562,  49.7500],\n",
      "          [ 47.1875,  64.0625,  63.4062,  ...,  62.7188,  64.9375,  52.4375],\n",
      "          [ 42.4688,  57.0625,  56.9688,  ...,  56.4375,  57.5938,  45.6250]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 41.5000,  62.7188,  68.3750,  ...,  51.7188,  51.6250,  39.4062],\n",
      "          [ 52.5625,  74.2500,  83.0000,  ...,  66.6875,  68.9375,  53.3438],\n",
      "          [ 53.5938,  84.5625,  98.4375,  ...,  82.5000,  72.5000,  54.3125],\n",
      "          ...,\n",
      "          [ 41.3750,  56.1562,  55.9375,  ...,  54.7812,  56.2812,  45.8438],\n",
      "          [ 43.6562,  59.6250,  59.3438,  ...,  58.3750,  60.0000,  48.2500],\n",
      "          [ 39.0000,  52.5625,  52.6875,  ...,  51.9375,  52.8125,  41.8125]],\n",
      "\n",
      "         [[ 40.8750,  61.9062,  67.5625,  ...,  50.9688,  50.8125,  38.7500],\n",
      "          [ 51.6875,  72.8750,  81.5625,  ...,  65.5625,  67.7500,  52.4375],\n",
      "          [ 52.7188,  83.1875,  97.0625,  ...,  81.2500,  71.2500,  53.4062],\n",
      "          ...,\n",
      "          [ 40.7500,  55.2812,  55.0938,  ...,  53.9375,  55.4062,  45.1250],\n",
      "          [ 42.9688,  58.6875,  58.4375,  ...,  57.4688,  59.0312,  47.4688],\n",
      "          [ 38.4062,  51.7500,  51.8750,  ...,  51.1562,  52.0000,  41.1562]],\n",
      "\n",
      "         [[ 43.5938,  65.1250,  70.5000,  ...,  54.1875,  54.2812,  41.6250],\n",
      "          [ 55.7188,  78.5625,  86.7500,  ...,  70.6875,  73.0625,  56.5000],\n",
      "          [ 56.7812,  88.3125, 101.3750,  ...,  85.8750,  76.6250,  57.5625],\n",
      "          ...,\n",
      "          [ 43.7812,  59.4375,  59.1875,  ...,  57.9688,  59.5625,  48.5000],\n",
      "          [ 46.2188,  63.1250,  62.8125,  ...,  61.7812,  63.5000,  51.0625],\n",
      "          [ 41.2812,  55.6562,  55.7812,  ...,  55.0000,  55.9375,  44.2500]]],\n",
      "\n",
      "\n",
      "        [[[ 40.0000,  60.4062,  68.5625,  ...,  71.3125,  64.6875,  42.9688],\n",
      "          [ 52.2188,  73.3125,  83.6250,  ...,  99.3750,  85.0000,  53.0625],\n",
      "          [ 52.7500,  80.6250,  99.2500,  ..., 130.7500, 110.5625,  66.5625],\n",
      "          ...,\n",
      "          [ 41.5625,  56.5000,  56.4062,  ...,  55.3125,  56.7188,  46.1250],\n",
      "          [ 43.8438,  59.9688,  59.7500,  ...,  58.7812,  60.3438,  48.4688],\n",
      "          [ 39.1250,  52.7812,  52.9375,  ...,  52.2188,  53.0312,  41.9375]],\n",
      "\n",
      "         [[ 39.3750,  59.5938,  67.7500,  ...,  70.8750,  64.0625,  42.3750],\n",
      "          [ 51.3438,  72.0625,  82.1875,  ...,  98.5625,  83.8750,  52.1875],\n",
      "          [ 51.9062,  79.1875,  97.8750,  ..., 130.2500, 109.7500,  65.8750],\n",
      "          ...,\n",
      "          [ 40.9062,  55.6250,  55.5312,  ...,  54.4688,  55.8125,  45.4062],\n",
      "          [ 43.1562,  59.0000,  58.8125,  ...,  57.8750,  59.4062,  47.6875],\n",
      "          [ 38.5312,  51.9688,  52.1250,  ...,  51.4375,  52.2188,  41.2812]],\n",
      "\n",
      "         [[ 42.1562,  62.9688,  70.7500,  ...,  72.3125,  66.5625,  44.9062],\n",
      "          [ 55.3438,  77.7500,  87.4375,  ..., 100.5625,  87.8125,  55.9688],\n",
      "          [ 55.9062,  84.5625, 102.3750,  ..., 129.7500, 111.8750,  68.7500],\n",
      "          ...,\n",
      "          [ 43.9688,  59.7812,  59.6875,  ...,  58.5312,  60.0000,  48.7812],\n",
      "          [ 46.4062,  63.4688,  63.2500,  ...,  62.2188,  63.8750,  51.2812],\n",
      "          [ 41.4375,  55.9062,  56.0625,  ...,  55.3125,  56.1562,  44.4062]]],\n",
      "\n",
      "\n",
      "        [[[ 57.1875,  98.8125, 120.8125,  ...,  60.6250,  51.3750,  38.1250],\n",
      "          [ 79.1875, 143.7500, 184.8750,  ...,  74.6250,  67.6875,  51.5938],\n",
      "          [ 97.9375, 180.3750, 235.8750,  ...,  93.3750,  68.1875,  51.5000],\n",
      "          ...,\n",
      "          [ 41.2812,  55.9688,  55.7500,  ...,  54.9062,  56.3438,  45.9062],\n",
      "          [ 43.5938,  59.5312,  59.2188,  ...,  58.4688,  60.0625,  48.2812],\n",
      "          [ 38.9688,  52.5000,  52.5938,  ...,  52.0000,  52.8438,  41.8438]],\n",
      "\n",
      "         [[ 56.8125,  98.2500, 120.4375,  ...,  59.8750,  50.5625,  37.5000],\n",
      "          [ 78.5000, 142.6250, 184.0000,  ...,  73.3125,  66.5625,  50.7188],\n",
      "          [ 97.3750, 179.5000, 235.2500,  ...,  92.1875,  67.0625,  50.6250],\n",
      "          ...,\n",
      "          [ 40.6250,  55.0938,  54.8750,  ...,  54.0625,  55.4688,  45.1875],\n",
      "          [ 42.9375,  58.5938,  58.3125,  ...,  57.5625,  59.0938,  47.5312],\n",
      "          [ 38.3750,  51.7188,  51.7812,  ...,  51.2188,  52.0312,  41.1875]],\n",
      "\n",
      "         [[ 58.9688, 100.1875, 121.4375,  ...,  62.9062,  54.0000,  40.3125],\n",
      "          [ 81.8750, 146.0000, 185.6250,  ...,  78.5000,  71.7500,  54.6250],\n",
      "          [100.0000, 181.3750, 234.8750,  ...,  96.4375,  72.2500,  54.5312],\n",
      "          ...,\n",
      "          [ 43.6562,  59.2188,  59.0000,  ...,  58.0938,  59.6250,  48.5625],\n",
      "          [ 46.1562,  63.0000,  62.6875,  ...,  61.8750,  63.5625,  51.0938],\n",
      "          [ 41.2812,  55.5938,  55.6875,  ...,  55.0625,  55.9688,  44.2812]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 35.2188,  45.4062,  43.8125,  ...,  51.4375,  52.6875,  41.9062],\n",
      "          [ 43.7500,  56.3125,  49.5625,  ...,  68.5625,  69.5000,  54.2812],\n",
      "          [ 41.5625,  51.2500,  45.9062,  ...,  68.1875,  68.5625,  53.6875],\n",
      "          ...,\n",
      "          [ 44.4688,  60.0938,  59.8125,  ...,  59.1875,  60.7500,  49.4688],\n",
      "          [ 46.7188,  63.3750,  62.8125,  ...,  62.5938,  64.2500,  51.6250],\n",
      "          [ 41.3750,  55.1562,  54.8750,  ...,  54.8750,  55.8125,  44.3438]],\n",
      "\n",
      "         [[ 34.6875,  44.7500,  43.2188,  ...,  50.6250,  51.9062,  41.2812],\n",
      "          [ 43.0938,  55.4062,  48.7812,  ...,  67.5625,  68.4375,  53.4375],\n",
      "          [ 40.9375,  50.4688,  45.3438,  ...,  67.1875,  67.5625,  52.8438],\n",
      "          ...,\n",
      "          [ 43.8125,  59.2188,  59.0000,  ...,  58.3750,  59.9062,  48.7500],\n",
      "          [ 46.0312,  62.4688,  61.9375,  ...,  61.7188,  63.3438,  50.8750],\n",
      "          [ 40.7812,  54.4062,  54.1250,  ...,  54.1250,  55.0312,  43.7188]],\n",
      "\n",
      "         [[ 37.1250,  47.7500,  45.9062,  ...,  54.1562,  55.4688,  44.1562],\n",
      "          [ 46.2500,  59.5312,  52.4062,  ...,  72.5625,  73.5625,  57.4062],\n",
      "          [ 43.9375,  54.1875,  48.0312,  ...,  72.1250,  72.5625,  56.7500],\n",
      "          ...,\n",
      "          [ 46.9688,  63.5000,  63.2188,  ...,  62.5625,  64.1875,  52.2812],\n",
      "          [ 49.3750,  67.0000,  66.3750,  ...,  66.1250,  67.9375,  54.5625],\n",
      "          [ 43.7500,  58.3438,  58.0312,  ...,  58.0312,  59.0312,  46.8750]]],\n",
      "\n",
      "\n",
      "        [[[ 71.9375, 119.5625, 142.5000,  ...,  75.1250,  69.1250,  47.9062],\n",
      "          [ 97.0000, 168.8750, 210.1250,  ..., 100.3125,  85.1250,  55.0625],\n",
      "          [112.8125, 200.2500, 253.3750,  ..., 129.5000, 106.0625,  64.4375],\n",
      "          ...,\n",
      "          [ 46.1250,  62.8125,  63.0000,  ...,  63.0000,  63.9062,  51.4375],\n",
      "          [ 48.0312,  65.5625,  65.3125,  ...,  65.5625,  66.7500,  53.2188],\n",
      "          [ 42.1875,  56.5312,  56.4688,  ...,  56.7500,  57.4375,  45.3750]],\n",
      "\n",
      "         [[ 71.6875, 119.1250, 142.2500,  ...,  74.6875,  68.5625,  47.4375],\n",
      "          [ 96.4375, 168.0000, 209.5000,  ...,  99.5000,  84.1250,  54.2812],\n",
      "          [112.4375, 199.6250, 253.0000,  ..., 129.0000, 105.2500,  63.7812],\n",
      "          ...,\n",
      "          [ 45.4375,  61.9375,  62.1250,  ...,  62.1250,  63.0000,  50.6875],\n",
      "          [ 47.3438,  64.6250,  64.4375,  ...,  64.6875,  65.8125,  52.4375],\n",
      "          [ 41.5938,  55.7500,  55.7188,  ...,  55.9688,  56.6250,  44.7188]],\n",
      "\n",
      "         [[ 73.3750, 120.5000, 142.6250,  ...,  76.2500,  70.8750,  49.7812],\n",
      "          [ 99.1875, 170.3750, 210.2500,  ..., 101.6875,  88.0625,  57.9688],\n",
      "          [114.5625, 200.8750, 252.2500,  ..., 129.0000, 107.8125,  66.8125],\n",
      "          ...,\n",
      "          [ 48.7188,  66.3750,  66.5625,  ...,  66.5625,  67.5000,  54.3438],\n",
      "          [ 50.7812,  69.3125,  69.0625,  ...,  69.3125,  70.5625,  56.2500],\n",
      "          [ 44.5938,  59.7812,  59.7500,  ...,  60.0312,  60.7188,  47.9375]]],\n",
      "\n",
      "\n",
      "        [[[ 74.0625, 123.0625, 146.7500,  ..., 144.8750, 122.3125,  75.9375],\n",
      "          [100.6875, 175.1250, 217.8750,  ..., 214.7500, 173.3750, 102.9375],\n",
      "          [118.1250, 209.1250, 264.5000,  ..., 260.7500, 206.7500, 120.0000],\n",
      "          ...,\n",
      "          [ 46.5625,  63.5312,  63.6875,  ...,  62.9688,  63.7812,  51.3125],\n",
      "          [ 48.4062,  66.1875,  66.0000,  ...,  65.5000,  66.5625,  53.0625],\n",
      "          [ 42.4375,  56.9375,  56.9375,  ...,  56.6875,  57.2812,  45.2500]],\n",
      "\n",
      "         [[ 73.8125, 122.6250, 146.5000,  ..., 144.6250, 121.8750,  75.6250],\n",
      "          [100.1875, 174.3750, 217.2500,  ..., 214.1250, 172.5000, 102.2500],\n",
      "          [117.6875, 208.5000, 264.0000,  ..., 260.2500, 206.0000, 119.3750],\n",
      "          ...,\n",
      "          [ 45.8750,  62.6250,  62.8125,  ...,  62.0938,  62.8750,  50.5625],\n",
      "          [ 47.7188,  65.2500,  65.0625,  ...,  64.6250,  65.6875,  52.2812],\n",
      "          [ 41.8438,  56.1250,  56.1250,  ...,  55.9375,  56.4688,  44.5938]],\n",
      "\n",
      "         [[ 75.4375, 123.8750, 146.8750,  ..., 145.0000, 123.1875,  77.4375],\n",
      "          [102.7500, 176.5000, 217.8750,  ..., 214.8750, 174.8750, 105.1875],\n",
      "          [119.6875, 209.5000, 263.0000,  ..., 259.5000, 207.2500, 121.8125],\n",
      "          ...,\n",
      "          [ 49.2188,  67.1250,  67.3125,  ...,  66.5625,  67.3750,  54.2188],\n",
      "          [ 51.1875,  69.9375,  69.7500,  ...,  69.2500,  70.3750,  56.0625],\n",
      "          [ 44.8750,  60.2188,  60.2188,  ...,  59.9688,  60.5625,  47.8125]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 33.4375,  40.7500,  29.4844,  ...,  51.2812,  53.9062,  42.3125],\n",
      "          [ 33.5000,  34.8750,  17.9844,  ...,  69.6250,  71.4375,  55.7188],\n",
      "          [ 28.4219,  28.9844,  14.2344,  ...,  69.8125,  71.9375,  56.3438],\n",
      "          ...,\n",
      "          [ 46.8750,  64.1875,  64.1875,  ...,  63.4062,  65.4375,  52.6875],\n",
      "          [ 49.1250,  67.6250,  67.5625,  ...,  67.0000,  68.6250,  54.4062],\n",
      "          [ 42.8438,  57.9688,  58.1875,  ...,  58.0312,  58.5312,  45.9375]],\n",
      "\n",
      "         [[ 33.0625,  40.4062,  29.2969,  ...,  50.5625,  53.1875,  41.7500],\n",
      "          [ 33.0625,  34.4062,  17.7500,  ...,  68.7500,  70.5000,  54.9375],\n",
      "          [ 28.1094,  28.7969,  14.3438,  ...,  68.9375,  71.0000,  55.5625],\n",
      "          ...,\n",
      "          [ 46.2812,  63.4062,  63.4062,  ...,  62.6250,  64.6875,  52.0312],\n",
      "          [ 48.5000,  66.8125,  66.8125,  ...,  66.2500,  67.7500,  53.6875],\n",
      "          [ 42.3125,  57.2500,  57.5000,  ...,  57.3438,  57.8438,  45.3438]],\n",
      "\n",
      "         [[ 34.8750,  42.0938,  30.2344,  ...,  54.0000,  56.6562,  44.5312],\n",
      "          [ 35.3438,  36.7500,  18.6562,  ...,  73.5000,  75.4375,  58.7812],\n",
      "          [ 29.8281,  29.8281,  13.5469,  ...,  73.7500,  75.9375,  59.4375],\n",
      "          ...,\n",
      "          [ 49.4375,  67.6875,  67.6875,  ...,  66.8750,  69.0625,  55.5625],\n",
      "          [ 51.8438,  71.3750,  71.3125,  ...,  70.7500,  72.4375,  57.3750],\n",
      "          [ 45.2188,  61.1875,  61.4375,  ...,  61.2500,  61.8125,  48.4688]]],\n",
      "\n",
      "\n",
      "        [[[ 33.0938,  40.8438,  30.6875,  ...,  51.3125,  55.2500,  43.0312],\n",
      "          [ 33.2812,  35.0312,  19.3594,  ...,  69.0625,  71.3750,  55.6562],\n",
      "          [ 27.5781,  28.3125,  14.7500,  ...,  69.0000,  71.3750,  55.8438],\n",
      "          ...,\n",
      "          [ 46.7188,  63.9375,  63.9062,  ...,  61.4688,  63.8438,  51.6250],\n",
      "          [ 49.0000,  67.4375,  67.3750,  ...,  65.7500,  67.5625,  53.7188],\n",
      "          [ 42.7500,  57.8438,  58.0938,  ...,  57.3438,  58.0312,  45.5938]],\n",
      "\n",
      "         [[ 32.7188,  40.4688,  30.4844,  ...,  50.6250,  54.5312,  42.4375],\n",
      "          [ 32.8438,  34.5312,  19.1094,  ...,  68.1875,  70.4375,  54.9062],\n",
      "          [ 27.2812,  28.1094,  14.8594,  ...,  68.0625,  70.5000,  55.0938],\n",
      "          ...,\n",
      "          [ 46.1250,  63.1562,  63.1250,  ...,  60.7188,  63.0312,  50.9688],\n",
      "          [ 48.3750,  66.6250,  66.6250,  ...,  65.0000,  66.7500,  53.0312],\n",
      "          [ 42.2500,  57.1562,  57.4062,  ...,  56.6562,  57.3125,  45.0000]],\n",
      "\n",
      "         [[ 34.5625,  42.2188,  31.4688,  ...,  54.0000,  57.9375,  45.2188],\n",
      "          [ 35.0938,  36.9062,  20.0938,  ...,  72.9375,  75.3750,  58.7500],\n",
      "          [ 29.0000,  29.1719,  14.0703,  ...,  72.8125,  75.3750,  58.9375],\n",
      "          ...,\n",
      "          [ 49.2812,  67.4375,  67.3750,  ...,  64.8125,  67.3125,  54.4375],\n",
      "          [ 51.6875,  71.1250,  71.1250,  ...,  69.3750,  71.3125,  56.6875],\n",
      "          [ 45.1250,  61.0625,  61.3438,  ...,  60.5625,  61.2500,  48.0938]]],\n",
      "\n",
      "\n",
      "        [[[ 65.8125, 113.0000, 134.8750,  ..., 137.3750, 117.1250,  71.2500],\n",
      "          [ 87.9375, 158.2500, 198.8750,  ..., 204.3750, 166.0000,  97.1875],\n",
      "          [102.9375, 189.1250, 242.5000,  ..., 251.2500, 200.6250, 114.8750],\n",
      "          ...,\n",
      "          [ 49.9688,  69.0000,  69.0625,  ...,  69.2500,  70.1250,  55.6250],\n",
      "          [ 51.5625,  71.5000,  71.5000,  ...,  71.8750,  72.6250,  56.9688],\n",
      "          [ 44.3438,  60.3750,  60.7188,  ...,  61.0625,  61.1250,  47.5938]],\n",
      "\n",
      "         [[ 65.6250, 112.5625, 134.6250,  ..., 137.1250, 116.6875,  70.9375],\n",
      "          [ 87.4375, 157.5000, 198.2500,  ..., 203.7500, 165.2500,  96.5000],\n",
      "          [102.5625, 188.5000, 242.0000,  ..., 250.7500, 200.0000, 114.3125],\n",
      "          ...,\n",
      "          [ 49.3438,  68.1875,  68.2500,  ...,  68.4375,  69.3125,  54.9375],\n",
      "          [ 50.9062,  70.6250,  70.6250,  ...,  71.0000,  71.7500,  56.2500],\n",
      "          [ 43.7812,  59.6250,  60.0000,  ...,  60.3438,  60.3750,  46.9688]],\n",
      "\n",
      "         [[ 67.5000, 114.0625, 135.2500,  ..., 137.7500, 118.0625,  72.8750],\n",
      "          [ 90.3750, 160.1250, 199.3750,  ..., 204.6250, 167.6250,  99.5000],\n",
      "          [105.0000, 190.1250, 241.6250,  ..., 250.2500, 201.2500, 116.8125],\n",
      "          ...,\n",
      "          [ 52.7188,  72.8750,  72.8750,  ...,  73.0625,  74.0000,  58.6875],\n",
      "          [ 54.4375,  75.4375,  75.4375,  ...,  75.8750,  76.6875,  60.0938],\n",
      "          [ 46.7812,  63.7500,  64.1250,  ...,  64.5000,  64.5000,  50.2188]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 88.7500, 136.8750, 153.0000,  ..., 148.6250, 127.1250,  82.5625],\n",
      "          [117.2500, 188.3750, 219.2500,  ..., 215.1250, 174.1250, 107.5000],\n",
      "          [132.1250, 217.7500, 259.5000,  ..., 262.2500, 207.8750, 124.3750],\n",
      "          ...,\n",
      "          [ 52.2812,  71.6250,  71.3125,  ...,  73.3125,  74.7500,  59.2500],\n",
      "          [ 54.0625,  74.5000,  74.5625,  ...,  76.2500,  77.3125,  60.5000],\n",
      "          [ 46.4062,  62.7812,  63.3438,  ...,  64.4375,  64.6250,  50.3750]],\n",
      "\n",
      "         [[ 88.5625, 136.5000, 152.7500,  ..., 148.3750, 126.6875,  82.1875],\n",
      "          [116.6875, 187.6250, 218.6250,  ..., 214.3750, 173.3750, 106.7500],\n",
      "          [131.7500, 217.0000, 259.0000,  ..., 261.5000, 207.1250, 123.7500],\n",
      "          ...,\n",
      "          [ 51.7500,  70.8125,  70.5625,  ...,  72.5625,  73.9375,  58.6562],\n",
      "          [ 53.5000,  73.6250,  73.7500,  ...,  75.3750,  76.4375,  59.8750],\n",
      "          [ 45.9375,  62.1562,  62.7188,  ...,  63.8125,  63.9688,  49.8438]],\n",
      "\n",
      "         [[ 89.6875, 137.2500, 153.1250,  ..., 148.7500, 127.8750,  83.7500],\n",
      "          [118.7500, 189.3750, 219.5000,  ..., 215.3750, 175.6250, 109.4375],\n",
      "          [133.3750, 218.1250, 258.7500,  ..., 261.2500, 208.6250, 126.1250],\n",
      "          ...,\n",
      "          [ 55.0625,  75.4375,  75.1250,  ...,  77.2500,  78.7500,  62.4062],\n",
      "          [ 56.9375,  78.4375,  78.5625,  ...,  80.3125,  81.4375,  63.7188],\n",
      "          [ 48.8750,  66.1875,  66.7500,  ...,  67.9375,  68.1250,  53.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 46.6875,  59.5000,  53.3438,  ...,  78.5625,  81.6875,  61.6250],\n",
      "          [ 46.0000,  59.6250,  53.8750,  ...,  78.8750,  82.0625,  63.1562],\n",
      "          [ 43.6875,  54.7812,  45.1562,  ...,  75.0625,  76.3750,  59.7500],\n",
      "          ...,\n",
      "          [ 50.4062,  68.1875,  67.2500,  ...,  67.0625,  69.7500,  55.8125],\n",
      "          [ 52.5000,  71.5625,  70.8750,  ...,  70.6250,  72.9375,  57.5938],\n",
      "          [ 45.4062,  61.0000,  61.1562,  ...,  60.9688,  61.8438,  48.5312]],\n",
      "\n",
      "         [[ 46.4375,  59.1250,  53.0000,  ...,  78.0000,  81.0625,  61.3125],\n",
      "          [ 45.5000,  58.9375,  53.3125,  ...,  77.8125,  81.0000,  62.4688],\n",
      "          [ 43.2500,  54.1875,  44.6875,  ...,  74.1250,  75.4375,  59.0938],\n",
      "          ...,\n",
      "          [ 49.9062,  67.4375,  66.4375,  ...,  66.3125,  69.0000,  55.2188],\n",
      "          [ 51.9688,  70.7500,  70.1250,  ...,  69.8125,  72.0625,  56.9688],\n",
      "          [ 44.9688,  60.4062,  60.5625,  ...,  60.3750,  61.2188,  48.0312]],\n",
      "\n",
      "         [[ 48.2812,  61.4062,  55.2500,  ...,  80.4375,  83.4375,  63.2500],\n",
      "          [ 48.4375,  62.7812,  56.7500,  ...,  82.7500,  85.8750,  66.1875],\n",
      "          [ 46.0312,  57.6875,  47.5312,  ...,  79.0625,  80.5000,  62.9375],\n",
      "          ...,\n",
      "          [ 53.0938,  71.8125,  70.8125,  ...,  70.6250,  73.5000,  58.7812],\n",
      "          [ 55.2812,  75.4375,  74.6875,  ...,  74.3750,  76.8125,  60.6562],\n",
      "          [ 47.8438,  64.3125,  64.5000,  ...,  64.2500,  65.1875,  51.0938]]],\n",
      "\n",
      "\n",
      "        [[[ 43.6875,  51.5938,  38.8125,  ...,  49.7812,  62.2188,  50.2812],\n",
      "          [ 38.6250,  41.3438,  25.3438,  ...,  37.1875,  54.1875,  47.3125],\n",
      "          [ 32.1250,  29.8438,  10.1406,  ...,  26.2031,  45.8125,  42.7812],\n",
      "          ...,\n",
      "          [ 49.5312,  66.4375,  64.8125,  ...,  69.6875,  70.5625,  55.5625],\n",
      "          [ 51.2188,  69.2500,  67.7500,  ...,  68.3750,  70.6875,  55.8438],\n",
      "          [ 44.5625,  59.2812,  58.6562,  ...,  58.5312,  59.7812,  47.0000]],\n",
      "\n",
      "         [[ 43.5312,  51.3438,  38.6250,  ...,  49.5938,  61.9375,  50.0938],\n",
      "          [ 38.2500,  40.9062,  25.0625,  ...,  36.7812,  53.5625,  46.8750],\n",
      "          [ 31.7969,  29.5312,  10.0547,  ...,  26.0938,  45.4375,  42.4062],\n",
      "          ...,\n",
      "          [ 49.0000,  65.6250,  64.0625,  ...,  68.7500,  69.6875,  54.9688],\n",
      "          [ 50.6875,  68.3750,  67.0000,  ...,  67.5625,  69.8750,  55.2188],\n",
      "          [ 44.1250,  58.6562,  58.0625,  ...,  57.9375,  59.1562,  46.5000]],\n",
      "\n",
      "         [[ 44.9375,  52.8125,  39.7188,  ...,  50.7500,  63.5000,  51.5625],\n",
      "          [ 40.5938,  43.5000,  26.5938,  ...,  38.9062,  56.7188,  49.5312],\n",
      "          [ 33.7500,  31.3594,  10.4531,  ...,  27.0156,  47.8438,  44.6875],\n",
      "          ...,\n",
      "          [ 52.1562,  70.0000,  68.3125,  ...,  73.0000,  74.1875,  58.4688],\n",
      "          [ 53.9375,  72.9375,  71.3750,  ...,  72.0625,  74.5000,  58.8125],\n",
      "          [ 46.9375,  62.4688,  61.8125,  ...,  61.6875,  63.0000,  49.5000]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 43.1875,  56.9375,  54.1562,  ..., 149.6250, 128.2500,  81.5625],\n",
      "          [ 54.6562,  75.6875,  74.7500,  ..., 219.8750, 179.1250, 108.5625],\n",
      "          [ 58.1875,  81.1875,  80.2500,  ..., 266.0000, 210.7500, 123.8750],\n",
      "          ...,\n",
      "          [ 53.0312,  74.8750,  76.8750,  ...,  77.8125,  77.3750,  60.4375],\n",
      "          [ 54.4062,  76.8125,  78.5000,  ...,  79.6875,  79.3750,  61.3750],\n",
      "          [ 46.4062,  63.9375,  65.3750,  ...,  66.3125,  65.6875,  50.5938]],\n",
      "\n",
      "         [[ 42.8438,  56.4375,  53.6562,  ..., 149.3750, 128.0000,  81.3750],\n",
      "          [ 54.1875,  74.9375,  74.0625,  ..., 219.3750, 178.5000, 108.0625],\n",
      "          [ 57.7188,  80.4375,  79.5625,  ..., 265.5000, 210.2500, 123.3750],\n",
      "          ...,\n",
      "          [ 52.5938,  74.3125,  76.3125,  ...,  77.1875,  76.7500,  59.9375],\n",
      "          [ 53.9688,  76.1250,  77.9375,  ...,  79.0625,  78.7500,  60.8438],\n",
      "          [ 46.0312,  63.4375,  64.8750,  ...,  65.8125,  65.1875,  50.1562]],\n",
      "\n",
      "         [[ 45.1250,  59.5000,  56.7500,  ..., 149.8750, 129.0000,  82.8125],\n",
      "          [ 57.4688,  79.5000,  78.5625,  ..., 220.1250, 180.5000, 110.5000],\n",
      "          [ 61.1562,  85.3125,  84.3750,  ..., 265.0000, 211.5000, 125.5625],\n",
      "          ...,\n",
      "          [ 55.7188,  78.7500,  80.8125,  ...,  81.7500,  81.3750,  63.4688],\n",
      "          [ 57.1875,  80.6875,  82.5625,  ...,  83.7500,  83.4375,  64.5000],\n",
      "          [ 48.7500,  67.2500,  68.7500,  ...,  69.6875,  69.0625,  53.1562]]],\n",
      "\n",
      "\n",
      "        [[[ 39.6250,  51.3750,  50.5938,  ...,  42.0000,  47.6562,  40.1562],\n",
      "          [ 51.4062,  70.5625,  69.7500,  ...,  54.4688,  60.0625,  48.4375],\n",
      "          [ 51.8125,  71.1250,  70.3125,  ...,  49.1250,  57.0625,  46.8750],\n",
      "          ...,\n",
      "          [ 50.6562,  70.8125,  71.9375,  ...,  66.5000,  68.6875,  54.8125],\n",
      "          [ 52.6562,  73.8750,  75.1875,  ...,  70.4375,  72.0625,  56.5938],\n",
      "          [ 45.1875,  62.0000,  63.1562,  ...,  60.3438,  60.7812,  47.3750]],\n",
      "\n",
      "         [[ 39.2812,  50.9062,  50.1250,  ...,  41.6250,  47.2812,  39.8750],\n",
      "          [ 50.9375,  69.9375,  69.1250,  ...,  53.9688,  59.5312,  48.0000],\n",
      "          [ 51.3750,  70.5000,  69.6875,  ...,  48.7188,  56.5938,  46.4688],\n",
      "          ...,\n",
      "          [ 50.2500,  70.2500,  71.3750,  ...,  65.9375,  68.0625,  54.3438],\n",
      "          [ 52.2188,  73.2500,  74.6250,  ...,  69.8125,  71.4375,  56.0938],\n",
      "          [ 44.8438,  61.5000,  62.6562,  ...,  59.8750,  60.2812,  47.0000]],\n",
      "\n",
      "         [[ 41.5625,  53.9375,  53.0938,  ...,  44.0625,  49.9062,  42.0000],\n",
      "          [ 54.0000,  74.1875,  73.3125,  ...,  57.1875,  63.0938,  50.8750],\n",
      "          [ 54.4375,  74.7500,  73.8750,  ...,  51.5938,  59.9688,  49.2188],\n",
      "          ...,\n",
      "          [ 53.2188,  74.3750,  75.5625,  ...,  69.8750,  72.1875,  57.5625],\n",
      "          [ 55.3125,  77.6250,  79.0625,  ...,  74.0000,  75.6875,  59.4688],\n",
      "          [ 47.5000,  65.1875,  66.4375,  ...,  63.4375,  63.8750,  49.7812]]],\n",
      "\n",
      "\n",
      "        [[[ 43.0938,  60.2188,  64.6250,  ..., 158.3750, 135.8750,  86.0000],\n",
      "          [ 53.9375,  75.8125,  77.8750,  ..., 234.1250, 192.6250, 116.8125],\n",
      "          [ 55.7188,  78.8125,  81.5000,  ..., 280.2500, 227.3750, 135.1250],\n",
      "          ...,\n",
      "          [ 52.0000,  73.1875,  75.0000,  ...,  75.1875,  75.5000,  59.2500],\n",
      "          [ 53.7500,  75.7500,  77.5000,  ...,  77.6250,  77.7500,  60.2500],\n",
      "          [ 45.9375,  63.2188,  64.6250,  ...,  64.8125,  64.3750,  49.6875]],\n",
      "\n",
      "         [[ 42.7812,  59.7500,  64.1875,  ..., 158.2500, 135.6250,  85.7500],\n",
      "          [ 53.4688,  75.1250,  77.1875,  ..., 233.6250, 192.0000, 116.3125],\n",
      "          [ 55.2500,  78.1250,  80.8125,  ..., 279.7500, 226.8750, 134.7500],\n",
      "          ...,\n",
      "          [ 51.5625,  72.6250,  74.4375,  ...,  74.5625,  74.8750,  58.7500],\n",
      "          [ 53.3125,  75.1250,  76.8750,  ...,  77.0000,  77.0625,  59.7188],\n",
      "          [ 45.5938,  62.7188,  64.1250,  ...,  64.3125,  63.8438,  49.2812]],\n",
      "\n",
      "         [[ 45.0625,  62.7188,  67.0625,  ..., 158.3750, 136.5000,  87.0625],\n",
      "          [ 56.6875,  79.6875,  81.8750,  ..., 234.0000, 193.6250, 118.5000],\n",
      "          [ 58.5625,  82.8125,  85.6875,  ..., 278.7500, 227.6250, 136.5000],\n",
      "          ...,\n",
      "          [ 54.6250,  76.9375,  78.8750,  ...,  79.0000,  79.3750,  62.2500],\n",
      "          [ 56.4688,  79.5625,  81.4375,  ...,  81.5625,  81.6875,  63.3125],\n",
      "          [ 48.2812,  66.5000,  67.9375,  ...,  68.1250,  67.6875,  52.1875]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 55.8438,  88.9375, 104.5625,  ...,  53.2500,  57.5312,  47.5312],\n",
      "          [ 62.8750, 110.0000, 141.0000,  ...,  72.0625,  74.7500,  58.8750],\n",
      "          [ 68.7500, 126.8750, 169.2500,  ...,  71.6250,  74.7500,  59.2500],\n",
      "          ...,\n",
      "          [ 50.5625,  69.3750,  69.2500,  ...,  66.5000,  69.1250,  55.8438],\n",
      "          [ 52.9688,  73.2500,  73.5625,  ...,  70.5000,  72.7500,  57.9375],\n",
      "          [ 46.0625,  62.4062,  62.9375,  ...,  61.0625,  61.9062,  48.8125]],\n",
      "\n",
      "         [[ 55.6250,  88.5625, 104.2500,  ...,  52.8125,  57.0625,  47.1562],\n",
      "          [ 62.4375, 109.2500, 140.5000,  ...,  71.5000,  74.1875,  58.4062],\n",
      "          [ 68.4375, 126.2500, 168.7500,  ...,  71.0625,  74.1875,  58.7812],\n",
      "          ...,\n",
      "          [ 50.1875,  68.8750,  68.8125,  ...,  66.0625,  68.6250,  55.4375],\n",
      "          [ 52.5938,  72.7500,  73.0625,  ...,  70.0000,  72.2500,  57.4688],\n",
      "          [ 45.7500,  61.9688,  62.5312,  ...,  60.6562,  61.4688,  48.4375]],\n",
      "\n",
      "         [[ 57.6562,  90.8125, 106.0000,  ...,  55.7812,  60.1250,  49.5625],\n",
      "          [ 65.8125, 113.1875, 143.3750,  ...,  75.5625,  78.3750,  61.7188],\n",
      "          [ 71.6875, 129.7500, 170.8750,  ...,  75.0625,  78.3750,  62.0938],\n",
      "          ...,\n",
      "          [ 52.9688,  72.6875,  72.6250,  ...,  69.6875,  72.4375,  58.5312],\n",
      "          [ 55.5312,  76.8125,  77.1250,  ...,  73.8750,  76.3125,  60.7188],\n",
      "          [ 48.2812,  65.4375,  66.0000,  ...,  64.0000,  64.9375,  51.1562]]],\n",
      "\n",
      "\n",
      "        [[[ 39.5000,  52.2188,  51.7812,  ..., 106.6875,  95.1250,  61.9375],\n",
      "          [ 52.0938,  70.8125,  70.0625,  ..., 151.2500, 126.1250,  76.3750],\n",
      "          [ 52.0938,  70.5000,  69.3750,  ..., 190.7500, 155.5000,  91.1250],\n",
      "          ...,\n",
      "          [ 48.8125,  65.6250,  64.0625,  ...,  65.7500,  68.9375,  55.7812],\n",
      "          [ 51.1562,  69.2500,  67.7500,  ...,  69.1250,  72.1250,  57.6250],\n",
      "          [ 44.6562,  59.7188,  59.2188,  ...,  60.1562,  61.4062,  48.5625]],\n",
      "\n",
      "         [[ 39.1875,  51.8125,  51.3750,  ..., 106.5625,  94.8750,  61.7812],\n",
      "          [ 51.6875,  70.3125,  69.5000,  ..., 151.0000, 125.6250,  76.0000],\n",
      "          [ 51.7188,  70.0000,  68.9375,  ..., 190.8750, 155.2500,  90.8750],\n",
      "          ...,\n",
      "          [ 48.4688,  65.1250,  63.5938,  ...,  65.3125,  68.4375,  55.3438],\n",
      "          [ 50.7812,  68.7500,  67.2500,  ...,  68.6250,  71.6250,  57.1875],\n",
      "          [ 44.3438,  59.2812,  58.8125,  ...,  59.7500,  60.9688,  48.1875]],\n",
      "\n",
      "         [[ 41.3750,  54.7188,  54.2500,  ..., 107.1250,  96.1875,  63.4062],\n",
      "          [ 54.5938,  74.2500,  73.4375,  ..., 151.3750, 127.7500,  78.5000],\n",
      "          [ 54.6250,  73.9375,  72.7500,  ..., 189.2500, 156.0000,  92.7500],\n",
      "          ...,\n",
      "          [ 51.1562,  68.7500,  67.1875,  ...,  68.9375,  72.3125,  58.4688],\n",
      "          [ 53.6250,  72.5625,  71.0000,  ...,  72.5000,  75.6250,  60.4062],\n",
      "          [ 46.8438,  62.6250,  62.0938,  ...,  63.0938,  64.3750,  50.9062]]],\n",
      "\n",
      "\n",
      "        [[[ 38.4375,  50.1875,  49.0938,  ..., 128.3750, 110.0000,  71.0625],\n",
      "          [ 50.2188,  67.5000,  65.7500,  ..., 182.8750, 146.2500,  88.6250],\n",
      "          [ 49.8438,  66.6250,  64.3750,  ..., 224.7500, 174.8750, 101.8750],\n",
      "          ...,\n",
      "          [ 49.4062,  66.9375,  65.9375,  ...,  64.1875,  67.6250,  54.9062],\n",
      "          [ 51.8750,  71.0625,  70.5000,  ...,  68.0625,  71.1875,  57.0312],\n",
      "          [ 45.2188,  60.9062,  61.0000,  ...,  59.5000,  60.8438,  48.2188]],\n",
      "\n",
      "         [[ 38.1250,  49.7812,  48.7188,  ..., 128.1250, 109.6875,  70.8125],\n",
      "          [ 49.8438,  67.0000,  65.3125,  ..., 182.2500, 145.6250,  88.0625],\n",
      "          [ 49.4688,  66.1875,  63.9688,  ..., 224.2500, 174.2500, 101.4375],\n",
      "          ...,\n",
      "          [ 49.0312,  66.5000,  65.5000,  ...,  63.7188,  67.1250,  54.5000],\n",
      "          [ 51.5000,  70.5625,  70.0625,  ...,  67.5625,  70.6875,  56.5938],\n",
      "          [ 44.9062,  60.4688,  60.5938,  ...,  59.0938,  60.4062,  47.8438]],\n",
      "\n",
      "         [[ 40.2500,  52.5625,  51.4375,  ..., 129.1250, 111.3125,  72.6250],\n",
      "          [ 52.6250,  70.8125,  68.9375,  ..., 184.0000, 148.5000,  91.0625],\n",
      "          [ 52.2188,  69.8750,  67.5000,  ..., 224.7500, 176.3750, 104.0625],\n",
      "          ...,\n",
      "          [ 51.7812,  70.1875,  69.0625,  ...,  67.3125,  70.8750,  57.5625],\n",
      "          [ 54.3750,  74.5000,  73.9375,  ...,  71.3125,  74.6250,  59.7500],\n",
      "          [ 47.4062,  63.8750,  63.9688,  ...,  62.4062,  63.8125,  50.5312]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 38.6562,  50.1562,  48.7500,  ...,  58.1562,  58.3750,  49.5000],\n",
      "          [ 49.9375,  67.0625,  65.3125,  ...,  73.0000,  73.7500,  58.2500],\n",
      "          [ 49.5312,  66.6250,  65.3125,  ...,  72.8125,  73.1250,  57.9688],\n",
      "          ...,\n",
      "          [ 49.7500,  67.2500,  69.6875,  ...,  62.5312,  65.6250,  54.2500],\n",
      "          [ 50.9375,  68.8125,  68.5625,  ...,  66.8125,  69.6250,  56.5312],\n",
      "          [ 44.3125,  58.5625,  58.3438,  ...,  58.6875,  60.0312,  48.1250]],\n",
      "\n",
      "         [[ 38.4375,  49.8750,  48.4688,  ...,  57.8125,  58.0312,  49.2500],\n",
      "          [ 49.6562,  66.6250,  64.9375,  ...,  72.5625,  73.3125,  57.9062],\n",
      "          [ 49.2812,  66.3125,  65.0000,  ...,  72.3750,  72.7500,  57.6250],\n",
      "          ...,\n",
      "          [ 49.4688,  66.8125,  69.2500,  ...,  62.1875,  65.2500,  53.9688],\n",
      "          [ 50.6562,  68.3750,  68.1250,  ...,  66.4375,  69.2500,  56.2188],\n",
      "          [ 44.0938,  58.2500,  58.0000,  ...,  58.4062,  59.7188,  47.8438]],\n",
      "\n",
      "         [[ 40.3750,  52.4375,  50.9375,  ...,  60.4688,  60.7500,  51.4062],\n",
      "          [ 52.2188,  70.1250,  68.3125,  ...,  76.3750,  77.1875,  60.9062],\n",
      "          [ 51.7812,  69.6875,  68.3125,  ...,  76.1875,  76.5000,  60.5938],\n",
      "          ...,\n",
      "          [ 52.0312,  70.3125,  72.8125,  ...,  65.3750,  68.6250,  56.7188],\n",
      "          [ 53.2812,  72.0000,  71.7500,  ...,  69.8750,  72.8125,  59.0938],\n",
      "          [ 46.3438,  61.2812,  61.0312,  ...,  61.4062,  62.7812,  50.3125]]],\n",
      "\n",
      "\n",
      "        [[[ 39.0625,  50.7188,  49.5000,  ...,  49.2500,  53.0312,  47.8125],\n",
      "          [ 50.2500,  67.4375,  65.8125,  ...,  64.1875,  68.0625,  55.5625],\n",
      "          [ 49.6875,  66.6250,  64.9375,  ...,  61.4062,  66.0000,  54.7188],\n",
      "          ...,\n",
      "          [ 48.7500,  65.5625,  64.6250,  ...,  64.8125,  67.1250,  55.0938],\n",
      "          [ 51.2188,  69.4375,  68.4375,  ...,  69.0625,  71.0000,  57.2500],\n",
      "          [ 45.0312,  60.0000,  59.5938,  ...,  60.0000,  60.8750,  48.5938]],\n",
      "\n",
      "         [[ 38.8438,  50.4375,  49.2188,  ...,  48.9688,  52.7188,  47.5938],\n",
      "          [ 49.9688,  67.0625,  65.4375,  ...,  63.7812,  67.6875,  55.2500],\n",
      "          [ 49.4375,  66.2500,  64.6250,  ...,  61.0938,  65.6250,  54.4062],\n",
      "          ...,\n",
      "          [ 48.5000,  65.1875,  64.2500,  ...,  64.5000,  66.8125,  54.7812],\n",
      "          [ 50.9375,  69.0625,  68.0625,  ...,  68.6875,  70.6250,  56.9375],\n",
      "          [ 44.8125,  59.6875,  59.3125,  ...,  59.6875,  60.5625,  48.3438]],\n",
      "\n",
      "         [[ 40.8125,  53.0312,  51.7188,  ...,  51.4688,  55.3750,  49.6562],\n",
      "          [ 52.5312,  70.5625,  68.8125,  ...,  67.1250,  71.1875,  58.0938],\n",
      "          [ 51.9688,  69.6875,  67.9375,  ...,  64.2500,  69.0625,  57.1875],\n",
      "          ...,\n",
      "          [ 50.9688,  68.5625,  67.5625,  ...,  67.8125,  70.2500,  57.5938],\n",
      "          [ 53.5625,  72.6250,  71.5625,  ...,  72.2500,  74.2500,  59.8750],\n",
      "          [ 47.0938,  62.7500,  62.3438,  ...,  62.7500,  63.6875,  50.8125]]],\n",
      "\n",
      "\n",
      "        [[[ 32.1875,  31.7344,  21.2969,  ..., 160.6250, 138.8750,  92.8125],\n",
      "          [ 31.8594,  32.6562,  13.5781,  ..., 227.0000, 187.5000, 118.9375],\n",
      "          [ 24.4062,  19.5469,   4.2930,  ..., 270.2500, 219.6250, 135.8750],\n",
      "          ...,\n",
      "          [ 49.4062,  67.5000,  67.1875,  ...,  64.7500,  66.8125,  54.8438],\n",
      "          [ 52.0000,  71.3750,  71.2500,  ...,  69.1250,  70.8125,  57.1562],\n",
      "          [ 45.5625,  61.1875,  61.3438,  ...,  60.0312,  60.8125,  48.5938]],\n",
      "\n",
      "         [[ 32.0312,  31.5625,  21.1875,  ..., 160.3750, 138.5000,  92.6250],\n",
      "          [ 31.6719,  32.4688,  13.5234,  ..., 226.3750, 186.8750, 118.5625],\n",
      "          [ 24.2812,  19.4531,   4.3594,  ..., 269.5000, 219.0000, 135.3750],\n",
      "          ...,\n",
      "          [ 49.1875,  67.1250,  66.8750,  ...,  64.3750,  66.4375,  54.5625],\n",
      "          [ 51.7500,  71.0000,  70.8750,  ...,  68.8125,  70.4375,  56.8438],\n",
      "          [ 45.3438,  60.8750,  61.0625,  ...,  59.7500,  60.5312,  48.3125]],\n",
      "\n",
      "         [[ 33.4375,  33.0938,  22.0781,  ..., 160.7500, 139.5000,  93.7500],\n",
      "          [ 33.2500,  34.0625,  14.0625,  ..., 227.1250, 188.7500, 120.5000],\n",
      "          [ 25.4531,  20.3281,   4.1172,  ..., 269.2500, 220.1250, 137.1250],\n",
      "          ...,\n",
      "          [ 51.6562,  70.5625,  70.3125,  ...,  67.6875,  69.8750,  57.3438],\n",
      "          [ 54.3750,  74.6250,  74.5000,  ...,  72.3125,  74.1250,  59.7500],\n",
      "          [ 47.6562,  64.0000,  64.1875,  ...,  62.8125,  63.6250,  50.7812]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[36.7188, 47.5938, 45.8750,  ..., 41.0000, 44.7812, 38.1875],\n",
      "          [46.7812, 62.4688, 60.2500,  ..., 53.4375, 58.3750, 48.8438],\n",
      "          [45.3750, 60.5312, 58.5938,  ..., 51.3750, 56.3438, 47.5625],\n",
      "          ...,\n",
      "          [44.8750, 60.0938, 59.3438,  ..., 58.0625, 60.8750, 51.1562],\n",
      "          [47.6250, 64.1875, 62.4375,  ..., 62.4375, 65.0625, 53.6562],\n",
      "          [42.5625, 56.4688, 55.5625,  ..., 55.6875, 57.1562, 46.2500]],\n",
      "\n",
      "         [[36.5625, 47.3750, 45.6875,  ..., 40.8438, 44.6250, 38.0312],\n",
      "          [46.5938, 62.2188, 60.0000,  ..., 53.2188, 58.1250, 48.6250],\n",
      "          [45.2188, 60.3125, 58.3750,  ..., 51.2188, 56.1562, 47.3750],\n",
      "          ...,\n",
      "          [44.7188, 59.8438, 59.0938,  ..., 57.8438, 60.6250, 50.9375],\n",
      "          [47.4375, 63.9062, 62.2188,  ..., 62.2188, 64.8125, 53.4375],\n",
      "          [42.4062, 56.2812, 55.3750,  ..., 55.5000, 56.9375, 46.0625]],\n",
      "\n",
      "         [[38.2500, 49.5938, 47.8125,  ..., 42.7188, 46.6875, 39.7812],\n",
      "          [48.7812, 65.1875, 62.8125,  ..., 55.6875, 60.8750, 50.9062],\n",
      "          [47.3125, 63.1250, 61.0938,  ..., 53.5625, 58.7812, 49.5938],\n",
      "          ...,\n",
      "          [46.7812, 62.6250, 61.8750,  ..., 60.5312, 63.4688, 53.3125],\n",
      "          [49.6562, 66.8750, 65.1250,  ..., 65.1250, 67.8750, 55.9688],\n",
      "          [44.3750, 58.9375, 57.9688,  ..., 58.0938, 59.6250, 48.2188]]],\n",
      "\n",
      "\n",
      "        [[[36.1875, 46.7500, 45.0625,  ..., 50.0625, 54.1875, 49.2812],\n",
      "          [46.2500, 61.5625, 59.2188,  ..., 64.4375, 68.1875, 55.5938],\n",
      "          [45.2188, 60.1875, 57.9062,  ..., 60.4375, 64.5625, 53.6250],\n",
      "          ...,\n",
      "          [44.3438, 59.1875, 58.9375,  ..., 57.2188, 60.1875, 50.7188],\n",
      "          [46.9062, 62.7500, 61.1875,  ..., 61.8125, 64.5625, 53.3438],\n",
      "          [42.0312, 55.5625, 54.5625,  ..., 55.2500, 56.7812, 46.0625]],\n",
      "\n",
      "         [[36.0312, 46.5312, 44.8750,  ..., 49.8125, 53.9375, 49.0938],\n",
      "          [46.0625, 61.3125, 59.0000,  ..., 64.1250, 67.8750, 55.3438],\n",
      "          [45.0625, 59.9375, 57.7188,  ..., 60.1875, 64.2500, 53.3750],\n",
      "          ...,\n",
      "          [44.1875, 58.9375, 58.6875,  ..., 57.0000, 59.9688, 50.5312],\n",
      "          [46.7500, 62.5000, 60.9375,  ..., 61.5938, 64.3125, 53.1250],\n",
      "          [41.9062, 55.3438, 54.3438,  ..., 55.0625, 56.5938, 45.8750]],\n",
      "\n",
      "         [[37.6875, 48.7188, 46.9375,  ..., 52.1562, 56.3750, 50.9688],\n",
      "          [48.2188, 64.2500, 61.7500,  ..., 67.2500, 71.1250, 58.0000],\n",
      "          [47.1250, 62.7500, 60.4062,  ..., 63.0312, 67.3125, 55.9062],\n",
      "          ...,\n",
      "          [46.2500, 61.7188, 61.4688,  ..., 59.6562, 62.7500, 52.8750],\n",
      "          [48.9062, 65.4375, 63.8125,  ..., 64.5000, 67.3125, 55.6250],\n",
      "          [43.8438, 57.9688, 56.9062,  ..., 57.6250, 59.2500, 48.0000]]],\n",
      "\n",
      "\n",
      "        [[[37.3750, 48.5938, 47.0312,  ..., 48.5625, 51.1250, 46.0000],\n",
      "          [47.4688, 63.5625, 61.5312,  ..., 62.6875, 66.3750, 54.5000],\n",
      "          [45.7812, 61.1250, 59.3438,  ..., 58.9375, 63.1875, 52.9062],\n",
      "          ...,\n",
      "          [44.4062, 59.2188, 58.8125,  ..., 57.1250, 60.1562, 50.7188],\n",
      "          [47.0000, 62.8438, 61.1875,  ..., 61.6875, 64.5000, 53.3125],\n",
      "          [42.0938, 55.6562, 54.6250,  ..., 55.1562, 56.7500, 46.0312]],\n",
      "\n",
      "         [[37.1875, 48.3750, 46.8125,  ..., 48.3438, 50.9062, 45.8125],\n",
      "          [47.2500, 63.2812, 61.2812,  ..., 62.4062, 66.0625, 54.2500],\n",
      "          [45.5938, 60.8750, 59.1250,  ..., 58.7188, 62.9375, 52.6875],\n",
      "          ...,\n",
      "          [44.2500, 58.9688, 58.5625,  ..., 56.9375, 59.9375, 50.5000],\n",
      "          [46.8125, 62.5938, 60.9375,  ..., 61.5000, 64.2500, 53.0938],\n",
      "          [41.9688, 55.4375, 54.4062,  ..., 54.9688, 56.5312, 45.8438]],\n",
      "\n",
      "         [[38.9062, 50.6562, 49.0000,  ..., 50.6250, 53.3125, 47.7500],\n",
      "          [49.4688, 66.3125, 64.1875,  ..., 65.3750, 69.2500, 56.8125],\n",
      "          [47.7188, 63.7188, 61.8750,  ..., 61.4688, 65.9375, 55.1562],\n",
      "          ...,\n",
      "          [46.2812, 61.7188, 61.3438,  ..., 59.5625, 62.7188, 52.8438],\n",
      "          [49.0000, 65.5625, 63.8125,  ..., 64.3750, 67.2500, 55.5938],\n",
      "          [43.9062, 58.0625, 56.9688,  ..., 57.5312, 59.1875, 47.9688]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 34.4375,  45.3125,  42.0000,  ...,  44.5625,  46.9062,  38.7500],\n",
      "          [ 44.5938,  59.8125,  54.6875,  ...,  58.3438,  61.3125,  49.9688],\n",
      "          [ 42.7812,  56.7188,  50.9062,  ...,  54.0625,  57.0625,  47.3750],\n",
      "          ...,\n",
      "          [ 73.5625, 118.4375, 148.6250,  ..., 102.6875,  75.3125,  54.8750],\n",
      "          [ 66.8750, 109.1875, 141.2500,  ...,  81.1250,  71.3750,  54.5938],\n",
      "          [ 47.7812,  72.4375,  93.5625,  ...,  58.6562,  58.0312,  44.5938]],\n",
      "\n",
      "         [[ 34.3125,  45.1250,  41.8438,  ...,  44.3750,  46.7188,  38.5938],\n",
      "          [ 44.4062,  59.5938,  54.5000,  ...,  58.1250,  61.0938,  49.7812],\n",
      "          [ 42.6250,  56.5312,  50.7188,  ...,  53.8438,  56.8438,  47.1875],\n",
      "          ...,\n",
      "          [ 73.5000, 118.1250, 148.2500,  ..., 102.3750,  75.0625,  54.6562],\n",
      "          [ 66.8750, 108.9375, 141.0000,  ...,  80.9375,  71.1250,  54.3750],\n",
      "          [ 47.6875,  72.2500,  93.3125,  ...,  58.4375,  57.8125,  44.4375]],\n",
      "\n",
      "         [[ 35.7812,  47.0938,  43.6250,  ...,  46.3125,  48.7500,  40.2500],\n",
      "          [ 46.3438,  62.2188,  56.8438,  ...,  60.6875,  63.7812,  51.9688],\n",
      "          [ 44.4688,  59.0000,  52.9062,  ...,  56.1875,  59.3125,  49.2500],\n",
      "          ...,\n",
      "          [ 75.5000, 120.7500, 150.3750,  ..., 105.0625,  78.3125,  57.1250],\n",
      "          [ 69.0000, 111.7500, 143.2500,  ...,  84.0625,  74.3125,  56.7812],\n",
      "          [ 49.7188,  74.9375,  95.6250,  ...,  61.0938,  60.4062,  46.4062]]],\n",
      "\n",
      "\n",
      "        [[[ 54.8438,  94.3125, 122.1250,  ..., 127.3750, 103.3750,  66.2500],\n",
      "          [ 61.4062, 119.4375, 170.0000,  ..., 176.3750, 132.3750,  78.3125],\n",
      "          [ 71.5625, 144.1250, 209.6250,  ..., 214.1250, 158.1250,  90.3125],\n",
      "          ...,\n",
      "          [ 37.6250,  51.1562,  52.4062,  ...,  48.1250,  51.7188,  44.3125],\n",
      "          [ 40.3125,  54.4062,  53.5000,  ...,  52.9062,  56.4375,  47.1562],\n",
      "          [ 36.7188,  49.2188,  48.3125,  ...,  48.5625,  50.5625,  40.9375]],\n",
      "\n",
      "         [[ 54.7812,  94.1250, 121.9375,  ..., 127.1875, 103.1875,  66.1875],\n",
      "          [ 61.1875, 119.0000, 169.5000,  ..., 175.7500, 131.8750,  78.0625],\n",
      "          [ 71.4375, 143.6250, 209.2500,  ..., 213.6250, 157.6250,  90.0000],\n",
      "          ...,\n",
      "          [ 37.5000,  50.9688,  52.2500,  ...,  48.0000,  51.5625,  44.1562],\n",
      "          [ 40.1562,  54.2188,  53.3438,  ...,  52.7812,  56.2500,  47.0000],\n",
      "          [ 36.6250,  49.0625,  48.1875,  ...,  48.4375,  50.4062,  40.7812]],\n",
      "\n",
      "         [[ 56.1250,  95.5625, 122.8750,  ..., 128.1250, 104.6250,  67.5625],\n",
      "          [ 63.4375, 121.5625, 171.1250,  ..., 177.5000, 134.5000,  80.4375],\n",
      "          [ 73.3125, 145.6250, 210.0000,  ..., 214.5000, 159.6250,  92.0625],\n",
      "          ...,\n",
      "          [ 39.0938,  53.1562,  54.5000,  ...,  50.0000,  53.7500,  46.0312],\n",
      "          [ 41.8750,  56.5625,  55.6562,  ...,  55.0000,  58.6875,  49.0000],\n",
      "          [ 38.1875,  51.1875,  50.2500,  ...,  50.5000,  52.5625,  42.5312]]],\n",
      "\n",
      "\n",
      "        [[[ 33.5000,  46.0938,  47.0000,  ..., 139.1250, 113.8750,  72.5625],\n",
      "          [ 42.5625,  60.4375,  62.1250,  ..., 197.3750, 151.8750,  90.3125],\n",
      "          [ 40.2188,  57.2500,  59.5312,  ..., 242.2500, 184.5000, 106.6875],\n",
      "          ...,\n",
      "          [ 71.0625, 115.5625, 147.1250,  ...,  51.1875,  52.4062,  44.3438],\n",
      "          [ 64.0625, 105.0625, 137.6250,  ...,  54.7812,  56.6250,  47.1250],\n",
      "          [ 46.5312,  69.3750,  90.3750,  ...,  49.5625,  50.7500,  41.0625]],\n",
      "\n",
      "         [[ 33.3438,  45.9062,  46.8125,  ..., 138.8750, 113.7500,  72.5000],\n",
      "          [ 42.4062,  60.1875,  61.9062,  ..., 196.7500, 151.2500,  90.0000],\n",
      "          [ 40.0625,  57.0312,  59.3438,  ..., 241.6250, 183.8750, 106.3750],\n",
      "          ...,\n",
      "          [ 71.0000, 115.2500, 146.7500,  ...,  51.0938,  52.2812,  44.2188],\n",
      "          [ 64.0000, 104.8125, 137.3750,  ...,  54.6875,  56.5000,  46.9688],\n",
      "          [ 46.4062,  69.1875,  90.1250,  ...,  49.4375,  50.6250,  40.9062]],\n",
      "\n",
      "         [[ 34.7812,  47.9062,  48.8438,  ..., 139.7500, 114.9375,  73.7500],\n",
      "          [ 44.2500,  62.8438,  64.6250,  ..., 198.2500, 153.6250,  92.1875],\n",
      "          [ 41.7812,  59.5000,  61.9375,  ..., 242.1250, 185.5000, 108.1875],\n",
      "          ...,\n",
      "          [ 73.0625, 117.9375, 148.8750,  ...,  53.2188,  54.4688,  46.0625],\n",
      "          [ 66.2500, 107.7500, 139.7500,  ...,  56.9688,  58.8750,  48.9688],\n",
      "          [ 48.4688,  72.0000,  92.5625,  ...,  51.5312,  52.7812,  42.6562]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 36.1250,  64.4375,  92.7500,  ...,  98.6250,  80.2500,  50.2188],\n",
      "          [ 48.2812,  76.9375, 128.2500,  ..., 136.1250,  97.2500,  60.5938],\n",
      "          [ 47.1562,  90.5625, 167.5000,  ..., 176.3750, 122.5625,  63.2188],\n",
      "          ...,\n",
      "          [152.8750, 222.2500, 220.0000,  ..., 217.8750, 215.2500, 149.1250],\n",
      "          [155.6250, 226.7500, 225.2500,  ..., 214.3750, 206.5000, 141.3750],\n",
      "          [102.1250, 148.3750, 147.8750,  ..., 137.1250, 129.8750,  88.9375]],\n",
      "\n",
      "         [[ 36.0312,  64.3125,  92.6250,  ...,  98.5000,  80.1250,  50.1562],\n",
      "          [ 48.1875,  76.6250, 127.9375,  ..., 135.7500,  96.8750,  60.4688],\n",
      "          [ 47.0625,  90.1875, 167.0000,  ..., 176.0000, 122.2500,  63.0625],\n",
      "          ...,\n",
      "          [152.7500, 222.0000, 219.7500,  ..., 217.6250, 215.0000, 149.0000],\n",
      "          [155.6250, 226.6250, 225.0000,  ..., 214.1250, 206.2500, 141.2500],\n",
      "          [102.0000, 148.1250, 147.6250,  ..., 136.7500, 129.5000,  88.8125]],\n",
      "\n",
      "         [[ 37.4375,  66.3125,  94.1250,  ..., 100.0625,  82.0625,  51.7812],\n",
      "          [ 50.0938,  79.8750, 130.3750,  ..., 138.5000, 100.3125,  62.9375],\n",
      "          [ 48.9375,  93.0000, 168.6250,  ..., 178.0000, 125.1250,  65.6250],\n",
      "          ...,\n",
      "          [153.8750, 223.5000, 221.2500,  ..., 219.3750, 216.7500, 150.3750],\n",
      "          [156.6250, 227.8750, 226.3750,  ..., 215.7500, 208.1250, 142.7500],\n",
      "          [103.3125, 149.8750, 149.3750,  ..., 138.8750, 131.7500,  90.5000]]],\n",
      "\n",
      "\n",
      "        [[[ 35.9688,  63.8750,  92.1250,  ..., 131.0000, 101.9375,  59.8125],\n",
      "          [ 48.1250,  76.5625, 127.1875,  ..., 195.0000, 137.3750,  72.3750],\n",
      "          [ 46.9688,  89.2500, 166.1250,  ..., 254.6250, 177.0000,  89.8750],\n",
      "          ...,\n",
      "          [ 28.7031,  40.2812,  39.1875,  ..., 214.3750, 212.2500, 147.3750],\n",
      "          [ 32.7812,  45.6250,  43.7812,  ..., 212.0000, 204.6250, 140.2500],\n",
      "          [ 31.7344,  43.5312,  42.3125,  ..., 136.0000, 129.0000,  88.5000]],\n",
      "\n",
      "         [[ 35.8750,  63.7500,  91.9375,  ..., 130.8750, 101.8125,  59.7812],\n",
      "          [ 48.0312,  76.3125, 126.7500,  ..., 194.5000, 137.0000,  72.1250],\n",
      "          [ 46.9062,  88.8750, 165.6250,  ..., 254.1250, 176.6250,  89.6875],\n",
      "          ...,\n",
      "          [ 28.6562,  40.2500,  39.1562,  ..., 214.1250, 212.0000, 147.2500],\n",
      "          [ 32.7500,  45.5938,  43.7812,  ..., 211.7500, 204.3750, 140.1250],\n",
      "          [ 31.7031,  43.5000,  42.2812,  ..., 135.6250, 128.7500,  88.3125]],\n",
      "\n",
      "         [[ 37.2812,  65.6875,  93.4375,  ..., 132.1250, 103.4375,  61.2812],\n",
      "          [ 49.9375,  79.5000, 129.2500,  ..., 196.6250, 139.8750,  74.7500],\n",
      "          [ 48.7500,  91.6875, 167.2500,  ..., 255.2500, 178.7500,  91.8750],\n",
      "          ...,\n",
      "          [ 29.6875,  41.6875,  40.5625,  ..., 215.7500, 213.7500, 148.6250],\n",
      "          [ 33.9375,  47.2500,  45.3438,  ..., 213.3750, 206.1250, 141.6250],\n",
      "          [ 32.8750,  45.1250,  43.8438,  ..., 137.7500, 130.8750,  90.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 36.0312,  64.0625,  92.3125,  ..., 132.5000, 102.6250,  60.0000],\n",
      "          [ 48.1875,  76.6875, 127.5625,  ..., 191.6250, 132.5000,  69.0625],\n",
      "          [ 47.0625,  89.7500, 166.5000,  ..., 232.8750, 154.3750,  75.9375],\n",
      "          ...,\n",
      "          [152.1250, 221.1250, 219.0000,  ..., 209.5000, 208.3750, 145.0000],\n",
      "          [155.2500, 226.2500, 225.1250,  ..., 208.5000, 201.3750, 138.1250],\n",
      "          [101.9375, 148.2500, 148.0000,  ..., 134.1250, 127.0000,  87.0625]],\n",
      "\n",
      "         [[ 35.9375,  63.9375,  92.1875,  ..., 132.3750, 102.5000,  59.9688],\n",
      "          [ 48.0625,  76.3750, 127.1250,  ..., 191.1250, 132.1250,  68.8125],\n",
      "          [ 46.9688,  89.3125, 166.1250,  ..., 232.3750, 154.0000,  75.7500],\n",
      "          ...,\n",
      "          [152.1250, 221.0000, 218.7500,  ..., 209.2500, 208.1250, 144.8750],\n",
      "          [155.1250, 226.1250, 224.8750,  ..., 208.2500, 201.1250, 138.0000],\n",
      "          [101.8125, 147.8750, 147.7500,  ..., 133.8750, 126.7500,  86.9375]],\n",
      "\n",
      "         [[ 37.3438,  65.8750,  93.6875,  ..., 133.5000, 104.1250,  61.4688],\n",
      "          [ 50.0000,  79.6250, 129.6250,  ..., 193.2500, 135.1250,  71.4375],\n",
      "          [ 48.8438,  92.1875, 167.7500,  ..., 233.7500, 156.3750,  78.1875],\n",
      "          ...,\n",
      "          [153.1250, 222.3750, 220.1250,  ..., 210.8750, 209.8750, 146.2500],\n",
      "          [156.1250, 227.3750, 226.2500,  ..., 209.8750, 202.8750, 139.3750],\n",
      "          [103.1250, 149.6250, 149.5000,  ..., 135.8750, 128.8750,  88.5625]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 77.1875, 113.3750, 129.3750,  ..., 231.8750, 193.6250, 124.1875],\n",
      "          [ 87.0000, 130.3750, 151.5000,  ..., 337.0000, 272.2500, 167.1250],\n",
      "          [ 96.1250, 141.8750, 159.5000,  ..., 401.5000, 323.7500, 195.6250],\n",
      "          ...,\n",
      "          [119.5000, 161.7500, 158.0000,  ..., 161.5000, 171.3750, 128.5000],\n",
      "          [124.3750, 170.1250, 167.5000,  ..., 170.2500, 178.2500, 132.7500],\n",
      "          [ 90.3125, 121.1875, 120.4375,  ..., 121.0625, 125.3750,  95.0625]],\n",
      "\n",
      "         [[ 77.3125, 113.3750, 129.3750,  ..., 231.8750, 193.5000, 124.1875],\n",
      "          [ 87.0625, 130.3750, 151.3750,  ..., 336.5000, 272.0000, 167.0000],\n",
      "          [ 96.2500, 141.8750, 159.5000,  ..., 401.0000, 323.5000, 195.5000],\n",
      "          ...,\n",
      "          [119.5625, 161.7500, 158.0000,  ..., 161.6250, 171.3750, 128.5000],\n",
      "          [124.4375, 170.1250, 167.6250,  ..., 170.2500, 178.2500, 132.7500],\n",
      "          [ 90.2500, 121.1250, 120.3750,  ..., 120.9375, 125.2500,  95.0000]],\n",
      "\n",
      "         [[ 78.4375, 115.0000, 130.8750,  ..., 232.6250, 194.6250, 125.1875],\n",
      "          [ 89.2500, 133.3750, 154.2500,  ..., 338.2500, 274.0000, 168.8750],\n",
      "          [ 98.2500, 144.7500, 162.1250,  ..., 402.2500, 325.2500, 197.1250],\n",
      "          ...,\n",
      "          [120.6875, 163.3750, 159.5000,  ..., 163.2500, 173.3750, 130.0000],\n",
      "          [125.5625, 171.7500, 169.1250,  ..., 172.0000, 180.1250, 134.1250],\n",
      "          [ 91.5000, 122.8750, 122.0625,  ..., 122.7500, 127.2500,  96.3750]]],\n",
      "\n",
      "\n",
      "        [[[105.7500, 173.2500, 214.2500,  ..., 152.5000, 142.3750, 101.6250],\n",
      "          [137.6250, 239.8750, 311.0000,  ..., 187.5000, 174.6250, 123.3125],\n",
      "          [157.8750, 280.5000, 367.7500,  ..., 201.3750, 192.6250, 136.5000],\n",
      "          ...,\n",
      "          [120.0625, 162.8750, 159.5000,  ..., 169.1250, 173.6250, 129.1250],\n",
      "          [124.8125, 171.0000, 168.6250,  ..., 174.1250, 177.2500, 131.0000],\n",
      "          [ 90.5000, 121.6250, 121.0000,  ..., 121.8750, 123.1250,  92.9375]],\n",
      "\n",
      "         [[105.8125, 173.2500, 214.2500,  ..., 152.5000, 142.3750, 101.6250],\n",
      "          [137.6250, 239.5000, 310.7500,  ..., 187.3750, 174.5000, 123.1875],\n",
      "          [157.7500, 280.2500, 367.2500,  ..., 201.2500, 192.5000, 136.3750],\n",
      "          ...,\n",
      "          [120.1875, 162.8750, 159.5000,  ..., 169.1250, 173.6250, 129.1250],\n",
      "          [124.9375, 171.0000, 168.7500,  ..., 174.1250, 177.2500, 131.0000],\n",
      "          [ 90.5000, 121.5000, 120.8750,  ..., 121.7500, 123.0000,  92.8750]],\n",
      "\n",
      "         [[106.8125, 174.5000, 215.2500,  ..., 153.8750, 143.8750, 102.7500],\n",
      "          [139.5000, 242.0000, 312.5000,  ..., 190.0000, 177.3750, 125.3125],\n",
      "          [159.5000, 282.2500, 368.5000,  ..., 203.7500, 195.1250, 138.3750],\n",
      "          ...,\n",
      "          [121.3125, 164.5000, 161.0000,  ..., 171.3750, 176.0000, 130.8750],\n",
      "          [126.0625, 172.6250, 170.2500,  ..., 176.2500, 179.5000, 132.7500],\n",
      "          [ 91.7500, 123.3125, 122.5625,  ..., 123.8750, 125.1875,  94.4375]]],\n",
      "\n",
      "\n",
      "        [[[105.8125, 173.3750, 214.3750,  ..., 218.1250, 178.7500, 115.0000],\n",
      "          [137.7500, 240.0000, 311.2500,  ..., 313.2500, 246.5000, 151.0000],\n",
      "          [158.1250, 281.0000, 368.0000,  ..., 372.0000, 291.7500, 175.3750],\n",
      "          ...,\n",
      "          [118.5000, 160.0000, 155.7500,  ..., 163.2500, 172.7500, 129.2500],\n",
      "          [123.6875, 168.8750, 166.0000,  ..., 171.3750, 179.2500, 133.2500],\n",
      "          [ 89.9375, 120.6250, 119.6875,  ..., 121.6250, 125.8125,  95.3125]],\n",
      "\n",
      "         [[105.8750, 173.2500, 214.3750,  ..., 218.1250, 178.7500, 115.0000],\n",
      "          [137.7500, 239.7500, 310.7500,  ..., 313.0000, 246.2500, 150.8750],\n",
      "          [158.0000, 280.5000, 367.5000,  ..., 371.7500, 291.5000, 175.2500],\n",
      "          ...,\n",
      "          [118.5625, 160.0000, 155.8750,  ..., 163.2500, 172.6250, 129.2500],\n",
      "          [123.7500, 168.8750, 166.0000,  ..., 171.5000, 179.2500, 133.2500],\n",
      "          [ 89.9375, 120.5000, 119.5625,  ..., 121.5000, 125.7500,  95.2500]],\n",
      "\n",
      "         [[106.8750, 174.6250, 215.2500,  ..., 219.0000, 179.8750, 116.0625],\n",
      "          [139.6250, 242.2500, 312.7500,  ..., 314.7500, 248.7500, 152.8750],\n",
      "          [159.7500, 282.5000, 369.0000,  ..., 373.0000, 293.2500, 177.0000],\n",
      "          ...,\n",
      "          [119.6875, 161.6250, 157.2500,  ..., 164.8750, 174.6250, 130.6250],\n",
      "          [124.8750, 170.5000, 167.5000,  ..., 173.1250, 181.1250, 134.7500],\n",
      "          [ 91.1250, 122.2500, 121.2500,  ..., 123.3750, 127.6875,  96.6875]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 81.9375, 112.4375, 121.8125,  ..., 126.9375, 124.0000,  95.3750],\n",
      "          [ 89.3750, 124.7500, 136.6250,  ..., 142.0000, 138.8750, 106.7500],\n",
      "          [ 95.3125, 131.5000, 139.6250,  ..., 143.2500, 143.3750, 110.8125],\n",
      "          ...,\n",
      "          [114.6250, 150.2500, 148.1250,  ..., 149.3750, 158.3750, 122.2500],\n",
      "          [119.1250, 158.1250, 156.8750,  ..., 157.8750, 165.1250, 126.4375],\n",
      "          [ 90.3750, 117.0000, 117.0000,  ..., 116.6875, 120.4375,  94.5000]],\n",
      "\n",
      "         [[ 82.1250, 112.5625, 122.0625,  ..., 127.1250, 124.1875,  95.5625],\n",
      "          [ 89.6250, 124.8750, 136.7500,  ..., 142.1250, 139.0000, 106.8750],\n",
      "          [ 95.5625, 131.6250, 139.7500,  ..., 143.5000, 143.5000, 111.0000],\n",
      "          ...,\n",
      "          [114.8125, 150.3750, 148.2500,  ..., 149.5000, 158.5000, 122.3750],\n",
      "          [119.3125, 158.2500, 157.0000,  ..., 158.0000, 165.2500, 126.5625],\n",
      "          [ 90.5000, 117.0625, 117.0625,  ..., 116.7500, 120.5625,  94.5625]],\n",
      "\n",
      "         [[ 83.0625, 113.9375, 123.2500,  ..., 128.2500, 125.3750,  96.5000],\n",
      "          [ 91.3750, 127.5000, 139.2500,  ..., 144.5000, 141.5000, 108.6875],\n",
      "          [ 97.2500, 134.1250, 142.1250,  ..., 145.7500, 145.8750, 112.6250],\n",
      "          ...,\n",
      "          [115.8125, 152.0000, 149.5000,  ..., 151.0000, 160.2500, 123.6250],\n",
      "          [120.3125, 159.8750, 158.3750,  ..., 159.6250, 167.0000, 127.8750],\n",
      "          [ 91.5625, 118.6250, 118.5625,  ..., 118.3750, 122.3125,  95.8125]]],\n",
      "\n",
      "\n",
      "        [[[ 42.2812,  44.2812,  39.1562,  ..., 175.8750, 157.5000, 112.1250],\n",
      "          [ 33.6250,  37.4375,  24.9688,  ..., 232.8750, 201.5000, 138.1250],\n",
      "          [ 25.4375,  22.7812,  11.3281,  ..., 265.0000, 228.0000, 153.3750],\n",
      "          ...,\n",
      "          [112.6250, 146.8750, 144.0000,  ..., 152.1250, 160.6250, 123.5625],\n",
      "          [117.5625, 155.5000, 153.7500,  ..., 158.8750, 165.8750, 126.8750],\n",
      "          [ 89.6250, 115.6250, 115.3750,  ..., 116.8750, 120.5625,  94.5625]],\n",
      "\n",
      "         [[ 42.3750,  44.3438,  39.2500,  ..., 176.0000, 157.6250, 112.1875],\n",
      "          [ 33.6250,  37.4688,  25.0156,  ..., 232.7500, 201.5000, 138.1250],\n",
      "          [ 25.4844,  22.8125,  11.4219,  ..., 265.0000, 228.0000, 153.3750],\n",
      "          ...,\n",
      "          [112.8125, 147.0000, 144.1250,  ..., 152.3750, 160.7500, 123.7500],\n",
      "          [117.7500, 155.6250, 153.8750,  ..., 159.0000, 166.0000, 127.0000],\n",
      "          [ 89.7500, 115.6875, 115.5000,  ..., 116.9375, 120.6250,  94.6250]],\n",
      "\n",
      "         [[ 43.1875,  45.3750,  39.9688,  ..., 177.1250, 158.8750, 113.1875],\n",
      "          [ 34.7188,  38.6562,  25.7188,  ..., 235.1250, 204.0000, 140.0000],\n",
      "          [ 26.2188,  23.4219,  11.4141,  ..., 267.0000, 230.3750, 155.1250],\n",
      "          ...,\n",
      "          [113.8125, 148.5000, 145.3750,  ..., 153.8750, 162.6250, 125.0625],\n",
      "          [118.7500, 157.1250, 155.2500,  ..., 160.6250, 167.7500, 128.2500],\n",
      "          [ 90.7500, 117.2500, 116.8750,  ..., 118.5625, 122.3750,  95.8750]]],\n",
      "\n",
      "\n",
      "        [[[136.2500, 216.0000, 256.7500,  ..., 187.8750, 171.3750, 120.6250],\n",
      "          [183.0000, 304.2500, 372.5000,  ..., 264.2500, 235.5000, 158.6250],\n",
      "          [209.8750, 353.2500, 434.5000,  ..., 322.0000, 286.5000, 188.2500],\n",
      "          ...,\n",
      "          [ 35.9375,  46.9688,  44.5312,  ..., 102.5625, 100.8750,  78.5625],\n",
      "          [ 39.9375,  52.1562,  48.2812,  ...,  90.6875,  92.0625,  73.9375],\n",
      "          [ 38.0938,  49.6562,  47.0625,  ...,  66.6250,  68.2500,  56.5312]],\n",
      "\n",
      "         [[136.3750, 216.1250, 257.0000,  ..., 188.0000, 171.5000, 120.7500],\n",
      "          [183.0000, 304.0000, 372.5000,  ..., 264.2500, 235.5000, 158.5000],\n",
      "          [209.8750, 353.0000, 434.2500,  ..., 322.0000, 286.5000, 188.2500],\n",
      "          ...,\n",
      "          [ 35.9375,  46.9688,  44.5312,  ..., 102.7500, 101.0000,  78.6875],\n",
      "          [ 39.9375,  52.1875,  48.3125,  ...,  90.8750,  92.2500,  74.0625],\n",
      "          [ 38.1250,  49.6875,  47.0938,  ...,  66.6875,  68.3125,  56.5625]],\n",
      "\n",
      "         [[137.2500, 217.2500, 257.7500,  ..., 189.1250, 172.7500, 121.6875],\n",
      "          [184.6250, 306.0000, 374.2500,  ..., 266.2500, 237.8750, 160.3750],\n",
      "          [211.3750, 354.7500, 435.5000,  ..., 324.0000, 288.5000, 189.8750],\n",
      "          ...,\n",
      "          [ 37.0625,  48.4375,  45.9062,  ..., 105.3125, 103.7500,  80.6875],\n",
      "          [ 41.1875,  53.8125,  49.8125,  ...,  93.5625,  95.0625,  76.1250],\n",
      "          [ 39.3438,  51.2812,  48.5938,  ...,  68.9375,  70.6250,  58.3438]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[108.3125, 175.3750, 216.2500,  ..., 119.4375, 111.2500,  83.3125],\n",
      "          [138.2500, 239.5000, 310.2500,  ..., 136.7500, 125.8750,  93.4375],\n",
      "          [156.6250, 277.5000, 364.7500,  ..., 144.0000, 136.0000, 101.0625],\n",
      "          ...,\n",
      "          [115.8125, 156.8750, 156.0000,  ..., 140.8750, 135.1250, 101.5000],\n",
      "          [119.1250, 162.1250, 161.7500,  ..., 138.8750, 128.6250,  95.3125],\n",
      "          [ 88.5000, 117.4375, 117.6250,  ...,  99.0000,  90.1875,  68.8125]],\n",
      "\n",
      "         [[108.5000, 175.5000, 216.3750,  ..., 119.6250, 111.4375,  83.4375],\n",
      "          [138.3750, 239.5000, 310.2500,  ..., 136.8750, 126.1250,  93.6250],\n",
      "          [156.7500, 277.5000, 364.7500,  ..., 144.1250, 136.2500, 101.3125],\n",
      "          ...,\n",
      "          [116.0625, 157.0000, 156.2500,  ..., 141.0000, 135.2500, 101.6875],\n",
      "          [119.3750, 162.3750, 162.0000,  ..., 139.0000, 128.8750,  95.5000],\n",
      "          [ 88.6875, 117.5000, 117.7500,  ...,  99.1250,  90.3125,  68.9375]],\n",
      "\n",
      "         [[109.1875, 176.5000, 217.2500,  ..., 120.6250, 112.5625,  84.2500],\n",
      "          [139.7500, 241.5000, 312.2500,  ..., 139.1250, 128.3750,  95.1875],\n",
      "          [158.0000, 279.5000, 366.2500,  ..., 146.2500, 138.3750, 102.8125],\n",
      "          ...,\n",
      "          [117.0625, 158.6250, 157.7500,  ..., 142.8750, 137.2500, 103.0625],\n",
      "          [120.3750, 163.8750, 163.5000,  ..., 141.0000, 130.8750,  96.9375],\n",
      "          [ 89.6250, 119.0000, 119.1875,  ..., 100.8125,  92.1250,  70.1875]]],\n",
      "\n",
      "\n",
      "        [[[ 80.7500, 123.0000, 144.5000,  ..., 226.6250, 185.6250, 119.1250],\n",
      "          [ 94.0625, 157.5000, 200.8750,  ..., 328.2500, 257.5000, 155.8750],\n",
      "          [107.1875, 188.3750, 249.2500,  ..., 388.5000, 301.7500, 178.2500],\n",
      "          ...,\n",
      "          [116.1250, 156.8750, 156.7500,  ..., 158.3750, 163.1250, 123.0625],\n",
      "          [119.4375, 162.5000, 162.8750,  ..., 163.8750, 167.7500, 126.0625],\n",
      "          [ 88.8750, 117.8750, 118.5625,  ..., 118.3750, 120.4375,  92.7500]],\n",
      "\n",
      "         [[ 80.9375, 123.1250, 144.6250,  ..., 226.7500, 185.7500, 119.2500],\n",
      "          [ 94.2500, 157.6250, 201.0000,  ..., 328.2500, 257.5000, 155.8750],\n",
      "          [107.3750, 188.3750, 249.2500,  ..., 388.5000, 301.7500, 178.2500],\n",
      "          ...,\n",
      "          [116.3750, 157.0000, 156.8750,  ..., 158.6250, 163.3750, 123.2500],\n",
      "          [119.6875, 162.6250, 163.0000,  ..., 164.1250, 168.0000, 126.2500],\n",
      "          [ 89.0000, 117.9375, 118.6875,  ..., 118.4375, 120.5000,  92.8125]],\n",
      "\n",
      "         [[ 81.6250, 124.2500, 145.7500,  ..., 227.6250, 186.8750, 120.0000],\n",
      "          [ 95.7500, 159.8750, 203.0000,  ..., 330.2500, 259.5000, 157.3750],\n",
      "          [108.7500, 190.5000, 251.1250,  ..., 390.2500, 303.5000, 179.6250],\n",
      "          ...,\n",
      "          [117.2500, 158.5000, 158.2500,  ..., 160.1250, 165.0000, 124.3750],\n",
      "          [120.5625, 164.1250, 164.3750,  ..., 165.6250, 169.6250, 127.3750],\n",
      "          [ 89.9375, 119.3125, 120.0000,  ..., 119.9375, 122.0625,  93.8750]]],\n",
      "\n",
      "\n",
      "        [[[ 65.3750,  91.6875, 104.3750,  ..., 226.8750, 186.0000, 119.3125],\n",
      "          [ 64.0000,  93.2500, 113.1875,  ..., 328.7500, 258.0000, 156.2500],\n",
      "          [ 63.5938,  92.6875, 112.6875,  ..., 389.5000, 302.5000, 178.7500],\n",
      "          ...,\n",
      "          [115.3750, 155.3750, 154.7500,  ..., 156.1250, 161.5000, 122.0625],\n",
      "          [118.9375, 161.5000, 161.6250,  ..., 162.1250, 166.5000, 125.3125],\n",
      "          [ 88.6875, 117.4375, 118.0000,  ..., 117.4375, 119.7500,  92.3125]],\n",
      "\n",
      "         [[ 65.6250,  91.8750, 104.6250,  ..., 227.1250, 186.1250, 119.4375],\n",
      "          [ 64.2500,  93.5000, 113.4375,  ..., 329.0000, 258.0000, 156.2500],\n",
      "          [ 63.8438,  93.0000, 112.9375,  ..., 389.5000, 302.5000, 178.7500],\n",
      "          ...,\n",
      "          [115.6250, 155.5000, 155.0000,  ..., 156.2500, 161.6250, 122.2500],\n",
      "          [119.1875, 161.6250, 161.7500,  ..., 162.3750, 166.6250, 125.5000],\n",
      "          [ 88.8125, 117.5625, 118.1250,  ..., 117.5625, 119.8125,  92.4375]],\n",
      "\n",
      "         [[ 66.3750,  93.0000, 105.6875,  ..., 228.0000, 187.1250, 120.1875],\n",
      "          [ 65.8125,  95.8125, 115.6250,  ..., 330.7500, 260.2500, 157.7500],\n",
      "          [ 65.3750,  95.1875, 115.0000,  ..., 391.0000, 304.5000, 180.1250],\n",
      "          ...,\n",
      "          [116.5000, 157.0000, 156.2500,  ..., 157.7500, 163.2500, 123.3750],\n",
      "          [120.0625, 163.1250, 163.1250,  ..., 163.8750, 168.3750, 126.6250],\n",
      "          [ 89.6875, 118.9375, 119.4375,  ..., 119.0000, 121.3750,  93.4375]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[115.1875, 184.5000, 227.1250,  ..., 240.2500, 195.8750, 125.8125],\n",
      "          [146.8750, 251.2500, 324.2500,  ..., 348.2500, 272.2500, 164.8750],\n",
      "          [165.8750, 290.2500, 379.7500,  ..., 411.0000, 318.5000, 188.5000],\n",
      "          ...,\n",
      "          [ 29.9531,  43.7500,  47.1250,  ..., 176.7500, 178.6250, 134.3750],\n",
      "          [ 32.2500,  44.3750,  43.4062,  ..., 179.7500, 181.5000, 136.3750],\n",
      "          [ 30.8906,  41.0000,  39.0312,  ..., 129.7500, 130.6250, 101.0625]],\n",
      "\n",
      "         [[115.3750, 184.6250, 227.2500,  ..., 240.5000, 196.1250, 126.0000],\n",
      "          [147.0000, 251.3750, 324.2500,  ..., 348.2500, 272.5000, 165.0000],\n",
      "          [165.8750, 290.2500, 379.7500,  ..., 411.0000, 318.5000, 188.5000],\n",
      "          ...,\n",
      "          [ 30.0312,  43.8750,  47.2812,  ..., 177.0000, 178.8750, 134.5000],\n",
      "          [ 32.3125,  44.5000,  43.5312,  ..., 180.0000, 181.7500, 136.6250],\n",
      "          [ 30.9844,  41.1562,  39.1562,  ..., 129.8750, 130.7500, 101.1250]],\n",
      "\n",
      "         [[115.9375, 185.5000, 228.1250,  ..., 241.3750, 197.0000, 126.6250],\n",
      "          [148.2500, 253.1250, 326.2500,  ..., 350.2500, 274.5000, 166.2500],\n",
      "          [167.0000, 292.0000, 381.2500,  ..., 412.7500, 320.2500, 189.7500],\n",
      "          ...,\n",
      "          [ 30.7344,  44.9375,  48.4688,  ..., 178.6250, 180.6250, 135.7500],\n",
      "          [ 33.0625,  45.5625,  44.5938,  ..., 181.7500, 183.5000, 137.7500],\n",
      "          [ 31.7188,  42.1250,  40.0625,  ..., 131.3750, 132.3750, 102.1250]]],\n",
      "\n",
      "\n",
      "        [[[ 57.7500,  74.7500,  81.0625,  ..., 171.2500, 143.2500,  97.8125],\n",
      "          [ 49.2812,  67.3125,  74.8125,  ..., 234.8750, 184.0000, 116.8125],\n",
      "          [ 44.4062,  62.4375,  66.6875,  ..., 272.2500, 207.2500, 126.5000],\n",
      "          ...,\n",
      "          [123.7500, 166.1250, 166.0000,  ..., 165.5000, 170.1250, 129.5000],\n",
      "          [127.0625, 171.7500, 172.1250,  ..., 171.3750, 175.1250, 132.7500],\n",
      "          [ 95.7500, 125.9375, 126.5625,  ..., 125.5000, 127.4375,  99.1250]],\n",
      "\n",
      "         [[ 57.9688,  75.0000,  81.3125,  ..., 171.5000, 143.3750,  97.9375],\n",
      "          [ 49.4688,  67.5000,  75.1250,  ..., 235.0000, 184.1250, 117.0000],\n",
      "          [ 44.5938,  62.6250,  66.9375,  ..., 272.2500, 207.3750, 126.6250],\n",
      "          ...,\n",
      "          [124.0000, 166.3750, 166.1250,  ..., 165.7500, 170.3750, 129.6250],\n",
      "          [127.3750, 172.0000, 172.3750,  ..., 171.6250, 175.3750, 132.8750],\n",
      "          [ 95.8750, 126.0625, 126.6875,  ..., 125.6250, 127.5625,  99.2500]],\n",
      "\n",
      "         [[ 58.5938,  75.9375,  82.1875,  ..., 172.3750, 144.5000,  98.6875],\n",
      "          [ 50.7500,  69.3125,  76.9375,  ..., 236.8750, 186.1250, 118.3750],\n",
      "          [ 45.7500,  64.3125,  68.6250,  ..., 274.0000, 209.1250, 127.9375],\n",
      "          ...,\n",
      "          [124.9375, 167.8750, 167.6250,  ..., 167.2500, 172.0000, 130.7500],\n",
      "          [128.2500, 173.5000, 173.7500,  ..., 173.1250, 177.0000, 134.0000],\n",
      "          [ 96.7500, 127.3750, 128.0000,  ..., 127.0000, 129.0000, 100.1875]]],\n",
      "\n",
      "\n",
      "        [[[ 59.7812,  78.1250,  84.9375,  ..., 104.9375,  98.5625,  77.0000],\n",
      "          [ 51.5938,  70.8750,  79.6250,  ..., 113.1875, 102.5625,  79.3750],\n",
      "          [ 46.1562,  65.6250,  70.3750,  ..., 113.7500, 103.7500,  80.1250],\n",
      "          ...,\n",
      "          [124.4375, 167.3750, 167.3750,  ..., 166.2500, 170.8750, 129.8750],\n",
      "          [127.6250, 172.7500, 173.1250,  ..., 172.1250, 175.7500, 133.0000],\n",
      "          [ 96.0000, 126.3750, 127.0625,  ..., 125.8750, 127.7500,  99.3125]],\n",
      "\n",
      "         [[ 59.9688,  78.3750,  85.1875,  ..., 105.1875,  98.8125,  77.1875],\n",
      "          [ 51.7812,  71.0625,  79.9375,  ..., 113.5000, 102.8750,  79.6250],\n",
      "          [ 46.3438,  65.8125,  70.6875,  ..., 114.1250, 104.1250,  80.3750],\n",
      "          ...,\n",
      "          [124.7500, 167.5000, 167.6250,  ..., 166.5000, 171.0000, 130.0000],\n",
      "          [127.8750, 172.8750, 173.3750,  ..., 172.3750, 175.8750, 133.2500],\n",
      "          [ 96.1875, 126.5000, 127.2500,  ..., 126.0625, 127.8750,  99.4375]],\n",
      "\n",
      "         [[ 60.6250,  79.3750,  86.1875,  ..., 106.1250,  99.8125,  77.9375],\n",
      "          [ 53.1250,  73.0000,  81.8750,  ..., 115.4375, 104.8750,  81.0625],\n",
      "          [ 47.5312,  67.6250,  72.5000,  ..., 115.9375, 106.0000,  81.7500],\n",
      "          ...,\n",
      "          [125.6250, 169.0000, 169.0000,  ..., 168.0000, 172.6250, 131.1250],\n",
      "          [128.7500, 174.3750, 174.8750,  ..., 173.8750, 177.5000, 134.3750],\n",
      "          [ 97.0000, 127.8750, 128.6250,  ..., 127.3750, 129.2500, 100.3750]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 91.6875, 152.2500, 193.7500,  ..., 196.5000, 156.7500,  98.9375],\n",
      "          [112.1250, 201.8750, 273.0000,  ..., 279.0000, 210.1250, 123.1875],\n",
      "          [128.1250, 235.8750, 323.7500,  ..., 331.2500, 246.3750, 140.5000],\n",
      "          ...,\n",
      "          [123.1875, 169.7500, 169.7500,  ..., 163.5000, 166.2500, 124.8750],\n",
      "          [125.9375, 174.0000, 174.1250,  ..., 167.7500, 169.8750, 127.0000],\n",
      "          [ 92.1875, 124.2500, 124.5625,  ..., 120.1250, 120.8125,  92.4375]],\n",
      "\n",
      "         [[ 91.8750, 152.5000, 194.0000,  ..., 196.8750, 157.1250,  99.0625],\n",
      "          [112.3125, 202.1250, 273.2500,  ..., 279.0000, 210.3750, 123.3750],\n",
      "          [128.2500, 236.0000, 324.0000,  ..., 331.5000, 246.6250, 140.6250],\n",
      "          ...,\n",
      "          [123.5000, 170.1250, 170.2500,  ..., 163.8750, 166.6250, 125.1250],\n",
      "          [126.2500, 174.3750, 174.5000,  ..., 168.1250, 170.2500, 127.2500],\n",
      "          [ 92.3750, 124.3750, 124.7500,  ..., 120.3125, 121.0000,  92.5625]],\n",
      "\n",
      "         [[ 92.3750, 153.2500, 194.6250,  ..., 197.5000, 157.8750,  99.6875],\n",
      "          [113.3125, 203.6250, 274.7500,  ..., 280.7500, 211.8750, 124.5000],\n",
      "          [129.1250, 237.3750, 325.2500,  ..., 333.0000, 248.0000, 141.6250],\n",
      "          ...,\n",
      "          [124.4375, 171.5000, 171.6250,  ..., 165.2500, 168.1250, 126.1875],\n",
      "          [127.1250, 175.8750, 176.0000,  ..., 169.6250, 171.6250, 128.2500],\n",
      "          [ 93.1875, 125.6875, 126.0625,  ..., 121.6250, 122.3750,  93.5000]]],\n",
      "\n",
      "\n",
      "        [[[ 34.6562,  43.0000,  45.3750,  ..., 199.8750, 157.0000,  98.6875],\n",
      "          [ 36.5000,  52.8125,  53.4375,  ..., 284.5000, 210.5000, 122.8750],\n",
      "          [ 31.6875,  45.4688,  45.9062,  ..., 338.5000, 247.1250, 140.1250],\n",
      "          ...,\n",
      "          [114.2500, 157.3750, 158.5000,  ..., 177.0000, 176.2500, 130.3750],\n",
      "          [114.0625, 158.5000, 162.1250,  ..., 177.2500, 176.1250, 130.1250],\n",
      "          [ 83.1250, 112.6250, 116.3125,  ..., 124.5000, 123.3125,  93.5000]],\n",
      "\n",
      "         [[ 34.7500,  43.0938,  45.5000,  ..., 200.1250, 157.2500,  98.8750],\n",
      "          [ 36.6250,  52.9688,  53.6250,  ..., 284.5000, 210.7500, 123.0000],\n",
      "          [ 31.8125,  45.6250,  46.0625,  ..., 338.5000, 247.3750, 140.2500],\n",
      "          ...,\n",
      "          [114.5000, 157.7500, 158.8750,  ..., 177.3750, 176.6250, 130.6250],\n",
      "          [114.3750, 158.8750, 162.5000,  ..., 177.6250, 176.5000, 130.5000],\n",
      "          [ 83.3125, 112.8125, 116.5000,  ..., 124.6875, 123.5000,  93.6250]],\n",
      "\n",
      "         [[ 35.4062,  44.0312,  46.4375,  ..., 200.8750, 158.0000,  99.4375],\n",
      "          [ 37.4375,  54.1875,  54.8750,  ..., 286.2500, 212.3750, 124.1875],\n",
      "          [ 32.4688,  46.6250,  47.0938,  ..., 340.0000, 248.7500, 141.2500],\n",
      "          ...,\n",
      "          [115.4375, 159.1250, 160.2500,  ..., 178.8750, 178.1250, 131.6250],\n",
      "          [115.3125, 160.2500, 163.8750,  ..., 179.1250, 178.1250, 131.5000],\n",
      "          [ 84.1250, 114.1250, 117.8125,  ..., 126.0625, 124.9375,  94.5625]]],\n",
      "\n",
      "\n",
      "        [[[ 26.4375,  32.7812,  30.6562,  ...,  39.3125,  42.7812,  40.5938],\n",
      "          [ 28.6562,  38.4062,  35.3125,  ...,  46.5625,  50.7812,  41.4062],\n",
      "          [ 23.0625,  29.4844,  25.5156,  ...,  39.0312,  43.9375,  37.0938],\n",
      "          ...,\n",
      "          [121.1875, 166.2500, 165.5000,  ..., 161.2500, 164.7500, 124.0625],\n",
      "          [124.4375, 171.3750, 171.0000,  ..., 166.3750, 169.1250, 126.7500],\n",
      "          [ 91.4375, 122.9375, 123.0000,  ..., 119.6250, 120.8125,  92.6250]],\n",
      "\n",
      "         [[ 26.5000,  32.9062,  30.7812,  ...,  39.4062,  42.9062,  40.6875],\n",
      "          [ 28.7656,  38.5312,  35.4375,  ...,  46.7188,  50.9375,  41.5312],\n",
      "          [ 23.1562,  29.6094,  25.6406,  ...,  39.1875,  44.1250,  37.2188],\n",
      "          ...,\n",
      "          [121.4375, 166.6250, 165.8750,  ..., 161.7500, 165.2500, 124.3125],\n",
      "          [124.6875, 171.7500, 171.3750,  ..., 166.7500, 169.6250, 127.0000],\n",
      "          [ 91.6250, 123.0625, 123.1875,  ..., 119.8125, 121.0000,  92.7500]],\n",
      "\n",
      "         [[ 27.0312,  33.5625,  31.3906,  ...,  40.2500,  43.8125,  41.3750],\n",
      "          [ 29.3438,  39.3750,  36.1875,  ...,  47.7812,  52.1250,  42.4688],\n",
      "          [ 23.5781,  30.1562,  26.0781,  ...,  40.0312,  45.0938,  38.0312],\n",
      "          ...,\n",
      "          [122.3125, 167.8750, 167.1250,  ..., 163.0000, 166.6250, 125.3125],\n",
      "          [125.5625, 173.1250, 172.6250,  ..., 168.1250, 171.0000, 128.0000],\n",
      "          [ 92.4375, 124.3750, 124.4375,  ..., 121.1250, 122.3125,  93.6250]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 76.4375, 130.2500, 179.1250,  ..., 135.1250, 108.5000,  74.1250],\n",
      "          [ 79.5000, 155.5000, 239.5000,  ..., 178.0000, 129.2500,  80.2500],\n",
      "          [ 74.4375, 157.3750, 259.5000,  ..., 211.8750, 149.2500,  87.9375],\n",
      "          ...,\n",
      "          [123.9375, 168.3750, 167.3750,  ..., 159.0000, 160.5000, 121.9375],\n",
      "          [127.0625, 173.5000, 173.0000,  ..., 161.7500, 160.2500, 120.6250],\n",
      "          [ 94.8750, 126.1875, 126.3125,  ..., 117.5000, 114.7500,  88.5000]],\n",
      "\n",
      "         [[ 76.6250, 130.5000, 179.3750,  ..., 135.3750, 108.6875,  74.2500],\n",
      "          [ 79.6875, 155.8750, 239.7500,  ..., 178.2500, 129.6250,  80.4375],\n",
      "          [ 74.6250, 157.6250, 259.7500,  ..., 212.2500, 149.5000,  88.1250],\n",
      "          ...,\n",
      "          [124.1875, 168.7500, 167.7500,  ..., 159.3750, 160.8750, 122.1250],\n",
      "          [127.3750, 173.8750, 173.3750,  ..., 162.2500, 160.6250, 120.8750],\n",
      "          [ 95.0625, 126.3750, 126.5000,  ..., 117.6875, 114.9375,  88.6875]],\n",
      "\n",
      "         [[ 77.0625, 131.1250, 180.0000,  ..., 136.1250, 109.5000,  74.8125],\n",
      "          [ 80.5625, 157.1250, 241.0000,  ..., 179.6250, 131.0000,  81.5000],\n",
      "          [ 75.4375, 158.7500, 261.2500,  ..., 213.3750, 150.7500,  89.0625],\n",
      "          ...,\n",
      "          [125.0000, 170.0000, 169.0000,  ..., 160.6250, 162.1250, 123.0625],\n",
      "          [128.2500, 175.1250, 174.5000,  ..., 163.3750, 161.8750, 121.8125],\n",
      "          [ 95.7500, 127.5625, 127.6250,  ..., 118.8125, 116.1250,  89.4375]]],\n",
      "\n",
      "\n",
      "        [[[103.0000, 163.5000, 196.3750,  ..., 108.7500,  97.3750,  71.6250],\n",
      "          [127.9375, 217.1250, 273.7500,  ..., 143.7500, 120.0000,  81.6875],\n",
      "          [145.1250, 251.8750, 322.2500,  ..., 188.5000, 154.8750,  99.5000],\n",
      "          ...,\n",
      "          [113.1875, 162.5000, 176.6250,  ...,  69.6250,  59.3125,  45.0000],\n",
      "          [102.9375, 148.8750, 166.2500,  ...,  60.4375,  58.5312,  45.1562],\n",
      "          [ 73.4375, 102.3125, 115.5625,  ...,  49.3750,  48.7188,  37.4062]],\n",
      "\n",
      "         [[103.1875, 163.7500, 196.7500,  ..., 109.0000,  97.5625,  71.8125],\n",
      "          [128.2500, 217.5000, 274.0000,  ..., 144.1250, 120.2500,  81.8750],\n",
      "          [145.3750, 252.1250, 322.2500,  ..., 188.8750, 155.2500,  99.6875],\n",
      "          ...,\n",
      "          [113.4375, 162.8750, 177.0000,  ...,  70.0000,  59.5938,  45.1875],\n",
      "          [103.1875, 149.2500, 166.6250,  ...,  60.7188,  58.7812,  45.3438],\n",
      "          [ 73.6875, 102.5000, 115.7500,  ...,  49.5938,  48.9375,  37.5312]],\n",
      "\n",
      "         [[103.6250, 164.3750, 197.3750,  ..., 109.6875,  98.3125,  72.3125],\n",
      "          [129.0000, 218.7500, 275.5000,  ..., 145.3750, 121.7500,  82.8750],\n",
      "          [146.1250, 253.3750, 323.7500,  ..., 190.1250, 156.5000, 100.6875],\n",
      "          ...,\n",
      "          [114.3125, 164.1250, 178.3750,  ...,  71.3125,  60.8750,  46.1250],\n",
      "          [104.1250, 150.6250, 168.0000,  ...,  62.0000,  60.0312,  46.2812],\n",
      "          [ 74.4375, 103.6875, 117.0000,  ...,  50.6562,  49.9375,  38.2812]]],\n",
      "\n",
      "\n",
      "        [[[ 38.3125,  47.9375,  55.9062,  ..., 215.3750, 171.6250, 109.1875],\n",
      "          [ 33.9062,  49.6562,  52.8125,  ..., 305.2500, 231.3750, 137.7500],\n",
      "          [ 28.9062,  41.6250,  44.5625,  ..., 359.2500, 269.2500, 156.2500],\n",
      "          ...,\n",
      "          [126.5625, 173.1250, 173.1250,  ..., 169.3750, 170.0000, 128.0000],\n",
      "          [129.1250, 177.0000, 177.2500,  ..., 170.1250, 168.6250, 126.3125],\n",
      "          [ 95.8750, 127.9375, 128.5000,  ..., 122.0000, 119.6875,  92.0000]],\n",
      "\n",
      "         [[ 38.4375,  48.0938,  56.0625,  ..., 215.7500, 172.0000, 109.3750],\n",
      "          [ 34.0312,  49.8438,  53.0625,  ..., 305.5000, 231.7500, 138.0000],\n",
      "          [ 29.0469,  41.8125,  44.7812,  ..., 359.5000, 269.2500, 156.5000],\n",
      "          ...,\n",
      "          [126.8750, 173.5000, 173.5000,  ..., 169.7500, 170.3750, 128.2500],\n",
      "          [129.5000, 177.5000, 177.6250,  ..., 170.6250, 169.0000, 126.5625],\n",
      "          [ 96.0625, 128.1250, 128.6250,  ..., 122.2500, 119.9375,  92.1250]],\n",
      "\n",
      "         [[ 38.9062,  48.8438,  56.7812,  ..., 216.5000, 172.7500, 109.8750],\n",
      "          [ 34.6875,  50.8750,  54.1562,  ..., 307.2500, 233.1250, 139.0000],\n",
      "          [ 29.5469,  42.6250,  45.6562,  ..., 361.0000, 270.7500, 157.3750],\n",
      "          ...,\n",
      "          [127.7500, 174.7500, 174.8750,  ..., 171.1250, 171.7500, 129.2500],\n",
      "          [130.2500, 178.7500, 179.0000,  ..., 171.8750, 170.3750, 127.5625],\n",
      "          [ 96.7500, 129.2500, 129.7500,  ..., 123.4375, 121.1875,  92.9375]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 22.2500,  26.2500,  23.8438,  ..., 196.1250, 153.3750,  97.1250],\n",
      "          [ 22.3750,  29.2656,  25.7500,  ..., 274.2500, 201.6250, 118.5000],\n",
      "          [ 17.1250,  21.0469,  17.1719,  ..., 324.5000, 235.3750, 134.2500],\n",
      "          ...,\n",
      "          [126.1250, 173.3750, 173.3750,  ..., 163.6250, 163.7500, 123.4375],\n",
      "          [128.6250, 177.2500, 177.6250,  ..., 165.1250, 162.3750, 121.3750],\n",
      "          [ 95.0625, 127.7500, 128.2500,  ..., 118.7500, 115.1875,  88.1250]],\n",
      "\n",
      "         [[ 22.3125,  26.3750,  23.9531,  ..., 196.5000, 153.6250,  97.2500],\n",
      "          [ 22.4844,  29.4219,  25.9062,  ..., 274.5000, 202.0000, 118.6875],\n",
      "          [ 17.2188,  21.1719,  17.2812,  ..., 324.7500, 235.7500, 134.5000],\n",
      "          ...,\n",
      "          [126.4375, 173.7500, 173.8750,  ..., 164.0000, 164.2500, 123.6250],\n",
      "          [128.8750, 177.7500, 178.1250,  ..., 165.6250, 162.8750, 121.6250],\n",
      "          [ 95.1875, 127.8750, 128.5000,  ..., 118.9375, 115.3750,  88.2500]],\n",
      "\n",
      "         [[ 22.6406,  26.7500,  24.2812,  ..., 197.1250, 154.3750,  97.8125],\n",
      "          [ 22.7969,  29.8438,  26.2344,  ..., 276.2500, 203.3750, 119.6250],\n",
      "          [ 17.4062,  21.3906,  17.4375,  ..., 326.2500, 237.0000, 135.3750],\n",
      "          ...,\n",
      "          [127.3125, 175.0000, 175.1250,  ..., 165.2500, 165.5000, 124.5625],\n",
      "          [129.7500, 179.0000, 179.3750,  ..., 166.8750, 164.1250, 122.5625],\n",
      "          [ 95.9375, 129.0000, 129.6250,  ..., 120.1250, 116.6250,  89.0625]]],\n",
      "\n",
      "\n",
      "        [[[ 29.9844,  34.3125,  32.9688,  ..., 196.1250, 153.3750,  97.1250],\n",
      "          [ 29.2500,  41.0938,  39.4375,  ..., 274.2500, 201.6250, 118.5000],\n",
      "          [ 24.9688,  34.3750,  32.4375,  ..., 324.5000, 235.3750, 134.2500],\n",
      "          ...,\n",
      "          [126.2500, 173.3750, 173.3750,  ..., 162.2500, 162.6250, 122.7500],\n",
      "          [128.6250, 177.3750, 177.5000,  ..., 164.0000, 161.3750, 120.6875],\n",
      "          [ 95.1250, 127.8125, 128.2500,  ..., 118.1875, 114.6250,  87.7500]],\n",
      "\n",
      "         [[ 30.0781,  34.4688,  33.1250,  ..., 196.5000, 153.6250,  97.2500],\n",
      "          [ 29.3906,  41.3438,  39.6875,  ..., 274.5000, 202.0000, 118.6875],\n",
      "          [ 25.1094,  34.5938,  32.6250,  ..., 324.7500, 235.7500, 134.5000],\n",
      "          ...,\n",
      "          [126.5000, 173.8750, 173.8750,  ..., 162.7500, 163.1250, 122.9375],\n",
      "          [129.0000, 177.8750, 178.0000,  ..., 164.5000, 161.8750, 120.9375],\n",
      "          [ 95.2500, 127.9375, 128.5000,  ..., 118.3125, 114.8125,  87.8125]],\n",
      "\n",
      "         [[ 30.4844,  35.0312,  33.6250,  ..., 197.1250, 154.3750,  97.8125],\n",
      "          [ 29.8594,  42.0000,  40.3125,  ..., 276.2500, 203.3750, 119.6250],\n",
      "          [ 25.4688,  35.0938,  33.0938,  ..., 326.2500, 237.0000, 135.3750],\n",
      "          ...,\n",
      "          [127.3750, 175.1250, 175.0000,  ..., 163.8750, 164.3750, 123.8750],\n",
      "          [129.7500, 179.1250, 179.2500,  ..., 165.7500, 163.1250, 121.8750],\n",
      "          [ 96.0625, 129.1250, 129.6250,  ..., 119.5000, 116.0000,  88.6250]]],\n",
      "\n",
      "\n",
      "        [[[ 52.7812,  77.6250,  87.1250,  ...,  53.9688,  50.1562,  43.6562],\n",
      "          [ 41.2500,  64.6250,  77.4375,  ...,  51.5000,  51.0000,  39.6250],\n",
      "          [ 35.7188,  54.8125,  60.7500,  ...,  42.5000,  42.7188,  34.5312],\n",
      "          ...,\n",
      "          [125.5000, 172.3750, 172.5000,  ..., 161.5000, 161.8750, 122.2500],\n",
      "          [128.2500, 176.7500, 177.0000,  ..., 163.3750, 160.5000, 120.1250],\n",
      "          [ 94.8750, 127.5000, 128.0000,  ..., 117.6875, 114.0625,  87.3125]],\n",
      "\n",
      "         [[ 52.9688,  77.7500,  87.2500,  ...,  54.1562,  50.3750,  43.8438],\n",
      "          [ 41.4688,  64.8125,  77.6250,  ...,  51.7812,  51.2812,  39.8438],\n",
      "          [ 35.9375,  55.1250,  60.9688,  ...,  42.7500,  42.9688,  34.7188],\n",
      "          ...,\n",
      "          [125.8125, 172.8750, 172.8750,  ..., 162.0000, 162.3750, 122.4375],\n",
      "          [128.5000, 177.1250, 177.5000,  ..., 163.7500, 161.0000, 120.3750],\n",
      "          [ 95.0625, 127.6250, 128.2500,  ..., 117.8750, 114.2500,  87.3750]],\n",
      "\n",
      "         [[ 53.3438,  78.4375,  87.9375,  ...,  54.7812,  51.0000,  44.2500],\n",
      "          [ 42.2188,  66.0625,  78.8750,  ...,  52.7188,  52.1875,  40.5000],\n",
      "          [ 36.5312,  56.1250,  61.9688,  ...,  43.4688,  43.6875,  35.2500],\n",
      "          ...,\n",
      "          [126.6250, 174.0000, 174.1250,  ..., 163.1250, 163.6250, 123.3750],\n",
      "          [129.3750, 178.3750, 178.7500,  ..., 165.0000, 162.2500, 121.3125],\n",
      "          [ 95.8125, 128.7500, 129.3750,  ..., 119.0625, 115.4375,  88.1875]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 84.9375, 142.5000, 183.8750,  ..., 188.6250, 143.7500,  89.1250],\n",
      "          [100.6875, 185.2500, 256.0000,  ..., 265.2500, 188.5000, 107.2500],\n",
      "          [115.2500, 217.1250, 304.7500,  ..., 317.7500, 222.8750, 122.9375],\n",
      "          ...,\n",
      "          [ 55.3438,  90.6875, 127.6250,  ..., 145.0000, 135.6250, 100.9375],\n",
      "          [ 46.8438,  73.7500, 108.1250,  ..., 142.8750, 127.5000,  93.1250],\n",
      "          [ 36.8438,  52.7188,  72.3125,  ..., 102.1875,  89.0625,  66.7500]],\n",
      "\n",
      "         [[ 85.1250, 142.8750, 184.3750,  ..., 189.1250, 144.1250,  89.2500],\n",
      "          [100.8750, 185.6250, 256.5000,  ..., 265.7500, 189.0000, 107.4375],\n",
      "          [115.4375, 217.5000, 305.2500,  ..., 318.0000, 223.3750, 123.1250],\n",
      "          ...,\n",
      "          [ 55.6562,  90.9375, 127.9375,  ..., 145.5000, 136.1250, 101.1250],\n",
      "          [ 47.1250,  74.0625, 108.5000,  ..., 143.3750, 127.8750,  93.3750],\n",
      "          [ 37.0625,  53.0312,  72.6250,  ..., 102.3750,  89.3125,  66.8750]],\n",
      "\n",
      "         [[ 85.5625, 143.5000, 184.8750,  ..., 189.7500, 144.6250,  89.7500],\n",
      "          [101.6875, 186.7500, 257.7500,  ..., 267.2500, 190.1250, 108.3750],\n",
      "          [116.1875, 218.6250, 306.5000,  ..., 319.5000, 224.5000, 124.0000],\n",
      "          ...,\n",
      "          [ 56.3438,  92.1250, 129.1250,  ..., 146.6250, 137.2500, 102.0000],\n",
      "          [ 47.8125,  75.2500, 109.6875,  ..., 144.5000, 129.1250,  94.2500],\n",
      "          [ 37.6250,  53.9062,  73.6250,  ..., 103.5000,  90.3750,  67.6250]]],\n",
      "\n",
      "\n",
      "        [[[ 70.3750, 111.8125, 134.8750,  ...,  25.8125,  29.4062,  30.9062],\n",
      "          [ 76.0000, 133.7500, 175.0000,  ...,  29.0156,  33.9062,  30.7031],\n",
      "          [ 83.9375, 152.2500, 204.2500,  ...,  19.8125,  25.3438,  25.5625],\n",
      "          ...,\n",
      "          [118.3125, 163.2500, 164.6250,  ..., 137.5000, 126.6875,  94.1875],\n",
      "          [118.3750, 164.6250, 168.0000,  ..., 136.1250, 118.8750,  86.6250],\n",
      "          [ 86.8750, 117.8750, 121.2500,  ...,  98.1250,  83.6875,  62.5625]],\n",
      "\n",
      "         [[ 70.5000, 112.0000, 135.2500,  ...,  25.9531,  29.5781,  31.0156],\n",
      "          [ 76.2500, 134.1250, 175.5000,  ...,  29.1875,  34.1250,  30.8750],\n",
      "          [ 84.1875, 152.6250, 204.7500,  ...,  19.9375,  25.5156,  25.7031],\n",
      "          ...,\n",
      "          [118.5625, 163.7500, 165.1250,  ..., 138.0000, 127.0000,  94.4375],\n",
      "          [118.6250, 165.0000, 168.5000,  ..., 136.6250, 119.2500,  86.8750],\n",
      "          [ 87.0000, 118.0625, 121.4375,  ...,  98.3750,  83.9375,  62.7812]],\n",
      "\n",
      "         [[ 70.9375, 112.6875, 135.8750,  ...,  26.2812,  29.9531,  31.3594],\n",
      "          [ 77.0000, 135.2500, 176.5000,  ...,  29.5625,  34.5625,  31.2812],\n",
      "          [ 84.8750, 153.6250, 205.7500,  ...,  20.1094,  25.7812,  26.0156],\n",
      "          ...,\n",
      "          [119.3750, 164.8750, 166.2500,  ..., 139.0000, 128.1250,  95.2500],\n",
      "          [119.4375, 166.1250, 169.5000,  ..., 137.6250, 120.4375,  87.6875],\n",
      "          [ 87.7500, 119.1250, 122.5000,  ...,  99.3750,  84.9375,  63.4375]]],\n",
      "\n",
      "\n",
      "        [[[ 84.9375, 142.5000, 183.8750,  ...,  87.8750,  53.1562,  38.1562],\n",
      "          [100.6250, 185.1250, 255.8750,  ...,  65.4375,  46.3438,  34.3125],\n",
      "          [115.1875, 217.0000, 304.5000,  ...,  41.5000,  32.6875,  27.0938],\n",
      "          ...,\n",
      "          [119.8125, 166.1250, 168.6250,  ..., 143.5000, 132.5000,  98.1875],\n",
      "          [120.0625, 167.5000, 171.5000,  ..., 138.8750, 121.6250,  88.5000],\n",
      "          [ 88.0000, 119.6250, 123.2500,  ...,  99.1875,  84.6250,  63.2188]],\n",
      "\n",
      "         [[ 85.0625, 142.8750, 184.2500,  ...,  88.0000,  53.3750,  38.3125],\n",
      "          [100.8750, 185.6250, 256.2500,  ...,  65.6250,  46.6250,  34.5312],\n",
      "          [115.4375, 217.5000, 305.0000,  ...,  41.7812,  32.8750,  27.2500],\n",
      "          ...,\n",
      "          [120.0625, 166.6250, 169.1250,  ..., 143.8750, 133.0000,  98.3750],\n",
      "          [120.3125, 168.0000, 172.0000,  ..., 139.3750, 122.0000,  88.7500],\n",
      "          [ 88.1875, 119.8750, 123.4375,  ...,  99.3750,  84.8750,  63.4375]],\n",
      "\n",
      "         [[ 85.5000, 143.3750, 184.8750,  ...,  88.6250,  53.9062,  38.6875],\n",
      "          [101.6875, 186.7500, 257.7500,  ...,  66.6250,  47.3438,  35.0000],\n",
      "          [116.1875, 218.6250, 306.5000,  ...,  42.4062,  33.3125,  27.5781],\n",
      "          ...,\n",
      "          [120.8750, 167.7500, 170.2500,  ..., 145.0000, 134.1250,  99.2500],\n",
      "          [121.1875, 169.1250, 173.2500,  ..., 140.5000, 123.2500,  89.6250],\n",
      "          [ 88.8750, 120.9375, 124.5625,  ..., 100.4375,  85.9375,  64.1250]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 47.0938,  58.0625,  48.7188,  ..., 179.5000, 136.3750,  83.8125],\n",
      "          [ 38.5938,  54.2188,  47.9688,  ..., 238.7500, 171.7500,  97.2500],\n",
      "          [ 34.3125,  49.2500,  43.1562,  ..., 253.6250, 185.6250, 103.3125],\n",
      "          ...,\n",
      "          [117.5000, 163.2500, 165.7500,  ..., 143.5000, 135.0000, 100.6250],\n",
      "          [116.8750, 163.5000, 168.1250,  ..., 142.0000, 127.1875,  93.0625],\n",
      "          [ 85.4375, 116.6250, 120.8750,  ..., 101.8750,  88.9375,  66.6250]],\n",
      "\n",
      "         [[ 47.2812,  58.3125,  48.9375,  ..., 180.0000, 136.7500,  84.0000],\n",
      "          [ 38.8125,  54.5938,  48.3125,  ..., 239.2500, 172.2500,  97.5000],\n",
      "          [ 34.5312,  49.5938,  43.5000,  ..., 254.1250, 186.1250, 103.5000],\n",
      "          ...,\n",
      "          [117.8125, 163.7500, 166.2500,  ..., 144.0000, 135.5000, 100.8750],\n",
      "          [117.1250, 164.0000, 168.6250,  ..., 142.5000, 127.5625,  93.3125],\n",
      "          [ 85.5625, 116.8125, 121.1250,  ..., 102.0625,  89.1875,  66.7500]],\n",
      "\n",
      "         [[ 47.5625,  58.7812,  49.3750,  ..., 180.6250, 137.3750,  84.4375],\n",
      "          [ 39.3438,  55.4062,  49.0000,  ..., 240.3750, 173.3750,  98.2500],\n",
      "          [ 34.9688,  50.3125,  44.0625,  ..., 255.2500, 187.1250, 104.2500],\n",
      "          ...,\n",
      "          [118.6250, 164.8750, 167.3750,  ..., 145.0000, 136.5000, 101.6250],\n",
      "          [117.9375, 165.1250, 169.7500,  ..., 143.5000, 128.7500,  94.0625],\n",
      "          [ 86.2500, 117.8750, 122.1875,  ..., 103.0625,  90.1875,  67.4375]]],\n",
      "\n",
      "\n",
      "        [[[ 25.8906,  28.0625,  22.9375,  ...,  17.3281,  22.9219,  21.4688],\n",
      "          [ 24.6250,  32.9688,  25.2188,  ...,  18.0000,  25.3906,  24.9375],\n",
      "          [ 20.2656,  26.1406,  17.4688,  ...,  10.6016,  17.5938,  19.8594],\n",
      "          ...,\n",
      "          [116.3750, 161.3750, 163.5000,  ..., 141.7500, 132.7500,  98.8750],\n",
      "          [115.7500, 161.8750, 166.5000,  ..., 140.2500, 124.9375,  91.3125],\n",
      "          [ 84.7500, 115.6875, 120.0625,  ..., 100.8125,  87.5000,  65.4375]],\n",
      "\n",
      "         [[ 25.9531,  28.2188,  23.0781,  ...,  17.4219,  23.0625,  21.5781],\n",
      "          [ 24.7812,  33.1875,  25.3906,  ...,  18.1250,  25.5625,  25.0938],\n",
      "          [ 20.3906,  26.2969,  17.5938,  ...,  10.6797,  17.7188,  19.9844],\n",
      "          ...,\n",
      "          [116.6250, 161.7500, 164.0000,  ..., 142.1250, 133.1250,  99.1250],\n",
      "          [116.0625, 162.3750, 166.8750,  ..., 140.7500, 125.3125,  91.5625],\n",
      "          [ 84.9375, 115.8750, 120.2500,  ..., 101.0000,  87.7500,  65.6250]],\n",
      "\n",
      "         [[ 26.2344,  28.5469,  23.2969,  ...,  17.5312,  23.2812,  21.7812],\n",
      "          [ 25.0625,  33.5625,  25.6250,  ...,  18.2188,  25.7969,  25.3438],\n",
      "          [ 20.5938,  26.5781,  17.6875,  ...,  10.6406,  17.8125,  20.1406],\n",
      "          ...,\n",
      "          [117.3750, 162.8750, 165.0000,  ..., 143.1250, 134.2500,  99.8750],\n",
      "          [116.8125, 163.3750, 168.0000,  ..., 141.7500, 126.4375,  92.3125],\n",
      "          [ 85.5625, 116.8750, 121.2500,  ..., 102.0000,  88.6875,  66.2500]]],\n",
      "\n",
      "\n",
      "        [[[ 19.1562,  29.0312,  47.5625,  ..., 183.0000, 136.5000,  83.3750],\n",
      "          [ 20.1875,  35.9375,  49.4375,  ..., 257.0000, 177.5000,  98.6875],\n",
      "          [ 16.8438,  34.0312,  53.4688,  ..., 308.7500, 211.2500, 113.7500],\n",
      "          ...,\n",
      "          [109.4375, 152.6250, 157.6250,  ..., 144.7500, 134.3750,  99.6875],\n",
      "          [105.6875, 149.5000, 158.8750,  ..., 142.2500, 125.8125,  91.5625],\n",
      "          [ 76.7500, 105.8750, 114.1875,  ..., 101.5000,  87.6250,  65.3125]],\n",
      "\n",
      "         [[ 19.2188,  29.2031,  47.8125,  ..., 183.3750, 136.8750,  83.5000],\n",
      "          [ 20.3125,  36.1875,  49.8125,  ..., 257.2500, 178.0000,  98.8750],\n",
      "          [ 16.9531,  34.2812,  53.8750,  ..., 309.2500, 211.7500, 114.0000],\n",
      "          ...,\n",
      "          [109.6875, 153.1250, 158.1250,  ..., 145.2500, 134.8750,  99.9375],\n",
      "          [105.9375, 150.0000, 159.3750,  ..., 142.7500, 126.2500,  91.8125],\n",
      "          [ 76.8750, 106.0625, 114.3750,  ..., 101.7500,  87.8750,  65.5000]],\n",
      "\n",
      "         [[ 19.4219,  29.5469,  48.2188,  ..., 184.0000, 137.3750,  84.0000],\n",
      "          [ 20.5000,  36.6250,  50.5000,  ..., 258.7500, 179.1250,  99.6875],\n",
      "          [ 17.0938,  34.6875,  54.6250,  ..., 310.7500, 212.7500, 114.7500],\n",
      "          ...,\n",
      "          [110.4375, 154.1250, 159.1250,  ..., 146.3750, 136.0000, 100.7500],\n",
      "          [106.7500, 151.0000, 160.3750,  ..., 143.8750, 127.4375,  92.6250],\n",
      "          [ 77.5625, 107.0625, 115.3750,  ..., 102.8125,  88.8750,  66.1875]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 20.3594,  25.0938,  23.8906,  ..., 185.8750, 140.8750,  87.1250],\n",
      "          [ 19.4062,  27.4375,  25.5938,  ..., 257.0000, 180.6250, 102.1875],\n",
      "          [ 13.7969,  18.5781,  16.1250,  ..., 303.7500, 210.6250, 115.2500],\n",
      "          ...,\n",
      "          [115.5000, 160.5000, 164.2500,  ..., 133.1250, 116.9375,  86.0625],\n",
      "          [113.5625, 159.3750, 165.8750,  ..., 130.2500, 108.5000,  78.3750],\n",
      "          [ 83.1875, 113.7500, 119.6250,  ...,  93.9375,  76.8125,  57.2812]],\n",
      "\n",
      "         [[ 20.4219,  25.2500,  24.0469,  ..., 186.3750, 141.2500,  87.3125],\n",
      "          [ 19.5312,  27.6250,  25.7812,  ..., 257.2500, 181.2500, 102.5000],\n",
      "          [ 13.8906,  18.7031,  16.2500,  ..., 304.2500, 211.1250, 115.5625],\n",
      "          ...,\n",
      "          [115.8750, 161.0000, 164.6250,  ..., 133.6250, 117.4375,  86.3750],\n",
      "          [113.9375, 159.8750, 166.3750,  ..., 130.7500, 109.0000,  78.7500],\n",
      "          [ 83.3750, 114.0000, 119.9375,  ...,  94.2500,  77.1250,  57.4688]],\n",
      "\n",
      "         [[ 20.6250,  25.4688,  24.2500,  ..., 187.0000, 141.8750,  87.6875],\n",
      "          [ 19.6875,  27.8750,  26.0000,  ..., 258.7500, 182.2500, 103.1875],\n",
      "          [ 13.9375,  18.7969,  16.2969,  ..., 305.7500, 212.2500, 116.2500],\n",
      "          ...,\n",
      "          [116.5000, 162.0000, 165.7500,  ..., 134.6250, 118.4375,  87.0625],\n",
      "          [114.6250, 160.8750, 167.3750,  ..., 131.7500, 110.0000,  79.3750],\n",
      "          [ 83.9375, 114.9375, 120.8125,  ...,  95.0625,  77.9375,  58.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 89.1250, 149.8750, 193.2500,  ..., 186.7500, 141.3750,  87.4375],\n",
      "          [106.5625, 195.6250, 269.0000,  ..., 258.7500, 182.0000, 103.0000],\n",
      "          [121.5000, 228.2500, 318.5000,  ..., 306.7500, 212.8750, 116.6875],\n",
      "          ...,\n",
      "          [116.1875, 161.6250, 165.2500,  ..., 125.5625, 106.3125,  78.0000],\n",
      "          [114.3125, 160.3750, 166.7500,  ..., 122.6875,  98.6250,  71.1250],\n",
      "          [ 83.6250, 114.4375, 120.1250,  ...,  88.8750,  70.5000,  52.7812]],\n",
      "\n",
      "         [[ 89.3750, 150.3750, 193.7500,  ..., 187.2500, 141.7500,  87.6250],\n",
      "          [106.8750, 196.1250, 269.5000,  ..., 259.2500, 182.5000, 103.3125],\n",
      "          [121.8750, 228.7500, 319.0000,  ..., 307.2500, 213.5000, 117.0000],\n",
      "          ...,\n",
      "          [116.5000, 162.0000, 165.7500,  ..., 125.9375, 106.7500,  78.3125],\n",
      "          [114.6250, 160.8750, 167.2500,  ..., 123.1875,  99.1250,  71.4375],\n",
      "          [ 83.8750, 114.6875, 120.4375,  ...,  89.1875,  70.8750,  53.0000]],\n",
      "\n",
      "         [[ 89.7500, 150.8750, 194.5000,  ..., 187.8750, 142.3750,  88.0000],\n",
      "          [107.5625, 197.2500, 271.0000,  ..., 260.7500, 183.5000, 104.0000],\n",
      "          [122.5000, 229.8750, 320.5000,  ..., 308.7500, 214.5000, 117.6875],\n",
      "          ...,\n",
      "          [117.1875, 163.1250, 166.8750,  ..., 126.9375, 107.6875,  78.9375],\n",
      "          [115.3125, 161.8750, 168.2500,  ..., 124.1250, 100.0625,  72.0625],\n",
      "          [ 84.4375, 115.6250, 121.3125,  ...,  90.0000,  71.6250,  53.5312]]],\n",
      "\n",
      "\n",
      "        [[[ 87.8750, 147.1250, 183.5000,  ..., 193.7500, 146.5000,  90.1250],\n",
      "          [104.1250, 190.3750, 252.7500,  ..., 271.5000, 191.6250, 108.1250],\n",
      "          [118.0625, 221.2500, 298.5000,  ..., 323.7500, 225.7500, 123.6250],\n",
      "          ...,\n",
      "          [116.8125, 162.6250, 166.5000,  ..., 131.3750, 115.1250,  84.8125],\n",
      "          [114.7500, 161.1250, 167.6250,  ..., 129.0000, 107.3125,  77.5625],\n",
      "          [ 83.8750, 114.7500, 120.5625,  ...,  93.4375,  76.2500,  56.8750]],\n",
      "\n",
      "         [[ 88.1250, 147.6250, 184.0000,  ..., 194.2500, 147.0000,  90.3750],\n",
      "          [104.4375, 191.0000, 253.2500,  ..., 272.0000, 192.1250, 108.4375],\n",
      "          [118.3750, 221.7500, 299.0000,  ..., 324.2500, 226.2500, 123.9375],\n",
      "          ...,\n",
      "          [117.1875, 163.1250, 167.0000,  ..., 131.8750, 115.5625,  85.1250],\n",
      "          [115.1250, 161.6250, 168.1250,  ..., 129.6250, 107.8125,  77.8750],\n",
      "          [ 84.0625, 115.0625, 120.8125,  ...,  93.7500,  76.6250,  57.0938]],\n",
      "\n",
      "         [[ 88.5000, 148.1250, 184.6250,  ..., 194.8750, 147.5000,  90.7500],\n",
      "          [105.1250, 192.0000, 254.5000,  ..., 273.5000, 193.2500, 109.1250],\n",
      "          [119.0625, 222.8750, 300.5000,  ..., 325.7500, 227.3750, 124.6250],\n",
      "          ...,\n",
      "          [117.8750, 164.2500, 168.1250,  ..., 132.7500, 116.5625,  85.7500],\n",
      "          [115.8125, 162.7500, 169.2500,  ..., 130.5000, 108.7500,  78.5000],\n",
      "          [ 84.6875, 116.0000, 121.7500,  ...,  94.5625,  77.3750,  57.6250]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[ 58.1875, 105.0000, 144.2500,  ...,  18.0000,  19.5938,  17.9062],\n",
      "          [ 60.7500, 128.3750, 197.0000,  ...,  19.7500,  21.1562,  20.8438],\n",
      "          [ 70.8750, 154.3750, 240.6250,  ...,  12.2109,  12.3594,  15.4766],\n",
      "          ...,\n",
      "          [110.9375, 157.3750, 161.2500,  ..., 130.1250, 117.2500,  85.2500],\n",
      "          [110.0625, 157.2500, 163.3750,  ..., 128.8750, 109.6875,  77.8750],\n",
      "          [ 78.9375, 110.5625, 115.9375,  ...,  91.4375,  75.5000,  54.5625]],\n",
      "\n",
      "         [[ 58.3750, 105.3125, 144.7500,  ...,  18.1250,  19.7344,  18.0156],\n",
      "          [ 61.0312, 128.8750, 197.7500,  ...,  19.8906,  21.3125,  21.0000],\n",
      "          [ 71.2500, 155.0000, 241.2500,  ...,  12.2969,  12.4531,  15.5859],\n",
      "          ...,\n",
      "          [111.3125, 157.8750, 161.7500,  ..., 130.6250, 117.6875,  85.5625],\n",
      "          [110.4375, 157.7500, 163.8750,  ..., 129.3750, 110.1875,  78.1875],\n",
      "          [ 79.1250, 110.8750, 116.2500,  ...,  91.7500,  75.8750,  54.7812]],\n",
      "\n",
      "         [[ 58.6562, 105.8125, 145.2500,  ...,  18.2031,  19.8281,  18.1094],\n",
      "          [ 61.5938, 129.7500, 198.7500,  ...,  19.9844,  21.4219,  21.1094],\n",
      "          [ 71.7500, 155.8750, 242.3750,  ...,  12.2734,  12.4219,  15.6172],\n",
      "          ...,\n",
      "          [111.9375, 158.8750, 162.7500,  ..., 131.5000, 118.5625,  86.1875],\n",
      "          [111.0625, 158.7500, 164.8750,  ..., 130.2500, 111.0625,  78.8125],\n",
      "          [ 79.6875, 111.7500, 117.1250,  ...,  92.5000,  76.5625,  55.2812]]],\n",
      "\n",
      "\n",
      "        [[[ 65.1875, 117.9375, 160.3750,  ..., 119.1250,  76.6875,  44.6250],\n",
      "          [ 71.8750, 148.3750, 221.6250,  ..., 145.6250,  73.8750,  40.4375],\n",
      "          [ 83.7500, 177.2500, 268.2500,  ..., 156.6250,  72.2500,  36.9375],\n",
      "          ...,\n",
      "          [110.7500, 157.0000, 160.8750,  ..., 129.6250, 116.5625,  84.8125],\n",
      "          [109.8125, 156.8750, 163.1250,  ..., 128.3750, 109.1250,  77.4375],\n",
      "          [ 78.7500, 110.3125, 115.8125,  ...,  91.2500,  75.1875,  54.3438]],\n",
      "\n",
      "         [[ 65.4375, 118.3125, 160.8750,  ..., 119.4375,  77.0000,  44.7812],\n",
      "          [ 72.1875, 149.0000, 222.2500,  ..., 146.2500,  74.3125,  40.7188],\n",
      "          [ 84.1250, 177.8750, 268.7500,  ..., 157.2500,  72.6875,  37.1875],\n",
      "          ...,\n",
      "          [111.0625, 157.5000, 161.5000,  ..., 130.1250, 117.0000,  85.1250],\n",
      "          [110.1250, 157.3750, 163.6250,  ..., 128.8750, 109.6250,  77.8125],\n",
      "          [ 78.9375, 110.6250, 116.1250,  ...,  91.5625,  75.5625,  54.5312]],\n",
      "\n",
      "         [[ 65.6875, 118.8750, 161.3750,  ..., 120.0000,  77.4375,  45.0938],\n",
      "          [ 72.7500, 149.8750, 223.3750,  ..., 147.1250,  75.1250,  41.1562],\n",
      "          [ 84.6250, 178.7500, 270.2500,  ..., 158.0000,  73.3750,  37.5625],\n",
      "          ...,\n",
      "          [111.6875, 158.5000, 162.3750,  ..., 130.8750, 117.9375,  85.6875],\n",
      "          [110.7500, 158.3750, 164.6250,  ..., 129.7500, 110.5000,  78.3750],\n",
      "          [ 79.5000, 111.5000, 117.0000,  ...,  92.3125,  76.3125,  55.0312]]],\n",
      "\n",
      "\n",
      "        [[[ 13.9219,  26.4375,  56.0938,  ..., 165.2500, 118.3750,  69.0000],\n",
      "          [ 14.6562,  31.4688,  51.7812,  ..., 232.0000, 150.8750,  78.0625],\n",
      "          [  8.6250,  23.9688,  49.1250,  ..., 283.5000, 183.0000,  91.4375],\n",
      "          ...,\n",
      "          [110.5625, 156.7500, 160.6250,  ..., 130.2500, 117.3750,  85.3750],\n",
      "          [109.6875, 156.7500, 162.8750,  ..., 129.0000, 109.8750,  78.0000],\n",
      "          [ 78.7500, 110.2500, 115.7500,  ...,  91.5000,  75.6250,  54.6562]],\n",
      "\n",
      "         [[ 13.9922,  26.6406,  56.3750,  ..., 165.7500, 118.6875,  69.2500],\n",
      "          [ 14.7500,  31.7188,  52.1875,  ..., 232.7500, 151.5000,  78.4375],\n",
      "          [  8.6719,  24.1719,  49.5000,  ..., 284.2500, 183.6250,  91.8125],\n",
      "          ...,\n",
      "          [110.9375, 157.2500, 161.1250,  ..., 130.7500, 117.8125,  85.6875],\n",
      "          [110.0625, 157.2500, 163.3750,  ..., 129.5000, 110.3750,  78.3125],\n",
      "          [ 78.9375, 110.5625, 116.0625,  ...,  91.8125,  76.0000,  54.8438]],\n",
      "\n",
      "         [[ 14.0469,  26.8438,  56.7500,  ..., 166.2500, 119.2500,  69.5625],\n",
      "          [ 14.7969,  31.9844,  52.8125,  ..., 233.7500, 152.5000,  79.0000],\n",
      "          [  8.6250,  24.3438,  50.0938,  ..., 285.5000, 184.5000,  92.3750],\n",
      "          ...,\n",
      "          [111.5625, 158.1250, 162.1250,  ..., 131.6250, 118.7500,  86.2500],\n",
      "          [110.6875, 158.1250, 164.3750,  ..., 130.3750, 111.2500,  78.9375],\n",
      "          [ 79.5000, 111.4375, 116.8750,  ...,  92.6250,  76.7500,  55.3750]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n",
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]],\n",
      "\n",
      "\n",
      "        [[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          ...,\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan],\n",
      "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "torch.Size([3, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(params, lr=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(data_loader, model, optimizer, loss_fn, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891da18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
